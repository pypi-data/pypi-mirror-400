"""
Pipeline Builder - å°† Studio å¯è§†åŒ–æ¨¡å‹è½¬æ¢ä¸º SAGE Pipeline

èŒè´£ï¼š
1. è§£æ VisualPipeline çš„èŠ‚ç‚¹å’Œè¿æ¥
2. æ‹“æ‰‘æ’åºèŠ‚ç‚¹ä»¥ç¡®å®šæ‰§è¡Œé¡ºåº
3. å°†æ¯ä¸ªèŠ‚ç‚¹æ˜ å°„åˆ°å¯¹åº”çš„ SAGE Operator
4. ä½¿ç”¨ SAGE DataStream API æ„å»º Pipeline
5. è¿”å›å¯æ‰§è¡Œçš„ Environment

ä¸è´Ÿè´£ï¼š
- æ‰§è¡Œ Pipelineï¼ˆç”± SAGE Engine å®Œæˆï¼‰
- UI äº¤äº’é€»è¾‘
- çŠ¶æ€ç®¡ç†ï¼ˆç”± SAGE Engine å®Œæˆï¼‰
"""

from collections import defaultdict, deque

# ä» SAGE å…¬å…± API å¯¼å…¥ï¼ˆå‚è€ƒ PACKAGE_ARCHITECTURE.mdï¼‰
from sage.kernel.api import LocalEnvironment
from sage.kernel.api.base_environment import BaseEnvironment
from sage.libs.foundation.io.sink import (
    FileSink,
    MemWriteSink,
    RetriveSink,
    TerminalSink,
)
from sage.libs.foundation.io.source import (
    APISource,
    CSVFileSource,
    DatabaseSource,
    FileSource,
    JSONFileSource,
    KafkaSource,
    SocketSource,
    TextFileSource,
)

from ..models import VisualNode, VisualPipeline
from .node_registry import get_node_registry


class PipelineBuilder:
    """
    å°† Studio çš„å¯è§†åŒ– Pipeline è½¬æ¢ä¸º SAGE å¯æ‰§è¡Œ Pipeline

    Usage:
        builder = PipelineBuilder()
        env = builder.build(visual_pipeline)
        job = env.execute()
    """

    def __init__(self):
        # ä½¿ç”¨å…¨å±€èŠ‚ç‚¹æ³¨å†Œè¡¨
        self.registry = get_node_registry()
        self._user_input = None  # Playground/Chat æ¨¡å¼çš„ç”¨æˆ·è¾“å…¥
        self._env_config = {}  # ç¼“å­˜ç¯å¢ƒé…ç½®

    def build(self, pipeline: VisualPipeline, user_input: str = None) -> BaseEnvironment:
        """
        ä» VisualPipeline æ„å»º SAGE Pipeline

        Args:
            pipeline: Studio çš„å¯è§†åŒ– Pipeline æ¨¡å‹
            user_input: Playground/Chat æ¨¡å¼çš„ç”¨æˆ·è¾“å…¥ (å¯é€‰)

        Returns:
            é…ç½®å¥½çš„ SAGE æ‰§è¡Œç¯å¢ƒ

        Raises:
            ValueError: å¦‚æœ Pipeline ç»“æ„æ— æ•ˆ
        """
        # ğŸ†• åŠ è½½ç¯å¢ƒå˜é‡
        self._load_environment_variables()

        # ğŸ†• ä¿å­˜ç”¨æˆ·è¾“å…¥
        self._user_input = user_input

        # 1. éªŒè¯ Pipeline
        self._validate_pipeline(pipeline)

        # 2. æ‹“æ‰‘æ’åºèŠ‚ç‚¹
        sorted_nodes = self._topological_sort(pipeline)

        # 3. åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        env = LocalEnvironment()

        # 4. æ„å»º DataStream Pipeline
        stream = None
        node_outputs = {}  # è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„è¾“å‡º stream

        for node in sorted_nodes:
            operator_class = self._get_operator_class(node.type)

            if stream is None:
                # ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ - åˆ›å»º source
                source_class, source_args, source_kwargs = self._create_source(node, pipeline)
                stream = env.from_source(
                    source_class, *source_args, name=node.label, **source_kwargs
                )
            else:
                # ğŸ†• å¢å¼ºé…ç½®
                enhanced_config = self._enhance_operator_config(operator_class, node.config)

                # åç»­èŠ‚ç‚¹ - æ·»åŠ  transformation
                stream = stream.map(operator_class, config=enhanced_config, name=node.label)

            node_outputs[node.id] = stream

        # 5. æ·»åŠ  sink
        if stream:
            stream.sink(self._create_sink(pipeline))

        return env

    def _validate_pipeline(self, pipeline: VisualPipeline):
        """éªŒè¯ Pipeline ç»“æ„çš„æœ‰æ•ˆæ€§"""
        if not pipeline.nodes:
            raise ValueError("Pipeline must contain at least one node")

        # æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹ç±»å‹æ˜¯å¦å·²æ³¨å†Œ
        for node in pipeline.nodes:
            # Source å’Œ Sink èŠ‚ç‚¹åœ¨ Registry ä¸­æœ‰æ³¨å†Œï¼Œä½†ç±»å‹ä¸åŒäº MapOperator
            # å®ƒä»¬ä¼šåœ¨ build() ä¸­è¢«ç‰¹æ®Šå¤„ç†ï¼Œæ‰€ä»¥è¿™é‡Œåªæ£€æŸ¥æ˜¯å¦å­˜åœ¨
            if self.registry.get_operator(node.type) is None:
                # æä¾›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯
                available_types = self.registry.list_types()
                error_msg = (
                    f"Unknown node type: '{node.type}'. \n"
                    f"Available types ({len(available_types)}): {available_types[:10]}... \n"
                    f"Hint: Node type should be in snake_case (e.g., 'terminal_sink', not 'TerminalSink')"
                )
                raise ValueError(error_msg)

        # æ£€æŸ¥è¿æ¥æ˜¯å¦æœ‰æ•ˆ
        node_ids = {node.id for node in pipeline.nodes}
        for conn in pipeline.connections:
            if conn.source_node_id not in node_ids:
                raise ValueError(f"Connection source not found: {conn.source_node_id}")
            if conn.target_node_id not in node_ids:
                raise ValueError(f"Connection target not found: {conn.target_node_id}")

    def _topological_sort(self, pipeline: VisualPipeline) -> list[VisualNode]:
        """
        å¯¹èŠ‚ç‚¹è¿›è¡Œæ‹“æ‰‘æ’åº

        Returns:
            æ’åºåçš„èŠ‚ç‚¹åˆ—è¡¨

        Raises:
            ValueError: å¦‚æœå­˜åœ¨å¾ªç¯ä¾èµ–
        """
        # æ„å»ºä¾èµ–å›¾
        in_degree = defaultdict(int)
        adjacency = defaultdict(list)
        node_map = {node.id: node for node in pipeline.nodes}

        # åˆå§‹åŒ–å…¥åº¦
        for node in pipeline.nodes:
            in_degree[node.id] = 0

        # æ„å»ºå›¾
        for conn in pipeline.connections:
            adjacency[conn.source_node_id].append(conn.target_node_id)
            in_degree[conn.target_node_id] += 1

        # Kahn ç®—æ³•
        queue = deque([node_id for node_id in in_degree if in_degree[node_id] == 0])
        sorted_nodes = []

        while queue:
            node_id = queue.popleft()
            sorted_nodes.append(node_map[node_id])

            for neighbor in adjacency[node_id]:
                in_degree[neighbor] -= 1
                if in_degree[neighbor] == 0:
                    queue.append(neighbor)

        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å¾ªç¯
        if len(sorted_nodes) != len(pipeline.nodes):
            remaining = [n.label for n in pipeline.nodes if n not in sorted_nodes]
            raise ValueError(
                f"Circular dependency detected in pipeline. Nodes in cycle: {remaining}"
            )

        return sorted_nodes

    def _load_environment_variables(self) -> None:
        """
        ä» ~/.sage/.env.json åŠ è½½ç¯å¢ƒå˜é‡

        æ”¯æŒçš„å˜é‡:
        - OPENAI_API_KEY: OpenAI API
        - å…¶ä»–è‡ªå®šä¹‰ç¯å¢ƒå˜é‡
        """
        import json
        import os
        from pathlib import Path

        env_file = Path.home() / ".sage" / ".env.json"
        if env_file.exists():
            try:
                with open(env_file) as f:
                    env_vars = json.load(f)
                    self._env_config = env_vars  # ç¼“å­˜é…ç½®
                    for key, value in env_vars.items():
                        os.environ[key] = value
                print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡: {', '.join(env_vars.keys())}")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½ç¯å¢ƒå˜é‡å¤±è´¥: {e}")
        else:
            print(f"â„¹ï¸ ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {env_file}")

    def _load_env_from_config(self) -> dict:
        """ä»ç¼“å­˜çš„é…ç½®ä¸­è¯»å–ç¯å¢ƒå˜é‡"""
        return self._env_config

    def _probe_url(self, url: str, timeout: float = 2.0) -> bool:
        """æ¢æµ‹ç«¯ç‚¹æ˜¯å¦å¯ç”¨

        Args:
            url: è¦æ¢æµ‹çš„ç«¯ç‚¹ URL
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        Returns:
            bool: ç«¯ç‚¹æ˜¯å¦å¯ç”¨
        """
        try:
            import requests

            response = requests.get(f"{url.rstrip('/')}/models", timeout=timeout)
            return response.status_code == 200
        except Exception:
            return False

    def _enhance_operator_config(self, operator_class, config: dict) -> dict:
        """
        å¢å¼º operator é…ç½®

        åŠŸèƒ½:
        1. OpenAIGenerator: æ™ºèƒ½ Qwen/GPT API key é€‰æ‹©
        2. ChromaRetriever: é»˜è®¤ ChromaDB è·¯å¾„å’Œå‚æ•°
        3. å…¶ä»–: ä¿æŒåŸé…ç½®
        """
        import os
        from pathlib import Path

        enhanced = config.copy()
        operator_name = operator_class.__name__

        # OpenAIGenerator: æ™ºèƒ½ API key é…ç½®
        if operator_name == "OpenAIGenerator":
            model = config.get("model", config.get("model_name", ""))

            # ç¡®ä¿ model_name å­—æ®µå­˜åœ¨
            if "model_name" not in enhanced and model:
                enhanced["model_name"] = model

            # ç¡®ä¿æ€»æ˜¯æœ‰ api_key å­—æ®µï¼ˆå³ä½¿ä¸º Noneï¼‰
            if "api_key" not in enhanced:
                api_key = (
                    os.environ.get("SAGE_PIPELINE_BUILDER_API_KEY")
                    or os.environ.get("SAGE_CHAT_API_KEY")
                    or os.environ.get("OPENAI_API_KEY")
                    or self._load_env_from_config().get("SAGE_PIPELINE_BUILDER_API_KEY")
                    or self._load_env_from_config().get("SAGE_CHAT_API_KEY")
                )
                enhanced["api_key"] = api_key

            # ç¡®ä¿ base_url å­—æ®µå­˜åœ¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰ï¼Œæœ¬åœ°ä¼˜å…ˆ
            if "base_url" not in enhanced:
                from sage.common.config.ports import SagePorts

                # ä¼˜å…ˆæ¢æµ‹æœ¬åœ° LLM ç«¯ç‚¹ï¼ˆ8001 â†’ 8901ï¼‰
                detected = None
                for port in [
                    SagePorts.get_recommended_llm_port(),
                    SagePorts.LLM_DEFAULT,
                    SagePorts.BENCHMARK_LLM,
                ]:
                    candidate = f"http://127.0.0.1:{port}/v1"
                    if self._probe_url(candidate):
                        detected = candidate
                        break

                if detected:
                    enhanced["base_url"] = detected
                    print(f"  âœ“ å‘ç°æœ¬åœ° LLM ç«¯ç‚¹: {detected}")
                else:
                    # å›è½åˆ°æ˜¾å¼é…ç½®çš„ OPENAI_BASE_URLï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦åˆ™ç•™ç©ºç”±ä¸Šæ¸¸å¤„ç†
                    env_base = os.environ.get("OPENAI_BASE_URL")
                    if env_base:
                        enhanced["base_url"] = env_base
                        print(f"  âœ“ ä½¿ç”¨æ˜¾å¼ OPENAI_BASE_URL: {env_base}")

        # ChromaRetriever: é»˜è®¤ ChromaDB é…ç½®
        elif operator_name == "ChromaRetriever":
            if "persist_directory" not in enhanced:
                chroma_path = Path.home() / ".sage" / "vector_db"
                enhanced["persist_directory"] = str(chroma_path)

            if "collection_name" not in enhanced:
                enhanced["collection_name"] = "sage_docs"

            if "top_k" not in enhanced:
                enhanced["top_k"] = 5

            print(f"  âœ“ ChromaRetriever: {enhanced['collection_name']} (top_k={enhanced['top_k']})")

        return enhanced

    def _get_operator_class(self, node_type: str):
        """è·å–èŠ‚ç‚¹ç±»å‹å¯¹åº”çš„ Operator ç±»"""
        operator_class = self.registry.get_operator(node_type)
        if not operator_class:
            raise ValueError(
                f"Unknown node type: {node_type}. Available types: {self.registry.list_types()}"
            )
        return operator_class

    def _create_source(self, node: VisualNode, pipeline: VisualPipeline):
        """
        æ ¹æ®èŠ‚ç‚¹ç±»å‹å’Œé…ç½®åˆ›å»ºåˆé€‚çš„æ•°æ®æº

        Returns:
            tuple: (source_class, args, kwargs)

        æ”¯æŒçš„æºç±»å‹ï¼š
        - file: FileSource (æ–‡ä»¶è·¯å¾„)
        - json_file: JSONFileSource (JSON æ–‡ä»¶)
        - csv_file: CSVFileSource (CSV æ–‡ä»¶)
        - text_file: TextFileSource (æ–‡æœ¬æ–‡ä»¶)
        - socket: SocketSource (ç½‘ç»œ socket)
        - kafka: KafkaSource (Kafka topic)
        - database: DatabaseSource (æ•°æ®åº“æŸ¥è¯¢)
        - api: APISource (HTTP API)
        - memory/data: å†…å­˜æ•°æ®æºï¼ˆç”¨äºæµ‹è¯•ï¼‰
        """
        from sage.common.core import SourceFunction

        source_type = node.config.get("source_type", "memory")

        # æ–‡ä»¶æº
        if source_type == "file":
            file_path = node.config.get("file_path", node.config.get("path"))
            return FileSource, (file_path,), {}

        elif source_type == "json_file":
            file_path = node.config.get("file_path", node.config.get("path"))
            return JSONFileSource, (file_path,), {}

        elif source_type == "csv_file":
            file_path = node.config.get("file_path", node.config.get("path"))
            delimiter = node.config.get("delimiter", ",")
            return CSVFileSource, (file_path, delimiter), {}

        elif source_type == "text_file":
            file_path = node.config.get("file_path", node.config.get("path"))
            return TextFileSource, (file_path,), {}

        # ç½‘ç»œæº
        elif source_type == "socket":
            host = node.config.get("host", "localhost")
            port = node.config.get("port", 9999)
            return SocketSource, (host, port), {}

        elif source_type == "kafka":
            topic = node.config.get("topic")
            bootstrap_servers = node.config.get("bootstrap_servers", "localhost:9092")
            return KafkaSource, (topic, bootstrap_servers), {}

        # æ•°æ®åº“æº
        elif source_type == "database":
            query = node.config.get("query")
            connection_string = node.config.get("connection_string")
            return DatabaseSource, (query, connection_string), {}

        # API æº
        elif source_type == "api":
            url = node.config.get("url")
            method = node.config.get("method", "GET")
            return APISource, (url, method), {}

        # å†…å­˜æ•°æ®æºï¼ˆé»˜è®¤ï¼Œç”¨äºæµ‹è¯•ï¼‰
        else:

            class SimpleListSource(SourceFunction):
                """Simple in-memory list source for testing and development"""

                def __init__(self, data):
                    super().__init__()
                    self.data = data if isinstance(data, list) else [data]

                def execute(self, data=None):
                    """Execute the source function"""
                    return self.data

            # ğŸ†• ä¼˜å…ˆä½¿ç”¨å¤–éƒ¨è¾“å…¥
            if hasattr(self, "_user_input") and self._user_input:
                initial_data = [{"input": self._user_input}]
                print(f"  âœ“ ä½¿ç”¨è¾“å…¥: {self._user_input[:50]}...")
            else:
                initial_data = node.config.get("data", [{"input": "test data"}])
            return SimpleListSource, (initial_data,), {}

    def _create_sink(self, pipeline: VisualPipeline):
        """
        æ ¹æ® Pipeline é…ç½®åˆ›å»ºåˆé€‚çš„æ•°æ®æ¥æ”¶å™¨

        Returns:
            Type: Sink class (not instance)

        æ”¯æŒçš„æ¥æ”¶å™¨ç±»å‹ï¼š
        - terminal: TerminalSink (ç»ˆç«¯è¾“å‡ºï¼Œå¸¦é¢œè‰²)
        - print: PrintSink (ç®€å•æ‰“å°)
        - file: FileSink (æ–‡ä»¶è¾“å‡º)
        - memory: MemWriteSink (å†…å­˜å†™å…¥ï¼Œç”¨äºæµ‹è¯•)
        - retrieve: RetriveSink (æ”¶é›†ç»“æœ)
        """

        # ä» pipeline çš„ execution_mode æˆ–å…¶ä»–é…ç½®ä¸­è·å– sink ç±»å‹
        # ğŸ†• Playground/Chat æ¨¡å¼é»˜è®¤ä½¿ç”¨ retrieve æ”¶é›†ç»“æœ
        sink_type = getattr(pipeline, "sink_type", "retrieve")

        if sink_type == "terminal":
            return TerminalSink
        elif sink_type == "file":
            return FileSink
        elif sink_type == "memory":
            return MemWriteSink
        elif sink_type == "retrieve":
            return RetriveSink
        else:
            # é»˜è®¤ä½¿ç”¨ RetriveSink (Playground/Chat æ¨¡å¼)
            return RetriveSink


# å…¨å±€ Builder å®ä¾‹
_default_builder = None


def get_pipeline_builder() -> PipelineBuilder:
    """è·å–å…¨å±€ PipelineBuilder å®ä¾‹"""
    global _default_builder
    if _default_builder is None:
        _default_builder = PipelineBuilder()
    return _default_builder
