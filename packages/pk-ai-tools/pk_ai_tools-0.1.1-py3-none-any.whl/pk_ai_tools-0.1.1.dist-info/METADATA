Metadata-Version: 2.4
Name: pk-ai-tools
Version: 0.1.1
Summary: Simple RAG pipeline + document ingestion utilities (LangChain + Chroma + Ollama).
Project-URL: Homepage, https://github.com/paulkv905/pk-ai-tools
Project-URL: Issues, https://github.com/paulkv905/pk-ai-tools/issues
Author: Paul Kviding
License: MIT
License-File: LICENSE
Keywords: chroma,embeddings,langchain,ollama,rag,retrieval
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Requires-Python: <3.14,>=3.10
Requires-Dist: chromadb<2,>=1.4
Requires-Dist: langchain-chroma<2,>=1.1
Requires-Dist: langchain-community<1,>=0.4
Requires-Dist: langchain-core<2,>=1.2
Requires-Dist: langchain-ollama<2,>=1.0
Requires-Dist: langchain<2,>=1.2
Requires-Dist: ollama<1,>=0.6
Requires-Dist: pandas<3,>=2.0
Requires-Dist: requests<3,>=2.31
Requires-Dist: zstandard>=0.25.0
Description-Content-Type: text/markdown

pk-ai-tools

`pk-ai-tools` is a small Python library that provides a reusable RAG (Retrieval-Augmented Generation) pipeline and a flexible document ingestion system.

It is built on top of:
- LangChain
- Chroma
- Ollama

The main goal of this project is to make it easy to:
- Ingest documents from many formats (PDF, Word, Excel, CSV, Markdown, HTML, etc.)
- Build or update a Chroma vector database
- Ask questions using a simple RAG pipeline backed by local Ollama models

This library was originally created for personal use and has been generalized to be reusable across projects.

## Installation

bash
pip install pk-ai-tools

Requires:

Python 3.9+

Ollama installed and running

## Quick example

```python
from pk_ai_tools import RAGPipeline

rag = RAGPipeline(
    doc_folder="./data",
    language="en",
    uuid="demo-user",
    model_name="llama3"
)

answer = rag.ask("What is this documentation about?")
print(answer)