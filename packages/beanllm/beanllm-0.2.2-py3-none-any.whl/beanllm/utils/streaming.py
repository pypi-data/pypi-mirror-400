"""
Streaming Helpers
ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ í—¬í¼
"""

import asyncio
from dataclasses import dataclass, field
from datetime import datetime
from typing import TYPE_CHECKING, Any, AsyncIterator, Callable, Dict, List, Optional

if TYPE_CHECKING:
    pass

try:
    from rich.console import Console
    from rich.live import Live
    from rich.markdown import Markdown
    from rich.panel import Panel
    from rich.text import Text

    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False
    Console = None
    Live = None
    Markdown = None
    Panel = None
    Text = None

try:
    from .logger import get_logger
except ImportError:
    import logging

    def get_logger(name: str):
        return logging.getLogger(name)


logger = get_logger(__name__)

if RICH_AVAILABLE:
    console = Console()
else:
    console = None


@dataclass
class StreamStats:
    """ìŠ¤íŠ¸ë¦¬ë° í†µê³„"""

    total_tokens: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    chunks: int = 0

    @property
    def duration(self) -> float:
        """ì†Œìš” ì‹œê°„ (ì´ˆ)"""
        if self.start_time and self.end_time:
            return (self.end_time - self.start_time).total_seconds()
        return 0.0

    @property
    def tokens_per_second(self) -> float:
        """ì´ˆë‹¹ í† í° ìˆ˜"""
        if self.duration > 0:
            return self.total_tokens / self.duration
        return 0.0


@dataclass
class StreamResponse:
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ê²°ê³¼"""

    content: str
    stats: StreamStats
    metadata: dict = field(default_factory=dict)


async def stream_response(
    stream: AsyncIterator[str],
    return_output: bool = True,
    display: bool = True,
    use_rich: bool = True,
    markdown: bool = False,
    show_stats: bool = False,
    panel_title: Optional[str] = None,
    on_chunk: Optional[Callable[[str], Any]] = None,
    enable_buffer: bool = False,
    buffer: Optional["StreamBuffer"] = None,
    stream_id: Optional[str] = None,
) -> Optional[StreamResponse]:
    """
    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì¶œë ¥ í—¬í¼

    ì°¸ê³ : LangChainê³¼ TeddyNoteì˜ stream_responseì—ì„œ ì˜ê°ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.
    beanllmì˜ ê°œì„ ëœ ê¸°ëŠ¥:
    - Rich ê¸°ë°˜ ì•„ë¦„ë‹¤ìš´ ì¶œë ¥
    - ë§ˆí¬ë‹¤ìš´ ë Œë”ë§
    - í†µê³„ ì •ë³´ (í† í° ìˆ˜, ì†ë„)
    - ì»¤ìŠ¤í…€ ì½œë°±
    - Panel ë˜í•‘
    - ë²„í¼ë§ ì§€ì› (ì¼ì‹œì •ì§€/ì¬ê°œ/ì¬ìƒ)

    Args:
        stream: AsyncIterator[str] - ìŠ¤íŠ¸ë¦¼ ì†ŒìŠ¤
        return_output: ì¶œë ¥ ë‚´ìš© ë°˜í™˜ ì—¬ë¶€
        display: í™”ë©´ ì¶œë ¥ ì—¬ë¶€
        use_rich: rich ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ì—¬ë¶€
        markdown: ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ ì—¬ë¶€
        show_stats: í†µê³„ ì •ë³´ í‘œì‹œ
        panel_title: Panel ì œëª©
        on_chunk: ì²­í¬ë§ˆë‹¤ í˜¸ì¶œí•  ì½œë°±
        enable_buffer: ë²„í¼ë§ í™œì„±í™”
        buffer: StreamingBuffer ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìë™ ìƒì„±)
        stream_id: ìŠ¤íŠ¸ë¦¼ ID

    Returns:
        StreamResponse | None: ì‘ë‹µ ê²°ê³¼ (return_output=Trueì¸ ê²½ìš°)

    Example:
        ```python
        from beanllm import Client, stream_response

        client = Client(model="gpt-4o-mini")
        stream = client.stream_chat(messages, temperature=0.7)

        # ê¸°ë³¸ ì¶œë ¥
        await stream_response(stream)

        # ë§ˆí¬ë‹¤ìš´ + í†µê³„
        result = await stream_response(
            stream,
            markdown=True,
            show_stats=True,
            panel_title="GPT-4o-mini"
        )
        print(f"Tokens: {result.stats.total_tokens}")
        print(f"Speed: {result.stats.tokens_per_second:.2f} tok/s")
        ```
    """
    stats = StreamStats(start_time=datetime.now())
    collected = []

    # Rich ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if use_rich and not RICH_AVAILABLE:
        logger.warning("Rich library not available. Falling back to plain output.")
        use_rich = False

    try:
        if display and use_rich and panel_title and console:
            # Rich Panel + Live ì—…ë°ì´íŠ¸
            with Live(console=console, refresh_per_second=10) as live:
                current_text = ""
                async for chunk in stream:
                    current_text += chunk
                    collected.append(chunk)
                    stats.chunks += 1

                    if on_chunk:
                        on_chunk(chunk)

                    # Live ì—…ë°ì´íŠ¸
                    if markdown:
                        content = Markdown(current_text)
                    else:
                        content = Text(current_text)

                    live.update(
                        Panel(
                            content,
                            title=f"[bold cyan]{panel_title}[/bold cyan]",
                            border_style="cyan",
                        )
                    )

        elif display and use_rich and console:
            # Rich ì¶œë ¥ (Panel ì—†ìŒ)
            current_text = ""
            async for chunk in stream:
                current_text += chunk
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

                # ì ì§„ì  ì¶œë ¥
                console.print(chunk, end="", markup=False)

            console.print()  # ì¤„ë°”ê¿ˆ

        elif display:
            # ì¼ë°˜ print ì¶œë ¥
            async for chunk in stream:
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

                print(chunk, end="", flush=True)

            print()  # ì¤„ë°”ê¿ˆ

        else:
            # ì¶œë ¥ ì—†ìŒ, ìˆ˜ì§‘ë§Œ
            async for chunk in stream:
                collected.append(chunk)
                stats.chunks += 1

                if on_chunk:
                    on_chunk(chunk)

        stats.end_time = datetime.now()

        # ë²„í¼ë§ëœ ê²½ìš° ë²„í¼ì—ì„œë„ ê°€ì ¸ì˜¤ê¸°
        if enable_buffer and buffer:
            buffered_content = buffer.get_content(stream_id)
            final_content = buffered_content if buffered_content else "".join(collected)
        else:
            final_content = "".join(collected)

        # í† í° ìˆ˜ ì¶”ì • (ê³µë°± ê¸°ì¤€)
        stats.total_tokens = len(final_content.split())

        # í†µê³„ í‘œì‹œ
        if show_stats and display:
            _display_stats(stats)

        if return_output:
            return StreamResponse(content=final_content, stats=stats, metadata={})

        return None

    except Exception as e:
        logger.error(f"Stream error: {e}")
        raise


def _display_stats(stats: StreamStats):
    """í†µê³„ ì •ë³´ í‘œì‹œ"""
    if not RICH_AVAILABLE or not console:
        # Plain text fallback
        print(f"\nDuration: {stats.duration:.2f}s")
        print(f"Tokens: {stats.total_tokens}")
        print(f"Speed: {stats.tokens_per_second:.2f} tok/s")
        print(f"Chunks: {stats.chunks}")
        return

    stats_panel = Panel(
        f"""[bold cyan]Duration:[/bold cyan] {stats.duration:.2f}s
[bold cyan]Tokens:[/bold cyan] {stats.total_tokens}
[bold cyan]Speed:[/bold cyan] {stats.tokens_per_second:.2f} tok/s
[bold cyan]Chunks:[/bold cyan] {stats.chunks}""",
        title="[bold yellow]ğŸ“Š Statistics[/bold yellow]",
        border_style="yellow",
        expand=False,
    )
    console.print()
    console.print(stats_panel)


async def stream_print(
    stream: AsyncIterator[str], markdown: bool = False, panel_title: Optional[str] = None
) -> str:
    """
    ê°„ë‹¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ (ì§§ì€ ë²„ì „)

    Example:
        ```python
        content = await stream_print(stream, markdown=True)
        ```
    """
    result = await stream_response(
        stream,
        return_output=True,
        display=True,
        use_rich=True,
        markdown=markdown,
        panel_title=panel_title,
    )
    return result.content if result else ""


async def stream_collect(stream: AsyncIterator[str]) -> str:
    """
    ìŠ¤íŠ¸ë¦¬ë° ìˆ˜ì§‘ë§Œ (ì¶œë ¥ ì—†ìŒ)

    Example:
        ```python
        content = await stream_collect(stream)
        ```
    """
    result = await stream_response(stream, return_output=True, display=False)
    return result.content if result else ""


class StreamBuffer:
    """
    ìŠ¤íŠ¸ë¦¬ë° ë²„í¼
    ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì„ ë™ì‹œì— ì²˜ë¦¬
    ì¼ì‹œì •ì§€, ì¬ê°œ, ì¬ìƒ ê¸°ëŠ¥ ì§€ì›
    """

    def __init__(self, max_size: int = 10000):
        self.buffers: Dict[str, List[str]] = {}
        self.max_size = max_size
        self.is_paused: Dict[str, bool] = {}  # ìŠ¤íŠ¸ë¦¼ë³„ ì¼ì‹œì •ì§€ ìƒíƒœ
        self._lock = asyncio.Lock()

    async def add_chunk(self, stream_id: str, chunk: str):
        """ì²­í¬ ì¶”ê°€"""
        async with self._lock:
            if stream_id not in self.buffers:
                self.buffers[stream_id] = []
                self.is_paused[stream_id] = False

            # ì¼ì‹œì •ì§€ ì¤‘ì´ì–´ë„ ë²„í¼ì—ëŠ” ì €ì¥
            self.buffers[stream_id].append(chunk)

            # ìµœëŒ€ í¬ê¸° ì œí•œ
            if len(self.buffers[stream_id]) > self.max_size:
                # ì˜¤ë˜ëœ í•­ëª© ì œê±° (FIFO)
                self.buffers[stream_id] = self.buffers[stream_id][-self.max_size :]

    def pause(self, stream_id: str):
        """ì¼ì‹œì •ì§€"""
        if stream_id in self.is_paused:
            self.is_paused[stream_id] = True

    def resume(self, stream_id: str):
        """ì¬ê°œ"""
        if stream_id in self.is_paused:
            self.is_paused[stream_id] = False

    def is_stream_paused(self, stream_id: str) -> bool:
        """ì¼ì‹œì •ì§€ ìƒíƒœ í™•ì¸"""
        return self.is_paused.get(stream_id, False)

    async def replay(
        self,
        stream_id: str,
        delay: float = 0.0,  # ì²­í¬ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)
    ) -> AsyncIterator[str]:
        """
        ì¬ìƒ (ë²„í¼ëœ ë‚´ìš©ì„ ë‹¤ì‹œ ìŠ¤íŠ¸ë¦¬ë°)

        Args:
            stream_id: ìŠ¤íŠ¸ë¦¼ ID
            delay: ì²­í¬ ê°„ ì§€ì—° ì‹œê°„ (ì›ë³¸ ì†ë„ ì¬í˜„)

        Yields:
            str: ì²­í¬
        """
        async with self._lock:
            chunks = self.buffers.get(stream_id, []).copy()

        for chunk in chunks:
            yield chunk
            if delay > 0:
                await asyncio.sleep(delay)

    def get_content(self, stream_id: str) -> str:
        """ì „ì²´ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        return "".join(self.buffers.get(stream_id, []))

    def clear(self, stream_id: str):
        """ë²„í¼ ì´ˆê¸°í™”"""
        if stream_id in self.buffers:
            del self.buffers[stream_id]
        if stream_id in self.is_paused:
            del self.is_paused[stream_id]

    def get_all(self) -> dict:
        """ëª¨ë“  ë²„í¼ ë‚´ìš©"""
        return {stream_id: "".join(chunks) for stream_id, chunks in self.buffers.items()}


# í¸ì˜ í•¨ìˆ˜
async def pretty_stream(stream: AsyncIterator[str], title: str = "Response") -> StreamResponse:
    """
    ì˜ˆìœ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥ (ëª¨ë“  ê¸°ëŠ¥ í™œì„±í™”)

    Example:
        ```python
        from beanllm import Client
        from beanllm.streaming import pretty_stream

        client = Client(model="gpt-4o-mini")
        stream = client.stream_chat(messages)
        result = await pretty_stream(stream, title="GPT-4o-mini")
        ```
    """
    return await stream_response(
        stream,
        return_output=True,
        display=True,
        use_rich=True,
        markdown=True,
        show_stats=True,
        panel_title=title,
    )
