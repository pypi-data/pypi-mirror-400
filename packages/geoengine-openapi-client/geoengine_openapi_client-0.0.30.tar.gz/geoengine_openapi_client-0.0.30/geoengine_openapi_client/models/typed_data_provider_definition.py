# coding: utf-8

"""
    Geo Engine API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 0.8.0
    Contact: dev@geoengine.de
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import json
import pprint
from pydantic import BaseModel, ConfigDict, Field, StrictStr, ValidationError, field_validator
from typing import Any, List, Optional
from geoengine_openapi_client.models.aruna_data_provider_definition import ArunaDataProviderDefinition
from geoengine_openapi_client.models.copernicus_dataspace_data_provider_definition import CopernicusDataspaceDataProviderDefinition
from geoengine_openapi_client.models.dataset_layer_listing_provider_definition import DatasetLayerListingProviderDefinition
from geoengine_openapi_client.models.ebv_portal_data_provider_definition import EbvPortalDataProviderDefinition
from geoengine_openapi_client.models.edr_data_provider_definition import EdrDataProviderDefinition
from geoengine_openapi_client.models.gbif_data_provider_definition import GbifDataProviderDefinition
from geoengine_openapi_client.models.gfbio_abcd_data_provider_definition import GfbioAbcdDataProviderDefinition
from geoengine_openapi_client.models.gfbio_collections_data_provider_definition import GfbioCollectionsDataProviderDefinition
from geoengine_openapi_client.models.net_cdf_cf_data_provider_definition import NetCdfCfDataProviderDefinition
from geoengine_openapi_client.models.pangaea_data_provider_definition import PangaeaDataProviderDefinition
from geoengine_openapi_client.models.sentinel_s2_l2_a_cogs_provider_definition import SentinelS2L2ACogsProviderDefinition
from geoengine_openapi_client.models.wildlive_data_connector_definition import WildliveDataConnectorDefinition
from pydantic import StrictStr, Field
from typing import Union, List, Set, Optional, Dict
from typing_extensions import Literal, Self

TYPEDDATAPROVIDERDEFINITION_ONE_OF_SCHEMAS = ["ArunaDataProviderDefinition", "CopernicusDataspaceDataProviderDefinition", "DatasetLayerListingProviderDefinition", "EbvPortalDataProviderDefinition", "EdrDataProviderDefinition", "GbifDataProviderDefinition", "GfbioAbcdDataProviderDefinition", "GfbioCollectionsDataProviderDefinition", "NetCdfCfDataProviderDefinition", "PangaeaDataProviderDefinition", "SentinelS2L2ACogsProviderDefinition", "WildliveDataConnectorDefinition"]

class TypedDataProviderDefinition(BaseModel):
    """
    TypedDataProviderDefinition
    """
    # data type: ArunaDataProviderDefinition
    oneof_schema_1_validator: Optional[ArunaDataProviderDefinition] = None
    # data type: CopernicusDataspaceDataProviderDefinition
    oneof_schema_2_validator: Optional[CopernicusDataspaceDataProviderDefinition] = None
    # data type: DatasetLayerListingProviderDefinition
    oneof_schema_3_validator: Optional[DatasetLayerListingProviderDefinition] = None
    # data type: EbvPortalDataProviderDefinition
    oneof_schema_4_validator: Optional[EbvPortalDataProviderDefinition] = None
    # data type: EdrDataProviderDefinition
    oneof_schema_5_validator: Optional[EdrDataProviderDefinition] = None
    # data type: GbifDataProviderDefinition
    oneof_schema_6_validator: Optional[GbifDataProviderDefinition] = None
    # data type: GfbioAbcdDataProviderDefinition
    oneof_schema_7_validator: Optional[GfbioAbcdDataProviderDefinition] = None
    # data type: GfbioCollectionsDataProviderDefinition
    oneof_schema_8_validator: Optional[GfbioCollectionsDataProviderDefinition] = None
    # data type: NetCdfCfDataProviderDefinition
    oneof_schema_9_validator: Optional[NetCdfCfDataProviderDefinition] = None
    # data type: PangaeaDataProviderDefinition
    oneof_schema_10_validator: Optional[PangaeaDataProviderDefinition] = None
    # data type: SentinelS2L2ACogsProviderDefinition
    oneof_schema_11_validator: Optional[SentinelS2L2ACogsProviderDefinition] = None
    # data type: WildliveDataConnectorDefinition
    oneof_schema_12_validator: Optional[WildliveDataConnectorDefinition] = None
    actual_instance: Optional[Union[ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition]] = None
    one_of_schemas: Set[str] = { "ArunaDataProviderDefinition", "CopernicusDataspaceDataProviderDefinition", "DatasetLayerListingProviderDefinition", "EbvPortalDataProviderDefinition", "EdrDataProviderDefinition", "GbifDataProviderDefinition", "GfbioAbcdDataProviderDefinition", "GfbioCollectionsDataProviderDefinition", "NetCdfCfDataProviderDefinition", "PangaeaDataProviderDefinition", "SentinelS2L2ACogsProviderDefinition", "WildliveDataConnectorDefinition" }

    model_config = ConfigDict(
        validate_assignment=True,
        protected_namespaces=(),
    )


    discriminator_value_class_map: Dict[str, str] = {
    }

    def __init__(self, *args, **kwargs) -> None:
        if args:
            if len(args) > 1:
                raise ValueError("If a position argument is used, only 1 is allowed to set `actual_instance`")
            if kwargs:
                raise ValueError("If a position argument is used, keyword arguments cannot be used.")
            super().__init__(actual_instance=args[0])
        else:
            super().__init__(**kwargs)

    @field_validator('actual_instance')
    def actual_instance_must_validate_oneof(cls, v):
        instance = TypedDataProviderDefinition.model_construct()
        error_messages = []
        match = 0
        # validate data type: ArunaDataProviderDefinition
        if not isinstance(v, ArunaDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `ArunaDataProviderDefinition`")
        else:
            match += 1
        # validate data type: CopernicusDataspaceDataProviderDefinition
        if not isinstance(v, CopernicusDataspaceDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `CopernicusDataspaceDataProviderDefinition`")
        else:
            match += 1
        # validate data type: DatasetLayerListingProviderDefinition
        if not isinstance(v, DatasetLayerListingProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `DatasetLayerListingProviderDefinition`")
        else:
            match += 1
        # validate data type: EbvPortalDataProviderDefinition
        if not isinstance(v, EbvPortalDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EbvPortalDataProviderDefinition`")
        else:
            match += 1
        # validate data type: EdrDataProviderDefinition
        if not isinstance(v, EdrDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `EdrDataProviderDefinition`")
        else:
            match += 1
        # validate data type: GbifDataProviderDefinition
        if not isinstance(v, GbifDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `GbifDataProviderDefinition`")
        else:
            match += 1
        # validate data type: GfbioAbcdDataProviderDefinition
        if not isinstance(v, GfbioAbcdDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `GfbioAbcdDataProviderDefinition`")
        else:
            match += 1
        # validate data type: GfbioCollectionsDataProviderDefinition
        if not isinstance(v, GfbioCollectionsDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `GfbioCollectionsDataProviderDefinition`")
        else:
            match += 1
        # validate data type: NetCdfCfDataProviderDefinition
        if not isinstance(v, NetCdfCfDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `NetCdfCfDataProviderDefinition`")
        else:
            match += 1
        # validate data type: PangaeaDataProviderDefinition
        if not isinstance(v, PangaeaDataProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `PangaeaDataProviderDefinition`")
        else:
            match += 1
        # validate data type: SentinelS2L2ACogsProviderDefinition
        if not isinstance(v, SentinelS2L2ACogsProviderDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `SentinelS2L2ACogsProviderDefinition`")
        else:
            match += 1
        # validate data type: WildliveDataConnectorDefinition
        if not isinstance(v, WildliveDataConnectorDefinition):
            error_messages.append(f"Error! Input type `{type(v)}` is not `WildliveDataConnectorDefinition`")
        else:
            match += 1
        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when setting `actual_instance` in TypedDataProviderDefinition with oneOf schemas: ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when setting `actual_instance` in TypedDataProviderDefinition with oneOf schemas: ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition. Details: " + ", ".join(error_messages))
        else:
            return v

    @classmethod
    def from_dict(cls, obj: Union[str, Dict[str, Any]]) -> Self:
        return cls.from_json(json.dumps(obj))

    @classmethod
    def from_json(cls, json_str: str) -> Self:
        """Returns the object represented by the json string"""
        instance = cls.model_construct()
        error_messages = []
        match = 0

        # use oneOf discriminator to lookup the data type
        _data_type = json.loads(json_str).get("type")
        if not _data_type:
            raise ValueError("Failed to lookup data type from the field `type` in the input.")

        # check if data type is `ArunaDataProviderDefinition`
        if _data_type == "Aruna":
            instance.actual_instance = ArunaDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `CopernicusDataspaceDataProviderDefinition`
        if _data_type == "CopernicusDataspace":
            instance.actual_instance = CopernicusDataspaceDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `DatasetLayerListingProviderDefinition`
        if _data_type == "DatasetLayerListing":
            instance.actual_instance = DatasetLayerListingProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `EbvPortalDataProviderDefinition`
        if _data_type == "EbvPortal":
            instance.actual_instance = EbvPortalDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `EdrDataProviderDefinition`
        if _data_type == "Edr":
            instance.actual_instance = EdrDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `GbifDataProviderDefinition`
        if _data_type == "Gbif":
            instance.actual_instance = GbifDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `GfbioAbcdDataProviderDefinition`
        if _data_type == "GfbioAbcd":
            instance.actual_instance = GfbioAbcdDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `GfbioCollectionsDataProviderDefinition`
        if _data_type == "GfbioCollections":
            instance.actual_instance = GfbioCollectionsDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `NetCdfCfDataProviderDefinition`
        if _data_type == "NetCdfCf":
            instance.actual_instance = NetCdfCfDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `PangaeaDataProviderDefinition`
        if _data_type == "Pangaea":
            instance.actual_instance = PangaeaDataProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `SentinelS2L2ACogsProviderDefinition`
        if _data_type == "SentinelS2L2ACogs":
            instance.actual_instance = SentinelS2L2ACogsProviderDefinition.from_json(json_str)
            return instance

        # check if data type is `WildliveDataConnectorDefinition`
        if _data_type == "WildLIVE!":
            instance.actual_instance = WildliveDataConnectorDefinition.from_json(json_str)
            return instance

        # deserialize data into ArunaDataProviderDefinition
        try:
            instance.actual_instance = ArunaDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into CopernicusDataspaceDataProviderDefinition
        try:
            instance.actual_instance = CopernicusDataspaceDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into DatasetLayerListingProviderDefinition
        try:
            instance.actual_instance = DatasetLayerListingProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EbvPortalDataProviderDefinition
        try:
            instance.actual_instance = EbvPortalDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into EdrDataProviderDefinition
        try:
            instance.actual_instance = EdrDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into GbifDataProviderDefinition
        try:
            instance.actual_instance = GbifDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into GfbioAbcdDataProviderDefinition
        try:
            instance.actual_instance = GfbioAbcdDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into GfbioCollectionsDataProviderDefinition
        try:
            instance.actual_instance = GfbioCollectionsDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into NetCdfCfDataProviderDefinition
        try:
            instance.actual_instance = NetCdfCfDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into PangaeaDataProviderDefinition
        try:
            instance.actual_instance = PangaeaDataProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into SentinelS2L2ACogsProviderDefinition
        try:
            instance.actual_instance = SentinelS2L2ACogsProviderDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))
        # deserialize data into WildliveDataConnectorDefinition
        try:
            instance.actual_instance = WildliveDataConnectorDefinition.from_json(json_str)
            match += 1
        except (ValidationError, ValueError) as e:
            error_messages.append(str(e))

        if match > 1:
            # more than 1 match
            raise ValueError("Multiple matches found when deserializing the JSON string into TypedDataProviderDefinition with oneOf schemas: ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition. Details: " + ", ".join(error_messages))
        elif match == 0:
            # no match
            raise ValueError("No match found when deserializing the JSON string into TypedDataProviderDefinition with oneOf schemas: ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition. Details: " + ", ".join(error_messages))
        else:
            return instance

    def to_json(self) -> str:
        """Returns the JSON representation of the actual instance"""
        if self.actual_instance is None:
            return "null"

        if hasattr(self.actual_instance, "to_json") and callable(self.actual_instance.to_json):
            return self.actual_instance.to_json()
        else:
            return json.dumps(self.actual_instance)

    def to_dict(self) -> Optional[Union[Dict[str, Any], ArunaDataProviderDefinition, CopernicusDataspaceDataProviderDefinition, DatasetLayerListingProviderDefinition, EbvPortalDataProviderDefinition, EdrDataProviderDefinition, GbifDataProviderDefinition, GfbioAbcdDataProviderDefinition, GfbioCollectionsDataProviderDefinition, NetCdfCfDataProviderDefinition, PangaeaDataProviderDefinition, SentinelS2L2ACogsProviderDefinition, WildliveDataConnectorDefinition]]:
        """Returns the dict representation of the actual instance"""
        if self.actual_instance is None:
            return None

        if hasattr(self.actual_instance, "to_dict") and callable(self.actual_instance.to_dict):
            return self.actual_instance.to_dict()
        else:
            # primitive type
            return self.actual_instance

    def to_str(self) -> str:
        """Returns the string representation of the actual instance"""
        return pprint.pformat(self.model_dump())


