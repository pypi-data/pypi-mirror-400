#!/usr/bin/env python3
"""
æ•°æ®é›†æ¢ç´¢è„šæœ¬
ç”¨äºæŸ¥çœ‹è…°æ¤MRIæ•°æ®é›†çš„æ ·æœ¬å’Œç»Ÿè®¡ä¿¡æ¯
"""

import sys
from collections import Counter
from pathlib import Path

import numpy as np
from datasets import Dataset, load_from_disk
from PIL import Image

# è®¾ç½®é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))


def explore_dataset():
    """æ¢ç´¢æ•°æ®é›†"""

    dataset_path = project_root / "data" / "medical" / "lumbar-spine-mri" / "cache"

    if not dataset_path.exists():
        print(f"âŒ æ•°æ®é›†ä¸å­˜åœ¨: {dataset_path}")
        print("è¯·å…ˆè¿è¡Œ scripts/download_lumbar_dataset.py ä¸‹è½½æ•°æ®é›†")
        return

    print("=" * 80)
    print("ğŸ“Š è…°æ¤MRIæ•°æ®é›†æ¢ç´¢")
    print("=" * 80)

    # åŠ è½½æ•°æ®é›†
    print(f"\nğŸ“‚ ä» {dataset_path} åŠ è½½æ•°æ®é›†...")
    dataset = load_from_disk(str(dataset_path))

    # ç¡®ä¿æ˜¯ Dataset ç±»å‹
    if not isinstance(dataset, Dataset):
        raise TypeError(f"Expected Dataset, got {type(dataset)}")

    # åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“‹ æ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
    print(f"   - æ ·æœ¬æ€»æ•°: {len(dataset)}")
    print(f"   - å­—æ®µ: {dataset.column_names}")
    print(f"   - Features: {dataset.features}")

    # æ ‡ç­¾åˆ†å¸ƒ
    labels = [sample["label"] for sample in dataset]  # type: ignore[index]
    label_counts = Counter(labels)

    print("\nğŸ·ï¸  æ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in sorted(label_counts.items()):
        percentage = count / len(dataset) * 100
        print(f"   - Label {label}: {count} samples ({percentage:.1f}%)")

    # å›¾åƒç»Ÿè®¡
    print("\nğŸ–¼ï¸  å›¾åƒç»Ÿè®¡ (å‰10ä¸ªæ ·æœ¬):")
    image_sizes = []

    for i in range(min(10, len(dataset))):
        sample = dataset[i]
        img = sample["image"]

        if isinstance(img, Image.Image):
            width, height = img.size
            mode = img.mode
            image_sizes.append((width, height))

            if i < 5:  # åªæ‰“å°å‰5ä¸ª
                print(f"   - æ ·æœ¬ {i}: {width}x{height}, mode={mode}, label={sample['label']}")

    if image_sizes:
        widths = [w for w, h in image_sizes]
        heights = [h for w, h in image_sizes]

        print("\nğŸ“ å›¾åƒå°ºå¯¸èŒƒå›´:")
        print(f"   - å®½åº¦: {min(widths)} ~ {max(widths)} (å¹³å‡: {np.mean(widths):.0f})")
        print(f"   - é«˜åº¦: {min(heights)} ~ {max(heights)} (å¹³å‡: {np.mean(heights):.0f})")

    # ä¿å­˜ä¸€äº›æ ·æœ¬
    output_dir = project_root / "examples" / "medical_diagnosis" / "data" / "samples"
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ’¾ ä¿å­˜æ ·æœ¬å›¾åƒåˆ°: {output_dir}")

    # æ¯ä¸ªæ ‡ç­¾ä¿å­˜ä¸€ä¸ªæ ·æœ¬
    saved_labels = set()
    saved_count = 0

    for i, sample in enumerate(dataset):  # type: ignore[arg-type]
        if not isinstance(sample, dict):
            continue
        label = sample["label"]

        if label not in saved_labels:
            img = sample["image"]
            if isinstance(img, Image.Image):
                output_path = output_dir / f"sample_label{label}_{i}.jpg"
                img.save(output_path)
                print(f"   âœ“ ä¿å­˜ label={label} æ ·æœ¬: {output_path.name}")
                saved_labels.add(label)
                saved_count += 1

                if saved_count >= 5:  # æœ€å¤šä¿å­˜5ä¸ªæ ·æœ¬
                    break

    # åˆ›å»ºç®€å•çš„ç»Ÿè®¡æŠ¥å‘Š
    report_path = output_dir / "dataset_report.txt"
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("è…°æ¤MRIæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ•°æ®é›†è·¯å¾„: {dataset_path}\n")
        f.write(f"æ ·æœ¬æ€»æ•°: {len(dataset)}\n")
        f.write(f"å­—æ®µ: {', '.join(dataset.column_names)}\n\n")

        f.write("æ ‡ç­¾åˆ†å¸ƒ:\n")
        for label, count in sorted(label_counts.items()):
            percentage = count / len(dataset) * 100
            f.write(f"  Label {label}: {count} ({percentage:.1f}%)\n")

        if image_sizes:
            f.write("\nå›¾åƒå°ºå¯¸èŒƒå›´:\n")
            f.write(f"  å®½åº¦: {min(widths)} ~ {max(widths)} (å¹³å‡: {np.mean(widths):.0f})\n")
            f.write(f"  é«˜åº¦: {min(heights)} ~ {max(heights)} (å¹³å‡: {np.mean(heights):.0f})\n")

    print(f"\nğŸ“Š ç»Ÿè®¡æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

    print("\n" + "=" * 80)
    print("âœ… æ•°æ®é›†æ¢ç´¢å®Œæˆ!")
    print("=" * 80)


if __name__ == "__main__":
    explore_dataset()
