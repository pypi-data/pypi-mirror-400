"""
mem1 + LangChain é›†æˆç¤ºä¾‹

æ¼”ç¤ºä¸‰å±‚è®°å¿†æ¶æ„ï¼š
- Tier 1 (çŸ­æœŸ): LangChain ç®¡ç†çš„å½“å‰ä¼šè¯
- Tier 2 (ç”»åƒ): mem1 ç”¨æˆ·ç”»åƒï¼Œæ³¨å…¥ system prompt
- Tier 3 (é•¿æœŸ): ES å­˜å‚¨çš„å†å²å¯¹è¯

æœ€æ–°åŠŸèƒ½ï¼š
- ä½¿ç”¨è‡ªå®šä¹‰ç”»åƒæ¨¡æ¿
- å‘¨æœŸæ€§ä»»åŠ¡å’Œå…³é”®æ•°å­—è®°å¿†
- æ—¶é—´èŒƒå›´æ§åˆ¶
"""
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.chat_history import InMemoryChatMessageHistory

from mem1 import Mem1Memory, Mem1Config
from mem1.prompts import YUQING_PROFILE_TEMPLATE

load_dotenv()

config = Mem1Config.from_env()
config.memory.auto_update_profile = True
config.memory.update_interval_rounds = 3

USER_ID = "langchain_demo_user"


def demo_manual_integration():
    """æ–¹å¼1: æ‰‹åŠ¨é›†æˆï¼ˆæ›´çµæ´»ï¼Œæ¨èï¼‰"""
    print("\n" + "="*60)
    print("æ–¹å¼1: æ‰‹åŠ¨é›†æˆ mem1 åˆ° LangChain")
    print("="*60)
    
    # ä½¿ç”¨èˆ†æƒ…è¡Œä¸šæ¨¡æ¿ï¼ŒæŒ‡å®šè¯é¢˜
    memory = Mem1Memory(
        config, 
        user_id=USER_ID,
        topic_id="yuqing_daily",  # æ—¥å¸¸èˆ†æƒ…è¯é¢˜
        profile_template=YUQING_PROFILE_TEMPLATE
    )
    
    print("\næ¸…ç©ºæ—§æ•°æ®...")
    memory.delete_user()
    
    # å…ˆæ·»åŠ ä¸€äº›èƒŒæ™¯å¯¹è¯
    print("æ·»åŠ èƒŒæ™¯å¯¹è¯...")
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "æˆ‘æ˜¯æç§‘ï¼Œå¸‚ç½‘ä¿¡åŠèˆ†æƒ…ç›‘æµ‹ç§‘ï¼Œæ¯å‘¨ä¸€è¦äº¤å‘¨æŠ¥ã€‚"},
            {"role": "assistant", "content": "æç§‘æ‚¨å¥½ï¼å·²è®°å½•ï¼šå‘¨ä¸€äº¤å‘¨æŠ¥ã€‚"}
        ]
    )
    
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "æŠ¥å‘Šè¦ç®€æ´ï¼Œæ§åˆ¶åœ¨500å­—ä»¥å†…ï¼Œå¤šç”¨æ•°æ®ã€‚"},
            {"role": "assistant", "content": "æ˜ç™½ï¼ŒæŠ¥å‘Šé£æ ¼ï¼šç®€æ´ã€æ•°æ®åŒ–ã€‚"}
        ]
    )
    
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "æœ¬æœˆå¤„ç†äº†97èµ·èˆ†æƒ…ï¼Œé‡å¤§èˆ†æƒ…11èµ·ã€‚"},
            {"role": "assistant", "content": "æœ¬æœˆæ•°æ®å·²è®°å½•ï¼š97èµ·ï¼ˆé‡å¤§11èµ·ï¼‰ã€‚"}
        ]
    )
    
    # è·å–ç”¨æˆ·ç”»åƒ (Tier 2)
    ctx = memory.get_context(query="å¸®æˆ‘å†™æŠ¥å‘Š", days_limit=7)
    
    # æ„å»º system prompt
    system_prompt = f"""ä½ æ˜¯ç½‘ä¿¡åŠèˆ†æƒ…ç›‘æµ‹åŠ©æ‰‹ã€‚

## ç”¨æˆ·ç”»åƒ
{ctx['import_content']}

## æœ€è¿‘å¯¹è¯
{ctx['normal_content'] if ctx['normal_content'] else 'ï¼ˆæ— å†å²å¯¹è¯ï¼‰'}

## å½“å‰æ—¶é—´
{ctx['current_time']}

è¯·æ ¹æ®ç”¨æˆ·ç”»åƒä¸­çš„åå¥½å’Œä¹ æƒ¯æ¥å›ç­”é—®é¢˜ã€‚
"""
    
    # LangChain LLMï¼ˆä½¿ç”¨ mem1 é…ç½®ï¼‰
    llm = ChatOpenAI(
        model=config.llm.model,
        api_key=config.llm.api_key,
        base_url=config.llm.base_url
    )
    
    # Tier 1: å½“å‰ä¼šè¯
    messages = [SystemMessage(content=system_prompt)]
    conversation_to_save = []
    
    # å¤šè½®å¯¹è¯
    user_inputs = [
        "ä½ å¥½ï¼Œè¿˜è®°å¾—æˆ‘å—ï¼Ÿ",
        "å¸®æˆ‘å†™ä¸ªæœ¬æœˆèˆ†æƒ…æ•°æ®çš„ç®€æŠ¥"
    ]
    
    for user_input in user_inputs:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {user_input}")
        messages.append(HumanMessage(content=user_input))
        
        response = llm.invoke(messages)
        print(f"ğŸ¤– åŠ©æ‰‹: {response.content[:200]}...")
        
        messages.append(response)
        conversation_to_save.append({"role": "user", "content": user_input})
        conversation_to_save.append({"role": "assistant", "content": response.content})
    
    # ä¿å­˜åˆ° Tier 3
    memory.add_conversation(
        messages=conversation_to_save,
        metadata={"session": "manual_demo", "type": "langchain"}
    )
    print("\nâœ“ ä¼šè¯å·²ä¿å­˜åˆ° ES")


def demo_chain_integration():
    """æ–¹å¼2: ä½¿ç”¨ LangChain Chain"""
    print("\n" + "="*60)
    print("æ–¹å¼2: LangChain Chain + mem1")
    print("="*60)
    
    memory = Mem1Memory(
        config, 
        user_id=USER_ID + "_chain",
        topic_id="weekly_plan",  # å‘¨è®¡åˆ’è¯é¢˜
        profile_template=YUQING_PROFILE_TEMPLATE
    )
    memory.delete_user()
    
    # æ·»åŠ èƒŒæ™¯
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "æˆ‘æ˜¯ç‹ç§‘é•¿ï¼Œæ¯å‘¨äº”è¦åšä¸‹å‘¨è®¡åˆ’ã€‚"},
            {"role": "assistant", "content": "ç‹ç§‘é•¿æ‚¨å¥½ï¼å·²è®°å½•ï¼šå‘¨äº”åšè®¡åˆ’ã€‚"}
        ]
    )
    
    ctx = memory.get_context(query="", days_limit=7)
    
    llm = ChatOpenAI(
        model=config.llm.model,
        api_key=config.llm.api_key,
        base_url=config.llm.base_url
    )
    
    # Tier 1: LangChain çŸ­æœŸè®°å¿†
    chat_history = InMemoryChatMessageHistory()
    
    # æ³¨å…¥ Tier 2 ç”»åƒ
    prompt = ChatPromptTemplate.from_messages([
        ("system", f"""ä½ æ˜¯ç½‘ä¿¡åŠèˆ†æƒ…ç›‘æµ‹åŠ©æ‰‹ã€‚

## ç”¨æˆ·ç”»åƒ
{ctx['import_content']}

## å½“å‰æ—¶é—´
{ctx['current_time']}
"""),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    
    chain = prompt | llm
    
    # å¯¹è¯
    queries = [
        "ä½ å¥½",
        "æˆ‘çš„å·¥ä½œä¹ æƒ¯æ˜¯ä»€ä¹ˆï¼Ÿ"
    ]
    
    for query in queries:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {query}")
        
        result = chain.invoke({"input": query, "history": chat_history.messages})
        print(f"ğŸ¤– åŠ©æ‰‹: {result.content[:200]}...")
        
        # æ›´æ–°çŸ­æœŸè®°å¿†
        chat_history.add_user_message(query)
        chat_history.add_ai_message(result.content)
        
        # ä¿å­˜åˆ° Tier 3
        memory.add_conversation(
            messages=[
                {"role": "user", "content": query},
                {"role": "assistant", "content": result.content}
            ],
            metadata={"session": "chain_demo", "type": "langchain"}
        )
    
    print("\nâœ“ ä¼šè¯å·²ä¿å­˜åˆ° ES")


def demo_with_image():
    """æ–¹å¼3: å¸¦å›¾ç‰‡çš„é›†æˆ - æ¼”ç¤ºå›¾ç‰‡è®°å¿†å¬å›"""
    print("\n" + "="*60)
    print("æ–¹å¼3: å¸¦å›¾ç‰‡çš„ LangChain é›†æˆ")
    print("="*60)
    
    from pathlib import Path
    
    memory = Mem1Memory(
        config,
        user_id=USER_ID + "_image",
        topic_id="yuqing_events",  # èˆ†æƒ…äº‹ä»¶è¯é¢˜
        profile_template=YUQING_PROFILE_TEMPLATE
    )
    memory.delete_user()
    
    # æ£€æŸ¥å›¾ç‰‡
    sample_image = Path(__file__).parent / "å¤©ä»·éº»èŠ±.png"
    if not sample_image.exists():
        print("âš ï¸ ç¤ºä¾‹å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡å›¾ç‰‡æ¼”ç¤º")
        return
    
    # 1. æ·»åŠ å¸¦å›¾ç‰‡çš„å¯¹è¯ï¼ˆæ¨¡æ‹Ÿç”¨æˆ·ä¸Šä¼ æˆªå›¾ï¼‰
    print("\n1. æ·»åŠ å¸¦å›¾ç‰‡çš„èˆ†æƒ…å¯¹è¯...")
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "å‘ç°ä¸€ä¸ªèˆ†æƒ…ï¼Œå¹¿ä¸œæ±Ÿé—¨æ™¯åŒºå¤©ä»·éº»èŠ±ï¼Œ60å…ƒä¸€æ ¹ï¼Œè¿™æ˜¯æˆªå›¾ã€‚"},
            {"role": "assistant", "content": "æ”¶åˆ°æˆªå›¾ã€‚è¿™æ˜¯æ¶ˆè´¹ç»´æƒç±»èˆ†æƒ…ï¼Œå»ºè®®å…³æ³¨åç»­å‘å±•ã€‚"}
        ],
        images=[{"filename": "å¤©ä»·éº»èŠ±.png", "path": str(sample_image)}],
        metadata={"event": "å¤©ä»·éº»èŠ±", "type": "èˆ†æƒ…å‘ç°"}
    )
    
    # 2. æ·»åŠ åç»­å¯¹è¯
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "å¸‚åœºç›‘ç®¡å±€ä»‹å…¥è°ƒæŸ¥äº†ï¼Œå•†å®¶æš‚åœè¥ä¸šã€‚"},
            {"role": "assistant", "content": "äº‹ä»¶è¿›å±•å·²è®°å½•ï¼šç›‘ç®¡ä»‹å…¥ï¼Œå•†å®¶æš‚åœã€‚"}
        ],
        metadata={"event": "å¤©ä»·éº»èŠ±", "type": "èˆ†æƒ…è·Ÿè¿›"}
    )
    
    memory.add_conversation(
        messages=[
            {"role": "user", "content": "è°ƒæŸ¥ç»“æœå‡ºæ¥äº†ï¼šä¸æ„æˆä»·æ ¼æ¬ºè¯ˆï¼Œä½†å­˜åœ¨æœåŠ¡æ€åº¦é—®é¢˜ã€‚"},
            {"role": "assistant", "content": "è°ƒæŸ¥ç»“è®ºå·²è®°å½•ã€‚"}
        ],
        metadata={"event": "å¤©ä»·éº»èŠ±", "type": "èˆ†æƒ…ç»“è®º"}
    )
    print("âœ“ å·²æ·»åŠ  3 æ¡å¯¹è¯ï¼ˆå« 1 å¼ å›¾ç‰‡ï¼‰")
    
    # 3. ç”¨æˆ·æé—®å…³äºå›¾ç‰‡çš„é—®é¢˜
    print("\n2. ç”¨æˆ·æé—®å…³äºå›¾ç‰‡...")
    
    llm = ChatOpenAI(
        model=config.llm.model,
        api_key=config.llm.api_key,
        base_url=config.llm.base_url
    )
    
    # è·å–ä¸Šä¸‹æ–‡
    ctx = memory.get_context(query="å¤©ä»·éº»èŠ±", days_limit=7)
    
    # æœç´¢ç›¸å…³å›¾ç‰‡
    images = memory.search_images(query="éº»èŠ± å¤©ä»· æ±Ÿé—¨")
    image_info = ""
    if images:
        image_info = "\n## ç›¸å…³å›¾ç‰‡\n"
        for img in images:
            image_info += f"- {img['filename']}: {img['description']}\n"
    
    system_prompt = f"""ä½ æ˜¯ç½‘ä¿¡åŠèˆ†æƒ…ç›‘æµ‹åŠ©æ‰‹ã€‚

## ç”¨æˆ·ç”»åƒ
{ctx['import_content']}

## æœ€è¿‘å¯¹è¯
{ctx['normal_content']}
{image_info}
## å½“å‰æ—¶é—´
{ctx['current_time']}

è¯·æ ¹æ®å¯¹è¯è®°å½•å’Œå›¾ç‰‡ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
"""
    
    # ç”¨æˆ·æé—®
    user_questions = [
        "ä¹‹å‰é‚£ä¸ªå¤©ä»·éº»èŠ±çš„æˆªå›¾è¿˜åœ¨å—ï¼Ÿæ˜¯ä»€ä¹ˆå†…å®¹ï¼Ÿ",
        "è¿™ä¸ªäº‹ä»¶æœ€åæ€ä¹ˆå¤„ç†çš„ï¼Ÿ"
    ]
    
    messages = [SystemMessage(content=system_prompt)]
    
    for question in user_questions:
        print(f"\nğŸ‘¤ ç”¨æˆ·: {question}")
        messages.append(HumanMessage(content=question))
        
        response = llm.invoke(messages)
        print(f"ğŸ¤– åŠ©æ‰‹: {response.content[:300]}...")
        
        messages.append(response)
    
    print("\nâœ“ å›¾ç‰‡è®°å¿†å¬å›æ¼”ç¤ºå®Œæˆ")


def demo_progressive_retrieval():
    """æ–¹å¼4: æ¸è¿›å¼æ£€ç´¢ - çœ token çš„æ™ºèƒ½æ£€ç´¢"""
    print("\n" + "="*60)
    print("æ–¹å¼4: æ¸è¿›å¼æ£€ç´¢ï¼ˆå…ˆæŸ¥è¿‘æœŸï¼Œä¸å¤Ÿå†æ‰©å±•ï¼‰")
    print("="*60)
    
    memory = Mem1Memory(
        config,
        user_id=USER_ID + "_progressive",
        topic_id="daily_work",
        profile_template=YUQING_PROFILE_TEMPLATE
    )
    memory.delete_user()
    
    # æ·»åŠ ä¸€äº›å¯¹è¯
    print("\næ·»åŠ æµ‹è¯•å¯¹è¯...")
    memory.add_conversation(messages=[
        {"role": "user", "content": "ä»Šå¤©å¤„ç†äº†3èµ·èˆ†æƒ…ã€‚"},
        {"role": "assistant", "content": "å·²è®°å½•ã€‚"}
    ])
    
    llm = ChatOpenAI(
        model=config.llm.model,
        api_key=config.llm.api_key,
        base_url=config.llm.base_url
    )
    
    # ä½¿ç”¨æ¸è¿›å¼æ£€ç´¢
    user_question = "ä»Šå¤©å¤„ç†äº†å¤šå°‘èˆ†æƒ…ï¼Ÿ"
    print(f"\nğŸ‘¤ ç”¨æˆ·: {user_question}")
    
    ctx = memory.get_context_progressive(
        query=user_question,
        max_days=31,
        step=7
    )
    
    print(f"ğŸ“– å®é™…æ£€ç´¢äº† {ctx.get('searched_days', '?')} å¤©ï¼Œ{ctx['conversations_count']} æ¡å¯¹è¯")
    
    system_prompt = f"""ä½ æ˜¯èˆ†æƒ…åŠ©æ‰‹ã€‚

## ç”¨æˆ·ç”»åƒ
{ctx['import_content']}

## å¯¹è¯è®°å½•
{ctx['normal_content']}

## å½“å‰æ—¶é—´
{ctx['current_time']}
"""
    
    messages = [SystemMessage(content=system_prompt), HumanMessage(content=user_question)]
    response = llm.invoke(messages)
    print(f"ğŸ¤– åŠ©æ‰‹: {response.content}")
    
    print("\nâœ“ æ¸è¿›å¼æ£€ç´¢æ¼”ç¤ºå®Œæˆ")


def demo_remote_memory_search():
    """æ–¹å¼5: è¿œæœŸè®°å¿†æ£€ç´¢ - ä½œä¸º Tool ä¾› LLM è°ƒç”¨"""
    print("\n" + "="*60)
    print("æ–¹å¼5: è¿œæœŸè®°å¿†æ£€ç´¢ï¼ˆsearch_conversations ä½œä¸º Toolï¼‰")
    print("="*60)
    
    from langchain.tools import tool
    
    memory = Mem1Memory(
        config,
        user_id=USER_ID + "_remote",
        topic_id="history_events",
        profile_template=YUQING_PROFILE_TEMPLATE
    )
    memory.delete_user()
    
    # æ¨¡æ‹Ÿæ·»åŠ "åŠå¹´å‰"çš„å¯¹è¯ï¼ˆå®é™…æ˜¯ä»Šå¤©ï¼Œæ¼”ç¤ºç”¨ï¼‰
    print("\næ·»åŠ æµ‹è¯•å¯¹è¯ï¼ˆæ¨¡æ‹Ÿå†å²æ•°æ®ï¼‰...")
    memory.add_conversation(messages=[
        {"role": "user", "content": "å»å¹´åŒåä¸€æœŸé—´å¤„ç†äº†156èµ·æ¶ˆè´¹æŠ•è¯‰èˆ†æƒ…ã€‚"},
        {"role": "assistant", "content": "å·²è®°å½•åŒåä¸€æ•°æ®ã€‚"}
    ])
    
    # å®šä¹‰ Tool
    @tool
    def search_memory(start_days: int, end_days: int) -> str:
        """æœç´¢ç”¨æˆ·å†å²å¯¹è¯è®°å½•ã€‚
        
        Args:
            start_days: èµ·å§‹å¤©æ•°ï¼ˆè·ä»Šå¤šå°‘å¤©ï¼Œè¾ƒè¿‘çš„ä¸€ç«¯ï¼‰
            end_days: ç»“æŸå¤©æ•°ï¼ˆè·ä»Šå¤šå°‘å¤©ï¼Œè¾ƒè¿œçš„ä¸€ç«¯ï¼‰
        
        ç¤ºä¾‹:
            search_memory(0, 7) - æœç´¢æœ€è¿‘7å¤©
            search_memory(170, 180) - æœç´¢çº¦åŠå¹´å‰çš„è®°å½•
        """
        convs = memory.search_conversations(start_days=start_days, end_days=end_days)
        if not convs:
            return "è¯¥æ—¶é—´æ®µæ— å¯¹è¯è®°å½•"
        return memory._format_conversations_for_llm(convs)
    
    print("\nå·²å®šä¹‰ search_memory Toolï¼Œå¯ä¾› LLM è°ƒç”¨")
    print(f"Tool æè¿°: {search_memory.description}")
    
    # æ¼”ç¤ºç›´æ¥è°ƒç”¨
    print("\nç›´æ¥è°ƒç”¨ç¤ºä¾‹:")
    print("  search_memory(0, 7) = æœ€è¿‘7å¤©çš„å¯¹è¯")
    result = search_memory.invoke({"start_days": 0, "end_days": 7})
    print(f"  ç»“æœ: {result[:100]}..." if len(result) > 100 else f"  ç»“æœ: {result}")
    
    print("\nâœ“ è¿œæœŸè®°å¿†æ£€ç´¢æ¼”ç¤ºå®Œæˆ")
    print("\næç¤º: å®é™…ä½¿ç”¨æ—¶ï¼Œå°† search_memory ç»‘å®šåˆ° LLMï¼Œè®© LLM æ ¹æ®ç”¨æˆ·é—®é¢˜è‡ªåŠ¨è°ƒç”¨")


if __name__ == "__main__":
    demo_manual_integration()
    # demo_chain_integration()
    # demo_with_image()
    # demo_progressive_retrieval()
    # demo_remote_memory_search()
