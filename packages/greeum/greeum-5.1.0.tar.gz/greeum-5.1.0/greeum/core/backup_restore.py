#!/usr/bin/env python3
"""
Greeum v2.6.1 - Memory Backup and Restore System
ì„ íƒì  ë³µì›ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œ ìœ ì—°í•œ ë°±ì—…/ë³µì› ì‹œìŠ¤í…œ
"""

import json
import os
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Optional, Dict, Any, Union
from pathlib import Path
import logging

# Legacy imports removed - using simplified structures
# from .memory_layer import MemoryItem, MemoryLayerType, MemoryPriority
# from .hierarchical_memory import HierarchicalMemorySystem

logger = logging.getLogger(__name__)


@dataclass
class RestoreFilter:
    """ë³µì› í•„í„° - ì„ íƒì  ë³µì›ì„ ìœ„í•œ ì¡°ê±´ ì„¤ì •"""
    
    date_from: Optional[datetime] = None
    date_to: Optional[datetime] = None
    keywords: Optional[List[str]] = None
    layers: Optional[List[str]] = None  # Changed from MemoryLayerType enum to strings
    importance_min: Optional[float] = None
    importance_max: Optional[float] = None
    tags: Optional[List[str]] = None
    
    def matches(self, memory_item: Dict[str, Any]) -> bool:
        """ë©”ëª¨ë¦¬ ì•„ì´í…œì´ í•„í„° ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸"""
        
        # ë‚ ì§œ ë²”ìœ„ ì²´í¬
        timestamp = memory_item.get('timestamp')
        if timestamp and isinstance(timestamp, str):
            timestamp = datetime.fromisoformat(timestamp)
        if self.date_from and timestamp and timestamp < self.date_from:
            return False
        if self.date_to and timestamp and timestamp > self.date_to:
            return False
            
        # í‚¤ì›Œë“œ ì²´í¬ (OR ì¡°ê±´)
        if self.keywords:
            content_lower = memory_item.get('content', '').lower()
            if not any(keyword.lower() in content_lower for keyword in self.keywords):
                return False
        
        # ê³„ì¸µ ì²´í¬
        if self.layers and memory_item.get('layer') not in self.layers:
            return False
            
        # ì¤‘ìš”ë„ ë²”ìœ„ ì²´í¬
        if self.importance_min and memory_item.importance < self.importance_min:
            return False
        if self.importance_max and memory_item.importance > self.importance_max:
            return False
            
        # íƒœê·¸ ì²´í¬ (OR ì¡°ê±´)
        if self.tags and memory_item.tags:
            if not any(tag in memory_item.tags for tag in self.tags):
                return False
        
        return True
    
    def is_full_restore(self) -> bool:
        """ëª¨ë“  ì¡°ê±´ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ ë³µì›"""
        return all([
            self.date_from is None,
            self.date_to is None,
            self.keywords is None or len(self.keywords) == 0,
            self.layers is None or len(self.layers) == 0,
            self.importance_min is None,
            self.importance_max is None,
            self.tags is None or len(self.tags) == 0
        ])
    
    def __str__(self) -> str:
        """í•„í„° ì¡°ê±´ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í‘œì‹œ"""
        conditions = []
        
        if self.date_from or self.date_to:
            date_range = f"{self.date_from or 'start'} ~ {self.date_to or 'end'}"
            conditions.append(f"[DATE] ë‚ ì§œ: {date_range}")
        
        if self.keywords:
            conditions.append(f"ğŸ” í‚¤ì›Œë“œ: {', '.join(self.keywords)}")
            
        if self.layers:
            layer_names = [layer.value for layer in self.layers]
            conditions.append(f"ğŸ“š ê³„ì¸µ: {', '.join(layer_names)}")
            
        if self.importance_min or self.importance_max:
            imp_range = f"{self.importance_min or 0.0} ~ {self.importance_max or 1.0}"
            conditions.append(f"â­ ì¤‘ìš”ë„: {imp_range}")
            
        if self.tags:
            conditions.append(f"ğŸ·ï¸  íƒœê·¸: {', '.join(self.tags)}")
        
        return "ì „ì²´ ë³µì›" if not conditions else "\n".join(conditions)


@dataclass 
class RestoreResult:
    """ë³µì› ê²°ê³¼ ì •ë³´"""
    
    success: bool
    total_processed: int = 0
    working_count: int = 0
    stm_count: int = 0
    ltm_count: int = 0
    skipped_count: int = 0
    error_count: int = 0
    conflicts_resolved: int = 0
    execution_time: float = 0.0
    errors: List[str] = None
    
    def __post_init__(self):
        if self.errors is None:
            self.errors = []


@dataclass
class BackupMetadata:
    """ë°±ì—… ë©”íƒ€ë°ì´í„°"""
    
    export_version: str
    timestamp: datetime
    total_memories: int
    greeum_version: str
    layers_info: Dict[str, int]
    source_system: str = "greeum"
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'BackupMetadata':
        data = data.copy()
        data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        return cls(**data)


class MemoryBackupEngine:
    """ë©”ëª¨ë¦¬ ë°±ì—… ì—”ì§„"""
    
    def __init__(self, hierarchical_system: HierarchicalMemorySystem):
        self.system = hierarchical_system
        
    def create_backup(self, output_path: str, include_metadata: bool = True) -> bool:
        """ì „ì²´ ë©”ëª¨ë¦¬ ë°±ì—… ìƒì„±"""
        try:
            backup_data = {
                "metadata": self._create_backup_metadata().to_dict(),
                "hierarchical_data": self._export_all_layers(),
            }
            
            if include_metadata:
                backup_data["system_metadata"] = {
                    "anchors": self._export_anchors(),
                    "statistics": self._export_statistics()
                }
            
            # ë°±ì—… íŒŒì¼ ì €ì¥
            backup_path = Path(output_path)
            backup_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ë°±ì—… ìƒì„± ì™„ë£Œ: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_backup_metadata(self) -> BackupMetadata:
        """ë°±ì—… ë©”íƒ€ë°ì´í„° ìƒì„±"""
        overview = self.system.get_system_overview()
        
        return BackupMetadata(
            export_version="2.6.1",
            timestamp=datetime.now(),
            total_memories=overview['total_memories'],
            greeum_version="2.6.1", 
            layers_info={
                layer_name: layer_info.get('total_count', 0) 
                for layer_name, layer_info in overview['layers'].items()
                if isinstance(layer_info, dict)
            }
        )
    
    def _export_all_layers(self) -> Dict[str, List[Dict]]:
        """ëª¨ë“  ê³„ì¸µì˜ ë©”ëª¨ë¦¬ ë‚´ë³´ë‚´ê¸°"""
        exported = {
            "working_memory": [],
            "stm": [],
            "ltm": []
        }
        
        try:
            # Working Memory ë‚´ë³´ë‚´ê¸°
            if hasattr(self.system, 'working_memory_adapter'):
                for memory_id, memory_item in self.system.working_memory_adapter.slot_to_memory.items():
                    exported["working_memory"].append(self._memory_to_dict(memory_item))
            
            # STM ë‚´ë³´ë‚´ê¸°  
            if hasattr(self.system, 'stm_layer'):
                for memory_id, memory_item in self.system.stm_layer.memory_cache.items():
                    exported["stm"].append(self._memory_to_dict(memory_item))
            
            # LTM ë‚´ë³´ë‚´ê¸° (BlockManager í†µí•´ì„œ)
            if hasattr(self.system, 'ltm_layer'):
                # LTMì€ ë¸”ë¡ ê¸°ë°˜ì´ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬ í•„ìš”
                ltm_memories = self._export_ltm_memories()
                exported["ltm"] = ltm_memories
                
        except Exception as e:
            logger.error(f"ê³„ì¸µ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
        
        return exported
    
    def _memory_to_dict(self, memory_item: MemoryItem) -> Dict[str, Any]:
        """MemoryItemì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "id": memory_item.id,
            "content": memory_item.content,
            "timestamp": memory_item.timestamp.isoformat() if memory_item.timestamp else None,
            "importance": memory_item.importance,
            "layer": memory_item.layer.value if memory_item.layer else None,
            "keywords": memory_item.keywords or [],
            "tags": memory_item.tags or [],
            "metadata": memory_item.metadata or {}
        }
    
    def _export_ltm_memories(self) -> List[Dict[str, Any]]:
        """LTM ë©”ëª¨ë¦¬ ë‚´ë³´ë‚´ê¸° (ë¸”ë¡ ê¸°ë°˜)"""
        ltm_memories = []
        try:
            # LTMì—ì„œ ëª¨ë“  ë¸”ë¡ ì¡°íšŒ
            if hasattr(self.system.ltm_layer, 'block_manager'):
                # BlockManagerì—ì„œ ëª¨ë“  ë¸”ë¡ ê°€ì ¸ì˜¤ê¸°
                all_blocks = self.system.ltm_layer.block_manager.get_all_blocks()
                for block in all_blocks:
                    ltm_memories.append({
                        "id": f"ltm_block_{block.get('block_index')}",
                        "content": block.get('context', ''),
                        "timestamp": block.get('timestamp', ''),
                        "importance": block.get('importance', 0.0),
                        "layer": "ltm",
                        "keywords": [],  # LTM í‚¤ì›Œë“œëŠ” ë³„ë„ í…Œì´ë¸”ì—ì„œ ì¡°íšŒ í•„ìš”
                        "tags": [],
                        "metadata": {
                            "block_index": block.get('block_index'),
                            "hash": block.get('hash'),
                            "prev_hash": block.get('prev_hash')
                        }
                    })
        except Exception as e:
            logger.error(f"LTM ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
        
        return ltm_memories
    
    def _export_anchors(self) -> Dict[str, Any]:
        """ì•µì»¤ ì •ë³´ ë‚´ë³´ë‚´ê¸°"""
        # TODO: ì•µì»¤ ì‹œìŠ¤í…œê³¼ ì—°ë™í•˜ì—¬ ì•µì»¤ ì •ë³´ ë‚´ë³´ë‚´ê¸°
        return {}
    
    def _export_statistics(self) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ë‚´ë³´ë‚´ê¸°"""
        try:
            return self.system.get_system_overview()
        except Exception as e:
            logger.error(f"í†µê³„ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
            return {}


class MemoryRestoreEngine:
    """ë©”ëª¨ë¦¬ ë³µì› ì—”ì§„"""
    
    def __init__(self, hierarchical_system: HierarchicalMemorySystem):
        self.system = hierarchical_system
        
    def restore_from_backup(
        self, 
        backup_file: str, 
        filter_config: RestoreFilter,
        merge_mode: bool = False,
        dry_run: bool = False
    ) -> RestoreResult:
        """
        ë©”ëª¨ë¦¬ ë³µì› ì‹¤í–‰
        
        Args:
            backup_file: ë°±ì—… íŒŒì¼ ê²½ë¡œ
            filter_config: ë³µì› í•„í„° ì„¤ì •
            merge_mode: Trueë©´ ê¸°ì¡´ ë°ì´í„°ì™€ ë³‘í•©, Falseë©´ êµì²´
            dry_run: Trueë©´ ì‹¤ì œë¡œ ë³µì›í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ
        """
        start_time = datetime.now()
        result = RestoreResult(success=False)
        
        try:
            # ë°±ì—… íŒŒì¼ ë¡œë“œ
            backup_data = self._load_backup(backup_file)
            if not backup_data:
                result.errors.append("ë°±ì—… íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
                return result
            
            # í˜¸í™˜ì„± ê²€ì¦
            if not self._validate_compatibility(backup_data):
                result.errors.append("ë°±ì—… íŒŒì¼ í˜¸í™˜ì„± ì˜¤ë¥˜")
                return result
            
            # í•„í„° ì ìš©í•˜ì—¬ ë³µì› ëŒ€ìƒ ì„ ë³„
            filtered_memories = self._apply_filters(backup_data, filter_config)
            
            if dry_run:
                return self._generate_preview(filtered_memories, result)
            
            # ì‹¤ì œ ë³µì› ì‹¤í–‰
            if not merge_mode:
                self._clear_existing_data(filter_config)
            
            result = self._restore_memories(filtered_memories, merge_mode, result)
            result.success = True
            
        except Exception as e:
            logger.error(f"ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")
            result.errors.append(str(e))
            
        finally:
            result.execution_time = (datetime.now() - start_time).total_seconds()
        
        return result
    
    def _load_backup(self, backup_file: str) -> Optional[Dict[str, Any]]:
        """ë°±ì—… íŒŒì¼ ë¡œë“œ"""
        try:
            with open(backup_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"ë°±ì—… íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    
    def _validate_compatibility(self, backup_data: Dict[str, Any]) -> bool:
        """ë°±ì—… í˜¸í™˜ì„± ê²€ì¦"""
        try:
            metadata = backup_data.get('metadata', {})
            export_version = metadata.get('export_version', '')
            
            # ë²„ì „ í˜¸í™˜ì„± ì²´í¬ (2.6.x ì‹œë¦¬ì¦ˆëŠ” ìƒí˜¸ í˜¸í™˜)
            if export_version.startswith('2.6'):
                return True
            
            # í–¥í›„ ë²„ì „ í˜¸í™˜ì„± ë¡œì§ ì¶”ê°€
            logger.warning(f"ë°±ì—… ë²„ì „ {export_version}ì€ ì™„ì „í•œ í˜¸í™˜ì„±ì´ ë³´ì¥ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
            return True  # ì¼ë‹¨ í—ˆìš©, ì¶”í›„ ì—„ê²©í•˜ê²Œ ë³€ê²½ ê°€ëŠ¥
            
        except Exception as e:
            logger.error(f"í˜¸í™˜ì„± ê²€ì¦ ì˜¤ë¥˜: {e}")
            return False
    
    def _apply_filters(self, backup_data: Dict[str, Any], filter_config: RestoreFilter) -> Dict[str, List[Dict]]:
        """í•„í„° ì¡°ê±´ì— ë§ëŠ” ë©”ëª¨ë¦¬ë§Œ ì„ ë³„"""
        hierarchical_data = backup_data.get('hierarchical_data', {})
        
        if filter_config.is_full_restore():
            return hierarchical_data
        
        filtered = {'working_memory': [], 'stm': [], 'ltm': []}
        
        for layer_name, memories in hierarchical_data.items():
            if layer_name not in filtered:
                continue
                
            for memory_data in memories:
                memory_item = self._dict_to_memory_item(memory_data)
                if filter_config.matches(memory_item):
                    filtered[layer_name].append(memory_data)
        
        return filtered
    
    def _dict_to_memory_item(self, memory_data: Dict[str, Any]) -> MemoryItem:
        """ë”•ì…”ë„ˆë¦¬ë¥¼ MemoryItemìœ¼ë¡œ ë³€í™˜"""
        layer_str = memory_data.get('layer', 'working')
        layer = MemoryLayerType.WORKING
        if layer_str == 'stm':
            layer = MemoryLayerType.STM
        elif layer_str == 'ltm':
            layer = MemoryLayerType.LTM
            
        timestamp_str = memory_data.get('timestamp')
        timestamp = None
        if timestamp_str:
            try:
                timestamp = datetime.fromisoformat(timestamp_str)
            except:
                timestamp = datetime.now()
        
        # Determine priority from importance score
        importance_score = memory_data.get('importance', 0.0)
        if importance_score >= 0.9:
            priority = MemoryPriority.CRITICAL
        elif importance_score >= 0.7:
            priority = MemoryPriority.HIGH
        elif importance_score >= 0.5:
            priority = MemoryPriority.MEDIUM
        elif importance_score >= 0.3:
            priority = MemoryPriority.LOW
        else:
            priority = MemoryPriority.DISPOSABLE
        
        return MemoryItem(
            id=memory_data.get('id', ''),
            content=memory_data.get('content', ''),
            timestamp=timestamp,
            layer=layer,
            priority=priority,
            metadata=memory_data.get('metadata', {}),
            keywords=memory_data.get('keywords', []),
            tags=memory_data.get('tags', []),
            embedding=memory_data.get('embedding', []),
            importance=importance_score
        )
    
    def _generate_preview(self, filtered_memories: Dict[str, List[Dict]], result: RestoreResult) -> RestoreResult:
        """ë³µì› ë¯¸ë¦¬ë³´ê¸° ìƒì„±"""
        result.working_count = len(filtered_memories.get('working_memory', []))
        result.stm_count = len(filtered_memories.get('stm', []))
        result.ltm_count = len(filtered_memories.get('ltm', []))
        result.total_processed = result.working_count + result.stm_count + result.ltm_count
        result.success = True
        
        return result
    
    def _clear_existing_data(self, filter_config: RestoreFilter):
        """ê¸°ì¡´ ë°ì´í„° ì‚­ì œ (êµì²´ ëª¨ë“œ)"""
        # í•„í„° ì¡°ê±´ì— ë§ëŠ” ê¸°ì¡´ ë°ì´í„°ë§Œ ì‚­ì œ
        # TODO: êµ¬í˜„ í•„ìš” - ì„ íƒì  ì‚­ì œ ë¡œì§
        logger.info("êµì²´ ëª¨ë“œ: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì‹œì‘")
        pass
    
    def _restore_memories(
        self, 
        filtered_memories: Dict[str, List[Dict]], 
        merge_mode: bool,
        result: RestoreResult
    ) -> RestoreResult:
        """ì‹¤ì œ ë©”ëª¨ë¦¬ ë³µì› ìˆ˜í–‰"""
        
        try:
            # Working Memory ë³µì›
            for memory_data in filtered_memories.get('working_memory', []):
                try:
                    memory_item = self._dict_to_memory_item(memory_data)
                    success = self._restore_to_working_memory(memory_item, merge_mode)
                    if success:
                        result.working_count += 1
                    else:
                        result.error_count += 1
                except Exception as e:
                    result.errors.append(f"Working Memory ë³µì› ì˜¤ë¥˜: {e}")
                    result.error_count += 1
            
            # STM ë³µì›
            for memory_data in filtered_memories.get('stm', []):
                try:
                    memory_item = self._dict_to_memory_item(memory_data)
                    success = self._restore_to_stm(memory_item, merge_mode)
                    if success:
                        result.stm_count += 1
                    else:
                        result.error_count += 1
                except Exception as e:
                    result.errors.append(f"STM ë³µì› ì˜¤ë¥˜: {e}")
                    result.error_count += 1
            
            # LTM ë³µì›
            for memory_data in filtered_memories.get('ltm', []):
                try:
                    success = self._restore_to_ltm(memory_data, merge_mode)
                    if success:
                        result.ltm_count += 1
                    else:
                        result.error_count += 1
                except Exception as e:
                    result.errors.append(f"LTM ë³µì› ì˜¤ë¥˜: {e}")
                    result.error_count += 1
            
            result.total_processed = result.working_count + result.stm_count + result.ltm_count
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ë³µì› ì¤‘ ì˜¤ë¥˜: {e}")
            result.errors.append(str(e))
        
        return result
    
    def _restore_to_working_memory(self, memory_item: MemoryItem, merge_mode: bool) -> bool:
        """Working Memoryë¡œ ë³µì›"""
        try:
            if hasattr(self.system, 'working_memory_adapter'):
                # ì¤‘ë³µ ì²´í¬ (merge_modeì—ì„œ)
                if merge_mode and self._is_duplicate_in_working(memory_item):
                    return False
                
                # Working Memoryì— ì¶”ê°€
                self.system.working_memory_adapter.slot_to_memory[memory_item.id] = memory_item
                self.system.working_memory_adapter.memory_to_slot[memory_item.id] = memory_item.id
                return True
        except Exception as e:
            logger.error(f"Working Memory ë³µì› ì˜¤ë¥˜: {e}")
        return False
    
    def _restore_to_stm(self, memory_item: MemoryItem, merge_mode: bool) -> bool:
        """STMìœ¼ë¡œ ë³µì›"""
        try:
            if hasattr(self.system, 'stm_layer'):
                # ì¤‘ë³µ ì²´í¬ (merge_modeì—ì„œ)
                if merge_mode and memory_item.id in self.system.stm_layer.memory_cache:
                    return False
                
                # STMì— ì¶”ê°€
                memory_item.layer = MemoryLayerType.STM
                return self.system.stm_layer.add_memory(memory_item) is not None
        except Exception as e:
            logger.error(f"STM ë³µì› ì˜¤ë¥˜: {e}")
        return False
    
    def _restore_to_ltm(self, memory_data: Dict[str, Any], merge_mode: bool) -> bool:
        """LTMìœ¼ë¡œ ë³µì›"""
        try:
            if hasattr(self.system, 'ltm_layer'):
                # LTMì€ ë¸”ë¡ ê¸°ë°˜ì´ë¯€ë¡œ íŠ¹ë³„í•œ ì²˜ë¦¬ í•„ìš”
                content = memory_data.get('content', '')
                importance = memory_data.get('importance', 0.0)
                
                # ì¤‘ë³µ ì²´í¬ëŠ” content ê¸°ë°˜ìœ¼ë¡œ (merge_modeì—ì„œ)
                if merge_mode:
                    # TODO: LTM ì¤‘ë³µ ì²´í¬ ë¡œì§ êµ¬í˜„
                    pass
                
                # LTM ë¸”ë¡ìœ¼ë¡œ ì¶”ê°€
                block_id = self.system.ltm_layer.add_memory_block(
                    content=content,
                    importance=importance,
                    keywords=memory_data.get('keywords', []),
                    tags=memory_data.get('tags', [])
                )
                return block_id is not None
        except Exception as e:
            logger.error(f"LTM ë³µì› ì˜¤ë¥˜: {e}")
        return False
    
    def _is_duplicate_in_working(self, memory_item: MemoryItem) -> bool:
        """Working Memoryì—ì„œ ì¤‘ë³µ ì²´í¬"""
        try:
            if hasattr(self.system, 'working_memory_adapter'):
                for existing_memory in self.system.working_memory_adapter.slot_to_memory.values():
                    if existing_memory.content == memory_item.content:
                        return True
        except Exception as e:
            logger.error(f"Working Memory ì¤‘ë³µ ì²´í¬ ì˜¤ë¥˜: {e}")
        return False
    
    def preview_restore(self, backup_file: str, filter_config: RestoreFilter) -> str:
        """ë³µì› ì „ ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸ ìƒì„±"""
        preview_result = self.restore_from_backup(backup_file, filter_config, dry_run=True)
        
        if not preview_result.success:
            return f"[ERROR] ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨:\n" + "\n".join(preview_result.errors)
        
        return f"""
ğŸ“‹ ë³µì› ë¯¸ë¦¬ë³´ê¸°
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š ë³µì› ëŒ€ìƒ: {preview_result.total_processed}ê°œ ë©”ëª¨ë¦¬
   [MEMORY] Working Memory: {preview_result.working_count}ê°œ
   [FAST] STM: {preview_result.stm_count}ê°œ  
   ğŸ›ï¸  LTM: {preview_result.ltm_count}ê°œ

ğŸ” í•„í„° ì¡°ê±´:
{filter_config}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n)
"""


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    print("ğŸ”§ Greeum v2.6.1 Backup/Restore System")
    print("RestoreFilter, BackupEngine, RestoreEngineì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!")