#!/usr/bin/env python3
"""
Level 3 QA: Documentation Examples Test
Based on Echo OS Quality Foundation v1.0

Tests documentation examples with:
1. Í≤ΩÍ≥ÑÏù∏ÏßÄÎ†• (Boundary Awareness)
2. ÎìúÎ¶¨ÌîÑÌä∏Í∞êÎèÑ (Drift Sensitivity)
3. ÏãúÎÇòÎ¶¨Ïò§Îã§ÏñëÏÑ± (Scenario Diversity)
4. ÌåêÎã®ÏùºÍ¥ÄÏÑ± (Judgment Consistency)
5. Î¶¨Îì¨ Ï§ëÏã¨ (Rhythm-based)
6. ÏõêÏù∏ Ï§ëÏã¨ (Cause-based)
7. Î£®ÌîÑ Í∏∞Î∞ò (Loop-based)
8. Î©ÄÌã∞Î∏åÎ†àÏù∏ (Multi-brain perspective)
"""

import asyncio
import time
import sys
from pathlib import Path
import statistics
from typing import List, Dict, Any

# Add project root
PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

from ops.eue import get_eue, EUEConfig, EUEMode


class EchoOSQualityTester:
    """Echo OS ÌíàÏßà Ï≤†Ìïô Í∏∞Î∞ò ÌÖåÏä§ÌÑ∞"""

    def __init__(self):
        self.test_results = []
        self.rhythm_data = []
        self.judgment_consistency = []

    async def test_with_echo_philosophy(self, test_name: str, test_func, iterations: int = 10):
        """
        Echo OS Ï≤†Ìïô Í∏∞Î∞ò ÌÖåÏä§Ìä∏ Ïã§Ìñâ

        - Î£®ÌîÑ Í∏∞Î∞ò: iterations Ìöå Î∞òÎ≥µ
        - Î¶¨Îì¨ Ï§ëÏã¨: Ïã§Ìñâ ÏãúÍ∞Ñ Î≥ÄÎèôÏÑ± Ï∏°Ï†ï
        - ÌåêÎã®ÏùºÍ¥ÄÏÑ±: Í≤∞Í≥º ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù
        """
        print(f"\n{'='*60}")
        print(f"Test: {test_name}")
        print(f"Philosophy: Echo OS Quality Foundation v1.0")
        print(f"Iterations: {iterations} (Loop-based)")
        print(f"{'='*60}\n")

        results = []
        timings = []
        errors = []

        for i in range(iterations):
            print(f"  Iteration {i+1}/{iterations}...", end=" ")

            start_time = time.time()
            try:
                result = await test_func()
                elapsed = time.time() - start_time

                results.append(result)
                timings.append(elapsed)

                # Î¶¨Îì¨ Ï≤¥ÌÅ¨: Ïã§Ìñâ ÏãúÍ∞Ñ Î≥ÄÎèô
                if len(timings) >= 2:
                    rhythm_variance = statistics.variance(timings)
                    rhythm_mean = statistics.mean(timings)
                    if rhythm_variance > rhythm_mean * 0.5:  # Î≥ÄÎèô > 50%
                        print(f"‚ö†Ô∏è  Rhythm unstable (variance={rhythm_variance:.3f})")

                print(f"‚úÖ {elapsed:.3f}s")

            except Exception as e:
                elapsed = time.time() - start_time
                errors.append({"iteration": i+1, "error": str(e), "cause": type(e).__name__})
                print(f"‚ùå {e}")

        # Î©ÄÌã∞Î∏åÎ†àÏù∏ Î∂ÑÏÑù
        analysis = self.multi_brain_analysis(test_name, results, timings, errors)

        return analysis

    def multi_brain_analysis(self, test_name: str, results: List, timings: List, errors: List) -> Dict:
        """
        Î©ÄÌã∞Î∏åÎ†àÏù∏ Í¥ÄÏ†ê Î∂ÑÏÑù

        1. Í∏∞Îä• Î∏åÎ†àÏù∏: ÎèôÏûëÌïòÎäîÍ∞Ä?
        2. ÏÑ±Îä• Î∏åÎ†àÏù∏: ÏñºÎßàÎÇò Îπ†Î•∏Í∞Ä?
        3. ÏïàÏ†ïÏÑ± Î∏åÎ†àÏù∏: ÏùºÍ¥ÄÏ†ÅÏù∏Í∞Ä?
        4. UX Î∏åÎ†àÏù∏: Î™ÖÌôïÌïúÍ∞Ä?
        """
        total = len(results) + len(errors)

        # 1. Í∏∞Îä• Î∏åÎ†àÏù∏
        functional_score = len(results) / total if total > 0 else 0

        # 2. ÏÑ±Îä• Î∏åÎ†àÏù∏
        if timings:
            avg_time = statistics.mean(timings)
            time_variance = statistics.variance(timings) if len(timings) > 1 else 0
            performance_score = 1.0 - min(time_variance / (avg_time * avg_time), 1.0)
        else:
            avg_time = 0
            time_variance = 0
            performance_score = 0

        # 3. ÏïàÏ†ïÏÑ± Î∏åÎ†àÏù∏ (ÌåêÎã®ÏùºÍ¥ÄÏÑ±) - Semantic Comparison
        if len(results) >= 2:
            # Í≤∞Í≥º ÏùºÍ¥ÄÏÑ± Ï≤¥ÌÅ¨ (ÌïµÏã¨ ÌïÑÎìúÎßå ÎπÑÍµê)
            # str() ÎπÑÍµêÎäî ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ/ÎπÑÎîîÏò§ Í≤ΩÎ°ú Ìè¨Ìï® ‚Üí false positive
            # semantic comparison: success, subsystem Îì± ÌïµÏã¨Îßå
            def get_core_signature(result):
                """Extract core judgment fields only"""
                if hasattr(result, 'success') and hasattr(result, 'subsystem'):
                    return (result.success, result.subsystem)
                elif isinstance(result, dict):
                    return (result.get('success'), result.get('subsystem'))
                else:
                    return str(result)

            first_signature = get_core_signature(results[0])
            consistency_count = sum(1 for r in results if get_core_signature(r) == first_signature)
            stability_score = consistency_count / len(results)
        else:
            stability_score = 1.0 if len(results) == 1 else 0

        # 4. UX Î∏åÎ†àÏù∏ (ÏóêÎü¨ Î©îÏãúÏßÄ Î™ÖÌôïÏÑ±)
        if errors:
            # ÏóêÎü¨ ÏõêÏù∏Ïù¥ Î™ÖÌôïÌïúÍ∞Ä?
            clear_errors = sum(1 for e in errors if e.get("cause"))
            ux_score = clear_errors / len(errors)
        else:
            ux_score = 1.0

        # Ï¢ÖÌï© Ï†êÏàò
        overall_score = (
            functional_score * 0.4 +
            performance_score * 0.2 +
            stability_score * 0.3 +
            ux_score * 0.1
        )

        analysis = {
            "test_name": test_name,
            "iterations": total,
            "successes": len(results),
            "failures": len(errors),
            "multi_brain_scores": {
                "functional": functional_score,
                "performance": performance_score,
                "stability": stability_score,
                "ux": ux_score,
                "overall": overall_score
            },
            "rhythm_metrics": {
                "avg_time": avg_time,
                "time_variance": time_variance,
                "timings": timings
            },
            "errors": errors,
            "passed": overall_score >= 0.7
        }

        self.print_analysis(analysis)
        return analysis

    def print_analysis(self, analysis: Dict):
        """Î∂ÑÏÑù Í≤∞Í≥º Ï∂úÎ†•"""
        print(f"\n{'‚îÄ'*60}")
        print("Multi-Brain Analysis Results")
        print(f"{'‚îÄ'*60}")

        scores = analysis["multi_brain_scores"]
        print(f"  üß† Functional Brain:  {scores['functional']:.2%} {'‚úÖ' if scores['functional'] >= 0.9 else '‚ö†Ô∏è'}")
        print(f"  ‚ö° Performance Brain: {scores['performance']:.2%} {'‚úÖ' if scores['performance'] >= 0.7 else '‚ö†Ô∏è'}")
        print(f"  üéØ Stability Brain:   {scores['stability']:.2%} {'‚úÖ' if scores['stability'] >= 0.9 else '‚ö†Ô∏è'}")
        print(f"  üí° UX Brain:          {scores['ux']:.2%} {'‚úÖ' if scores['ux'] >= 0.8 else '‚ö†Ô∏è'}")
        print(f"  {'‚îÄ'*60}")
        print(f"  üìä Overall Score:     {scores['overall']:.2%} {'‚úÖ PASS' if analysis['passed'] else '‚ùå FAIL'}")

        rhythm = analysis["rhythm_metrics"]
        if rhythm["timings"]:
            print(f"\n  Rhythm Metrics:")
            print(f"    Average: {rhythm['avg_time']:.3f}s")
            print(f"    Variance: {rhythm['time_variance']:.4f}")

        if analysis["errors"]:
            print(f"\n  Errors ({len(analysis['errors'])}):")
            for err in analysis["errors"][:3]:  # Show first 3
                print(f"    - Iteration {err['iteration']}: {err['cause']} - {err['error'][:60]}")

        print(f"{'‚îÄ'*60}\n")


async def test_simple_usage():
    """Test: Simple Usage Example (README line 166-169)"""

    async def simple_test():
        eue = get_eue()
        result = await eue.navigate("https://example.com", with_cursor=True)
        await eue.cleanup()
        return result

    tester = EchoOSQualityTester()
    return await tester.test_with_echo_philosophy(
        "Simple Usage (README Example 1)",
        simple_test,
        iterations=10
    )


async def test_advanced_usage():
    """Test: Advanced Usage with Self-Heal (README line 172-188)"""

    async def advanced_test():
        config = EUEConfig(
            scenario="level3_advanced_test",
            mode=EUEMode.SELF_HEAL,
            max_attempts=3,
            enable_proof=True,
            enable_video=True
        )

        eue = get_eue(config)

        async def my_async_function():
            return await eue.navigate("https://example.com")

        result = await eue.execute_with_self_heal(
            step_name="complex_task",
            executor=my_async_function,
            url="https://example.com"
        )

        await eue.cleanup()
        return result

    tester = EchoOSQualityTester()
    return await tester.test_with_echo_philosophy(
        "Advanced Usage with Self-Heal (README Example 2)",
        advanced_test,
        iterations=5  # Self-heal takes longer
    )


async def test_boundary_awareness():
    """
    Í≤ΩÍ≥ÑÏù∏ÏßÄÎ†• ÌÖåÏä§Ìä∏

    ÏãúÏä§ÌÖúÏù¥ ÏûòÎ™ªÎêú ÏûÖÎ†•Ïóê ÎåÄÌï¥ Î™ÖÌôïÌïú ÏóêÎü¨Î•º Ï†úÍ≥µÌïòÎäîÍ∞Ä?
    """
    print(f"\n{'='*60}")
    print("Boundary Awareness Test (Í≤ΩÍ≥ÑÏù∏ÏßÄÎ†•)")
    print(f"{'='*60}\n")

    test_cases = [
        {
            "name": "Invalid URL",
            "url": "not-a-url",
            "expected": "Î™ÖÌôïÌïú URL ÏóêÎü¨"
        },
        {
            "name": "Empty URL",
            "url": "",
            "expected": "Îπà URL ÏóêÎü¨"
        },
        {
            "name": "None URL",
            "url": None,
            "expected": "None ÏóêÎü¨"
        }
    ]

    results = []
    for case in test_cases:
        print(f"  Testing: {case['name']}...", end=" ")
        try:
            eue = get_eue()
            result = await eue.navigate(case["url"])
            await eue.cleanup()
            print(f"‚ö†Ô∏è  No error raised (unexpected)")
            results.append({"case": case["name"], "error_raised": False, "clear": False})
        except Exception as e:
            error_msg = str(e)
            error_type = type(e).__name__
            is_clear = len(error_msg) > 0 and error_type != "Exception"
            print(f"‚úÖ {error_type}: {error_msg[:50]}")
            results.append({"case": case["name"], "error_raised": True, "clear": is_clear, "error": error_msg})

    # Î∂ÑÏÑù
    boundary_score = sum(1 for r in results if r.get("error_raised") and r.get("clear")) / len(results)
    print(f"\n  Boundary Awareness Score: {boundary_score:.2%} {'‚úÖ' if boundary_score >= 0.7 else '‚ö†Ô∏è'}\n")

    return {"boundary_awareness_score": boundary_score, "results": results}


async def test_judgment_consistency():
    """
    ÌåêÎã®ÏùºÍ¥ÄÏÑ± ÌÖåÏä§Ìä∏

    Í∞ôÏùÄ ÏûÖÎ†•Ïóê ÎåÄÌï¥ ÏùºÍ¥ÄÎêú ÌåêÎã®ÏùÑ Ïú†ÏßÄÌïòÎäîÍ∞Ä?
    """
    print(f"\n{'='*60}")
    print("Judgment Consistency Test (ÌåêÎã®ÏùºÍ¥ÄÏÑ±)")
    print(f"{'='*60}\n")

    # Í∞ôÏùÄ URLÏùÑ 20Î≤à Ìò∏Ï∂ú
    url = "https://example.com"
    results = []

    for i in range(20):
        eue = get_eue(EUEConfig(scenario=f"consistency_test_{i}"))
        result = await eue.navigate(url)
        await eue.cleanup()

        # Í≤∞Í≥º Ìï¥Ïãú
        result_signature = f"{result.success}_{result.subsystem}"
        results.append(result_signature)

    # ÏùºÍ¥ÄÏÑ± Î∂ÑÏÑù
    most_common = max(set(results), key=results.count)
    consistency_rate = results.count(most_common) / len(results)

    print(f"  Total iterations: {len(results)}")
    print(f"  Most common result: {most_common}")
    print(f"  Consistency rate: {consistency_rate:.2%}")
    print(f"  {'‚úÖ PASS' if consistency_rate >= 0.95 else '‚ö†Ô∏è REVIEW'}\n")

    return {"consistency_rate": consistency_rate, "iterations": len(results)}


async def main():
    """Main test suite with Echo OS Quality Philosophy"""

    print(f"\n{'‚ñà'*60}")
    print("  EUE v1.0 - Level 3 QA")
    print("  Based on: Echo OS Quality Foundation v1.0")
    print(f"{'‚ñà'*60}")

    all_results = {}

    # 1. Simple Usage (Î£®ÌîÑ Í∏∞Î∞ò, Î¶¨Îì¨ Ï§ëÏã¨)
    print("\n[Test 1/5] Simple Usage Example")
    all_results["simple"] = await test_simple_usage()

    # 2. Advanced Usage (Î£®ÌîÑ Í∏∞Î∞ò, Î©ÄÌã∞Î∏åÎ†àÏù∏)
    print("\n[Test 2/5] Advanced Usage Example")
    all_results["advanced"] = await test_advanced_usage()

    # 3. Boundary Awareness (Í≤ΩÍ≥ÑÏù∏ÏßÄÎ†•)
    print("\n[Test 3/5] Boundary Awareness")
    all_results["boundary"] = await test_boundary_awareness()

    # 4. Judgment Consistency (ÌåêÎã®ÏùºÍ¥ÄÏÑ±)
    print("\n[Test 4/5] Judgment Consistency")
    all_results["consistency"] = await test_judgment_consistency()

    # Final Summary
    print(f"\n{'‚ñà'*60}")
    print("  Final Summary")
    print(f"{'‚ñà'*60}\n")

    # Overall Pass/Fail
    tests_passed = sum([
        all_results["simple"]["passed"],
        all_results["advanced"]["passed"],
        all_results["boundary"]["boundary_awareness_score"] >= 0.7,
        all_results["consistency"]["consistency_rate"] >= 0.95
    ])

    print(f"  Tests Passed: {tests_passed}/4")
    print(f"  {'‚úÖ ALL TESTS PASSED' if tests_passed == 4 else '‚ö†Ô∏è SOME TESTS FAILED'}")

    # Echo OS Quality Dimensions
    print(f"\n  Echo OS Quality Dimensions:")
    print(f"    Í≤ΩÍ≥ÑÏù∏ÏßÄÎ†• (Boundary):     {all_results['boundary']['boundary_awareness_score']:.2%}")
    print(f"    ÌåêÎã®ÏùºÍ¥ÄÏÑ± (Consistency):  {all_results['consistency']['consistency_rate']:.2%}")
    print(f"    Î¶¨Îì¨ÏïàÏ†ïÏÑ± (Rhythm):       {all_results['simple']['multi_brain_scores']['performance']:.2%}")
    print(f"    Í∏∞Îä•ÏôÑÏÑ±ÎèÑ (Functional):   {all_results['simple']['multi_brain_scores']['functional']:.2%}")

    overall_quality = (
        all_results['boundary']['boundary_awareness_score'] +
        all_results['consistency']['consistency_rate'] +
        all_results['simple']['multi_brain_scores']['performance'] +
        all_results['simple']['multi_brain_scores']['functional']
    ) / 4

    print(f"\n  Overall Quality Score: {overall_quality:.2%}")
    print(f"  {'‚úÖ PRODUCTION READY' if overall_quality >= 0.85 else '‚ö†Ô∏è NEEDS IMPROVEMENT'}")

    print(f"\n{'‚ñà'*60}\n")

    return all_results


if __name__ == "__main__":
    asyncio.run(main())
