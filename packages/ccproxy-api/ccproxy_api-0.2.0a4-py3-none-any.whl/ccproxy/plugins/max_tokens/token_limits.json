{
  "claude-opus-4-1-20250805": {
    "max_output_tokens": 32000,
    "max_input_tokens": 200000
  },
  "claude-opus-4-20250514": {
    "max_output_tokens": 32000,
    "max_input_tokens": 200000
  },
  "claude-sonnet-4-20250514": {
    "max_output_tokens": 64000,
    "max_input_tokens": 1000000
  },
  "claude-3-7-sonnet-20250219": {
    "max_output_tokens": 8192,
    "max_input_tokens": 200000
  },
  "claude-3-5-sonnet-20241022": {
    "max_output_tokens": 8192,
    "max_input_tokens": 200000
  },
  "claude-3-5-haiku-20241022": {
    "max_output_tokens": 8192,
    "max_input_tokens": 200000
  },
  "claude-3-opus-20240229": {
    "max_output_tokens": 4096,
    "max_input_tokens": 200000
  },
  "claude-3-sonnet-20240229": {
    "max_output_tokens": 4096,
    "max_input_tokens": 200000
  },
  "claude-3-haiku-20240307": {
    "max_output_tokens": 4096,
    "max_input_tokens": 200000
  },
  "gpt-5": {
    "max_output_tokens": 128000,
    "max_input_tokens": 272000
  },
  "gpt-5-codex": {
    "max_output_tokens": 128000,
    "max_input_tokens": 272000
  },
  "_metadata": {
    "source": "generated from ~/.cache/ccproxy/model_pricing.json",
    "claude_models_count": 9,
    "codex_models_count": 2,
    "total_models": 11,
    "generated_for": "max_tokens plugin enforce mode support",
    "note": "Flat structure format, uses simple model names for compatibility with request handling"
  }
}
