# -*- coding: utf-8 -*-
"""image2biomass.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nJgCTJkFuJr7-Pf3tL6BUErwFZMgfkvr
"""

from google.colab import drive
drive.mount("/content/drive")

"""# 1.0 Preprocessing 1: Tabular Data"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

train=pd.read_csv("/content/drive/MyDrive/csiro-biomass/train.csv")

"""## 2.0 Original Featurization"""

train["Sampling_Date"]=pd.to_datetime(train["Sampling_Date"])
train["Month"]=train["Sampling_Date"].dt.month
train["Day"]=train["Sampling_Date"].dt.day
train["DayOfYear"]=train["Sampling_Date"].dt.dayofyear
train["DayOfWeek"]=train["Sampling_Date"].dt.dayofweek

def get_season_southern(month):
  if month in [12,1,2]:
    return "Summer"
  elif month in [3,4,5]:
    return "Fall"
  elif month in [6,7,8]:
    return "Winter"
  else:
    return "Spring"

train["Season"]=train["Month"].apply(get_season_southern)

train["image_id"]=train["sample_id"].str.split("__").str[0]
wide_train=train.pivot_table(index=["image_id","image_path","Sampling_Date","State","Species",
                                    "Pre_GSHH_NDVI","Height_Ave_cm","Month","Day","DayOfYear","DayOfWeek"],columns="target_name",values="target").reset_index()
wide_train.set_index('image_id',inplace=True)
wide_train.head()

wide_train.info()

X=wide_train[["Pre_GSHH_NDVI","Height_Ave_cm","State","Species","Month","Day","DayOfYear","DayOfWeek"]]

from sklearn.preprocessing import LabelEncoder
le_map_train = {}
from sklearn.preprocessing import LabelEncoder
for col in ["State","Species"]:
  le = LabelEncoder()
  X[col] = le.fit_transform(X[col].astype(str))
  le_map_train[col] = le

y=wide_train["Dry_Clover_g"]
# Prepare multi-targets for model training: predict Green, Dead, Clover
# and compute derived targets (GDM, Dry_Total) from these predictions later.
y_multi = wide_train[["Dry_Green_g","Dry_Dead_g","Dry_Clover_g"]].reset_index(drop=True)
wide_train["GDM_g"] = wide_train["Dry_Green_g"] + wide_train["Dry_Clover_g"]
wide_train["Dry_Total_g"] = wide_train[["Dry_Green_g","Dry_Dead_g","Dry_Clover_g"]].sum(axis=1)

"""## 2.1 MI Measurement 1"""

from sklearn.feature_selection import mutual_info_regression
from sklearn.preprocessing import StandardScaler

scaler=StandardScaler()
X_preprocessed=scaler.fit_transform(X)

ori_mi_scores=mutual_info_regression(X_preprocessed,y,random_state=42)
mi_df=pd.DataFrame({'Feature':X.columns,'Mutual_Information':ori_mi_scores}).sort_values(by="Mutual_Information",ascending=False)

print(mi_df)

!pip install chekml

"""# 3.0 Chek's Featurization

## 3.1.0 InequalityFeaturizer
"""

X["target"] = y

from sklearn.model_selection import train_test_split
from chekml.featurization import InequalityFeaturizerSlow

# Create a reproducible train/validation split of the tabular data
# Keep the target column present for featurizers that expect it
X_train_tab, X_val_tab = train_test_split(X, test_size=0.2, random_state=42)

def _validate_features(df_feat, name="features", min_unique=2, impute=True):
  # Basic validations to ensure featurizer output is usable.
  # Returns (clean_df, imputed_columns_list)
  if df_feat is None:
    raise ValueError(f"{name} is None")
  if not isinstance(df_feat, (pd.DataFrame,)):
    raise TypeError(f"{name} must be a pandas DataFrame")
  n_rows, n_cols = df_feat.shape
  if n_rows == 0:
    raise ValueError(f"{name} has zero rows")

  # NaN handling: optionally impute, otherwise raise
  nan_counts = df_feat.isna().sum()
  total_nans = nan_counts.sum()
  imputed_cols = []
  if total_nans > 0:
    if not impute:
      raise ValueError(f"{name} contains {int(total_nans)} NaN values")
    # Impute numeric columns with median, object/category with mode
    for col, cnt in nan_counts.items():
      if cnt == 0:
        continue
      if pd.api.types.is_numeric_dtype(df_feat[col]):
        median = df_feat[col].median()
        df_feat[col] = df_feat[col].fillna(median)
        imputed_cols.append(col)
      else:
        mode = df_feat[col].mode()
        if not mode.empty:
          df_feat[col] = df_feat[col].fillna(mode.iloc[0])
          imputed_cols.append(col)
        else:
          # fallback to fill with empty string
          df_feat[col] = df_feat[col].fillna("")
          imputed_cols.append(col)

    # Re-check for NaNs
    remaining = df_feat.isna().sum().sum()
    if remaining > 0:
      raise ValueError(f"{name} still contains {int(remaining)} NaN values after imputation")

  # Constant columns check
  const_cols = [c for c in df_feat.columns if df_feat[c].nunique() < min_unique]
  if const_cols:
    print(f"Warning: {name} has constant/low-variance columns: {const_cols[:10]}")

  return df_feat, imputed_cols

# Fit featurizer on training split and also featurize validation split
featurizer = InequalityFeaturizerSlow()
# Use fit/transform API: fit on training split, then transform train to get features
featurizer.fit(X_train_tab.copy(), level=2, stage=2)
IFed_df_train = featurizer.transform(X_train_tab.copy())
IFed_df_train, imputed_train = _validate_features(IFed_df_train, name="IFed_df_train", impute=True)
if imputed_train:
  print(f"Imputed columns in IFed_df_train: {imputed_train}")

# Attempt to featurize validation split. If the featurizer does not support
# a separate transform API, we run featurize on the validation set as well
# to validate consistency. This ensures featurizer is deterministic and
# produces usable features on unseen rows.
try:
    # transform validation split using fitted featurizer
    IFed_df_val = featurizer.transform(X_val_tab.copy())
    IFed_df_val, imputed_val = _validate_features(IFed_df_val, name="IFed_df_val", impute=True)
    if imputed_val:
      print(f"Imputed columns in IFed_df_val: {imputed_val}")
except Exception as e:
  # If featurizer can't be applied separately, raise a helpful error
  raise RuntimeError("Featurizer failed on validation split; check featurizer implementation") from e

# For downstream steps that expect a single IFed_df variable, use the
# training featurized DataFrame. Keep the validation featurized DataFrame
# available as IFed_df_val for validation during model training.
IFed_df = IFed_df_train

"""## 3.1.1 MI Measurement 2"""

from sklearn.feature_selection import mutual_info_regression
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold

# Compute MI scores for features generated on the training split.
# Align the target vector with the featurized training DataFrame to
# avoid inconsistent sample-size errors.
IFed_df_train = IFed_df_train.reset_index(drop=True)
X_train_tab = X_train_tab.reset_index(drop=True)
if 'target' in IFed_df_train.columns:
  y_train = IFed_df_train['target'].reset_index(drop=True)
  X_feat = IFed_df_train.drop(columns=['target'])
else:
  y_train = X_train_tab['target'].reset_index(drop=True)
  X_feat = IFed_df_train

vt = VarianceThreshold(threshold=0.0)
scaler = StandardScaler()

x_no_constant = vt.fit_transform(X_feat)
kept_features = X_feat.columns[vt.get_support()]
X_scaled = scaler.fit_transform(x_no_constant)
X_preprocessed = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0)

IFed_mi_scores = mutual_info_regression(X_preprocessed, y_train.values, random_state=42)
IFed_mi_df = pd.DataFrame({'Feature':kept_features, 'Mutual_Information': IFed_mi_scores}).sort_values(by='Mutual_Information', ascending=False)
print(IFed_mi_df)

"""## 3.2.0 InformationRepurposedFeaturizer"""

from chekml.featurization import InformationRepurposedFeaturizerSlow
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor

def mi_metric(y_true,y_pred):
  y_true=np.asarray(y_true)
  y_pred=np.asarray(y_pred)

  mi=mutual_info_regression(y_pred.reshape(-1,1),y_true,
                            discrete_features=False,random_state=42)
  return float(mi[0])

def mi_loss(y):
  y=np.asarray(y)
  mi=mutual_info_regression(
      y.reshape(-1,1),y,discrete_features=False,random_state=42
  )[0]
  return y*(1.0+mi)

def distance_correlation(x, y):
    x = np.asarray(x, dtype=float).ravel()
    y = np.asarray(y, dtype=float).ravel()

    n = len(x)
    if n < 2:
        return 0.0

    if np.std(x) == 0.0 or np.std(y) == 0.0:
        return 0.0

    # Pairwise distances
    a = np.abs(x[:, None] - x[None, :])
    b = np.abs(y[:, None] - y[None, :])

    # Double centering
    A = a - a.mean(axis=0) - a.mean(axis=1)[:, None] + a.mean()
    B = b - b.mean(axis=0) - b.mean(axis=1)[:, None] + b.mean()

    dcov = np.mean(A * B)
    dvar_x = np.mean(A * A)
    dvar_y = np.mean(B * B)

    if dvar_x <= 0.0 or dvar_y <= 0.0:
        return 0.0

    return float(np.sqrt(dcov / np.sqrt(dvar_x * dvar_y)))

def dcor_metric(y_true, y_pred):
    dcor = distance_correlation(y_true, y_pred)
    return 0.0 if not np.isfinite(dcor) else dcor

def dcor_loss(y):
    y = np.asarray(y)

    dcor = distance_correlation(y, y)
    if not np.isfinite(dcor):
        dcor = 0.0

    return y * (1.0 + dcor)

custom_models = [
    ('decision_tree', DecisionTreeRegressor(random_state=42)),
    ('xg_boost', XGBRegressor(random_state=42, n_estimators=50))
]

custom_loss = {
    'mutual_information': (mi_loss, 'maximize'),
    'distance_correlation': (dcor_loss, 'maximize')
}

custom_loss = {
    'mutual_information': (mi_loss, 'maximize'),
    'distance_correlation': (dcor_loss, 'maximize')
}

custom_metrics = {
    'mutual_information': (mi_metric, 'maximize'),
    'distance_correlation': (dcor_metric, 'maximize')
}

result_df, metric_scores_df, feature_mi, trained_models = InformationRepurposedFeaturizerSlow(
    df=IFed_df,
    models=custom_models,
    loss_functions=custom_loss,
    metrics=custom_metrics,
    prediction_mode='top_n',
    top_n=3,
    score_key='mutual_information',
    level=2,
    save_models=True,
    save_results_file='model_results.txt',
)

result_df.shape

result_df.info()

"""## 3.2.1 MI Measurement 3"""

from sklearn.feature_selection import mutual_info_regression
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import VarianceThreshold

X_result_df = result_df.copy()
# IMPORTANT: remove target column if present
if 'target' in X_result_df.columns:
    X_result_df = X_result_df.drop(columns=['target'])

vt=VarianceThreshold(threshold=0.0)
scaler=StandardScaler()

x_no_constant=vt.fit_transform(X_result_df)
kept_features = X_result_df.columns[vt.get_support()]
X_scaled=scaler.fit_transform(x_no_constant)
X_preprocessed = np.nan_to_num(X_scaled, nan=0.0, posinf=0.0, neginf=0.0)

# Align result_df targets with training targets (result_df was produced from IFed_df_train)
if 'target' in result_df.columns:
  y_result = result_df['target'].reset_index(drop=True)
else:
  y_result = X_train_tab['target'].reset_index(drop=True)

IFed_IRFed_mi_scores = mutual_info_regression(X_preprocessed, y_result.values, random_state=42)
IFed_IRFed_mi_df = pd.DataFrame({'Feature':kept_features, 'Mutual_Information': IFed_IRFed_mi_scores}).sort_values(by='Mutual_Information', ascending=False)
print(IFed_IRFed_mi_df)

# Include image path and multi-target columns in the small dataframe used by the dataset
small_all_df=pd.concat([
  X.reset_index(drop=True),
  wide_train[["image_path","Dry_Green_g","Dry_Dead_g","Dry_Clover_g","GDM_g","Dry_Total_g"]].reset_index(drop=True)
],axis=1)

small_all_df.info()

"""# 4.0 Preprocessing 2: Image Integration

## 4.1 Image Loader
"""

import torch
from torch.utils.data import Dataset
from PIL import Image
from torchvision import transforms
from sklearn.preprocessing import StandardScaler
import os
from torch.utils.data import DataLoader

BASE_IMG_DIR = "/content/drive/MyDrive/csiro-biomass"

img_transform=transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor()
])

class ImageTabularDataset(Dataset):
  def __init__(self, df, tab_cols, target_cols, scaler=None):
    self.df = df.reset_index(drop=True)
    self.tab_cols = tab_cols
    # support passing a single string or a list of target columns
    if isinstance(target_cols, str):
      target_cols = [target_cols]
    self.target_cols = target_cols

    tab_data = df[tab_cols].values.astype(np.float32)
    if scaler is None:
      self.scaler = StandardScaler()
      self.tabular = self.scaler.fit_transform(tab_data)
    else:
      self.scaler = scaler
      self.tabular = self.scaler.transform(tab_data)

    # store multi-target array shape (N, n_targets)
    # If target columns are missing (test-time), create a dummy zero array
    n_targets = len(self.target_cols) if self.target_cols is not None else 3
    missing = False
    if self.target_cols is None:
      missing = True
    else:
      for c in self.target_cols:
        if c not in df.columns:
          missing = True
          break

    if missing:
      self.targets = np.zeros((len(self.df), n_targets), dtype=np.float32)
    else:
      self.targets = df[self.target_cols].values.astype(np.float32)

  def __len__(self):
    return len(self.df)

  def __getitem__(self,idx):
    rel_path=self.df.loc[idx,"image_path"]
    img_path=os.path.join(BASE_IMG_DIR,rel_path)

    img=Image.open(img_path).convert("RGB")
    img=img_transform(img)

    tab=torch.tensor(self.tabular[idx])
    y=torch.tensor(self.targets[idx]).float()
    return img,tab,y

dataset=ImageTabularDataset(
  small_all_df,
  ["State","Species","Pre_GSHH_NDVI","Height_Ave_cm","Month","Day","DayOfYear","DayOfWeek"],
  target_cols=["Dry_Green_g","Dry_Dead_g","Dry_Clover_g"]
)
loader=DataLoader(dataset,batch_size=32,shuffle=True)
# Create train/validation splits for supervised PyTorch training
from sklearn.model_selection import train_test_split
from torch.utils.data import Subset

_idxs = list(range(len(dataset)))
train_idx, val_idx = train_test_split(_idxs, test_size=0.2, random_state=42)
train_loader = DataLoader(Subset(dataset, train_idx), batch_size=32, shuffle=True)
val_loader = DataLoader(Subset(dataset, val_idx), batch_size=32, shuffle=False)

"""## 4.2 Deep Feature Extractor
extracts faetures using EarlyFusion or BilinearFusion, FiLM or Mine
"""

import torch
import torch.nn as nn
import torchvision.models as models

class ImageEncoder(nn.Module):
    def __init__(self, out_dim=128, pretrained=True):
        super().__init__()
        backbone = models.resnet18(pretrained=pretrained)
        self.cnn = nn.Sequential(*list(backbone.children())[:-1])  # remove FC
        self.fc = nn.Linear(512, out_dim)

    def forward(self, x):
        x = self.cnn(x)               # [B, 512, 1, 1]
        x = x.view(x.size(0), -1)     # [B, 512]
        return self.fc(x)             # [B, out_dim]

class TabularEncoder(nn.Module):
  def __init__(self,d_in,d_out=64):
    super().__init__()
    self.net=nn.Sequential(
        nn.Linear(d_in,128),
        nn.ReLU(),
        nn.BatchNorm1d(128),
        nn.Linear(128,d_out)
    )

  def forward(self,x):
    return self.net(x)

class EarlyFusion(nn.Module):
  def __init__(self,img_dim,tab_dim,out_dim=128):
    super().__ini__()
    self.net=nn.Sequential(
        nn.Linear(img_dim+tab_dim,out_sim=128),
        nn.ReLU(),
        nn.Linear(256,out_dim)
    )

  def forward(self,img_feat,tab_feat):
    x=torch.cat([img_feat,tab_feat],dim=1)
    return self.net(x)

class BilinearFusion(nn.Module):
  def __init__(self,img_dim,tab_dim,out_dim=128):
    super().__init__()
    self.bilinear=nn.Bilinear(img_dim,tab_dim,out_dim)

  def forward(self,img_feat,tab_feat):
    return self.bilinear(img_feat)

class FiLM(nn.Module):
  def __init__(self,tab_dim,img_dim):
    super().__init__()
    self.gamma=nn.Linear(tab_dim,img_dim)
    self.beta=nn.Linear(tab_dim,img_dim)

  def forward(self,img_feat,tab_feat):
    gamma=self.gamma(tab_feat)
    beta=self.beta(tab_feat)
    return gamma*img_feat + beta

class ImageMIEncoder(nn.Module):
  def __init__(self,d_in,d_z=32):
    super().__init__()
    self.net=nn.Sequential(
        nn.Linear(d_in,128),
        nn.ReLU(),
        nn.Linear(128,d_z)
    )

  def forward(self,x):
    return self.net(x)

class MINE(nn.Module):
  def __init__(self,d_in):
    super().__init__()
    self.net=nn.Sequential(
        nn.Linear(d_in,64),
        nn.ReLU(),
        nn.Linear(64,1)
    )

  def forward(self,z,t):
    return self.net(torch.cat([z,t],dim=1))

def mi_loss(mine,z,t):
  joint=mine(z,t)
  t_perm=t[torch.randperm(t.size(0))]
  marginal=mine(z,t_perm)

  return -(joint.mean() - torch.log(torch.exp(marginal).mean()+1e-8))

img_enc=ImageEncoder(out_dim=128)
tab_enc=TabularEncoder(d_in=dataset.tabular.shape[1],d_out=64)

mi_enc=ImageMIEncoder(d_in=128,d_z=32)
mine=MINE(d_in=32+64)

optimizer=torch.optim.Adam(
    list(img_enc.parameters())+
    list(tab_enc.parameters())+
    list(mi_enc.parameters())+
    list(mine.parameters()),
    lr=1e-4
)

epochs=10
for epoch in range(epochs):
  epoch_loss=0.0

  for img,tab,y in loader:
    img_feat=img_enc(img)
    tab_feat=tab_enc(tab)

    z=mi_enc(img_feat)
    loss=mi_loss(mine,z,tab_feat)

    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    epoch_loss += loss.item()
  print(f"Epoch {epoch+1}/{epochs} MI Loss: {epoch_loss/len(loader):.4f}")

img_enc.eval()
tab_enc.eval()
mi_enc.eval()

Z_img=[]
Z_tab=[]
device=torch.device("cuda"if torch.cuda.is_available() else "cpu")
with torch.no_grad():
  Z_y = []
  for img, tab, y in loader:
    img = img.to(device)
    tab = tab.to(device)

    img_feat = img_enc(img)
    z = mi_enc(img_feat)
    t = tab_enc(tab)

    Z_img.append(z.cpu())
    Z_tab.append(t.cpu())
    Z_y.append(y.cpu())

Z_img=torch.cat(Z_img)
Z_tab=torch.cat(Z_tab)
Z_y = torch.cat(Z_y).float()

# Create train/validation splits for feature datasets (used in offline heads)
from sklearn.model_selection import train_test_split
idxs = np.arange(len(Z_y))
train_idx_feat, val_idx_feat = train_test_split(idxs, test_size=0.2, random_state=42)

"""Measuring MI between image and tabular"""

from sklearn.feature_selection import mutual_info_regression

mi_scores = mutual_info_regression(
    Z_img.numpy(),
    Z_tab.mean(dim=1).numpy()
)
print(mi_scores)

with torch.no_grad():
  mi_estimate=-mi_loss(mine,Z_img,Z_tab).item()

print("Estimate MI:",mi_estimate)

"""# 5.0 Final Model (Featured by Info from Image + Tabular)"""

class FeatureDataset(Dataset):
  def __init__(self,Z_img,Z_tab,y):
    self.Z_img=Z_img.float()
    self.Z_tab=Z_tab.float()
    self.y=y.float()

  def __len__(self):
    return len(self.y)

  def __getitem__(self,idx):
    return self.Z_img[idx],self.Z_tab[idx],self.y[idx]

full_feat_dataset = FeatureDataset(Z_img, Z_tab, Z_y)
train_feat_dataset = FeatureDataset(Z_img[train_idx_feat], Z_tab[train_idx_feat], Z_y[train_idx_feat])
val_feat_dataset = FeatureDataset(Z_img[val_idx_feat], Z_tab[val_idx_feat], Z_y[val_idx_feat])

train_feat_loader = DataLoader(train_feat_dataset, batch_size=32, shuffle=True)
val_feat_loader = DataLoader(val_feat_dataset, batch_size=32, shuffle=False)
feat_loader = DataLoader(full_feat_dataset, batch_size=32, shuffle=True)

"""## 5.1 Offline Feature Learning"""

class EarlyFusionHead(nn.Module):
  def __init__(self,z_dim,t_dim):
    super().__init__()
    self.net=nn.Sequential(
        nn.Linear(z_dim+t_dim,128),
        nn.ReLU(),
        nn.Linear(128,3)
    )

  def forward(self,z,t):
    return self.net(torch.cat([z,t],dim=1))

class BilinearHead(nn.Module):
  def __init__(self,z_dim,t_dim):
    super().__init__()
    self.bilin=nn.Bilinear(z_dim,t_dim,128)
    self.fc=nn.Linear(128,3)

  def forward(self,z,t):
    return self.fc(torch.relu(self.bilin(z,t)))

class FiLMHead(nn.Module):
  def __init__(self,z_dim,t_dim):
    super().__init__()
    self.gamma=nn.Linear(t_dim,z_dim)
    self.beta=nn.Linear(t_dim,z_dim)
    self.fc=nn.Linear(z_dim,3)

  def forward(self,z,t):
    g=self.gamma(t)
    b=self.beta(t)
    return self.fc(g*z+b)

model=EarlyFusionHead(z_dim=32,t_dim=64).to(device)
opt=torch.optim.Adam(model.parameters(),lr=1e-3)
loss_fn = nn.MSELoss()

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

for epoch in range(100):
  model.train()
  total=0
  for z,t,y in train_feat_loader:
    z,t,y = z.to(device), t.to(device), y.to(device)

    pred = model(z,t)  # shape [B,3]
    loss = loss_fn(pred, y)

    opt.zero_grad()
    loss.backward()
    opt.step()

    total += loss.item()

  # validation
  model.eval()
  preds = []
  trues = []
  with torch.no_grad():
    for z,t,y in val_feat_loader:
      z,t,y = z.to(device), t.to(device), y.to(device)
      p = model(z,t)
      preds.append(p.cpu().numpy())
      trues.append(y.cpu().numpy())

  preds = np.vstack(preds)
  trues = np.vstack(trues)

  # per-target metrics
  mse_per_target = mean_squared_error(trues, preds, multioutput='raw_values')
  mae_per_target = mean_absolute_error(trues, preds, multioutput='raw_values')
  r2_per_target = [r2_score(trues[:,i], preds[:,i]) for i in range(trues.shape[1])]

  # derived targets from predictions
  preds_gdm = preds[:,0] + preds[:,2]
  trues_gdm = trues[:,0] + trues[:,2]
  preds_total = preds.sum(axis=1)
  trues_total = trues.sum(axis=1)

  mse_gdm = mean_squared_error(trues_gdm, preds_gdm)
  mse_total = mean_squared_error(trues_total, preds_total)

  print(f"[OFFLINE] Epoch {epoch+1} TrainMSE={total/len(train_feat_loader):.4f} ValMSE_per_target={mse_per_target} ValMSE_gdm={mse_gdm:.4f} ValMSE_total={mse_total:.4f}")

"""## 5.2 Online Feature Learning"""

for m in [img_enc,tab_enc,mi_enc]:
  m.eval()
  for p in m.parameters():
    p.requires_grad=False

class MultimodelFiLM(nn.Module):
  def __init__(self,img_enc,tab_enc,mi_enc):
    super().__init__()
    self.img_enc=img_enc
    self.tab_enc=tab_enc
    self.mi_enc=mi_enc

    self.gamma=nn.Linear(64,32)
    self.beta=nn.Linear(64,32)
    self.head=nn.Linear(32,3)

  def forward(self,img,tab):
    z=self.mi_enc(self.img_enc(img))
    t=self.tab_enc(tab)
    return self.head(self.gamma(t)*z+self.beta(t))

model=MultimodelFiLM(img_enc,tab_enc,mi_enc).to(device)
opt=torch.optim.Adam(model.parameters(),lr=1e-3)
loss_fn=nn.MSELoss()

for epoch in range(100):
  model.train()
  total=0
  for img,tab,y in train_loader:
    img,tab,y = img.to(device), tab.to(device), y.to(device)

    pred = model(img,tab)  # [B,3]
    loss = loss_fn(pred, y)

    opt.zero_grad()
    loss.backward()
    opt.step()

    total += loss.item()

  # validation
  model.eval()
  preds = []
  trues = []
  with torch.no_grad():
    for img,tab,y in val_loader:
      img,tab,y = img.to(device), tab.to(device), y.to(device)
      p = model(img,tab)
      preds.append(p.cpu().numpy())
      trues.append(y.cpu().numpy())

  preds = np.vstack(preds)
  trues = np.vstack(trues)
  mse_per_target = mean_squared_error(trues, preds, multioutput='raw_values')

  print(f"[ONLINE FROZEN] Epoch {epoch+1} TrainMSE={total/len(train_loader):.4f} ValMSE_per_target={mse_per_target}")

"""## 5.3 MI Deep Regularizer"""

class FullMIModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.img_enc=ImageEncoder(128)
    self.mi_enc=ImageMIEncoder(128,32)
    # infer tabular input dimension from the dataset if available
    try:
      tab_input_dim = int(dataset.tabular.shape[1])
    except Exception:
      # fallback to a sensible default (8 features) if dataset not available
      tab_input_dim = 8
    self.tab_enc=TabularEncoder(tab_input_dim,64)

    self.film=FiLM(64,32)
    self.head=nn.Linear(32,3)

  def forward(self,img,tab):
    z = self.mi_enc(self.img_enc(img))   # z ∈ ℝ^{B×32}
    t = self.tab_enc(tab)                # t ∈ ℝ^{B×64}
    return self.head(self.film(z,t)), z, t

# INFERENCE: moved to run after full training completes. See bottom of file.


model = FullMIModel().to(device)
opt = torch.optim.Adam(model.parameters(), lr=1e-4)

# weight for MI regularizer
lamb = 1.0

best_val = float('inf')
best_epoch = -1
ckpt_path = "best_fullmi_model.pt"

for epoch in range(40):
  total = 0
  model.train()
  for img, tab, y in train_loader:
    img, tab, y = img.to(device), tab.to(device), y.to(device)

    pred, z, t = model(img, tab)

    # pred shape [B,3], y shape [B,3]
    loss_task = nn.MSELoss()(pred, y)
    loss_mi   = mi_loss(mine, z, t)

    loss = loss_task + lamb * loss_mi

    opt.zero_grad()
    loss.backward()
    opt.step()

    total += loss.item()

  # validation
  model.eval()
  preds = []
  trues = []
  with torch.no_grad():
    for img,tab,y in val_loader:
      img,tab,y = img.to(device), tab.to(device), y.to(device)
      p,_,_ = model(img,tab)
      preds.append(p.cpu().numpy())
      trues.append(y.cpu().numpy())

  preds = np.vstack(preds)
  trues = np.vstack(trues)
  mse_per_target = mean_squared_error(trues, preds, multioutput='raw_values')
  # Use mean validation MSE across targets as selection metric (lower is better)
  val_score = float(np.mean(mse_per_target))
  print(f"[END TO END MI] Epoch {epoch+1} TrainLoss={total/len(train_loader):.4f} ValMSE_per_target={mse_per_target} ValScore={val_score:.4f}")

  # Save best checkpoint
  try:
    if val_score < best_val:
      best_val = val_score
      best_epoch = epoch + 1
      torch.save(model.state_dict(), ckpt_path)
      print(f"Saved best checkpoint to {ckpt_path} (epoch {best_epoch}, val_score={best_val:.4f})")
  except Exception as e:
    print("Failed to save checkpoint:", e)
  
# ---- Moved inference block: run inference and write submission after full training completes ----
# load test metadata
test_csv_path = "/content/drive/MyDrive/csiro-biomass/test.csv"
try:
  test_df = pd.read_csv(test_csv_path)
except Exception as e:
  print(f"Could not read test csv at {test_csv_path}: {e}")
  test_df = None

if test_df is not None:
  # create date-based features same as train
  if "Sampling_Date" in test_df.columns:
    test_df["Sampling_Date"] = pd.to_datetime(test_df["Sampling_Date"])
    test_df["Month"] = test_df["Sampling_Date"].dt.month
    test_df["Day"] = test_df["Sampling_Date"].dt.day
    test_df["DayOfYear"] = test_df["Sampling_Date"].dt.dayofyear
    test_df["DayOfWeek"] = test_df["Sampling_Date"].dt.dayofweek

  # Ensure required tabular columns exist
  tab_cols = ["State","Species","Pre_GSHH_NDVI","Height_Ave_cm","Month","Day","DayOfYear","DayOfWeek"]
  for c in tab_cols:
    if c not in test_df.columns:
      test_df[c] = 0

  # Fit LabelEncoders on training `wide_train` and apply to test
  # Reuse the LabelEncoders fitted on training to avoid unseen-label errors
  for col in ["State","Species"]:
    if col in le_map_train:
      try:
        test_df[col] = le_map_train[col].transform(test_df[col].astype(str).values)
      except Exception:
        # fallback: fit on combined values
        le = LabelEncoder()
        le.fit(pd.concat([wide_train[col].astype(str), test_df[col].astype(str)], axis=0).unique())
        test_df[col] = le.transform(test_df[col].astype(str).values)
        le_map_train[col] = le
    else:
      le = LabelEncoder()
      le.fit(test_df[col].astype(str).values)
      test_df[col] = le.transform(test_df[col].astype(str).values)
      le_map_train[col] = le

  # Build small test dataframe matching dataset input
  # We need image_path and the tabular fields
  small_test_df = test_df.copy()

  # derive image_id for sample naming
  if "sample_id" in test_df.columns:
    small_test_df["image_id"] = test_df["sample_id"].str.split("__").str[0]
  elif "image_id" in test_df.columns:
    small_test_df["image_id"] = test_df["image_id"]
  else:
    # fallback: derive from image_path basename
    small_test_df["image_id"] = small_test_df["image_path"].apply(lambda p: os.path.splitext(os.path.basename(p))[0])

  # Ensure each image appears only once in the test set (prevents repeated inference)
  # If the test file is sample-submission-style (one row per metric), there will
  # be multiple rows for the same image — keep only the first occurrence.
  small_test_df = small_test_df.drop_duplicates(subset=["image_id"]).reset_index(drop=True)
  print(f"Test rows: {len(test_df)}, unique images after dedupe: {small_test_df['image_id'].nunique()}, rows used for inference: {len(small_test_df)}")

  # instantiate test dataset (no targets present)
  # Run InequalityFeaturizer on test tabular data (featurizer expects a 'target' column)
  try:
    test_tab_only = small_test_df[tab_cols].copy()
    # transform test tabular using the featurizer fitted on training split
    try:
      IFed_df_test = featurizer.transform(test_tab_only.copy())
    except Exception:
      # some featurizers expect a 'target' column at transform-time; provide a dummy
      test_tab_only["target"] = 0.0
      IFed_df_test = featurizer.transform(test_tab_only.copy())

    IFed_df_test, imputed_test = _validate_features(IFed_df_test, name="IFed_df_test", impute=True)
    IFed_df_test.to_csv("IFed_df_test.csv", index=False)
    print("Saved IFed_df_test.csv")
  except Exception as e:
    print("Inequality featurization on test failed:", e)
    # Fallback: construct IFed_df_test from IFed_df_train column names using
    # training means or sensible defaults so saved IRF models can still be applied.
    try:
      print("Building fallback IFed_df_test using IFed_df_train statistics")
      train_cols = [c for c in IFed_df_train.columns if c != 'target']
      fallback_vals = {}
      for c in train_cols:
        if c in IFed_df_train.columns and pd.api.types.is_numeric_dtype(IFed_df_train[c]):
          fallback_vals[c] = [float(IFed_df_train[c].mean())]
        else:
          # categorical/text fallback: use mode or first value
          try:
            mode = IFed_df_train[c].mode()
            fallback_vals[c] = [mode.iloc[0] if not mode.empty else IFed_df_train[c].iloc[0]]
          except Exception:
            fallback_vals[c] = [0]

      IFed_df_test = pd.DataFrame(fallback_vals)
      IFed_df_test, imputed_test = _validate_features(IFed_df_test, name="IFed_df_test_fallback", impute=True)
      IFed_df_test.to_csv("IFed_df_test_fallback.csv", index=False)
      print("Saved IFed_df_test_fallback.csv")
    except Exception as e2:
      print("Fallback IFed_df_test construction failed:", e2)
      IFed_df_test = pd.DataFrame(columns=[c for c in IFed_df_train.columns if c != 'target'])
      print("Using empty IFed_df_test with columns:", IFed_df_test.columns.tolist())

    # Attempt to load and apply saved IRF models only if IFed_df_test has columns
    try:
      import glob, cloudpickle
      from sklearn.impute import SimpleImputer
      from sklearn.preprocessing import StandardScaler

      if IFed_df_test is None or IFed_df_test.shape[0] == 0:
        print("IFed_df_test is empty — skipping IRF saved-model application")
      else:
        saved_dir = "saved_models"
        if os.path.isdir(saved_dir):
          pkl_files = glob.glob(os.path.join(saved_dir, "*.pkl"))
          if pkl_files:
            for p in pkl_files:
              try:
                model_name = os.path.splitext(os.path.basename(p))[0]
                with open(p, 'rb') as f:
                  m = cloudpickle.load(f)

                # determine required input columns
                cols = None
                if hasattr(m, 'feature_names_in_'):
                  try:
                    cols = list(m.feature_names_in_)
                  except Exception:
                    cols = None

                if cols is None and hasattr(m, 'n_features_in_'):
                  n = int(m.n_features_in_)
                  # use IFed_df_train column ordering (exclude 'target') to pick first n cols
                  train_cols = [c for c in IFed_df_train.columns if c != 'target']
                  cols = train_cols[:n]

                if cols is None:
                  # fallback to all IFed_df_test feature columns (exclude target)
                  cols = [c for c in IFed_df_test.columns if c != 'target']

                # check cols exist in IFed_df_test
                missing = [c for c in cols if c not in IFed_df_test.columns]
                if missing:
                  print(f"Skipping model {model_name}: missing columns in IFed_df_test: {missing}")
                  continue

                # Fit imputer and scaler on IFed_df_train for these cols to mimic training preprocessing
                X_train_cols = IFed_df_train[cols].copy()
                imp = SimpleImputer(strategy='mean')
                sc = StandardScaler()
                X_train_imp = imp.fit_transform(X_train_cols)
                X_train_scaled = sc.fit_transform(X_train_imp)

                # transform test
                X_test_cols = IFed_df_test[cols].copy()
                X_test_imp = imp.transform(X_test_cols)
                X_test_scaled = sc.transform(X_test_imp)

                # predict
                try:
                  preds = m.predict(X_test_scaled)
                except Exception as e:
                  print(f"Model {model_name} failed to predict: {e}")
                  continue

                # if preds is 2D with shape (N,1) flatten
                preds = np.asarray(preds).reshape(-1)
                IFed_df_test[f"irf_pred__{model_name}"] = preds
                print(f"Applied model {model_name} to IFed_df_test -> irf_pred__{model_name}")
              except Exception as e:
                print(f"Failed to apply model from {p}: {e}")
          else:
            print("No pickled IRF models found in saved_models/")
        else:
          print("saved_models/ directory not found; skipping IRF model application")

        # save augmented IFed_df_test with IRF preds
        IFed_df_test.to_csv("IFed_df_test_with_irf_preds.csv", index=False)
        print("Saved IFed_df_test_with_irf_preds.csv")
    except Exception as e:
      print("Applying saved IRF models failed:", e)

  # instantiate test dataset reusing the training tabular scaler for consistent scaling
  test_dataset = ImageTabularDataset(small_test_df, tab_cols, target_cols=["Dry_Green_g","Dry_Dead_g","Dry_Clover_g"], scaler=dataset.scaler)
  test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
  # Quick check: compare IFed_df_test feature stats to IFed_df_train
  try:
    if IFed_df_test is not None and not IFed_df_test.empty:
      num_cols = [c for c in IFed_df_test.columns if pd.api.types.is_numeric_dtype(IFed_df_test[c]) and c in IFed_df_train.columns]
      if num_cols:
        train_means = IFed_df_train[num_cols].mean()
        test_means = IFed_df_test[num_cols].mean()
        mean_diff = (test_means - train_means).abs()
        summary = pd.DataFrame({"train_mean": train_means, "test_mean": test_means, "abs_diff": mean_diff})
        summary = summary.sort_values(by="abs_diff", ascending=False)
        print("IFed numerical feature mean differences (top 10):")
        print(summary.head(10))
      else:
        print("No numeric IFed features in common to compare between train and test.")
  except Exception as e:
    print("Failed to compare IFed_df_train/test stats:", e)

  # run inference
  # Before inference, if a best checkpoint exists load it so we use the best validation model
  try:
    if os.path.exists(ckpt_path):
      model.load_state_dict(torch.load(ckpt_path, map_location=device))
      model.to(device)
      print(f"Loaded checkpoint {ckpt_path} for inference (best_epoch={best_epoch})")
  except Exception as e:
    print(f"Failed to load checkpoint {ckpt_path}: {e}")

  # Quick validation inference on one validation batch to sanity-check predictions
  try:
    model.eval()
    with torch.no_grad():
      batch = next(iter(val_loader))
      v_img, v_tab, v_y = batch
      v_img = v_img.to(device)
      v_tab = v_tab.to(device)
      v_y = v_y.to(device)
      out = model(v_img, v_tab)
      if isinstance(out, (tuple, list)):
        out = out[0]
      preds_val = out.cpu().numpy()
      trues_val = v_y.cpu().numpy()
      rmse = np.sqrt(np.mean((preds_val - trues_val) ** 2, axis=0))
      print("Quick val batch RMSE per target:", rmse)
      print("Sample preds vs true (first 5):")
      for i in range(min(5, preds_val.shape[0])):
        print(f"idx{i}: pred={preds_val[i]}, true={trues_val[i]}")
  except Exception as e:
    print("Validation inference failed:", e)
  preds_all = []
  ids = []
  with torch.no_grad():
    for img, tab, _ in test_loader:
      img = img.to(device)
      tab = tab.to(device)
      out = model(img, tab)
      # Handle models that return (pred,) or (pred,z,t)
      if isinstance(out, tuple) or isinstance(out, list):
        out = out[0]
      out = out.cpu().numpy()
      preds_all.append(out)

  if preds_all:
    preds_all = np.vstack(preds_all)

    # create submission rows
    image_ids = small_test_df["image_id"].values[: preds_all.shape[0]]
    rows = []
    for i, img_id in enumerate(image_ids):
      g = float(preds_all[i,0])
      d = float(preds_all[i,1])
      c = float(preds_all[i,2])
      gdm = g + c
      total = g + d + c

      rows.append({"sample_id": f"{img_id}__Dry_Green_g", "target": g})
      rows.append({"sample_id": f"{img_id}__Dry_Dead_g", "target": d})
      rows.append({"sample_id": f"{img_id}__Dry_Clover_g", "target": c})
      rows.append({"sample_id": f"{img_id}__Dry_Total_g", "target": total})
      rows.append({"sample_id": f"{img_id}__GDM_g", "target": gdm})

    submission = pd.DataFrame(rows)
    submission.to_csv("submission.csv", index=False)
    print("Wrote submission.csv with", len(submission), "rows")

# 6.0 Other Testing

## 6.1 Model (Unfeatured Image ONLY)

import torch.nn as nn
import torch.nn.functional as F

class CNNBackbone(nn.Module):
  def __init__(self,out_channels=32):
    super().__init__()
    self.conv=nn.Sequential(
        nn.Conv2d(3,16,3,padding=1),
        nn.ReLU(),
        nn.MaxPool2d(2),

        nn.Conv2d(16,out_channels,3,padding=1),
        nn.ReLU(),
        nn.AdaptiveAvgPool2d((1,1))
    )

    def forward(self,x):
      return self.conv(x).flatten(1)

class LateFusion(nn.Module):
  def __init__(self,tab_dim):
    super().__init__()
    self.cnn=CNNBackbone(32)
    self.tab_fc=nn.Linear(tab_dim,16)
    self.fc=nn.Linear(32+16,1)

  def forward(self,img,tab):
    c=self.cnn(img)
    t=F.relu(self.tab_fc(tab))
    return self.fc(torch.cat([c,t],dim=1))

class FiLM(nn.Module):
  def __init__(self,tab_dim):
    super().__init__()
    self.conv=nn.Conv2d(3,32,3,padding=1)
    self.film=nn.Linear(tab_dim,64)
    self.pool=nn.AdaptiveAvgPool2d((1,1))
    self.fc=nn.Linear(32,1)

  def forward(self,img,tab):
    x=self.conv(img)

    gamma,beta=self.film(tab).chunk(2,dim=1)
    gamma=gamma.view(-1,32,1,1)
    beta=beta.view(-1,32,1,1)

    x=F.relu(gamma*x+beta)
    x=self.pool(x).flatten(1)
    return self.fc(x)

class AttentionFusion(nn.Module):
  def __init__(self,tab_dim):
    super().__init__()
    self.conv=nn.Conv2d(3,32,3,padding=1)
    self.attn=nn.Linear(tab_dim,32)
    self.pool=nn.AdaptiveAvgPool2d((1,1))
    self.fc=nn.Linear(32,1)

  def forward(self,img,tab):
    x=self.conv(img)
    w=torch.sigmoid(self.attn(tab)).view(-1,32,1,1)
    x=F.relu(x*w)
    x=self.pool(x).flatten(1)
    return self.fc(x)

def train(model,loader,epochs=10):
  opt=torch.optim.Adam(model.parameters(),lr=1e-3)
  loss_fn=nn.MSELoss()

  for e in range(20):
    total=0
    for img,tab,y in loader:
      pred=model(img,tab)
      loss=loss_fn(pred,y)

      opt.zero_grad()
      loss.backward()
      opt.step()
      total += loss.item()
    print(f"Epoch {e}:MSE ={total/len(loader):.4f}")

tab_dim=len(["State","Species","Pre_GSHH_NDVI","Height_Ave_cm","Month","Day","DayOfYear","DayOfWeek"])
model=FiLM(tab_dim)
train(model,loader)

"""## 6.2 Model (Featured Tabular ONLY)"""

selected_features = IFed_IRFed_mi_df.loc[
    IFed_IRFed_mi_df["Mutual_Information"] > 0.4,
    "Feature"
].tolist()

X_selected = result_df[selected_features].copy()
y=result_df["target"]

from sklearn.preprocessing import StandardScaler
import numpy as np

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_selected)

from sklearn.model_selection import train_test_split

X_train, X_val, y_train, y_val = train_test_split(
    X_scaled,
    y,
    test_size=0.2,
    random_state=42
)

y_scaler = StandardScaler()
y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1,1))
y_val_scaled = y_scaler.transform(y_val.values.reshape(-1,1))

import tensorflow as tf
from tensorflow.keras import layers, models

model = models.Sequential([
    layers.Input(shape=(X_train.shape[1],)),
    layers.Dense(64, activation="relu"),
    layers.Dense(32, activation="relu"),
    layers.Dense(1)   # one neuron per target
])

model.compile(
    optimizer="adam",
    loss="mse",
    metrics=["mae"]
)

history = model.fit(
    X_train,
    y_train_scaled,
    validation_data=(X_val, y_val_scaled),
    epochs=100,
    batch_size=16,
    verbose=1
)

print(X_selected.shape)   # (357, num_features)
print(y.shape)            # (32,) ← mismatch

val_loss, val_mae = model.evaluate(X_val, y_val_scaled)
print("Validation MAE:", val_mae)

import matplotlib.pyplot as plt

# Plot MSE loss
plt.figure(figsize=(10,4))
plt.plot(history.history['loss'], label='Train Loss (MSE)')
plt.plot(history.history['val_loss'], label='Validation Loss (MSE)')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.legend()
plt.show()

# Plot MAE
plt.figure(figsize=(10,4))
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.title('Training vs Validation MAE')
plt.legend()
plt.show()

