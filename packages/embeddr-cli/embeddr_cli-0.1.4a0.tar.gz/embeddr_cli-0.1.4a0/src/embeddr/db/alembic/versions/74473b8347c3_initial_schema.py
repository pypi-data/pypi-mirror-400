"""initial_schema

Revision ID: 74473b8347c3
Revises:
Create Date: 2026-01-05 07:49:46.101967

"""

from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
import sqlmodel


# revision identifiers, used by Alembic.
revision: str = "74473b8347c3"
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "collection",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("description", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("collection", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_collection_name"), ["name"], unique=False)

    op.create_table(
        "dataset",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("description", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column(
            "type", sa.Enum("REGULAR", "IMAGE_PAIR", name="datasettype"), nullable=False
        ),
        sa.Column("collection_id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.Column(
            "captioning_config", sqlmodel.sql.sqltypes.AutoString(), nullable=True
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("dataset", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_dataset_collection_id"), ["collection_id"], unique=False
        )
        batch_op.create_index(batch_op.f("ix_dataset_name"), ["name"], unique=False)

    op.create_table(
        "librarypath",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("path", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("librarypath", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_librarypath_path"), ["path"], unique=True)

    op.create_table(
        "workflow",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("description", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("data", sa.JSON(), nullable=True),
        sa.Column("meta", sa.JSON(), nullable=True),
        sa.Column("is_active", sa.Boolean(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("workflow", schema=None) as batch_op:
        batch_op.create_index(batch_op.f("ix_workflow_name"), ["name"], unique=False)

    op.create_table(
        "generation",
        sa.Column("id", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("workflow_id", sa.Integer(), nullable=False),
        sa.Column("prompt_id", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("status", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("prompt", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("inputs", sa.JSON(), nullable=True),
        sa.Column("outputs", sa.JSON(), nullable=True),
        sa.Column("error_message", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("updated_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["workflow_id"],
            ["workflow.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("generation", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_generation_prompt_id"), ["prompt_id"], unique=False
        )

    op.create_table(
        "localimage",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("path", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("filename", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("library_path_id", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.Column("width", sa.Integer(), nullable=True),
        sa.Column("height", sa.Integer(), nullable=True),
        sa.Column("file_size", sa.Integer(), nullable=True),
        sa.Column("mime_type", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("media_type", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("duration", sa.Float(), nullable=True),
        sa.Column("fps", sa.Float(), nullable=True),
        sa.Column("frame_count", sa.Integer(), nullable=True),
        sa.Column("prompt", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("tags", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("phash", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("is_archived", sa.Boolean(), nullable=False),
        sa.ForeignKeyConstraint(
            ["library_path_id"],
            ["librarypath.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    with op.batch_alter_table("localimage", schema=None) as batch_op:
        batch_op.create_index(
            batch_op.f("ix_localimage_is_archived"), ["is_archived"], unique=False
        )
        batch_op.create_index(
            batch_op.f("ix_localimage_media_type"), ["media_type"], unique=False
        )
        batch_op.create_index(batch_op.f("ix_localimage_path"), ["path"], unique=True)
        batch_op.create_index(
            batch_op.f("ix_localimage_phash"), ["phash"], unique=False
        )

    op.create_table(
        "collectionitem",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("collection_id", sa.Integer(), nullable=False),
        sa.Column("image_id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["collection_id"],
            ["collection.id"],
        ),
        sa.ForeignKeyConstraint(
            ["image_id"],
            ["localimage.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "datasetitem",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("dataset_id", sa.Integer(), nullable=False),
        sa.Column("original_image_id", sa.Integer(), nullable=False),
        sa.Column(
            "processed_image_path", sqlmodel.sql.sqltypes.AutoString(), nullable=True
        ),
        sa.Column("pair_image_path", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("caption", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.ForeignKeyConstraint(
            ["dataset_id"],
            ["dataset.id"],
        ),
        sa.ForeignKeyConstraint(
            ["original_image_id"],
            ["localimage.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_table(
        "imagelineage",
        sa.Column("parent_id", sa.Integer(), nullable=False),
        sa.Column("child_id", sa.Integer(), nullable=False),
        sa.Column("created_at", sa.DateTime(), nullable=False),
        sa.ForeignKeyConstraint(
            ["child_id"],
            ["localimage.id"],
        ),
        sa.ForeignKeyConstraint(
            ["parent_id"],
            ["localimage.id"],
        ),
        sa.PrimaryKeyConstraint("parent_id", "child_id"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("imagelineage")
    op.drop_table("datasetitem")
    op.drop_table("collectionitem")
    with op.batch_alter_table("localimage", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_localimage_phash"))
        batch_op.drop_index(batch_op.f("ix_localimage_path"))
        batch_op.drop_index(batch_op.f("ix_localimage_media_type"))
        batch_op.drop_index(batch_op.f("ix_localimage_is_archived"))

    op.drop_table("localimage")
    with op.batch_alter_table("generation", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_generation_prompt_id"))

    op.drop_table("generation")
    with op.batch_alter_table("workflow", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_workflow_name"))

    op.drop_table("workflow")
    with op.batch_alter_table("librarypath", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_librarypath_path"))

    op.drop_table("librarypath")
    with op.batch_alter_table("dataset", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_dataset_name"))
        batch_op.drop_index(batch_op.f("ix_dataset_collection_id"))

    op.drop_table("dataset")
    with op.batch_alter_table("collection", schema=None) as batch_op:
        batch_op.drop_index(batch_op.f("ix_collection_name"))

    op.drop_table("collection")
    # ### end Alembic commands ###
