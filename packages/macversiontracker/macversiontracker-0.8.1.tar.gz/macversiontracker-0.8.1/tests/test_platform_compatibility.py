"""Platform compatibility tests for cross-platform environments."""

import os
import platform
import sys
import tempfile
import unittest
from unittest.mock import MagicMock, patch

import pytest

from versiontracker.handlers.auto_update_handlers import (
    handle_blacklist_auto_updates,
)


class TestCrossPlatformUtils(unittest.TestCase):
    """Test utilities work across different platforms."""

    def test_temp_directory_creation(self):
        """Test temporary directory creation works on all platforms."""
        from pathlib import Path

        with tempfile.TemporaryDirectory() as temp_dir:
            temp_path = Path(temp_dir)
            self.assertTrue(temp_path.exists())
            self.assertTrue(temp_path.is_dir())

            # Test file creation in temp directory
            test_file = temp_path / "test.txt"
            test_file.write_text("test content")
            self.assertEqual(test_file.read_text(), "test content")

    def test_path_handling(self):
        """Test path handling works across platforms."""
        from pathlib import Path

        # Test path construction
        test_path = Path("test") / "path" / "file.txt"

        # Should work on both Windows and Unix-like systems
        self.assertIn("test", str(test_path))
        self.assertIn("path", str(test_path))
        self.assertIn("file.txt", str(test_path))

    @pytest.mark.skipif(os.environ.get("CI") == "true", reason="Terminal tests may fail in CI environments")
    def test_terminal_detection(self):
        """Test terminal capability detection."""
        import sys

        # Test if we're connected to a terminal
        result = sys.stdout.isatty()
        self.assertIsInstance(result, bool)

    def test_environment_variable_handling(self):
        """Test environment variable handling across platforms."""
        test_var = "VERSIONTRACKER_TEST_VAR"
        test_value = "test_value"

        # Ensure clean state
        original_value = os.environ.get(test_var)

        try:
            # Set environment variable
            os.environ[test_var] = test_value
            self.assertEqual(os.environ.get(test_var), test_value)

            # Delete environment variable
            del os.environ[test_var]
            self.assertIsNone(os.environ.get(test_var))

        finally:
            # Restore original value
            if original_value is not None:
                os.environ[test_var] = original_value
            elif test_var in os.environ:
                del os.environ[test_var]


class TestCICompatibility(unittest.TestCase):
    """Test compatibility with CI environments."""

    def test_ci_detection(self):
        """Test CI environment detection."""
        ci_indicators = ["CI", "GITHUB_ACTIONS", "TRAVIS", "JENKINS_URL"]

        is_ci = any(os.environ.get(indicator) for indicator in ci_indicators)

        # This test documents CI detection logic
        self.assertIsInstance(is_ci, bool)

    @patch("versiontracker.handlers.auto_update_handlers.get_config")
    @patch("versiontracker.handlers.auto_update_handlers.get_homebrew_casks")
    @patch("versiontracker.handlers.auto_update_handlers.get_casks_with_auto_updates")
    def test_homebrew_mocking_in_ci(self, mock_get_auto_updates, mock_get_casks, mock_get_config):
        """Test Homebrew operations work with mocking in CI."""
        is_ci = os.environ.get("CI", "").lower() in ("true", "1")

        if is_ci and platform.system() != "Darwin":
            # On non-macOS CI systems, Homebrew should be mocked
            mock_config = MagicMock()
            mock_config.get.return_value = []
            mock_config.save.return_value = True
            mock_get_config.return_value = mock_config
            mock_get_casks.return_value = []
            mock_get_auto_updates.return_value = []

            mock_options = MagicMock()
            result = handle_blacklist_auto_updates(mock_options)
            self.assertEqual(result, 0)
        else:
            # Skip test on macOS or non-CI environments
            self.skipTest("Test only runs in CI on non-macOS systems")

    def test_platform_specific_skipping(self):
        """Test platform-specific tests are properly skipped."""
        current_platform = platform.system()

        # Verify we can detect platform correctly
        self.assertIn(current_platform, ["Darwin", "Linux", "Windows"])

        # Test that non-macOS systems skip macOS-specific functionality
        if current_platform != "Darwin":
            with self.assertRaises(ImportError):
                # This should fail on non-macOS systems
                from versiontracker.macos_integration import send_notification

                send_notification("test", "test")

    @pytest.mark.skipif(os.environ.get("CI") == "true", reason="Timing-sensitive test may fail in CI")
    def test_timing_sensitive_operations(self):
        """Test operations that depend on timing."""
        import time

        start_time = time.time()
        time.sleep(0.1)  # 100ms sleep
        end_time = time.time()

        # Allow for timing variation in CI environments
        elapsed = end_time - start_time
        self.assertGreater(elapsed, 0.05)  # At least 50ms
        self.assertLess(elapsed, 1.0)  # Less than 1 second

    def test_subprocess_handling(self):
        """Test subprocess operations work in CI."""
        from versiontracker.utils import run_command

        # Use a command that should work on all platforms
        command = "echo test"

        with patch("versiontracker.utils._execute_subprocess") as mock_exec:
            mock_process = MagicMock()
            mock_process.communicate.return_value = (b"test\n", b"")
            mock_process.returncode = 0
            mock_exec.return_value = mock_process

            stdout, returncode = run_command(command)

            self.assertEqual(returncode, 0)
            mock_exec.assert_called_once()


class TestPlatformSpecificSkips(unittest.TestCase):
    """Test platform-specific functionality with appropriate skips."""

    @pytest.mark.skipif(sys.platform != "darwin", reason="macOS only")
    def test_macos_specific_functionality(self):
        """Test macOS-specific functionality."""
        # This test would only run on macOS
        from versiontracker.macos_integration import MacOSNotifications

        notifier = MacOSNotifications()
        self.assertIsInstance(notifier, MacOSNotifications)

    @pytest.mark.skipif(sys.platform == "darwin", reason="Non-macOS platforms only")
    def test_non_macos_functionality(self):
        """Test functionality on non-macOS platforms."""
        # This test would skip on macOS
        self.assertNotEqual(sys.platform, "darwin")

    @pytest.mark.skipif(sys.platform == "win32", reason="Unix-specific functionality")
    def test_unix_specific_functionality(self):
        """Test Unix-specific functionality."""
        # Test Unix-specific features
        self.assertNotEqual(sys.platform, "win32")


class TestResourceCleanup(unittest.TestCase):
    """Test proper resource cleanup in all environments."""

    def setUp(self):
        """Set up test fixtures."""
        self.temp_files = []
        self.temp_dirs = []

    def tearDown(self):
        """Clean up resources."""
        import shutil

        # Clean up temporary files and directories
        self._cleanup_temp_files()
        self._cleanup_temp_directories(shutil)

    def _cleanup_temp_files(self):
        """Helper method to clean up temporary files."""
        self._safe_cleanup_files(self.temp_files)

    def _cleanup_temp_directories(self, shutil):
        """Helper method to clean up temporary directories."""
        self._safe_cleanup_directories(self.temp_dirs, shutil)

    def _safe_cleanup_files(self, file_list):
        """Safely clean up a list of files."""
        for temp_file in file_list:
            try:
                if temp_file.exists():
                    temp_file.unlink()
            except Exception:
                pass  # Best effort cleanup

    def _safe_cleanup_directories(self, dir_list, shutil):
        """Safely clean up a list of directories."""
        for temp_dir in dir_list:
            try:
                if temp_dir.exists():
                    shutil.rmtree(temp_dir)
            except Exception:
                pass  # Best effort cleanup

    def test_file_cleanup(self):
        """Test file cleanup works properly."""
        from pathlib import Path

        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_path = Path(temp_file.name)
            self.temp_files.append(temp_path)

            # File should exist
            self.assertTrue(temp_path.exists())

            # Write to file
            temp_file.write(b"test content")
            temp_file.flush()

        # File should still exist after context exit (delete=False)
        self.assertTrue(temp_path.exists())

        # Cleanup will happen in tearDown

    def test_directory_cleanup(self):
        """Test directory cleanup works properly."""
        from pathlib import Path

        temp_dir = Path(tempfile.mkdtemp())
        self.temp_dirs.append(temp_dir)

        # Directory should exist
        self.assertTrue(temp_dir.exists())

        # Create a file in the directory
        test_file = temp_dir / "test.txt"
        test_file.write_text("test content")
        self.assertTrue(test_file.exists())

        # Cleanup will happen in tearDown


class TestNetworkMocking(unittest.TestCase):
    """Test network operation mocking for CI compatibility."""

    def test_http_request_mocking(self):
        """Test HTTP request mocking works in all environments."""
        from unittest.mock import Mock

        # Mock a hypothetical HTTP library instead of real requests
        with patch("builtins.__import__"):
            # Mock the requests module
            mock_requests = Mock()
            mock_response = Mock()
            mock_response.status_code = 200
            mock_response.json.return_value = {"status": "ok"}
            mock_requests.get.return_value = mock_response

            # Test the mocking pattern
            response = mock_requests.get("https://api.example.com/status")

            self.assertEqual(response.status_code, 200)
            self.assertEqual(response.json(), {"status": "ok"})

    def test_subprocess_mocking(self):
        """Test subprocess mocking for external commands."""
        with patch("subprocess.run") as mock_run:
            mock_run.return_value = MagicMock()
            mock_run.return_value.stdout = "mocked output"
            mock_run.return_value.returncode = 0

            import subprocess

            result = subprocess.run(["echo", "test"], capture_output=True, text=True)

            self.assertEqual(result.returncode, 0)
            self.assertEqual(result.stdout, "mocked output")


class TestMemoryManagement(unittest.TestCase):
    """Test memory management in long-running tests."""

    def test_large_data_structures(self):
        """Test handling of large data structures."""
        # Create a large list
        large_list = list(range(10000))

        # Process it using helper method
        processed = self._process_large_list(large_list)

        # Verify it worked
        self.assertEqual(len(processed), 5000)
        self.assertEqual(processed[0], 0)
        # Last even number in range(10000) is 9998, so 9998 * 2 = 19996
        self.assertEqual(processed[-1], 19996)

        # Clean up explicitly
        del large_list
        del processed

    def _process_large_list(self, large_list):
        """Helper method to process large list with conditional logic."""
        return [x * 2 for x in large_list if x % 2 == 0]

    def test_memory_intensive_operations(self):
        """Test memory-intensive operations complete successfully."""
        # Create multiple temporary objects using helper method
        temp_objects = self._create_test_memory_objects()

        # Verify they were created
        self.assertEqual(len(temp_objects), 1000)

        # Process them using helper method
        total_values = self._count_total_values(temp_objects)
        self.assertEqual(total_values, 100000)

        # Clean up
        temp_objects.clear()

    def _create_test_memory_objects(self):
        """Helper method to create test memory objects with loop."""
        temp_objects = []
        for i in range(1000):
            temp_obj = {"id": i, "data": f"test_data_{i}", "values": list(range(100))}
            temp_objects.append(temp_obj)
        return temp_objects

    def _count_total_values(self, temp_objects):
        """Helper method to count total values with comprehension."""
        return sum(len(obj["values"]) for obj in temp_objects)


if __name__ == "__main__":
    unittest.main()
