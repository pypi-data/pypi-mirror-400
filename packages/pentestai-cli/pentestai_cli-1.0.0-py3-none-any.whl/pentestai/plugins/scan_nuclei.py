from __future__ import annotations

import json
import subprocess
from typing import Dict, Any, List

from pentestai.plugins.base import Plugin
from pentestai.core.artifacts import Artifact, now_iso, save_artifact, ws_paths


class NucleiPlugin(Plugin):
    name = "nuclei"

    def run(self, ctx, args: Dict[str, Any]) -> Dict[str, Any]:
        paths = ws_paths(ctx.workspace)
        live = paths["artifacts"] / "recon_live.json"
        if not live.exists():
            raise RuntimeError("Missing recon_live.json. Run: pentestai recon run")

        live_data = json.loads(live.read_text(encoding="utf-8"))
        urls = live_data["data"].get("urls", [])
        urls_file = paths["artifacts"] / "scan_urls.txt"
        urls_file.write_text("\n".join(urls) + ("\n" if urls else ""), encoding="utf-8")

        # read flags from ctx.vars (CLI) with fallback to args
        severity = (
            (ctx.vars.get("nuclei_severity") if hasattr(ctx, "vars") else None)
            or args.get("severity")
            or "low,medium,high,critical"
        )
        tags = ((ctx.vars.get("nuclei_tags") if hasattr(ctx, "vars") else "") or "").strip()
        exclude_tags = ((ctx.vars.get("nuclei_exclude_tags") if hasattr(ctx, "vars") else "") or "").strip()
        templates = ((ctx.vars.get("nuclei_templates") if hasattr(ctx, "vars") else "") or "").strip()

        rate_limit = str((ctx.vars.get("nuclei_rate_limit") if hasattr(ctx, "vars") else None) or 150)
        concurrency = str((ctx.vars.get("nuclei_concurrency") if hasattr(ctx, "vars") else None) or 25)
        retries = str((ctx.vars.get("nuclei_retries") if hasattr(ctx, "vars") else None) or 1)

        dry_run = bool((ctx.vars.get("dry_run") if hasattr(ctx, "vars") else False))

        out_jsonl = paths["artifacts"] / "scan_nuclei.jsonl"

        cmd = [
            "nuclei",
            "-l",
            str(urls_file),
            "-severity",
            str(severity),
            "-jsonl",
            "-o",
            str(out_jsonl),
            "-rate-limit",
            rate_limit,
            "-c",
            concurrency,
            "-retries",
            retries,
        ]
        if tags:
            cmd += ["-tags", tags]
        if exclude_tags:
            cmd += ["-exclude-tags", exclude_tags]
        if templates:
            cmd += ["-t", templates]

        # execute / dry-run 
        exit_code = 0
        stderr_tail = ""
        stdout_tail = ""
        if dry_run:
            # don't run; keep empty findings
            findings: List[dict] = []
        else:
            r = subprocess.run(cmd, capture_output=True, text=True)
            exit_code = r.returncode
            stderr_tail = (r.stderr or "")[-2000:]
            stdout_tail = (r.stdout or "")[-2000:]

            findings = []
            if out_jsonl.exists():
                for line in out_jsonl.read_text(encoding="utf-8", errors="ignore").splitlines():
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        findings.append(json.loads(line))
                    except Exception:
                        pass

        art = Artifact(
            kind="scan.nuclei",
            created_at=now_iso(),
            data={
                "findings": findings,
                "count": len(findings),
                "severity": str(severity),
                "tags": tags,
                "exclude_tags": exclude_tags,
                "templates": templates,
                "rate_limit": int(rate_limit),
                "concurrency": int(concurrency),
                "retries": int(retries),
                "dry_run": dry_run,
            },
            meta={
                "cmd": cmd,
                "exit_code": exit_code,
                "stderr": stderr_tail,
                "stdout": stdout_tail,
            },
        )

        save_artifact(paths["artifacts"] / "scan_findings.json", art)
        return art.model_dump()
