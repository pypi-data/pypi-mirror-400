#!/usr/bin/env python3
# coding: utf-8
# Copyright (c) 2025 Huawei Technologies Co., Ltd.
# This program is free software, you can redistribute it and/or modify it under the terms and conditions of
# CANN Open Software License Agreement Version 2.0 (the "License").
# Please refer to the License for details. You may not use this file except in compliance with the License.
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
# INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
# See LICENSE in the root of the software repository for the full text of the License.
# -----------------------------------------------------------------------------------------------------------
import enum
from typing import Iterator, overload, Union, List, Dict, Tuple, Optional


class DataType(enum.Enum):
    DT_INT4 = ...
    DT_INT8 = ...
    DT_INT16 = ...
    DT_INT32 = ...
    DT_INT64 = ...
    DT_FP8 = ...
    DT_FP16 = ...
    DT_FP32 = ...
    DT_BF16 = ...
    DT_HF4 = ...
    DT_HF8 = ...
    DT_UINT8 = ...
    DT_UINT16 = ...
    DT_UINT32 = ...
    DT_UINT64 = ...
    DT_BOOL = ...
    DT_DOUBLE = ...
    DT_BOTTOM = ...


class ScatterMode(enum.Enum):
    NONE = ...      # 仅做数据搬运
    ADD = ...       # 加法模式
    MULTIPLY = ...  # 乘法模式


class NodeType(enum.Enum):
    LOCAL = ...
    INCAST = ...
    OUTCAST = ...


class TileOpFormat(enum.Enum):
    TILEOP_ND = ...
    TILEOP_NZ = ...


class CachePolicy(enum.Enum):
    NONE_CACHEABLE = ...


class ReduceMode(enum.Enum):
    ATOMIC_ADD = ...


class MemoryType(enum.Enum):
    MEM_UB = ...
    MEM_L1 = ...
    MEM_L0A = ...
    MEM_L0B = ...
    MEM_L0C = ...
    MEM_DEVICE_DDR = ...


class FunctionType(enum.Enum):
    STATIC = ...
    DYNAMIC = ...
    DYNAMIC_LOOP = ...


class GraphType:
    TENSOR_GRAPH = ...


class CastMode(enum.Enum):
    CAST_NONE = ...
    CAST_RINT = ...
    CAST_ROUND = ...
    CAST_FLOOR = ...
    CAST_CEIL = ...
    CAST_TRUNC = ...
    CAST_ODD = ...


class LogBaseType(enum.Enum):
    LOG_E = ...
    LOG_2 = ...
    LOG_10 = ...


class OpType(enum.Enum):
    EQ = ...
    NE = ...
    LT = ...
    LE = ...
    GT = ...
    GE = ...


class OutType(enum.Enum):
    BOOL = ...
    BIT = ...


class ReLuType(enum.Enum):
    NO_RELU = ...
    RELU = ...


class Element:

    def __init__(self, dtype: DataType, data: Union[int, float]): ...

    def _get_signed_data(self) -> int: ...

    def _get_float_data(self) -> float: ...

    def _get_data_type(self) -> DataType: ...

    def _is_float(self) -> bool: ...


class SymbolicScalar:

    @overload
    def __init__(self): ...

    @overload
    def __init__(self, name: str): ...

    @overload
    def __init__(self, value: int): ...

    @overload
    def __init__(self, name: str, val: int): ...

    def IsImmediate(self) -> bool: ...

    def IsSymbol(self) -> bool: ...

    def IsExpression(self) -> bool: ...

    def ConcreteValid(self) -> bool: ...

    def Concrete(self) -> int: ...

    def AsIntermediateVariable(self) -> None: ...

    def Dump(self) -> str: ...

    def Eq(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Ne(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Lt(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Le(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Gt(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Ge(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def RAdd(self, other: int) -> SymbolicScalar: ...

    def RSub(self, other: int) -> SymbolicScalar: ...

    def RMul(self, other: int) -> SymbolicScalar: ...

    def RDiv(self, other: int) -> SymbolicScalar: ...

    def RMod(self, other: int) -> SymbolicScalar: ...

    def Add(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Sub(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Mul(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Div(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Mod(self, other: Union[SymbolicScalar, int]) -> SymbolicScalar: ...

    def Pos(self) -> SymbolicScalar: ...

    def Neg(self) -> SymbolicScalar: ...

    def Not(self) -> SymbolicScalar: ...


class Tensor:

    @overload
    def __init__(self): ...

    @overload
    def __init__(self, dtype: DataType, shape: List[int],
                 name: str = "", format: TileOpFormat = TileOpFormat.TILEOP_ND): ...

    @overload
    def __init__(self, dtype: DataType, shape: List[SymbolicScalar],
                 name: str = "", format: TileOpFormat = TileOpFormat.TILEOP_ND): ...

    def GetDataType(self) -> DataType: ...

    def GetShape(self) -> List[int]: ...

    def GetShapeAt(self, index: int) -> int: ...

    def Move(self, other: Tensor) -> Tensor: ...

    def SetCachePolicy(self, policy: CachePolicy, value: bool): ...

    def GetCachePolicy(self, policy: CachePolicy) -> bool: ...

    def SetName(self, name: str): ...

    def GetName(self) -> str: ...

    def Id(self) -> int: ...

    def Dim(self) -> int: ...

    def Format(self) -> TileOpFormat: ...


def GetInputShape(a: Tensor, axis: int) -> SymbolicScalar: ...


def GetInputData(
        a: Tensor, offsets: List[SymbolicScalar]) -> SymbolicScalar: ...


def GetTensorData(
        a: Tensor, offset: List[SymbolicScalar]) -> SymbolicScalar: ...


def SetTensorData(value: SymbolicScalar,
                  offset: List[SymbolicScalar], dst: Tensor): ...


def MarkDynamic(a: Tensor, axis: int): ...


def SetLocation(fname: str, lineno: int, backtrace: str) -> None: ...


def ClearLocation() -> None: ...


class DeviceTensorData:

    def __init__(self, dtype: DataType, addr: int, shape: List[int]): ...

    def GetDataType(self) -> DataType: ...

    def GetDataPtr(self) -> int: ...

    def GetShape(self) -> List[int]: ...


class RecordIfBranch:

    def __init__(self, cond: SymbolicScalar,
                 file: str = "", line: int = 0): ...

    def __bool__(self) -> bool: ...


class LoopRange:

    def __init__(self, start: SymbolicScalar, stop: SymbolicScalar,
                 step: Union[SymbolicScalar, int]): ...

    def Dump(self) -> str: ...

    def Begin(self) -> SymbolicScalar: ...

    def End(self) -> SymbolicScalar: ...

    def Step(self) -> SymbolicScalar: ...


def IsLoopBegin(symbol: SymbolicScalar, begin: SymbolicScalar) -> SymbolicScalar: ...


def IsLoopEnd(symbol: SymbolicScalar, end: SymbolicScalar) -> SymbolicScalar: ...


class RecordFunc:

    @overload
    def __init__(self, name: str): ...

    @overload
    def __init__(self, name: str, args: List[Tensor]): ...

    @overload
    def __init__(self, name: str, inputs: List[Tensor] = [], outputs: List[Tensor] = [],
                 inplaces: List[tuple[Tensor, Tensor]] = []): ...

    def EndFunction(self): ...


class RecordLoopFunc:

    def __init__(self, name: str, func_type: FunctionType, iter_name: str, loop_range: LoopRange,
                 unroll_List: set[int] = set(), submit_before_loop: bool = False): ...

    def __iter__(self) -> Iterator[SymbolicScalar]: ...


def BeginFunction(name: str, graph_type: GraphType,
                  func_type: FunctionType, *args): ...


def EndFunction(name: str, generate_call: bool = True): ...


def GetWorkSpaceSize(handle: int, inputs: List[DeviceTensorData], outputs: List[DeviceTensorData]) -> int: ...


def SetVecTile(*shapes: int): ...


def GetVecTile() -> List[int]: ...


def SetCubeTile(m: List[int], k: List[int],
                n: List[int], set_l1_tile: bool = False): ...


def GetCubeTile() -> Tuple[List[int], List[int], List[int], bool]: ...


def SetMatrixSize(size: List[int]): ...


def SetBuildStatic(static: bool): ...


def SetSemanticLabel(label: str, filename: str, lineno: int): ...


@overload
def SetOption(key: str, value: bool): ...


@overload
def SetOption(key: str, value: str): ...


@overload
def SetOption(key: str, value: int): ...


@overload
def SetOption(key: str, value: List[int]): ...


@overload
def SetOption(key: str, value: Dict[int, int]): ...


def GetOption(key: str) -> Union[bool, str, int, List[int], Dict[int, int]]: ...


def GetOptions() -> Dict[str, Union[bool, str, int, List[int], Dict[int, int]]]: ...


def SetPrintOptions(edge_items: int, precision: int, threshold: int, linewidth: int): ...


def BytesOf(t: DataType) -> int: ...


def Reset(): ...


def Dump() -> str: ...


# runtime
def DeviceInit(): ...


def DeviceFini(): ...
def CopyToHost(tensorData: DeviceTensorData): ...
def SetVerifyData(inputs: List[DeviceTensorData],
                  outputs: List[DeviceTensorData],
                  goldens: List[DeviceTensorData]): ...


def OperatorDeviceRunOnceDataFromDevice(operator_id: int,
                                        a: List[DeviceTensorData],
                                        dst: List[DeviceTensorData],
                                        stream_id: int,
                                        workspace_ptr: int): ...


def DeviceRunOnceDataFromHost(a: List[DeviceTensorData],
                              dst: List[DeviceTensorData]): ...


def OperatorBegin() -> int: ...


def OperatorEnd(operator_id: int): ...


def OperatorDeviceSynchronize(stream_id: int): ...

def CostModelRunOnceDataFromHost(a: List[DeviceTensorData],
                              dst: List[DeviceTensorData]): ...

# operations


def add(a: Tensor, b: Tensor) -> Tensor: ...


def sub(a: Tensor, b: Tensor) -> Tensor: ...


def mul(a: Tensor, b: Tensor) -> Tensor: ...


def div(a: Tensor, b: Tensor) -> Tensor: ...


@overload
def view(a: Tensor, shapes: List[int],
         offsets: List[SymbolicScalar]) -> Tensor: ...


@overload
def view(a: Tensor, shapes: List[int], valid_shape: List[SymbolicScalar],
         offsets: List[SymbolicScalar]) -> Tensor: ...


@overload
def view(a: Tensor, dtype: DataType) -> Tensor: ...


def exp(a: Tensor) -> Tensor: ...


def transpose(a: Tensor, axis: List[int]) -> Tensor: ...


def abs(a: Tensor) -> Tensor: ...


def reciprocal(a: Tensor) -> Tensor: ...


def rsqrt(a: Tensor) -> Tensor: ...


def sqrt(a: Tensor) -> Tensor: ...


def neg(a: Tensor) -> Tensor: ...


def log(a: Tensor, base: LogBaseType) -> Tensor: ...


def cast(a: Tensor, dtype: DataType, mode: CastMode) -> Tensor: ...


def add_s(a: Tensor, b: Element) -> Tensor: ...


def sub_s(a: Tensor, b: Element) -> Tensor: ...


def mul_s(a: Tensor, b: Element) -> Tensor: ...


def div_s(a: Tensor, b: Element) -> Tensor: ...


def row_max_single(a: Tensor, axis: int = -1) -> Tensor: ...


def row_sum_single(a: Tensor, axis: int = -1) -> Tensor: ...


def compact(a: Tensor) -> Tensor: ...


def indexput(src: Tensor, indices: List[Tensor], values: Tensor) -> Tensor: ...


def scatter_(self: Tensor, indices: Tensor, src: Element,
             axis: int = -1, reduce: str = "") -> Tensor: ...


def scatter(self: Tensor, indices: Tensor, src: Element,
            axis: int = -1, reduce: str = "") -> Tensor: ...


def gather_element(params: Tensor, indices: Tensor,
                   axis: int = -1) -> Tensor: ...


def gate(a: Tensor, b: Tensor, mask: Tensor) -> Tensor: ...


def duplicate(a: Tensor) -> Tensor: ...


def full(elem: Element, shape: List[int],
         valid_shape: Optional[List[SymbolicScalar]] = None) -> Tensor: ...


@overload
def reshape(a: Tensor, shape: List[int], valid_shape: Optional[List[SymbolicScalar]] = None,
            inplace: bool = False) -> Tensor: ...


@overload
def reshape(a: Tensor, shape: List[SymbolicScalar], inplace: bool) -> Tensor: ...


def clone(a: Tensor) -> Tensor: ...


def reduce(aggregation: List[Tensor], reduce_mode: ReduceMode) -> Tensor: ...


@overload
def maximum(a: Tensor, b: Tensor) -> Tensor: ...


@overload
def minimum(a: Tensor, b: Tensor) -> Tensor: ...


def unsqueeze(a: Tensor, axis: int) -> Tensor: ...


def tensor_index(a: Tensor, indices: Tensor) -> Tensor: ...


def scatter_update(self: Tensor, indices: Tensor, src: Tensor, axis: int = -1,
                   cacheMode: str = "PA_BNSD", chunkSize: int = 1) -> Tensor: ...


def expand(a: Tensor, shape: List[int], valid_shape: Union[List[int], List[SymbolicScalar]] = [
]) -> Tensor: ...


def new_compact(a: Tensor) -> Tensor: ...


def logic_not(a: Tensor) -> Tensor: ...


def where(a: Tensor, b: Union[Tensor, Element], c: Union[Tensor, Element]) -> Tensor: ...


def assign(a: Tensor) -> Tensor: ...


def concat(a: List[Tensor], axis: int) -> Tensor: ...


def pad(a: Tensor, new_shape: Union[List[int], List[SymbolicScalar]]) -> Tensor: ...


def topk(a: Tensor, k: int, axis: int = -1,
         islargest: bool = True) -> Tensor: ...


class MatmulExtendParam:
    @overload
    def __init__(self): ...

    @overload
    def __init__(self, bias_tensor: Tensor, scale_tensor: Tensor,
                 scale: int = 0, relu_type: ReLuType = ReLuType.NoReLu): ...


@overload
def matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
           b_trans: bool = False, c_matrix_nz: bool = False) -> Tensor: ...


@overload
def matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
           b_trans: bool = False, c_matrix_nz: bool = False, extend_params: MatmulExtendParam = None) -> Tensor: ...


def batch_matmul(dtype: DataType, a: Tensor, b: Tensor, a_trans: bool = False,
                 b_trans: bool = False, c_matrix_nz: bool = False) -> Tensor: ...


def sort(a: Tensor, axis: int = -1, islargest: bool = True) -> Tensor: ...


def quantize(a: Tensor, scale: Tensor, zero_point: Tensor,
             dtype: DataType) -> Tensor: ...


def scalar_divs(a: Tensor, b: Element,
                reverse_operand: bool = False) -> Tensor: ...


def scalar_adds(a: Tensor, b: Element,
                reverse_operand: bool = False) -> Tensor: ...


def scalar_maxs(a: Tensor, b: Element,
                reverse_operand: bool = False) -> Tensor: ...


def scalar_subs(a: Tensor, b: Element,
                reverse_operand: bool = False) -> Tensor: ...


def scalar_muls(a: Tensor, b: Element,
                reverse_operand: bool = False) -> Tensor: ...


def scalar_sub(a: Tensor, b: Tensor) -> Tensor: ...


def scalar_div(a: Tensor, b: Tensor) -> Tensor: ...


@overload
def assemble(a: List[Tensor], axis: int) -> Tensor: ...


@overload
def assemble(a: Tensor, offset: List[SymbolicScalar], dst: Tensor) -> None: ...


@overload
def maximum(a: Tensor, b: Element) -> Tensor: ...


@overload
def minimum(a: Tensor, b: Element) -> Tensor: ...


def maxs(a: Tensor, b: Element) -> Tensor: ...


# pass config
class PassConfigKey(enum.Enum):
    KEY_DUMP_GRAPH = ...


class PassConfigs:
    printGraph = ...
    dumpGraph = ...
    dumpPassTimeCost = ...
    preCheck = ...
    postCheck = ...
    disablePass = ...
    healthCheck = ...


def GetPassDefaultConfig(key: PassConfigKey, default_value: bool) -> bool: ...


def SetPassDefaultConfig(key: str, value: bool): ...


def GetPassConfig(strategy: str, identifier: str, key: PassConfigKey, default_value: bool) -> bool: ...


def SetPassConfig(strategy: str, identifier: str, key: PassConfigKey, value: bool): ...


def GetPassConfigs(strategy: str, identifier: str) -> PassConfigs: ...

def SetOperationConfig(key: str, value: bool): ...

def GetOperationConfig(key: str, default_value: bool) -> bool: ...

def GetOptionsTree() -> str: ...

def ResetLog(): ...
