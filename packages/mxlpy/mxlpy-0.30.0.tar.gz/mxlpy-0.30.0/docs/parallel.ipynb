{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94caf128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from mxlpy.parallel import Cache, parallelise\n",
    "from typing import Any\n",
    "from collections.abc import Hashable\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2271c4c7",
   "metadata": {},
   "source": [
    "## Parallelization\n",
    "\n",
    "`mxlpy` allows easy parallelisation of functions using the `parallel` module.  \n",
    "\n",
    "The API of this is built in a way to allow for easy mapping, saving results and stopping execution of long running functions.  \n",
    "\n",
    "**Sharp edge**: be aware that the usual issues of [multiprocessing on Windows](https://docs.python.org/3.7/library/multiprocessing.html#multiprocessing-programming) apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98fea94",
   "metadata": {},
   "source": [
    "## Basic API\n",
    "\n",
    "The most basic call to `parallelise` just requires\n",
    "\n",
    "1. A function that consumes an input and returns it's result\n",
    "2. A tuple of `(key, input)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca917f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(x: int) -> int:\n",
    "    return x**2\n",
    "\n",
    "\n",
    "res = parallelise(fn, inputs=[(\"a\", 1), (\"b\", 2)])\n",
    "\n",
    "print(dict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ad1d82",
   "metadata": {},
   "source": [
    "## Restricting cores\n",
    "\n",
    "By default `parallelise` will use all available CPU cores.  \n",
    "In case you want to limit that, you can use the `max_workers` parameter to set an explicit number.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e8a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    max_workers=2,\n",
    ")\n",
    "\n",
    "print(dict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286c75c",
   "metadata": {},
   "source": [
    "## Caching results\n",
    "\n",
    "By supplying the `Cache` class, you can automatically save and retrieve your calculated values.  \n",
    "\n",
    "The default settings are\n",
    "\n",
    "- Write results into `.cache` folder\n",
    "- Write and load a `pickle` file, using `{key}.p` of `inputs` as the name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    cache=Cache(),\n",
    ")\n",
    "\n",
    "print(dict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e83667",
   "metadata": {},
   "source": [
    "You can overrwite all of this.  \n",
    "Shown here is how you set a custom temporary directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f591912",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    cache=Cache(\n",
    "        tmp_dir=Path(\".cache\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(dict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55a0ce",
   "metadata": {},
   "source": [
    "And shown here is how you can implement custom load and save functions.  \n",
    "\n",
    "**Be careful to always update both `load_fn` and `save_fn` if you change one of them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_fn(k: Hashable) -> str:\n",
    "    return f\"{k}.p\"\n",
    "\n",
    "\n",
    "def load_fn(file: Path) -> Any:\n",
    "    with file.open(\"rb\") as fp:\n",
    "        return pickle.load(fp)  # nosec\n",
    "\n",
    "\n",
    "def save_fn(file: Path, data: Any) -> None:\n",
    "    with file.open(\"wb\") as fp:\n",
    "        pickle.dump(data, fp)\n",
    "\n",
    "\n",
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    cache=Cache(\n",
    "        name_fn=name_fn,\n",
    "        load_fn=load_fn,\n",
    "        save_fn=save_fn,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(dict(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20728226",
   "metadata": {},
   "source": [
    "## Timeouts\n",
    "\n",
    "You can set a timeout for long-running functions.  \n",
    "This timeout runs **per function call**, so you can recover all other runs without any problems.  \n",
    "\n",
    "E.g. check below how `a` is retrieved, while `b` caused a timeout and is thus missing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def delay_for_seconds(t: int) -> int:\n",
    "    time.sleep(t)\n",
    "    return t\n",
    "\n",
    "\n",
    "res = parallelise(\n",
    "    delay_for_seconds,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    timeout=1,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3641d4",
   "metadata": {},
   "source": [
    "## Progress bar customisation\n",
    "\n",
    "We use [tqdm](https://pypi.org/project/tqdm/) as our progress bar.  \n",
    "\n",
    "You can disable it using the `disable_tqdm` flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df237a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7a34a9",
   "metadata": {},
   "source": [
    "and customise the loop descriptor using `tqdm_desc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ede15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = parallelise(\n",
    "    fn,\n",
    "    inputs=[(\"a\", 1), (\"b\", 2)],\n",
    "    tqdm_desc=\"Loop name\",\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe83c16",
   "metadata": {},
   "source": [
    "## Running sequentially\n",
    "\n",
    "You can run a function sequentially using `parallel=False`.  \n",
    "While it might seems odd in the beginning to do this, the point is easy refactoring in cases where you might *nest* analyses.  \n",
    "\n",
    "You generally don't want `n` processes to spawn `n` new processes each.  \n",
    "The `parallel=False` flag allows you to re-use analyses written using `parallel=True` with only a single change.  \n",
    "\n",
    "This can also occasionally be useful for de-bugging functions running in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6018f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_fn(x: int) -> dict[str, int]:\n",
    "    res = parallelise(\n",
    "        fn,\n",
    "        inputs=[(\"a1\", x), (\"b1\", x**2)],\n",
    "        parallel=False,  # this shouldn't be set to True!\n",
    "    )\n",
    "    return dict(res)\n",
    "\n",
    "\n",
    "res = parallelise(\n",
    "    other_fn,\n",
    "    inputs=[(\"x1\", 2), (\"x2\", 3)],\n",
    "    parallel=True,\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da932317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxlpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
