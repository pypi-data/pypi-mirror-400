{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11d2b23",
   "metadata": {},
   "source": [
    "# **Example**: Splitting a Python Source File into Chunks with `CodeSplitter`\n",
    "\n",
    "Suppose you have a Python code file and want to split it into chunks that respect function and class boundaries (rather than just splitting every N characters). The [**`CodeSplitter`**](https://andreshere00.github.io/Splitter_MR/api_reference/splitter/#codesplitter) leverages [LangChain's RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/code_splitter/) to achieve this, making it ideal for preparing code for LLM ingestion, code review, or annotation.\n",
    "\n",
    "![Programming languages](https://bairesdev.mo.cloudinary.net/blog/2020/10/top-programming-languages.png?tx=w_1920,q_auto)\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Read the Python Source File\n",
    "\n",
    "We will use the [**`VanillaReader`**](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#vanillareader) to load our code file. You can provide a local file path (or a URL if your implementation supports it).\n",
    "\n",
    "!!! Note\n",
    "    In case that you use [`MarkItDownReader`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#markitdownreader) or [`DoclingReader`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#doclingreader), save your files in `txt` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e68c60f",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from splitter_mr.reader import VanillaReader\n",
    "\n",
    "reader = VanillaReader()\n",
    "reader_output = reader.read(\n",
    "    \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/code_example.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46c6421",
   "metadata": {},
   "source": [
    "\n",
    "The [`reader_output`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#splitter_mr.schema.models.ReaderOutput) is an object containing the raw code and its metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4f1198",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\\n\\nfrom ...schema import ReaderOutput, SplitterOutput\\nfrom ..base_splitter import BaseSplitter\\n\\n\\ndef get_langchain_language(lang_str: str) -> Language:\\n    \\\"\\\"\\\"\\n    Map a string language name to Langchain Language enum.\\n    Raises ValueError if not found.\\n    \\\"\\\"\\\"\\n    lookup = {lang.name.lower(): lang for lang in Language}\\n    key = lang_str.lower()\\n    if key not in lookup:\\n        raise ValueError(\\n            f\\\"Unsupported language '{lang_str}'. Supported: {list(lookup.keys())}\\\"\\n        )\\n    return lookup[key]\\n\\n\\nclass CodeSplitter(BaseSplitter):\\n    \\\"\\\"\\\"\\n    CodeSplitter recursively splits source code into programmatically meaningful chunks\\n    (functions, classes, methods, etc.) for the given programming language.\\n\\n    Args:\\n        chunk_size (int): Maximum chunk size, in characters.\\n        language (str): Programming language (e.g., \\\"python\\\", \\\"java\\\", \\\"kotlin\\\", etc.)\\n\\n    Notes:\\n        - Uses Langchain's RecursiveCharacterTextSplitter and its language-aware `from_language` method.\\n        - See Langchain docs: https://python.langchain.com/docs/how_to/code_splitter/\\n    \\\"\\\"\\\"\\n\\n    def __init__(\\n        self,\\n        chunk_size: int = 1000,\\n        language: str = \\\"python\\\",\\n    ):\\n        super().__init__(chunk_size)\\n        self.language = language\\n\\n    def split(self, reader_output: ReaderOutput) -> SplitterOutput:\\n        \\\"\\\"\\\"\\n        Splits code in `reader_output['text']` according to the syntax of the specified\\n        programming language, using function/class boundaries where possible.\\n\\n        Args:\\n            reader_output (ReaderOutput): Object containing at least a 'text' field,\\n                plus optional document metadata.\\n\\n        Returns:\\n            SplitterOutput: Dataclass defining the output structure for all splitters.\\n\\n        Raises:\\n            ValueError: If language is not supported.\\n\\n        Example:\\n            ```python\\n            from splitter_mr.splitter import CodeSplitter\\n\\n            reader_output = ReaderOutput(\\n                text: \\\"def foo():\\\\\\\\n    pass\\\\\\\\n\\\\\\\\nclass Bar:\\\\\\\\n    def baz(self):\\\\\\\\n        pass\\\",\\n                document_name: \\\"example.py\\\",\\n                document_path: \\\"/tmp/example.py\\\"\\n            )\\n            splitter = CodeSplitter(chunk_size=50, language=\\\"python\\\")\\n            output = splitter.split(reader_output)\\n            print(output.chunks)\\n            ```\\n            ```python\\n            ['def foo():\\\\\\\\n    pass\\\\\\\\n', 'class Bar:\\\\\\\\n    def baz(self):\\\\\\\\n        pass']\\n            ```\\n        \\\"\\\"\\\"\\n        # Initialize variables\\n        text = reader_output.text\\n        chunk_size = self.chunk_size\\n\\n        # Get Langchain language enum\\n        lang_enum = get_langchain_language(self.language)\\n\\n        splitter = RecursiveCharacterTextSplitter.from_language(\\n            language=lang_enum, chunk_size=chunk_size, chunk_overlap=0\\n        )\\n        texts = splitter.create_documents([text])\\n        chunks = [doc.page_content for doc in texts]\\n\\n        # Generate chunk_id and append metadata\\n        chunk_ids = self._generate_chunk_ids(len(chunks))\\n        metadata = self._default_metadata()\\n\\n        # Return output\\n        output = SplitterOutput(\\n            chunks=chunks,\\n            chunk_id=chunk_ids,\\n            document_name=reader_output.document_name,\\n            document_path=reader_output.document_path,\\n            document_id=reader_output.document_id,\\n            conversion_method=reader_output.conversion_method,\\n            reader_method=reader_output.reader_method,\\n            ocr_method=reader_output.ocr_method,\\n            split_method=\\\"code_splitter\\\",\\n            split_params={\\\"chunk_size\\\": chunk_size, \\\"language\\\": self.language},\\n            metadata=metadata,\\n        )\\n        return output\\n\",\n",
      "    \"document_name\": \"code_example.py\",\n",
      "    \"document_path\": \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/code_example.py\",\n",
      "    \"document_id\": \"066b580e-4c01-4e99-af82-4c0510c2fdd2\",\n",
      "    \"conversion_method\": \"txt\",\n",
      "    \"reader_method\": \"vanilla\",\n",
      "    \"ocr_method\": null,\n",
      "    \"page_placeholder\": null,\n",
      "    \"metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(reader_output.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130a2c8",
   "metadata": {},
   "source": [
    "\n",
    "To see the code content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84e1e883",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
      "\n",
      "from ...schema import ReaderOutput, SplitterOutput\n",
      "from ..base_splitter import BaseSplitter\n",
      "\n",
      "\n",
      "def get_langchain_language(lang_str: str) -> Language:\n",
      "    \"\"\"\n",
      "    Map a string language name to Langchain Language enum.\n",
      "    Raises ValueError if not found.\n",
      "    \"\"\"\n",
      "    lookup = {lang.name.lower(): lang for lang in Language}\n",
      "    key = lang_str.lower()\n",
      "    if key not in lookup:\n",
      "        raise ValueError(\n",
      "            f\"Unsupported language '{lang_str}'. Supported: {list(lookup.keys())}\"\n",
      "        )\n",
      "    return lookup[key]\n",
      "\n",
      "\n",
      "class CodeSplitter(BaseSplitter):\n",
      "    \"\"\"\n",
      "    CodeSplitter recursively splits source code into programmatically meaningful chunks\n",
      "    (functions, classes, methods, etc.) for the given programming language.\n",
      "\n",
      "    Args:\n",
      "        chunk_size (int): Maximum chunk size, in characters.\n",
      "        language (str): Programming language (e.g., \"python\", \"java\", \"kotlin\", etc.)\n",
      "\n",
      "    Notes:\n",
      "        - Uses Langchain's RecursiveCharacterTextSplitter and its language-aware `from_language` method.\n",
      "        - See Langchain docs: https://python.langchain.com/docs/how_to/code_splitter/\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        chunk_size: int = 1000,\n",
      "        language: str = \"python\",\n",
      "    ):\n",
      "        super().__init__(chunk_size)\n",
      "        self.language = language\n",
      "\n",
      "    def split(self, reader_output: ReaderOutput) -> SplitterOutput:\n",
      "        \"\"\"\n",
      "        Splits code in `reader_output['text']` according to the syntax of the specified\n",
      "        programming language, using function/class boundaries where possible.\n",
      "\n",
      "        Args:\n",
      "            reader_output (ReaderOutput): Object containing at least a 'text' field,\n",
      "                plus optional document metadata.\n",
      "\n",
      "        Returns:\n",
      "            SplitterOutput: Dataclass defining the output structure for all splitters.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If language is not supported.\n",
      "\n",
      "        Example:\n",
      "            ```python\n",
      "            from splitter_mr.splitter import CodeSplitter\n",
      "\n",
      "            reader_output = ReaderOutput(\n",
      "                text: \"def foo():\\\\n    pass\\\\n\\\\nclass Bar:\\\\n    def baz(self):\\\\n        pass\",\n",
      "                document_name: \"example.py\",\n",
      "                document_path: \"/tmp/example.py\"\n",
      "            )\n",
      "            splitter = CodeSplitter(chunk_size=50, language=\"python\")\n",
      "            output = splitter.split(reader_output)\n",
      "            print(output.chunks)\n",
      "            ```\n",
      "            ```python\n",
      "            ['def foo():\\\\n    pass\\\\n', 'class Bar:\\\\n    def baz(self):\\\\n        pass']\n",
      "            ```\n",
      "        \"\"\"\n",
      "        # Initialize variables\n",
      "        text = reader_output.text\n",
      "        chunk_size = self.chunk_size\n",
      "\n",
      "        # Get Langchain language enum\n",
      "        lang_enum = get_langchain_language(self.language)\n",
      "\n",
      "        splitter = RecursiveCharacterTextSplitter.from_language(\n",
      "            language=lang_enum, chunk_size=chunk_size, chunk_overlap=0\n",
      "        )\n",
      "        texts = splitter.create_documents([text])\n",
      "        chunks = [doc.page_content for doc in texts]\n",
      "\n",
      "        # Generate chunk_id and append metadata\n",
      "        chunk_ids = self._generate_chunk_ids(len(chunks))\n",
      "        metadata = self._default_metadata()\n",
      "\n",
      "        # Return output\n",
      "        output = SplitterOutput(\n",
      "            chunks=chunks,\n",
      "            chunk_id=chunk_ids,\n",
      "            document_name=reader_output.document_name,\n",
      "            document_path=reader_output.document_path,\n",
      "            document_id=reader_output.document_id,\n",
      "            conversion_method=reader_output.conversion_method,\n",
      "            reader_method=reader_output.reader_method,\n",
      "            ocr_method=reader_output.ocr_method,\n",
      "            split_method=\"code_splitter\",\n",
      "            split_params={\"chunk_size\": chunk_size, \"language\": self.language},\n",
      "            metadata=metadata,\n",
      "        )\n",
      "        return output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5cf01",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Step 2: Chunk the Code Using `CodeSplitter`\n",
    "\n",
    "To split your code by language-aware logical units, instantiate the `CodeSplitter`, specifying the `chunk_size` (maximum number of characters per chunk) and `language` (e.g., `\"python\"`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1bf9210",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from splitter_mr.splitter import CodeSplitter\n",
    "\n",
    "splitter = CodeSplitter(chunk_size=1000, language=\"python\")\n",
    "splitter_output = splitter.split(reader_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aef0f4",
   "metadata": {},
   "source": [
    "\n",
    "The [`splitter_output`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#splitter_mr.schema.models.ReaderOutput) contains the split code chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24c7b3b6",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunks=['from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\\n\\nfrom ...schema import ReaderOutput, SplitterOutput\\nfrom ..base_splitter import BaseSplitter\\n\\n\\ndef get_langchain_language(lang_str: str) -> Language:\\n    \"\"\"\\n    Map a string language name to Langchain Language enum.\\n    Raises ValueError if not found.\\n    \"\"\"\\n    lookup = {lang.name.lower(): lang for lang in Language}\\n    key = lang_str.lower()\\n    if key not in lookup:\\n        raise ValueError(\\n            f\"Unsupported language \\'{lang_str}\\'. Supported: {list(lookup.keys())}\"\\n        )\\n    return lookup[key]', 'class CodeSplitter(BaseSplitter):\\n    \"\"\"\\n    CodeSplitter recursively splits source code into programmatically meaningful chunks\\n    (functions, classes, methods, etc.) for the given programming language.\\n\\n    Args:\\n        chunk_size (int): Maximum chunk size, in characters.\\n        language (str): Programming language (e.g., \"python\", \"java\", \"kotlin\", etc.)\\n\\n    Notes:\\n        - Uses Langchain\\'s RecursiveCharacterTextSplitter and its language-aware `from_language` method.\\n        - See Langchain docs: https://python.langchain.com/docs/how_to/code_splitter/\\n    \"\"\"\\n\\n    def __init__(\\n        self,\\n        chunk_size: int = 1000,\\n        language: str = \"python\",\\n    ):\\n        super().__init__(chunk_size)\\n        self.language = language\\n\\n    def split(self, reader_output: ReaderOutput) -> SplitterOutput:\\n        \"\"\"\\n        Splits code in `reader_output[\\'text\\']` according to the syntax of the specified\\n        programming language, using function/class boundaries where possible.', \"Args:\\n            reader_output (ReaderOutput): Object containing at least a 'text' field,\\n                plus optional document metadata.\\n\\n        Returns:\\n            SplitterOutput: Dataclass defining the output structure for all splitters.\\n\\n        Raises:\\n            ValueError: If language is not supported.\\n\\n        Example:\\n            ```python\\n            from splitter_mr.splitter import CodeSplitter\", 'reader_output = ReaderOutput(\\n                text: \"def foo():\\\\\\\\n    pass\\\\\\\\n\\\\\\\\nclass Bar:\\\\\\\\n    def baz(self):\\\\\\\\n        pass\",\\n                document_name: \"example.py\",\\n                document_path: \"/tmp/example.py\"\\n            )\\n            splitter = CodeSplitter(chunk_size=50, language=\"python\")\\n            output = splitter.split(reader_output)\\n            print(output.chunks)\\n            ```\\n            ```python\\n            [\\'def foo():\\\\\\\\n    pass\\\\\\\\n\\', \\'class Bar:\\\\\\\\n    def baz(self):\\\\\\\\n        pass\\']\\n            ```\\n        \"\"\"\\n        # Initialize variables\\n        text = reader_output.text\\n        chunk_size = self.chunk_size\\n\\n        # Get Langchain language enum\\n        lang_enum = get_langchain_language(self.language)', 'splitter = RecursiveCharacterTextSplitter.from_language(\\n            language=lang_enum, chunk_size=chunk_size, chunk_overlap=0\\n        )\\n        texts = splitter.create_documents([text])\\n        chunks = [doc.page_content for doc in texts]\\n\\n        # Generate chunk_id and append metadata\\n        chunk_ids = self._generate_chunk_ids(len(chunks))\\n        metadata = self._default_metadata()', '# Return output\\n        output = SplitterOutput(\\n            chunks=chunks,\\n            chunk_id=chunk_ids,\\n            document_name=reader_output.document_name,\\n            document_path=reader_output.document_path,\\n            document_id=reader_output.document_id,\\n            conversion_method=reader_output.conversion_method,\\n            reader_method=reader_output.reader_method,\\n            ocr_method=reader_output.ocr_method,\\n            split_method=\"code_splitter\",\\n            split_params={\"chunk_size\": chunk_size, \"language\": self.language},\\n            metadata=metadata,\\n        )\\n        return output'] chunk_id=['fb8dd18e-7519-4dc7-a09c-037a914bbf69', 'db617a4a-5b69-4e63-aaf4-9a421fc06fa2', 'fece7161-c58f-444e-85e0-16452b46a563', '104f647b-defa-4ce1-a9d7-c465a62712d5', '4a9b8b7b-5cbe-43f4-9089-3e4fa823d110', 'a258847d-9b4e-40e6-8d04-8f4a9d71a702'] document_name='code_example.py' document_path='https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/code_example.py' document_id='066b580e-4c01-4e99-af82-4c0510c2fdd2' conversion_method='txt' reader_method='vanilla' ocr_method=None split_method='code_splitter' split_params={'chunk_size': 1000, 'language': 'python'} metadata={}\n"
     ]
    }
   ],
   "source": [
    "print(splitter_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c5a665",
   "metadata": {},
   "source": [
    "\n",
    "To inspect the split results, iterate over the chunks and print them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1aebcb6e",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 0 ========================================\n",
      "from langchain_text_splitters import Language, RecursiveCharacterTextSplitter\n",
      "\n",
      "from ...schema import ReaderOutput, SplitterOutput\n",
      "from ..base_splitter import BaseSplitter\n",
      "\n",
      "\n",
      "def get_langchain_language(lang_str: str) -> Language:\n",
      "    \"\"\"\n",
      "    Map a string language name to Langchain Language enum.\n",
      "    Raises ValueError if not found.\n",
      "    \"\"\"\n",
      "    lookup = {lang.name.lower(): lang for lang in Language}\n",
      "    key = lang_str.lower()\n",
      "    if key not in lookup:\n",
      "        raise ValueError(\n",
      "            f\"Unsupported language '{lang_str}'. Supported: {list(lookup.keys())}\"\n",
      "        )\n",
      "    return lookup[key]\n",
      "======================================== Chunk 1 ========================================\n",
      "class CodeSplitter(BaseSplitter):\n",
      "    \"\"\"\n",
      "    CodeSplitter recursively splits source code into programmatically meaningful chunks\n",
      "    (functions, classes, methods, etc.) for the given programming language.\n",
      "\n",
      "    Args:\n",
      "        chunk_size (int): Maximum chunk size, in characters.\n",
      "        language (str): Programming language (e.g., \"python\", \"java\", \"kotlin\", etc.)\n",
      "\n",
      "    Notes:\n",
      "        - Uses Langchain's RecursiveCharacterTextSplitter and its language-aware `from_language` method.\n",
      "        - See Langchain docs: https://python.langchain.com/docs/how_to/code_splitter/\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        chunk_size: int = 1000,\n",
      "        language: str = \"python\",\n",
      "    ):\n",
      "        super().__init__(chunk_size)\n",
      "        self.language = language\n",
      "\n",
      "    def split(self, reader_output: ReaderOutput) -> SplitterOutput:\n",
      "        \"\"\"\n",
      "        Splits code in `reader_output['text']` according to the syntax of the specified\n",
      "        programming language, using function/class boundaries where possible.\n",
      "======================================== Chunk 2 ========================================\n",
      "Args:\n",
      "            reader_output (ReaderOutput): Object containing at least a 'text' field,\n",
      "                plus optional document metadata.\n",
      "\n",
      "        Returns:\n",
      "            SplitterOutput: Dataclass defining the output structure for all splitters.\n",
      "\n",
      "        Raises:\n",
      "            ValueError: If language is not supported.\n",
      "\n",
      "        Example:\n",
      "            ```python\n",
      "            from splitter_mr.splitter import CodeSplitter\n",
      "======================================== Chunk 3 ========================================\n",
      "reader_output = ReaderOutput(\n",
      "                text: \"def foo():\\\\n    pass\\\\n\\\\nclass Bar:\\\\n    def baz(self):\\\\n        pass\",\n",
      "                document_name: \"example.py\",\n",
      "                document_path: \"/tmp/example.py\"\n",
      "            )\n",
      "            splitter = CodeSplitter(chunk_size=50, language=\"python\")\n",
      "            output = splitter.split(reader_output)\n",
      "            print(output.chunks)\n",
      "            ```\n",
      "            ```python\n",
      "            ['def foo():\\\\n    pass\\\\n', 'class Bar:\\\\n    def baz(self):\\\\n        pass']\n",
      "            ```\n",
      "        \"\"\"\n",
      "        # Initialize variables\n",
      "        text = reader_output.text\n",
      "        chunk_size = self.chunk_size\n",
      "\n",
      "        # Get Langchain language enum\n",
      "        lang_enum = get_langchain_language(self.language)\n",
      "======================================== Chunk 4 ========================================\n",
      "splitter = RecursiveCharacterTextSplitter.from_language(\n",
      "            language=lang_enum, chunk_size=chunk_size, chunk_overlap=0\n",
      "        )\n",
      "        texts = splitter.create_documents([text])\n",
      "        chunks = [doc.page_content for doc in texts]\n",
      "\n",
      "        # Generate chunk_id and append metadata\n",
      "        chunk_ids = self._generate_chunk_ids(len(chunks))\n",
      "        metadata = self._default_metadata()\n",
      "======================================== Chunk 5 ========================================\n",
      "# Return output\n",
      "        output = SplitterOutput(\n",
      "            chunks=chunks,\n",
      "            chunk_id=chunk_ids,\n",
      "            document_name=reader_output.document_name,\n",
      "            document_path=reader_output.document_path,\n",
      "            document_id=reader_output.document_id,\n",
      "            conversion_method=reader_output.conversion_method,\n",
      "            reader_method=reader_output.reader_method,\n",
      "            ocr_method=reader_output.ocr_method,\n",
      "            split_method=\"code_splitter\",\n",
      "            split_params={\"chunk_size\": chunk_size, \"language\": self.language},\n",
      "            metadata=metadata,\n",
      "        )\n",
      "        return output\n"
     ]
    }
   ],
   "source": [
    "for idx, chunk in enumerate(splitter_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx} \" + \"=\" * 40)\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d91a1",
   "metadata": {},
   "source": [
    "\n",
    "**And that's it!** You now have an efficient, language-aware way to chunk your code files for downstream tasks. \n",
    "\n",
    "Remember that you have plenty of programming languages available: **JavaScript, Go, Rust, Java**, etc. Currently, the available programming languages are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93df7dcb",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "\n",
    "SUPPORTED_PROGRAMMING_LANGUAGES: Set[str] = {\n",
    "    \"lua\",\n",
    "    \"java\",\n",
    "    \"ts\",\n",
    "    \"tsx\",\n",
    "    \"ps1\",\n",
    "    \"psm1\",\n",
    "    \"psd1\",\n",
    "    \"ps1xml\",\n",
    "    \"php\",\n",
    "    \"php3\",\n",
    "    \"php4\",\n",
    "    \"php5\",\n",
    "    \"phps\",\n",
    "    \"phtml\",\n",
    "    \"rs\",\n",
    "    \"cs\",\n",
    "    \"csx\",\n",
    "    \"cob\",\n",
    "    \"cbl\",\n",
    "    \"hs\",\n",
    "    \"scala\",\n",
    "    \"swift\",\n",
    "    \"tex\",\n",
    "    \"rb\",\n",
    "    \"erb\",\n",
    "    \"kt\",\n",
    "    \"kts\",\n",
    "    \"go\",\n",
    "    \"html\",\n",
    "    \"htm\",\n",
    "    \"rst\",\n",
    "    \"ex\",\n",
    "    \"exs\",\n",
    "    \"md\",\n",
    "    \"markdown\",\n",
    "    \"proto\",\n",
    "    \"sol\",\n",
    "    \"c\",\n",
    "    \"h\",\n",
    "    \"cpp\",\n",
    "    \"cc\",\n",
    "    \"cxx\",\n",
    "    \"c++\",\n",
    "    \"hpp\",\n",
    "    \"hh\",\n",
    "    \"hxx\",\n",
    "    \"js\",\n",
    "    \"mjs\",\n",
    "    \"py\",\n",
    "    \"pyw\",\n",
    "    \"pyc\",\n",
    "    \"pyo\",\n",
    "    \"pl\",\n",
    "    \"pm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef832e8",
   "metadata": {},
   "source": [
    "\n",
    "!!! Note\n",
    "\n",
    "    Remember that you can visit the [LangchainTextSplitter documentation](https://python.langchain.com/docs/how_to/code_splitter/) to see the up-to-date information about the available programming languages to split on.\n",
    "\n",
    "## Complete Script\n",
    "\n",
    "Here is a full example you can run directly:\n",
    "\n",
    "```python\n",
    "from splitter_mr.reader import VanillaReader\n",
    "from splitter_mr.splitter import CodeSplitter\n",
    "\n",
    "# Step 1: Read the code file\n",
    "reader = VanillaReader()\n",
    "reader_output = reader.read(\"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/code_example.py\")\n",
    "\n",
    "print(reader_output.model_dump_json(indent=4))  # See metadata\n",
    "print(reader_output.text)  # See raw code\n",
    "\n",
    "# Step 2: Split code into logical chunks, max 1000 chars per chunk\n",
    "splitter = CodeSplitter(chunk_size=1000, language=\"python\")\n",
    "splitter_output = splitter.split(reader_output)\n",
    "\n",
    "print(splitter_output)  # Print the SplitterOutput object\n",
    "\n",
    "# Step 3: Visualize code chunks\n",
    "for idx, chunk in enumerate(splitter_output.chunks):\n",
    "    print(\"=\"*40 + f\" Chunk {idx} \" + \"=\"*40)\n",
    "    print(chunk)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8acd67c",
   "metadata": {},
   "source": [
    "\n",
    "### References\n",
    "\n",
    "[LangChain's RecursiveCharacterTextSplitter](https://python.langchain.com/docs/how_to/code_splitter/) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "orig_format": "markdown",
  "source_file": "docs/examples/schema/code_splitter.md"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
