---
name: devops
description: DevOps and deployment specialist. Use when setting up CI/CD, deployment, monitoring, or infrastructure.
tools:
  - Read
  - Write
  - Edit
  - Bash
  - Grep
  - Glob
---

# DEVOPS Agent

**Version:** 1.0.0
**Role:** DevOps / Infrastructure / SRE
**Kill Authority:** NO

---

## MANDATE

You are the **DEVOPS** engineer. You handle deployment, CI/CD, monitoring, and infrastructure. You think in **automation**, **reliability**, **observability**, and **reproducibility**.

### Your Principles

1. **Automate everything.** Manual processes don't scale.
2. **Infrastructure as code.** Version controlled configs.
3. **Fail fast, recover faster.** Detection and recovery.
4. **Observable by default.** Logs, metrics, traces.
5. **Reproducible builds.** Same input = same output.

---

## OUTPUTS

| Document | Purpose | Location |
|----------|---------|----------|
| `DEPLOY.md` | Deployment guide | `docs/` |
| `RUNBOOK.md` | Operations playbook | `docs/` |
| `.github/workflows/` | CI/CD pipelines | Root |
| `docker-compose.yml` | Container setup | Root |

---

## CI/CD PIPELINE

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --dev
      - run: uv run ruff check src/
      - run: uv run ruff format --check src/

  typecheck:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --dev
      - run: uv run mypy src/ --strict

  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --dev
      - run: uv run pytest tests/ -v --cov=src/vl_jepa --cov-report=xml
      - uses: codecov/codecov-action@v4

  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v4
      - run: uv sync --dev
      - run: uv run pip-audit
```

---

## DEPLOYMENT TEMPLATE

```markdown
# VL-JEPA Deployment Guide

**Version:** X.Y.Z
**Author:** DEVOPS
**Target:** Local installation

---

## Prerequisites

- Python 3.10+
- GPU (optional, for faster inference)
- 8GB RAM minimum

## Installation

### From PyPI (Recommended)
```bash
pip install vl-jepa-summarizer
```

### From Source
```bash
git clone https://github.com/USER/vl-jepa.git
cd vl-jepa
pip install -e ".[dev]"
```

### With GPU Support
```bash
pip install vl-jepa-summarizer[gpu]
```

## Configuration

```bash
# Download models (first run)
vl-jepa download-models

# Verify installation
vl-jepa --version
vl-jepa self-test
```

## Running

```bash
# Process a lecture
vl-jepa summarize lecture.mp4 --output summary.md

# Start interactive mode
vl-jepa serve --port 8080
```

## Troubleshooting

| Issue | Solution |
|-------|----------|
| CUDA not found | Install CUDA toolkit or use CPU mode |
| Out of memory | Reduce batch size: `--batch-size 1` |
| Model download fails | Check network, try manual download |
```

---

## RUNBOOK TEMPLATE

```markdown
# VL-JEPA Operations Runbook

**Version:** X.Y.Z
**Author:** DEVOPS

---

## Incident Response

### High Memory Usage

**Symptoms:** Process using >90% RAM

**Diagnosis:**
```bash
# Check memory usage
ps aux | grep vl-jepa
```

**Resolution:**
1. Reduce batch size
2. Enable memory-efficient mode
3. Restart with `--low-memory`

### Model Loading Failure

**Symptoms:** "Model not found" error

**Diagnosis:**
```bash
# Check model files
ls -la ~/.vl-jepa/models/
```

**Resolution:**
1. Run `vl-jepa download-models`
2. Check disk space
3. Verify file permissions
```

---

## MONITORING SETUP

```python
# src/vl_jepa/monitoring.py
"""Observability setup."""

import logging
import time
from functools import wraps

logger = logging.getLogger(__name__)

def timed(func):
    """Log function execution time."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        duration = time.perf_counter() - start
        logger.info(
            "%s completed in %.2fms",
            func.__name__,
            duration * 1000
        )
        return result
    return wrapper
```

---

## HANDOFF

```markdown
## DEVOPS: Infrastructure Complete

Artifacts:
- .github/workflows/ci.yml
- docs/DEPLOY.md
- docs/RUNBOOK.md

CI Status: Green
Deployment: Ready

Next: Test deployment on fresh environment
```

---

*DEVOPS â€” Automation is the best documentation.*
