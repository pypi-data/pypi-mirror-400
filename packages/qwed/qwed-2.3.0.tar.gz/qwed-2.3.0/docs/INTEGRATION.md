# ğŸ¯ QWED Integration Guide

> **TL;DR:** Don't call your LLM yourself. Let QWED handle it. âœ…

---

## âš ï¸ Common Mistake

**Most users think:**

![Wrong Integration Pattern](assets/qwed_wrong_integration.png)

### âŒ DON'T DO THIS:

```python
# âŒ WRONG!
import openai
from qwed import QWEDClient

# Calling LLM yourself
response = openai.ChatCompletion.create(...)

# Then trying to verify
qwed.verify(response.content)  # TOO LATE!
```

**Why this fails:**
- ğŸš« No control over LLM prompts
- ğŸš« No DSL enforcement  
- ğŸš« Vulnerable to prompt injection
- ğŸš« Can't guarantee structured output

---

## âœ… Correct Approach

![Correct Integration Pattern](assets/qwed_correct_integration.png)

### âœ… DO THIS:

```python
# âœ… CORRECT!
from qwed import QWEDClient

qwed = QWEDClient(api_key="qwed_...")

# Just call QWED directly
result = qwed.verify("Is 2+2 equal to 4?")

print(result.verified)  # True âœ…
```

**Why this works:**
- âœ… QWED controls LLM internally
- âœ… Structured prompts ensure DSL output
- âœ… Formal verification layer active
- âœ… 100% deterministic results

---

## ğŸ”„ How QWED Really Works

![QWED Architecture Flow](assets/qwed_architecture_flow.png)

### Step-by-Step:

```
1ï¸âƒ£ Your Code
    â”‚
    â”œâ”€â†’ "Is 15% of 200 equal to 30?"
    â”‚
    â–¼
2ï¸âƒ£ QWED API Gateway
    â”‚
    â”œâ”€â†’ Sends to LLM (with special prompts)
    â”‚   â”œâ”€â†’ LLM extracts: "15% Ã— 200 = 30"
    â”‚   â””â”€â†’ Returns structured data
    â”‚
    â”œâ”€â†’ Sends to Formal Verifiers
    â”‚   â”œâ”€â†’ SymPy calculates: 0.15 Ã— 200 = 30
    â”‚   â””â”€â†’ Verification: âœ… MATCH
    â”‚
    â–¼
3ï¸âƒ£ Deterministic Result
    â”‚
    â””â”€â†’ {verified: true, evidence: {...}}
```

---

## ğŸ“– Quick Start Examples

### 1ï¸âƒ£ Math Verification

```python
from qwed import QWEDClient

client = QWEDClient(api_key="your_key")

# âœ… Natural language input
result = client.verify("Is 2+2 equal to 5?")

# What happens inside QWED:
# ğŸ“ LLM extracts: "2+2=5"
# ğŸ”¬ SymPy verifies: 2+2 = 4 (not 5!)
# âŒ Returns: verified=False

print(result.verified)  # False
print(result.reason)    # "Expected 4, got 5"
print(result.evidence)  # {"calculated": 4, "claimed": 5}
```

**Visual Flow:**
```
User Query â†’ QWED â†’ [LLM: "2+2=5"] â†’ [SymPy: 4â‰ 5] â†’ âŒ Failed
```

---

### 2ï¸âƒ£ Code Security

```python
dangerous_code = """
def get_user(username):
    query = f"SELECT * FROM users WHERE name='{username}'"
    return db.execute(query)
"""

result = client.verify_code(dangerous_code, language="python")

# What happens inside QWED:
# ğŸ“ LLM identifies: String interpolation in SQL
# ğŸ”¬ AST parser finds: User input in query
# ğŸš« Security engine: SQL INJECTION RISK
# âŒ Returns: blocked=True

print(result.blocked)  # True ğŸš«
print(result.vulnerabilities)  # ["SQL Injection"]
print(result.severity)  # "HIGH"
```

**Visual Flow:**
```
Code â†’ QWED â†’ [LLM: Detects SQL] â†’ [AST: f-string in query] â†’ ğŸš« BLOCKED
```

---

## ğŸ¨ Visual Comparison

### Traditional LLM Call:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your App   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ "Calculate 2+2"
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPT-4 API  â”‚ ğŸ² Random output
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ "2 + 2 = 5"  âŒ WRONG!
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your App   â”‚ ğŸ’¥ Uses wrong answer
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### QWED Call:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Your App   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ "Calculate 2+2"
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         QWED API             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ LLM  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ SymPy   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚   "2+2=4"           â”‚ Verify â”‚
â”‚                     â–¼        â”‚
â”‚              âœ… VERIFIED     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ "4" âœ…
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Your App   â”‚ âœ… Correct!
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Understanding the Security Model

### The Trust Boundary:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            UNTRUSTED ZONE            â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚   LLM (OpenAI/Anthropic/etc)   â”‚  â•‘
â•‘  â”‚   â€¢ Can hallucinate            â”‚  â•‘
â•‘  â”‚   â€¢ Non-deterministic          â”‚  â•‘
â•‘  â”‚   â€¢ Prompt-injectable          â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•¤â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                 â”‚ Structured Output (DSL)
                 â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           TRUSTED ZONE               â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘
â•‘  â”‚   Formal Verifiers             â”‚  â•‘
â•‘  â”‚   â€¢ SymPy (Math)               â”‚  â•‘
â•‘  â”‚   â€¢ Z3 (Logic)                 â”‚  â•‘
â•‘  â”‚   â€¢ AST (Code)                 â”‚  â•‘
â•‘  â”‚   â€¢ SQLGlot (SQL)              â”‚  â•‘
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

**Key Point:** QWED ensures LLM output passes through the trust boundary via formal verification.

---

## ğŸ¯ Do's and Don'ts

### âœ… DO:

```python
# âœ… Call QWED directly
result = qwed.verify("Calculate 15% of 200")

# âœ… Use natural language
result = qwed.verify("Is the square root of 16 equal to 4?")

# âœ… Let QWED handle LLM internally
result = qwed.verify_code(untrusted_code, language="python")

# âœ… Trust the verification results
if result.verified:
    use_output(result.value)
```

### âŒ DON'T:

```python
# âŒ Call LLM yourself first
llm_output = openai.chat(...) 
qwed.verify(llm_output)  # TOO LATE!

# âŒ Try to bypass QWED's LLM
result = qwed.verify_math("2+2", skip_llm=True)  # No such option

# âŒ Mix QWED calls with direct LLM calls
llm_result = gpt4.complete(...)
qwed_result = qwed.verify(...)  # Inconsistent!

# âŒ Assume LLM output is correct
value = llm.generate("Calculate...")
use_value_directly(value)  # DANGEROUS!
```

---

## ğŸ‰ Quick Summary

### Remember These 3 Things:

1. **âŒ Don't call LLM yourself**  
   Let QWED handle it internally

2. **âœ… Call QWED directly**  
   Use natural language queries

3. **ğŸ”’ Trust the verification**  
   QWED uses formal methods, not guessing

### One-Line Integration:

```python
result = QWEDClient(api_key="...").verify("Your question here")
```

**That's it!** ğŸš€

---

*See [Full Integration Guide](https://docs.qwedai.com/integration) for framework integrations, debugging, and advanced usage.*
