"""
Graphiti CRUD åŠŸèƒ½æ¼”ç¤º V2
ä½¿ç”¨Graphitiå®ç°å®Œæ•´çš„CRUDæ“ä½œï¼Œè¿æ¥Neo4jæ•°æ®åº“
åŒ…å«è‡ªå®šä¹‰åˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼Œè§£å†³é˜¿é‡Œäº‘25ä¸ªæ‰¹é‡é™åˆ¶é—®é¢˜
"""

import asyncio
import json
import logging
import os
import re
import sys
import time
from datetime import datetime, timezone
from typing import List, Optional

from graphiti_core_ecolink.utils.maintenance import clear_data

from graphiti_core_ecolink.nodes import EpisodeType

from graphiti_core_ecolink import Graphiti

from graphiti_core_ecolink.search.search_config import SearchConfig
from graphiti_core_ecolink.utils.maintenance.community_operations import update_community



# ==================== å¯¼å…¥å…¶ä»–æ¨¡å— ====================
# å¯¼å…¥é˜¿é‡Œäº‘æ¨¡å‹é…ç½®

from rag_test.llm.aliyun_models_config import get_model_config, ALIYUN_API_CONFIG

# å¯¼å…¥OpenAIå®¢æˆ·ç«¯
from openai import AsyncOpenAI

# å¯¼å…¥Graphitiçš„åµŒå…¥å™¨åŸºç±»
from graphiti_core_ecolink.embedder.client import EmbedderClient


# ==================== è‡ªå®šä¹‰åˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ ====================
class BatchLimitedOpenAIEmbedder(EmbedderClient):
    """è‡ªå®šä¹‰OpenAIåµŒå…¥å™¨ï¼Œå®ç°åˆ†æ‰¹å¤„ç†ä»¥é¿å…è¶…è¿‡25ä¸ªé™åˆ¶"""

    # æ·»åŠ ç±»å‹æ³¨è§£ä»¥å…¼å®¹Graphitiçš„ç±»å‹æ£€æŸ¥
    embedding_dim: int = 1536

    def __init__(self, config, client=None):
        self.config = config
        self.client = client or AsyncOpenAI(
            api_key=config.api_key,
            base_url=config.base_url
        )
        self.batch_size = 20  # è®¾ç½®ä¸º20ï¼Œç¡®ä¿ä¸è¶…è¿‡25ä¸ªé™åˆ¶
        # è®¾ç½®embedding_dimå±æ€§ä»¥å…¼å®¹Graphiti
        self.embedding_dim = getattr(config, 'embedding_dim', 1536)

    async def create(self, input_data):
        """å•ä¸ªæ–‡æœ¬åµŒå…¥"""
        if isinstance(input_data, str):
            input_data = [input_data]
        elif isinstance(input_data, list) and len(input_data) == 1:
            input_data = input_data
        else:
            # å¦‚æœinput_dataæ˜¯åˆ—è¡¨ï¼Œå–ç¬¬ä¸€ä¸ªå…ƒç´ 
            input_data = [input_data[0] if isinstance(input_data, list) else str(input_data)]

        result = await self.client.embeddings.create(
            input=input_data,
            model=self.config.embedding_model
        )
        return result.data[0].embedding

    async def create_batch(self, input_data_list):
        """åˆ†æ‰¹å¤„ç†ï¼Œç¡®ä¿ä¸è¶…è¿‡25ä¸ªé™åˆ¶"""
        if not input_data_list:
            return []

        all_embeddings = []
        total_batches = (len(input_data_list) + self.batch_size - 1) // self.batch_size

        logger.info(f"å¼€å§‹åˆ†æ‰¹å¤„ç† {len(input_data_list)} ä¸ªæ–‡æœ¬ï¼Œåˆ† {total_batches} æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š {self.batch_size} ä¸ª")

        for i in range(0, len(input_data_list), self.batch_size):
            batch = input_data_list[i:i + self.batch_size]
            batch_num = i // self.batch_size + 1

            logger.info(f"å¤„ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼ŒåŒ…å« {len(batch)} ä¸ªæ–‡æœ¬")

            try:
                # è°ƒç”¨é˜¿é‡Œäº‘API
                result = await self.client.embeddings.create(
                    input=batch,
                    model=self.config.embedding_model
                )

                # æ”¶é›†è¿™ä¸€æ‰¹çš„ç»“æœ
                batch_embeddings = [embedding.embedding for embedding in result.data]
                all_embeddings.extend(batch_embeddings)

                logger.info(f"ç¬¬ {batch_num} æ‰¹å¤„ç†æˆåŠŸï¼Œè·å¾— {len(batch_embeddings)} ä¸ªåµŒå…¥å‘é‡")

                # æ·»åŠ å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                if i + self.batch_size < len(input_data_list):
                    await asyncio.sleep(0.5)

            except Exception as e:
                logger.error(f"ç¬¬ {batch_num} æ‰¹å¤„ç†å¤±è´¥: {e}")
                # å¦‚æœæŸä¸€æ‰¹å¤±è´¥ï¼Œå°è¯•é€ä¸ªå¤„ç†
                logger.info(f"å°è¯•é€ä¸ªå¤„ç†ç¬¬ {batch_num} æ‰¹çš„æ–‡æœ¬")

                for j, text in enumerate(batch):
                    try:
                        single_result = await self.client.embeddings.create(
                            input=[text],
                            model=self.config.embedding_model
                        )
                        all_embeddings.append(single_result.data[0].embedding)
                        logger.info(f"å•ä¸ªæ–‡æœ¬ {j + 1}/{len(batch)} å¤„ç†æˆåŠŸ")
                    except Exception as single_e:
                        logger.error(f"å•ä¸ªæ–‡æœ¬ {j + 1}/{len(batch)} å¤„ç†å¤±è´¥: {single_e}")
                        # æ·»åŠ ç©ºå‘é‡ä½œä¸ºå ä½ç¬¦
                        all_embeddings.append([0.0] * self.embedding_dim)

                # æ·»åŠ å»¶è¿Ÿ
                if i + self.batch_size < len(input_data_list):
                    await asyncio.sleep(1)

        logger.info(f"åˆ†æ‰¹å¤„ç†å®Œæˆï¼Œæ€»å…±è·å¾— {len(all_embeddings)} ä¸ªåµŒå…¥å‘é‡")
        return all_embeddings


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
)
logger = logging.getLogger(__name__)


def estimate_tokens(text: str) -> int:
    """
    ä¼°ç®—æ–‡æœ¬çš„tokenæ•°é‡
    ä½¿ç”¨ç®€å•çš„ä¼°ç®—æ–¹æ³•ï¼šå¤§çº¦4ä¸ªå­—ç¬¦=1ä¸ªtoken

    Args:
        text: è¦ä¼°ç®—çš„æ–‡æœ¬

    Returns:
        int: ä¼°ç®—çš„tokenæ•°é‡
    """
    # ç®€å•çš„tokenä¼°ç®—ï¼šå¤§çº¦4ä¸ªå­—ç¬¦=1ä¸ªtoken
    return len(text) // 4


def split_text_by_tokens(text: str, max_tokens: int = 512, overlap: int = 50) -> List[str]:
    """
    æŒ‰tokenæ•°é‡åˆ†å‰²æ–‡æœ¬

    Args:
        text: è¦åˆ†å‰²çš„æ–‡æœ¬
        max_tokens: æ¯ä¸ªåˆ†ç‰‡çš„æœ€å¤§tokenæ•°é‡
        overlap: åˆ†ç‰‡ä¹‹é—´çš„é‡å tokenæ•°é‡

    Returns:
        List[str]: åˆ†å‰²åçš„æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
    """
    if not text.strip():
        return []

    # æŒ‰å¥å­åˆ†å‰²ï¼Œä¿æŒè¯­ä¹‰å®Œæ•´æ€§
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]+', text)
    chunks = []
    current_chunk = ""
    current_tokens = 0

    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue

        sentence_tokens = estimate_tokens(sentence)

        # å¦‚æœå½“å‰å¥å­åŠ ä¸Šå½“å‰åˆ†ç‰‡è¶…è¿‡æœ€å¤§tokenæ•°
        if current_tokens + sentence_tokens > max_tokens and current_chunk:
            chunks.append(current_chunk.strip())

            # è®¡ç®—é‡å éƒ¨åˆ†
            overlap_text = ""
            overlap_tokens = 0
            words = current_chunk.split()

            # ä»åå¾€å‰æ·»åŠ è¯ï¼Œç›´åˆ°è¾¾åˆ°é‡å tokenæ•°
            for word in reversed(words):
                word_tokens = estimate_tokens(word)
                if overlap_tokens + word_tokens <= overlap:
                    overlap_text = word + " " + overlap_text
                    overlap_tokens += word_tokens
                else:
                    break

            current_chunk = overlap_text + sentence
            current_tokens = overlap_tokens + sentence_tokens
        else:
            current_chunk += sentence + "ã€‚"
            current_tokens += sentence_tokens

    # æ·»åŠ æœ€åä¸€ä¸ªåˆ†ç‰‡
    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    return chunks


class GraphitiCRUD:
    """Graphiti CRUDæ“ä½œç±» - ä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œåˆ†æ‰¹å¤„ç†åµŒå…¥å™¨"""

    def __init__(self, uri: str, user: str, password: str, api_key: str,
                 base_url: Optional[str] = None, model_config: str = "fast"):
        """
        åˆå§‹åŒ–Graphiti CRUDç±»

        Args:
            uri: Neo4jæ•°æ®åº“URI
            user: Neo4jç”¨æˆ·å
            password: Neo4jå¯†ç 
            api_key: APIå¯†é’¥ï¼ˆOpenAIæˆ–é˜¿é‡Œäº‘ç­‰ï¼‰
            base_url: APIåŸºç¡€URLï¼ˆç”¨äºé˜¿é‡Œäº‘ç­‰ç¬¬ä¸‰æ–¹æœåŠ¡ï¼‰
            model_config: æ¨¡å‹é…ç½®åç§° ("fast", "balanced", "performance", "longtext")
        """
        self.uri = uri
        self.user = user
        self.password = password
        self.api_key = api_key
        self.base_url = base_url or ALIYUN_API_CONFIG["base_url"]
        self.model_config_name = model_config
        self.model_config = get_model_config(model_config)
        self.graphiti: Optional[Graphiti] = None

        # è®¾ç½®ç¯å¢ƒå˜é‡
        import os
        os.environ['OPENAI_API_KEY'] = api_key
        if self.base_url:
            os.environ['OPENAI_BASE_URL'] = self.base_url

    async def connect(self):
        """è¿æ¥åˆ°Neo4jæ•°æ®åº“å¹¶åˆå§‹åŒ–Graphitiï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œåˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼‰"""
        try:
            logger.info("æ­£åœ¨è¿æ¥åˆ°Neo4jæ•°æ®åº“...")

            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from graphiti_core_ecolink.llm_client import LLMConfig
            from graphiti_core_ecolink.embedder.openai import OpenAIEmbedderConfig

            # å¯¼å…¥é˜¿é‡Œäº‘LLMå®¢æˆ·ç«¯
            from llm.aliyun_llm_client import AliyunLLMClient

            # åˆ›å»ºLLMé…ç½® - ä½¿ç”¨é˜¿é‡Œäº‘ç™¾è”æ¨¡å‹
            chat_model = self.model_config["chat_model"]
            logger.info(f"ä½¿ç”¨èŠå¤©æ¨¡å‹: {chat_model} ({self.model_config['description']})")
            print(chat_model, 'chat_modelchat_modelchat_modelchat_model')

            llm_config = LLMConfig(
                api_key=self.api_key,
                base_url=self.base_url,
                model=chat_model,  # é˜¿é‡Œäº‘ç™¾è”èŠå¤©æ¨¡å‹
                temperature=self.model_config.get("temperature", 0.3),
                max_tokens=self.model_config.get("max_tokens", 4096)
            )

            # åˆ›å»ºè‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯
            llm_client = AliyunLLMClient(config=llm_config)

            # åˆ›å»ºåµŒå…¥å®¢æˆ·ç«¯ - ä½¿ç”¨é˜¿é‡Œäº‘ç™¾è”å‘é‡æ¨¡å‹
            embedding_model = self.model_config["embedding_model"]
            logger.info(f"ä½¿ç”¨å‘é‡æ¨¡å‹: {embedding_model}")
            print(embedding_model, 'embedding_modelembedding_modelembedding_model')
            embedder_config = OpenAIEmbedderConfig(
                api_key=self.api_key,
                base_url=self.base_url,
                embedding_model=embedding_model  # é˜¿é‡Œäº‘ç™¾è”å‘é‡æ¨¡å‹
            )

            # ä½¿ç”¨è‡ªå®šä¹‰çš„åˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼Œé¿å…è¶…è¿‡25ä¸ªé™åˆ¶
            embedder = BatchLimitedOpenAIEmbedder(config=embedder_config)

            # åˆå§‹åŒ–Graphitiï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œåˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼‰
            self.graphiti = Graphiti(
                self.uri,
                self.user,
                self.password,
                llm_client=llm_client,
                embedder=embedder
                # ä¸ä¼ å…¥cross_encoderå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤çš„æœç´¢æ–¹å¼
            )

            # åˆå§‹åŒ–æ•°æ®åº“ç´¢å¼•å’Œçº¦æŸ
            await self.graphiti.build_indices_and_constraints()
            logger.info("æˆåŠŸè¿æ¥åˆ°Neo4jæ•°æ®åº“å¹¶åˆå§‹åŒ–ç´¢å¼•")

        except Exception as e:
            logger.error(f"è¿æ¥æ•°æ®åº“å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥å’ŒLLMå®¢æˆ·ç«¯"""
        if self.graphiti:
            # å…³é—­Graphitiè¿æ¥
            await self.graphiti.close()
            logger.info("æ•°æ®åº“è¿æ¥å·²å…³é—­")

            # å…³é—­LLMå®¢æˆ·ç«¯
            if hasattr(self.graphiti, 'llm_client'):
                try:
                    llm_client = self.graphiti.llm_client
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬çš„è‡ªå®šä¹‰é˜¿é‡Œäº‘å®¢æˆ·ç«¯
                    if hasattr(llm_client, 'close'):
                        await llm_client.close()
                        logger.info("LLMå®¢æˆ·ç«¯å·²å…³é—­")
                except Exception as e:
                    logger.warning(f"å…³é—­LLMå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")

    # ==================== CREATE æ“ä½œ ====================

    async def add_episode(self, name: str, content: str, description: str = "ç”¨æˆ·è¾“å…¥", group_id: str = None, agent_id: str = None) -> str:
        """
        æ·»åŠ ä¸€ä¸ªepisodeï¼ˆåˆ›å»ºæ•°æ®ï¼‰

        Args:
            name: episodeåç§°
            content: episodeå†…å®¹
            description: episodeæè¿°

        Returns:
            str: episodeçš„UUID
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æ·»åŠ episode: {name}")

            result = await self.graphiti.add_episode(
                name=name,
                episode_body=content,
                source_description=description,
                reference_time=datetime.now(timezone.utc),
                source=EpisodeType.text,
                update_communities=True,  # å¯ç”¨ç¤¾åŒºæ›´æ–°
                group_id=group_id,
                agent_id=agent_id,
            )
            print(result.communities, '//////')
            logger.info(f"æˆåŠŸæ·»åŠ episode: {name}")
            return result.episode.uuid

        except Exception as e:
            logger.error(f"æ·»åŠ episodeå¤±è´¥: {e}")
            raise

    async def add_json_episode(self, name: str, data: dict, description: str = "JSONæ•°æ®") -> str:
        """
        æ·»åŠ JSONæ ¼å¼çš„episode

        Args:
            name: episodeåç§°
            data: JSONæ•°æ®
            description: episodeæè¿°

        Returns:
            str: episodeçš„UUID
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æ·»åŠ JSON episode: {name}")

            result = await self.graphiti.add_episode(
                name=name,
                episode_body=json.dumps(data, ensure_ascii=False),
                source_description=description,
                reference_time=datetime.now(timezone.utc),
                source=EpisodeType.json
            )

            logger.info(f"æˆåŠŸæ·»åŠ JSON episode: {name}")
            return result.episode.uuid

        except Exception as e:
            logger.error(f"æ·»åŠ JSON episodeå¤±è´¥: {e}")
            raise

    async def process_documents_from_directory(self, doc_dir: str = "doc", max_tokens: int = 2048, overlap: int = 100,
                                               group_id: str = None) -> List[str]:
        """
        è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡æ¡£ï¼ŒæŒ‰tokenæ•°é‡åˆ†ç‰‡ï¼Œç„¶åæ·»åŠ åˆ°graphitiä¸­

        Args:
            doc_dir: æ–‡æ¡£ç›®å½•è·¯å¾„ï¼ˆç›¸å¯¹äºå½“å‰æ–‡ä»¶ï¼‰
            max_tokens: æ¯ä¸ªåˆ†ç‰‡çš„æœ€å¤§tokenæ•°é‡ï¼ˆå»ºè®®2048æˆ–æ›´å¤§ï¼‰
            overlap: åˆ†ç‰‡ä¹‹é—´çš„é‡å tokenæ•°é‡

        Returns:
            List[str]: æ‰€æœ‰æ·»åŠ çš„episode UUIDåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        # æ„å»ºå®Œæ•´çš„æ–‡æ¡£ç›®å½•è·¯å¾„
        current_dir = os.path.dirname(os.path.abspath(__file__))
        full_doc_dir = os.path.join(current_dir, doc_dir)

        if not os.path.exists(full_doc_dir):
            raise FileNotFoundError(f"æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {full_doc_dir}")

        episode_uuids = []

        try:
            # éå†ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
            for filename in os.listdir(full_doc_dir):
                file_path = os.path.join(full_doc_dir, filename)
                print(file_path, 'file_pathfile_pathfile_path')

                # åªå¤„ç†æ–‡æœ¬æ–‡ä»¶
                if os.path.isfile(file_path) and filename.lower().endswith(('.txt', '.md')):
                    logger.info(f"æ­£åœ¨å¤„ç†æ–‡æ¡£: {filename}")

                    # è¯»å–æ–‡ä»¶å†…å®¹
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # æŒ‰tokenæ•°é‡åˆ†ç‰‡ï¼ˆä½¿ç”¨æ›´å¤§çš„åˆ†ç‰‡å¤§å°ï¼‰
                    chunks = split_text_by_tokens(content, max_tokens, overlap)
                    logger.info(f"æ–‡æ¡£ {filename} è¢«åˆ†å‰²ä¸º {len(chunks)} ä¸ªç‰‡æ®µ")

                    # ä¸ºæ¯ä¸ªåˆ†ç‰‡åˆ›å»ºepisode
                    for i, chunk in enumerate(chunks):
                        chunk_name = f"{os.path.splitext(filename)[0]}_ç‰‡æ®µ_{i + 1:03d}"
                        chunk_description = f"æ¥è‡ªæ–‡æ¡£ {filename} çš„ç¬¬ {i + 1} ä¸ªç‰‡æ®µï¼Œå…± {len(chunks)} ä¸ªç‰‡æ®µ"

                        try:
                            episode_uuid = await self.add_episode(
                                name=chunk_name,
                                content=chunk,
                                description=chunk_description,
                                group_id=group_id,
                                agent_id="qingcai"
                            )

                            episode_uuids.append(episode_uuid)

                            logger.info(f"æˆåŠŸæ·»åŠ ç‰‡æ®µ {i + 1}/{len(chunks)}: {chunk_name}")

                        except Exception as e:
                            logger.error(f"æ·»åŠ ç‰‡æ®µ {i + 1} å¤±è´¥: {e}")
                            continue

            logger.info(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±æ·»åŠ äº† {len(episode_uuids)} ä¸ªepisode")
            return episode_uuids

        except Exception as e:
            logger.error(f"å¤„ç†æ–‡æ¡£ç›®å½•å¤±è´¥: {e}")
            raise

    # ==================== READ æ“ä½œ ====================

    async def search_edges(self, query: str, num_results: int = 10, group_ids: list[str] | None = None, agent_ids: list[str] | None = None) -> List:
        """
        æœç´¢è¾¹ï¼ˆå…³ç³»ï¼Œä¸ä½¿ç”¨é‡æ’åºåŠŸèƒ½ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            num_results: è¿”å›ç»“æœæ•°é‡
            group_ids: ç»„IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ
            agent_ids: ä»£ç†IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ

        Returns:
            List: æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æœç´¢è¾¹: {query}")

            # ä½¿ç”¨ç®€å•çš„æœç´¢é…ç½®ï¼Œä¸ä½¿ç”¨é‡æ’åº
            from graphiti_core_ecolink.search.search_config import SearchConfig, EdgeSearchConfig, EdgeSearchMethod, \
                EdgeReranker

            # åˆ›å»ºä¸ä½¿ç”¨é‡æ’åºçš„æœç´¢é…ç½®
            search_config = SearchConfig(
                edge_config=EdgeSearchConfig(
                    search_methods=[EdgeSearchMethod.bm25, EdgeSearchMethod.cosine_similarity],
                    reranker=EdgeReranker.rrf  # ä½¿ç”¨RRFè€Œä¸æ˜¯äº¤å‰ç¼–ç å™¨é‡æ’åº
                ),
                limit=num_results
            )
            # ä½¿ç”¨_searchæ–¹æ³•è¿›è¡Œæœç´¢
            results = await self.graphiti._search(
                query=query,
                config=search_config,
                group_ids=group_ids,
                agent_ids=agent_ids
            )

            logger.info(f"è¾¹æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results.edges)} ä¸ªç»“æœ")
            return results.edges

        except Exception as e:
            import traceback
            logger.error(f"è¾¹æœç´¢å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            raise

    async def search_nodes(self, query: str, num_results: int = 10, group_ids: list[str] | None = None, agent_ids: list[str] | None = None) -> List:
        """
        æœç´¢èŠ‚ç‚¹ï¼ˆä¸ä½¿ç”¨é‡æ’åºåŠŸèƒ½ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            num_results: è¿”å›ç»“æœæ•°é‡
            group_ids: ç»„IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ
            agent_ids: ä»£ç†IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ

        Returns:
            List: æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æœç´¢èŠ‚ç‚¹: {query}")

            # ä½¿ç”¨ç®€å•çš„æœç´¢é…ç½®ï¼Œä¸ä½¿ç”¨é‡æ’åº
            from graphiti_core_ecolink.search.search_config import SearchConfig, NodeSearchConfig, NodeSearchMethod, \
                NodeReranker

            # åˆ›å»ºä¸ä½¿ç”¨é‡æ’åºçš„æœç´¢é…ç½®
            search_config = SearchConfig(
                node_config=NodeSearchConfig(
                    search_methods=[NodeSearchMethod.bm25, NodeSearchMethod.cosine_similarity],
                    reranker=NodeReranker.rrf  # ä½¿ç”¨RRFè€Œä¸æ˜¯äº¤å‰ç¼–ç å™¨é‡æ’åº
                ),
                limit=num_results
            )

            # ä½¿ç”¨_searchæ–¹æ³•è¿›è¡Œæœç´¢
            results = await self.graphiti._search(
                query=query,
                config=search_config,
                group_ids=group_ids,
                agent_ids=agent_ids
            )
            for item in results.nodes:
                print(item.agent_id,'nodeesnodeesnodeesnodeesnodees')

            logger.info(f"èŠ‚ç‚¹æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results.nodes)} ä¸ªèŠ‚ç‚¹")
            return results.nodes

        except Exception as e:
            logger.error(f"èŠ‚ç‚¹æœç´¢å¤±è´¥: {e}")
            raise

    async def search_with_center_node(self, query: str, center_node_uuid: str, num_results: int = 10, group_ids: list[str] | None = None, agent_ids: list[str] | None = None) -> List:
        """
        åŸºäºä¸­å¿ƒèŠ‚ç‚¹çš„æœç´¢ï¼ˆä¸ä½¿ç”¨é‡æ’åºåŠŸèƒ½ï¼‰

        Args:
            query: æœç´¢æŸ¥è¯¢
            center_node_uuid: ä¸­å¿ƒèŠ‚ç‚¹UUID
            num_results: è¿”å›ç»“æœæ•°é‡
            group_ids: ç»„IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ
            agent_ids: ä»£ç†IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ

        Returns:
            List: æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨åŸºäºä¸­å¿ƒèŠ‚ç‚¹ {center_node_uuid} æœç´¢: {query}")

            # ä½¿ç”¨ç®€å•çš„æœç´¢é…ç½®ï¼Œä¸ä½¿ç”¨é‡æ’åº
            from graphiti_core_ecolink.search.search_config import SearchConfig, EdgeSearchConfig, EdgeSearchMethod, \
                EdgeReranker

            # åˆ›å»ºä¸ä½¿ç”¨é‡æ’åºçš„æœç´¢é…ç½®
            search_config = SearchConfig(
                edge_config=EdgeSearchConfig(
                    search_methods=[EdgeSearchMethod.bm25, EdgeSearchMethod.cosine_similarity],
                    reranker=EdgeReranker.node_distance  # ä½¿ç”¨èŠ‚ç‚¹è·ç¦»è€Œä¸æ˜¯äº¤å‰ç¼–ç å™¨é‡æ’åº
                ),
                limit=num_results
            )

            # ä½¿ç”¨_searchæ–¹æ³•è¿›è¡Œæœç´¢
            results = await self.graphiti._search(
                query=query,
                config=search_config,
                center_node_uuid=center_node_uuid,
                group_ids=group_ids,
                agent_ids=agent_ids
            )

            logger.info(f"ä¸­å¿ƒèŠ‚ç‚¹æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results.edges)} ä¸ªç»“æœ")
            return results.edges

        except Exception as e:
            logger.error(f"ä¸­å¿ƒèŠ‚ç‚¹æœç´¢å¤±è´¥: {e}")
            raise

    async def search_edges_with_temporal_sorting(self, query: str, num_results: int = 10,
                                                 sort_by_time: bool = True,
                                                 time_order: str = "desc",
                                                 group_ids: list[str] | None = None,
                                                 agent_ids: list[str] | None = None) -> List:
        """
        æœç´¢è¾¹ï¼ˆå…³ç³»ï¼‰ï¼Œæ”¯æŒæ—¶åºæ’åº

        Args:
            query: æœç´¢æŸ¥è¯¢
            num_results: è¿”å›ç»“æœæ•°é‡
            sort_by_time: æ˜¯å¦æŒ‰æ—¶é—´æ’åº
            time_order: æ—¶é—´æ’åºé¡ºåº ("desc" é™åº, "asc" å‡åº)
            group_ids: ç»„IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ
            agent_ids: ä»£ç†IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ

        Returns:
            List: æœç´¢ç»“æœåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æœç´¢è¾¹ï¼ˆå¸¦æ—¶åºæ’åºï¼‰: {query}")

            from graphiti_core_ecolink.search.search_config import (
                SearchConfig, EdgeSearchConfig, EdgeSearchMethod,
                EdgeReranker
            )

            # åˆ›å»ºæœç´¢é…ç½®
            search_config = SearchConfig(
                edge_config=EdgeSearchConfig(
                    search_methods=[EdgeSearchMethod.bm25, EdgeSearchMethod.cosine_similarity],
                    reranker=EdgeReranker.rrf
                ),
                limit=num_results
            )

            # ä½¿ç”¨_searchæ–¹æ³•è¿›è¡Œæœç´¢
            results = await self.graphiti._search(
                query=query,
                config=search_config,
                group_ids=group_ids,
                agent_ids=agent_ids
            )
            for item in results.edges:
                print(item.agent_id,'------')
            # æ‰‹åŠ¨å®ç°æ—¶åºæ’åº
            if sort_by_time and results.edges:
                # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
                sorted_edges = sorted(
                    results.edges,
                    key=lambda x: getattr(x, 'created_at', datetime.min),
                    reverse=(time_order == "desc")
                )
                logger.info(f"è¾¹æœç´¢ï¼ˆå¸¦æ—¶åºæ’åºï¼‰å®Œæˆï¼Œæ‰¾åˆ° {len(sorted_edges)} ä¸ªç»“æœï¼Œå·²æŒ‰æ—¶é—´{time_order}æ’åº")
                return sorted_edges
            else:
                logger.info(f"è¾¹æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results.edges)} ä¸ªç»“æœ")
                return results.edges

        except Exception as e:
            import traceback
            logger.error(f"è¾¹æœç´¢ï¼ˆå¸¦æ—¶åºæ’åºï¼‰å¤±è´¥: {e}")
            logger.error(traceback.format_exc())
            raise

    async def search_episodes_with_temporal_sorting(self, query: str, num_results: int = 10,
                                                    sort_by_time: bool = True,
                                                    time_order: str = "desc",
                                                    group_ids: list[str] | None = None,
                                                    agent_ids: list[str] | None = None) -> List:
        """
        æœç´¢episodeï¼Œæ”¯æŒæ—¶åºæ’åº

        Args:
            query: æœç´¢æŸ¥è¯¢
            num_results: è¿”å›ç»“æœæ•°é‡
            sort_by_time: æ˜¯å¦æŒ‰æ—¶é—´æ’åº
            time_order: æ—¶é—´æ’åºé¡ºåº ("desc" é™åº, "asc" å‡åº)
            group_ids: ç»„IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ
            agent_ids: ä»£ç†IDåˆ—è¡¨ï¼Œç”¨äºè¿‡æ»¤æœç´¢ç»“æœ

        Returns:
            List: episodeæœç´¢ç»“æœåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æœç´¢episodeï¼ˆå¸¦æ—¶åºæ’åºï¼‰: {query}")

            from graphiti_core_ecolink.search.search_config import (
                SearchConfig, EpisodeSearchConfig, EpisodeSearchMethod,
                EpisodeReranker
            )

            # åˆ›å»ºæœç´¢é…ç½®
            search_config = SearchConfig(
                episode_config=EpisodeSearchConfig(
                    search_methods=[EpisodeSearchMethod.bm25],
                    reranker=EpisodeReranker.rrf
                ),
                limit=num_results
            )

            # ä½¿ç”¨_searchæ–¹æ³•è¿›è¡Œæœç´¢
            results = await self.graphiti._search(
                query=query,
                config=search_config,
                group_ids=group_ids or ["999"],
                agent_ids=agent_ids
            )
            print(results.episodes,'1111111111111')
            for item in results.episodes:
                print(item.agent_id,'itemitemitemitem')
            # æ‰‹åŠ¨å®ç°æ—¶åºæ’åº
            if sort_by_time and results.episodes:
                # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
                sorted_episodes = sorted(
                    results.episodes,
                    key=lambda x: getattr(x, 'created_at', datetime.min),
                    reverse=(time_order == "desc")
                )
                logger.info(f"Episodeæœç´¢ï¼ˆå¸¦æ—¶åºæ’åºï¼‰å®Œæˆï¼Œæ‰¾åˆ° {len(sorted_episodes)} ä¸ªç»“æœï¼Œå·²æŒ‰æ—¶é—´{time_order}æ’åº")
                return sorted_episodes
            else:
                logger.info(f"Episodeæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results.episodes)} ä¸ªç»“æœ")
                return results.episodes

        except Exception as e:
            logger.error(f"Episodeæœç´¢ï¼ˆå¸¦æ—¶åºæ’åºï¼‰å¤±è´¥: {e}")
            raise

    # ==================== UPDATE æ“ä½œ ====================

    async def add_updated_episode(self, name: str, content: str, description: str = "æ›´æ–°æ•°æ®") -> str:
        """
        é€šè¿‡æ·»åŠ æ–°çš„episodeæ¥"æ›´æ–°"æ•°æ®
        ï¼ˆGraphitiä¸­æ•°æ®æ˜¯ä¸å¯å˜çš„ï¼Œé€šè¿‡æ·»åŠ æ–°ç‰ˆæœ¬å®ç°æ›´æ–°ï¼‰

        Args:
            name: episodeåç§°
            content: æ›´æ–°åçš„å†…å®¹
            description: episodeæè¿°

        Returns:
            str: æ–°episodeçš„UUID
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨æ·»åŠ æ›´æ–°episode: {name}")

            # æ·»åŠ æ–°çš„episodeä½œä¸º"æ›´æ–°"
            result = await self.graphiti.add_episode(
                name=f"{name}_updated",
                episode_body=content,
                source_description=description,
                reference_time=datetime.now(timezone.utc),
                source=EpisodeType.text,
                update_communities=True
            )

            logger.info(f"æˆåŠŸæ·»åŠ æ›´æ–°episode: {name}")
            return result.episode.uuid

        except Exception as e:
            logger.error(f"æ·»åŠ æ›´æ–°episodeå¤±è´¥: {e}")
            raise

    # ==================== DELETE æ“ä½œ ====================

    async def delete_all_data(self):
        """åˆ é™¤æ‰€æœ‰æ•°æ®"""
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info("æ­£åœ¨åˆ é™¤æ‰€æœ‰æ•°æ®...")

            await clear_data(self.graphiti.driver)

            logger.info("æˆåŠŸåˆ é™¤æ‰€æœ‰æ•°æ®")

        except Exception as e:
            logger.error(f"åˆ é™¤æ•°æ®å¤±è´¥: {e}")
            raise

    async def delete_group_data(self, group_ids: List[str]):
        """
        åˆ é™¤æŒ‡å®šç»„çš„æ•°æ®

        Args:
            group_ids: è¦åˆ é™¤çš„ç»„IDåˆ—è¡¨
        """
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            logger.info(f"æ­£åœ¨åˆ é™¤ç»„æ•°æ®: {group_ids}")

            await clear_data(self.graphiti.driver, group_ids=group_ids)

            logger.info(f"æˆåŠŸåˆ é™¤ç»„æ•°æ®: {group_ids}")

        except Exception as e:
            logger.error(f"åˆ é™¤ç»„æ•°æ®å¤±è´¥: {e}")
            raise

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    async def demo_temporal_sorting(self):
        """æ¼”ç¤ºæ—¶åºæ’åºåŠŸèƒ½"""
        if self.graphiti is None:
            raise RuntimeError("Graphitiå®ä¾‹æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨connect()æ–¹æ³•")

        try:
            print("\n" + "=" * 60)
            print("æ—¶åºæ’åºåŠŸèƒ½æ¼”ç¤º")
            print("=" * 60)

            # 1. æŒ‰æ—¶é—´é™åºæœç´¢å…³ç³»ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
            print("\n1. æŒ‰æ—¶é—´é™åºæœç´¢å…³ç³»ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰:")
            desc_results = await self.search_edges_with_temporal_sorting(
                query="äº”ç¯å’Œä½³ä¼Ÿ",
                num_results=5,
                sort_by_time=True,
                time_order="desc"
            )
            print(f"æ‰¾åˆ° {len(desc_results)} ä¸ªç»“æœï¼ˆæŒ‰æ—¶é—´é™åºï¼‰")
            self.print_search_results(desc_results, "å…³ç³»ï¼ˆæ—¶é—´é™åºï¼‰")

            # 2. æŒ‰æ—¶é—´å‡åºæœç´¢å…³ç³»ï¼ˆæœ€æ—©çš„åœ¨å‰ï¼‰
            print("\n2. æŒ‰æ—¶é—´å‡åºæœç´¢å…³ç³»ï¼ˆæœ€æ—©çš„åœ¨å‰ï¼‰:")
            asc_results = await self.search_edges_with_temporal_sorting(
                query="äº”ç¯å’Œä½³ä¼Ÿ",
                num_results=5,
                sort_by_time=True,
                time_order="asc"
            )
            print(f"æ‰¾åˆ° {len(asc_results)} ä¸ªç»“æœï¼ˆæŒ‰æ—¶é—´å‡åºï¼‰")
            self.print_search_results(asc_results, "å…³ç³»ï¼ˆæ—¶é—´å‡åºï¼‰")

            # 3. å¯¹æ¯”ï¼šä¸ä½¿ç”¨æ—¶åºæ’åº
            print("\n3. ä¸ä½¿ç”¨æ—¶åºæ’åºï¼ˆé»˜è®¤æ’åºï¼‰:")
            default_results = await self.search_edges("äº”ç¯å’Œä½³ä¼Ÿ", num_results=5)
            print(f"æ‰¾åˆ° {len(default_results)} ä¸ªç»“æœï¼ˆé»˜è®¤æ’åºï¼‰")
            self.print_search_results(default_results, "å…³ç³»ï¼ˆé»˜è®¤æ’åºï¼‰")

            print("\n" + "=" * 60)
            print("æ—¶åºæ’åºæ¼”ç¤ºå®Œæˆï¼")
            print("=" * 60)

        except Exception as e:
            logger.error(f"æ—¶åºæ’åºæ¼”ç¤ºå¤±è´¥: {e}")
            raise

    def print_search_results(self, results: List, result_type: str = "è¾¹"):
        """
        æ‰“å°æœç´¢ç»“æœ

        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            result_type: ç»“æœç±»å‹ï¼ˆ"è¾¹"æˆ–"èŠ‚ç‚¹"ï¼‰
        """
        print(f"\n=== {result_type}æœç´¢ç»“æœ ===")
        if not results:
            print("æ²¡æœ‰æ‰¾åˆ°ç»“æœ")
            return

        print(f"æ‰¾åˆ° {len(results)} ä¸ª{result_type}ç»“æœ:")
        for i, result in enumerate(results, 1):
            print(f"\nç»“æœ {i}:")
            if hasattr(result, 'uuid'):
                print(f"UUID: {result.uuid}")
            if hasattr(result, 'fact'):
                print(f"äº‹å®: {result.fact}")
            if hasattr(result, 'name'):
                print(f"åç§°: {result.name}")
            if hasattr(result, 'summary'):
                summary = result.summary[:100] + '...' if len(result.summary) > 100 else result.summary
                print(f"æ‘˜è¦: {summary}")
            # æ˜¾ç¤ºæ—¶é—´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if hasattr(result, 'created_at') and result.created_at:
                print(f"åˆ›å»ºæ—¶é—´: {result.created_at}")
            if hasattr(result, 'valid_at') and result.valid_at:
                print(f"æœ‰æ•ˆæ—¶é—´: {result.valid_at}")
            if hasattr(result, 'invalid_at') and result.invalid_at:
                print(f"å¤±æ•ˆæ—¶é—´: {result.invalid_at}")
            # æ˜¾ç¤ºæ¥æºepisodeä¿¡æ¯ï¼ˆå¦‚æœæ˜¯è¾¹çš„è¯ï¼‰
            if hasattr(result, 'episodes') and result.episodes:
                print(f"æ¥æºepisode: {result.episodes}")
            print("-" * 50)

    async def use_graphiti_clustering_directly(self, group_id: str):
        """ç›´æ¥ä½¿ç”¨ Graphiti çš„èšç±»åŠŸèƒ½"""
        try:
            from graphiti_core_ecolink.utils.maintenance.community_operations import get_community_clusters, build_communities

            # 2. æ„å»ºç¤¾åŒº
            communities, edges = await build_communities(
                self.graphiti.driver,
                self.graphiti.clients.llm_client,
                [group_id]
            )
            print(communities, edges, '///')
            print(len(communities), len(edges))
            # 3. ğŸ”‘ å…³é”®æ­¥éª¤ï¼š ä¿å­˜æ•°æ®åˆ° Neo4j
            print("æ­¥éª¤3:  ä¿å­˜æ•°æ®åˆ° Neo4j...")

            await self.fix_and_save_communities(communities, edges)

        except Exception as e:
            logger.error(f"ä½¿ç”¨ Graphiti åŸç”Ÿèšç±»å¤±è´¥: {e}")
            raise

    async def _fix_community_data(self, community_node):
        """ä¿®å¤ç¤¾åŒºèŠ‚ç‚¹æ•°æ®"""
        try:
            # ä¿®å¤åç§°
            if not community_node.name:
                community_node.name = "æœªå‘½åç¤¾åŒº"

            # ä¿®å¤æ‘˜è¦
            if not community_node.summary:
                community_node.summary = "åŒ…å«ç›¸å…³å®ä½“çš„ç¤¾åŒº"

            # ç¡®ä¿å…¶ä»–å­—æ®µæœ‰æ•ˆ
            if not community_node.group_id:
                community_node.group_id = "default"

            if not community_node.labels:
                community_node.labels = ['Community']

            return community_node

        except Exception as e:
            print(f"ä¿®å¤ç¤¾åŒºæ•°æ®å¤±è´¥: {e}")
            return community_node

    async def fix_and_save_communities(self, communities: List, edges: List):
        """ä¿®å¤å¹¶ä¿å­˜ build_communities çš„ç»“æœ"""
        try:
            saved_communities = []
            saved_edges = []

            for community in communities:
                try:
                    # 1. ä¿®å¤æ•°æ®
                    community = await self._fix_community_data(community)

                    # 2. ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆå…³é”®æ­¥éª¤ï¼‰
                    if community.name and len(community.name) > 0:
                        await community.generate_name_embedding(self.graphiti.clients.embedder)
                        print(f"ä¸ºç¤¾åŒº '{community.name[:30]}...' ç”ŸæˆåµŒå…¥å‘é‡æˆåŠŸ")
                    else:
                        print(f"è·³è¿‡åµŒå…¥ç”Ÿæˆï¼šç¤¾åŒºåç§°æ— æ•ˆ")

                    # 3. ä¿å­˜ç¤¾åŒº
                    await community.save(self.graphiti.driver)
                    saved_communities.append(community)
                    print(f"ç¤¾åŒºä¿å­˜æˆåŠŸ: {community.uuid}")

                except Exception as e:
                    print(f"ç¤¾åŒºä¿å­˜å¤±è´¥: {e}")
                    continue

            # ä¿å­˜è¾¹
            for edge in edges:
                try:
                    await edge.save(self.graphiti.driver)
                    saved_edges.append(edge)
                except Exception as e:
                    print(f"è¾¹ä¿å­˜å¤±è´¥: {e}")
            print(len(saved_communities), len(saved_edges), '//././././././')
            return saved_communities, saved_edges

        except Exception as e:
            print(f"ä¿®å¤å’Œä¿å­˜ç¤¾åŒºå¤±è´¥: {e}")
            raise


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºCRUDæ“ä½œï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œåˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼‰"""

    # é…ç½®å‚æ•°
    NEO4J_URI = "bolt://192.168.4.20:9687"
    NEO4J_USER = "neo4j"
    NEO4J_PASSWORD = "password"
    API_KEY = "sk-12924ea745d84ff59c6aea09ffe2a343"  # è¯·ç¡®ä¿è¿™æ˜¯æ­£ç¡®çš„é˜¿é‡Œäº‘APIå¯†é’¥

    # é˜¿é‡Œäº‘APIé…ç½®
    ALIYUN_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # é˜¿é‡Œäº‘é€šä¹‰åƒé—®APIç«¯ç‚¹

    # åˆ›å»ºCRUDå®ä¾‹ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œperformanceé…ç½®ï¼‰
    crud = GraphitiCRUD(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD, API_KEY, ALIYUN_BASE_URL, model_config="balanced")

    # try:
    # è¿æ¥æ•°æ®åº“
    await crud.connect()

    print("=" * 60)
    # ç”Ÿæˆç¤¾åŒº
    # await crud.use_graphiti_clustering_directly(group_id="xxx")

    # ==================== CREATE æ“ä½œæ¼”ç¤º ====================
    # print("\n1. åˆ›å»ºæ•°æ® (CREATE)")
    # print("-" * 40)

    # æ·»åŠ æ–‡æœ¬episode
    #         episode_uuid1 = await crud.add_episode(
    #             name="äººç‰©ä¿¡æ¯ç¤ºä¾‹",
    #             content="""å¼ ä¸‰å’Œæå››éƒ½æ˜¯è…¾è®¯å…¬å¸çš„å‘˜å·¥ï¼Œå¼ ä¸‰æ˜¯ä¸€åé«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œè´Ÿè´£å‰ç«¯å¼€å‘ï¼Œ
    # æå››æ˜¯ä¸€åäº§å“ç»ç†ï¼Œè´Ÿè´£ç”¨æˆ·å¢é•¿äº§å“ã€‚ä»–ä»¬éƒ½åœ¨æ·±åœ³æ€»éƒ¨å·¥ä½œï¼Œ
    # å¼ ä¸‰æ“…é•¿Reactã€Vueã€TypeScriptç­‰å‰ç«¯æŠ€æœ¯ï¼Œæå››ç†Ÿæ‚‰äº§å“è®¾è®¡ã€ç”¨æˆ·ç ”ç©¶ã€æ•°æ®åˆ†æã€‚
    # ä»–ä»¬ç»å¸¸ä¸€èµ·å¼€ä¼šè®¨è®ºäº§å“åŠŸèƒ½ï¼Œå¼ ä¸‰è´Ÿè´£æŠ€æœ¯å®ç°ï¼Œæå››è´Ÿè´£äº§å“éœ€æ±‚ã€‚
    # ç‹äº”ä¹Ÿæ˜¯è…¾è®¯çš„å‘˜å·¥ï¼Œæ˜¯ä¸€åæ•°æ®ç§‘å­¦å®¶ï¼Œå’Œå¼ ä¸‰ã€æå››åœ¨åŒä¸€ä¸ªé¡¹ç›®ç»„å·¥ä½œã€‚""",
    #             description="ç”¨æˆ·è¾“å…¥çš„äººç‰©ä¿¡æ¯"
    #         )
    #         print(f"æ·»åŠ æ–‡æœ¬episodeæˆåŠŸï¼ŒUUID: {episode_uuid1}")

    # ==================== æ–‡æ¡£å¤„ç†æ¼”ç¤º ====================
    # print("\n2. æ–‡æ¡£å¤„ç† (DOCUMENT PROCESSING)")
    # print("-" * 40)

    # å¤„ç†docç›®å½•ä¸‹çš„æ–‡æ¡£ï¼Œä½¿ç”¨æ›´å¤§çš„åˆ†ç‰‡å¤§å°é¿å…è¿‡å¤šåˆ†ç‰‡
    # print("æ­£åœ¨å¤„ç†docç›®å½•ä¸‹çš„æ–‡æ¡£...")
    # episode_uuids = await crud.process_documents_from_directory(
    #     doc_dir="doc",
    #     max_tokens=2048,  # å¢åŠ åˆ†ç‰‡å¤§å°ï¼Œå‡å°‘åˆ†ç‰‡æ•°é‡
    #     overlap=100        # å¢åŠ é‡å ï¼Œä¿æŒè¯­ä¹‰è¿ç»­æ€§
    # )
    # print(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼Œå…±æ·»åŠ äº† {len(episode_uuids)} ä¸ªepisode")
    # print(f"å‰5ä¸ªepisode UUID: {episode_uuids[:5] if len(episode_uuids) > 5 else episode_uuids}")
    #
    # # ==================== READ æ“ä½œæ¼”ç¤º ====================
    # print("\n3. è¯»å–æ•°æ® (READ)")
    # print("-" * 40)

    # æœç´¢è¾¹ï¼ˆå…³ç³»ï¼‰
    # print("æœç´¢edges---")
    # edge_results = await crud.search_edges_with_temporal_sorting(
    #     query="åœ†æ˜å›­",
    #     num_results=5,
    #     sort_by_time=True,      # å¯ç”¨æ—¶åºæ’åº
    #     time_order="desc",       # æœ€æ–°çš„å…³ç³»åœ¨å‰
    #     group_ids=["888"],
    #     agent_ids=["qingcai"]
    # )
    # print(f"æœç´¢ç»“æœæ•°é‡: {len(edge_results)}")
    # crud.print_search_results(edge_results, "å…³ç³»ï¼ˆæ—¶åºæ’åºï¼‰")
    # # #
    # print("æœç´¢episodes-----")
    # episode_results = await crud.search_episodes_with_temporal_sorting(
    #     query="å®¢æˆ·æ¿€æ´»",
    #     num_results=5,
    #     sort_by_time=True,
    #     time_order="desc",
    #     group_ids=["6"],
    #     agent_ids=None
    # )
    # print(f"Episodeæœç´¢ç»“æœæ•°é‡: {len(episode_results)}")
    # crud.print_search_results(episode_results, "Episodeï¼ˆæ—¶åºæ’åºï¼‰")

    # æœç´¢è¾¹ï¼ˆå…³ç³»ï¼‰
    # print("\n3.1 æœç´¢å…³ç³»:")
    # edge_results = await crud.search_edges("å·¥ç¨‹å¸ˆ", num_results=5)
    # crud.print_search_results(edge_results, "å…³ç³»")
    #
    # æœç´¢èŠ‚ç‚¹
    print("\n3.2 æœç´¢èŠ‚ç‚¹:")
    node_results = await crud.search_nodes("åœ†æ˜å›­",
        num_results=5,
        group_ids=["888"],
        agent_ids=["qingcai"])
    crud.print_search_results(node_results, "èŠ‚ç‚¹")
    # #
    # # åŸºäºä¸­å¿ƒèŠ‚ç‚¹çš„æœç´¢
    # if edge_results:
    #     center_uuid = edge_results[0].source_node_uuid
    #     print(f"\n3.3 åŸºäºä¸­å¿ƒèŠ‚ç‚¹ {center_uuid} çš„æœç´¢:")
    #     center_results = await crud.search_with_center_node(
    #         "å·¥ç¨‹å¸ˆ", center_uuid, num_results=3
    #     )
    #     crud.print_search_results(center_results, "ä¸­å¿ƒèŠ‚ç‚¹å…³ç³»")
    #
    # # ==================== UPDATE æ“ä½œæ¼”ç¤º ====================
    # print("\n4. æ›´æ–°æ•°æ® (UPDATE)")
    # print("-" * 40)
    #
    # # é€šè¿‡æ·»åŠ æ–°episodeæ¥"æ›´æ–°"æ•°æ®
    # updated_uuid = await crud.add_updated_episode(
    #     name="å¼ ä¸‰ä¿¡æ¯æ›´æ–°",
    #     content="å¼ ä¸‰æ˜¯ä¸€åé«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œåœ¨åŒ—äº¬å·¥ä½œï¼Œæ“…é•¿Pythonã€æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ ï¼Œæœ‰5å¹´å·¥ä½œç»éªŒã€‚",
    #     description="æ›´æ–°åçš„äººç‰©ä¿¡æ¯"
    # )
    # print(f"æ·»åŠ æ›´æ–°episodeæˆåŠŸï¼ŒUUID: {updated_uuid}")
    #
    # # æœç´¢æ›´æ–°åçš„ä¿¡æ¯
    # print("\næœç´¢æ›´æ–°åçš„ä¿¡æ¯:")
    # update_results = await crud.search_edges("é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆ", num_results=3)
    # crud.print_search_results(update_results, "æ›´æ–°åå…³ç³»")
    #
    # # ==================== ç»¼åˆæ¼”ç¤º ====================
    # print("\n5. ç»¼åˆæœç´¢æ¼”ç¤º")
    # print("-" * 40)
    #
    # # æœç´¢ä¸åŒç±»å‹çš„ä¿¡æ¯
    # search_queries = [
    #     "å·¥ç¨‹å¸ˆ",
    #     "Python",
    #     "å…¬å¸",
    #     "æœºå™¨å­¦ä¹ "
    # ]
    #
    # for query in search_queries:
    #     print(f"\næœç´¢: {query}")
    #     results = await crud.search_edges(query, num_results=3)
    #     if results:
    #         print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å…³ç³»")
    #         for result in results[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
    #             print(f"  - {result.fact}")
    #     else:
    #         print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
    #
    # print("\n" + "=" * 60)
    # print("CRUDæ¼”ç¤ºå®Œæˆï¼ï¼ˆä½¿ç”¨è‡ªå®šä¹‰é˜¿é‡Œäº‘ç™¾è”LLMå®¢æˆ·ç«¯å’Œåˆ†æ‰¹å¤„ç†åµŒå…¥å™¨ï¼‰")
    # print("=" * 60)

    # except Exception as e:
    #     logger.error(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    #     print(f"é”™è¯¯: {e}")
    #
    # finally:
    #     # å…³é—­è¿æ¥
    #     await crud.close()


if __name__ == "__main__":
    # è¿è¡Œä¸»å‡½æ•°
    asyncio.run(main())
# æ¸…é£å’Œå¸…å¸…ç°åœ¨æ˜¯æœ‹å‹å…³ç³»ï¼Œæ¸…é£çš„èº«ä»½è¯æ˜¯123ï¼Œå¸…å¸…èº«ä»½è¯æ˜¯789ï¼Œä»–ä»¬å¤©å¤©ç…²ç”µè¯ç²¥
#
#
# äº”ç¯æ˜¯æ¥å…¬å¸çš„æ–°åŒäº‹ï¼Œä»–çš„ç»°å·å«å°å¸…å“¥
# äº”ç¯è¿˜æœ‰ä¸ªç»°å·ï¼Œå«å°é’è›™
# äº”ç¯æ˜¯å¸…å¸…çš„åŒäº‹ï¼Œä»–çš„ç»°å·å«å°ç”°é¸¡