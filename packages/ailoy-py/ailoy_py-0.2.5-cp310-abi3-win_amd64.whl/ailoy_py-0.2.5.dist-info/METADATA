Metadata-Version: 2.4
Name: ailoy-py
Version: 0.2.5
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Programming Language :: Rust
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Programming Language :: Python :: 3.14
Classifier: Programming Language :: Python :: Implementation :: CPython
Summary: A lightweight library for building AI applications
Author-email: "Brekkylab Inc." <contact@brekkylab.com>
License-Expression: Apache-2.0
Requires-Python: >=3.10
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
Project-URL: Documentation, https://brekkylab.github.io/ailoy
Project-URL: Homepage, https://brekkylab.github.io/ailoy
Project-URL: Issues, https://github.com/brekkylab/ailoy/issues
Project-URL: Repository, https://github.com/brekkylab/ailoy

# ailoy-py

Ailoy is a lightweight library for building AI applications — such as **agent systems** or **RAG pipelines** — with ease. It is designed to enable AI features effortlessly, one can just import and use.

See our [documentation](https://brekkylab.github.io/ailoy) for more details.

## Install

```bash
pip install ailoy-py
```

## Quickstart

### Asynchronous version (recommended)
```python
import asyncio

import ailoy as ai


async def main():
    # Create Qwen3-0.6B local LangModel
    model = await ai.LangModel.new_local("Qwen/Qwen3-0.6B")

    # Create an agent using this model
    agent = ai.Agent(model)

    # Ask a prompt and iterate over agent's responses
    async for resp in agent.run("What is your name?"):
        print(resp)


if __name__ == "__main__":
    asyncio.run(main())
```

### Synchronous version
```python
import ailoy as ai


def main():
    # Create Qwen3-0.6B LocalLanguageModel
    model = ai.LangModel.new_local_sync("Qwen/Qwen3-0.6B")

    # Create an agent using this model
    agent = ai.Agent(model)

    # Ask a prompt and iterate over agent's responses
    for resp in agent.run_sync("What is your name?"):
        print(resp)


if __name__ == "__main__":
    main()
```

## Building from source

### Prerequisites

- Rust >= 1.88
- Python >= 3.10
- C/C++ compiler
  (recommended versions are below)
  - GCC >= 13
  - LLVM Clang >= 17
  - Apple Clang >= 15
  - MSVC >= 19.29
- CMake >= 3.28.0
- Git
- OpenMP (required to build Faiss)
- BLAS (required to build Faiss)
- LAPACK (required to build Faiss)
- Vulkan SDK (on Windows and Linux)

### Setup development environment

```bash
pip install maturin

# This generates `_core.cpython-3xx-darwin.so` under `ailoy/`
maturin develop
```

### Generate wheel

```bash
maturin build --out ./dist
```

