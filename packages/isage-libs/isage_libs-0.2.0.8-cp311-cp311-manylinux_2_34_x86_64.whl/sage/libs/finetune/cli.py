#!/usr/bin/env python3
"""
Finetune CLI - Command Handlers
CLI å‘½ä»¤å¤„ç†å™¨ï¼ˆç²¾ç®€ç‰ˆï¼Œè°ƒç”¨æ¨¡å—åŒ–çš„æ ¸å¿ƒé€»è¾‘ï¼‰

æœ¬æ–‡ä»¶åªè´Ÿè´£ï¼š
1. å®šä¹‰ CLI å‘½ä»¤å’Œå‚æ•°
2. å¤„ç†ç”¨æˆ·äº¤äº’
3. è°ƒç”¨æ ¸å¿ƒæ¨¡å—å®Œæˆå®é™…å·¥ä½œ
"""

import json
import shutil
import subprocess
from pathlib import Path

import typer
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm, IntPrompt, Prompt
from rich.table import Table

from sage.libs.finetune.core import generate_training_config, prepare_training_data
from sage.libs.finetune.models import TASK_NAMES, FinetuneTask
from sage.libs.finetune.service import (
    merge_lora_weights,
    start_training,
)
from sage.libs.finetune.utils import (
    check_training_dependencies,
    get_finetune_output_dir,
    get_sage_root,
    show_install_instructions,
)

app = typer.Typer(
    name="finetune",
    help="ğŸ“ å¤§æ¨¡å‹å¾®è°ƒå·¥å…· - æ”¯æŒä»£ç ç†è§£ã€å¯¹è¯ã€æŒ‡ä»¤ç­‰å¤šç§åœºæ™¯",
)

console = Console()


@app.command("start")
def start_finetune(
    task: str | None = typer.Option(None, "--task", "-t", help="ä»»åŠ¡ç±»å‹"),
    model: str | None = typer.Option(None, "--model", "-m", help="åŸºç¡€æ¨¡å‹"),
    data: str | None = typer.Option(None, "--data", "-d", help="æ•°æ®æ–‡ä»¶"),
    output: str | None = typer.Option(None, "--output", "-o", help="è¾“å‡ºç›®å½•"),
    framework: str = typer.Option("llama-factory", "--framework", "-f"),
    format: str = typer.Option("alpaca", "--format"),
    auto: bool = typer.Option(False, "--auto", help="è‡ªåŠ¨æ¨¡å¼"),
    skip_install: bool = typer.Option(False, "--skip-install"),
):
    """ğŸ“ å¯åŠ¨äº¤äº’å¼å¾®è°ƒæµç¨‹"""
    console.print(Panel.fit("[bold cyan]ğŸ“ SAGEå¤§æ¨¡å‹å¾®è°ƒå‘å¯¼[/bold cyan]", border_style="cyan"))

    # é€‰æ‹©ä»»åŠ¡ç±»å‹
    if not task and not auto:
        task = _select_task()
    elif not task:
        task = "code"

    task_type = FinetuneTask(task)
    console.print(f"\nâœ… ä»»åŠ¡: [green]{TASK_NAMES[task_type]}[/green]\n")

    # æ£€æŸ¥ä¾èµ–
    if not skip_install and not check_training_dependencies():
        show_install_instructions()
        console.print("\n[red]âŒ è¯·å…ˆå®‰è£…ä¾èµ–æˆ–ä½¿ç”¨ --skip-install[/red]")
        raise typer.Exit(1)

    # é€‰æ‹©æ¨¡å‹
    if not model:
        model = _select_model(task_type, auto)
    console.print(f"âœ… æ¨¡å‹: [green]{model}[/green]\n")

    # å¤„ç†æ•°æ®æº
    root_dir, custom_data_path = _handle_data_source(task_type, data, auto)

    # è®¾ç½®è¾“å‡ºç›®å½•
    if not output:
        output_dir = get_finetune_output_dir() / task_type.value
    else:
        output_dir = Path(output)
    output_dir.mkdir(parents=True, exist_ok=True)
    console.print(f"âœ… è¾“å‡º: [green]{output_dir}[/green]\n")

    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    console.print("[bold]ğŸ“ ç”Ÿæˆè®­ç»ƒæ•°æ®...[/bold]")
    dataset_path = prepare_training_data(
        task_type, root_dir or Path.cwd(), output_dir, format, custom_data_path
    )

    # ç”Ÿæˆé…ç½®
    console.print("\n[bold]âš™ï¸  ç”Ÿæˆé…ç½®...[/bold]")
    config_path = generate_training_config(model, dataset_path, output_dir, framework)
    console.print(f"âœ… é…ç½®: [cyan]{config_path}[/cyan]\n")

    # ä¿å­˜å…ƒä¿¡æ¯
    _save_meta(
        output_dir,
        task_type,
        model,
        framework,
        format,
        dataset_path,
        config_path,
        root_dir,
        custom_data_path,
    )

    # æ˜¾ç¤ºä¸‹ä¸€æ­¥
    _show_next_steps(output_dir, config_path)

    # è¯¢é—®æ˜¯å¦ç«‹å³è®­ç»ƒ
    if not auto and Confirm.ask("\næ˜¯å¦ç«‹å³å¯åŠ¨è®­ç»ƒ?", default=False):
        console.print("\n[bold]ğŸš€ å¯åŠ¨è®­ç»ƒ...[/bold]")
        start_training(config_path, use_native=True)


@app.command("run")
def run_training(
    config: str = typer.Argument(..., help="é…ç½®æ–‡ä»¶æˆ–è¾“å‡ºç›®å½•"),
    use_native: bool = typer.Option(True, "--use-native/--use-llamafactory"),
):
    """ğŸš€ è¿è¡Œå¾®è°ƒè®­ç»ƒ"""
    config_path = Path(config)

    if config_path.is_dir():
        possible_configs = list(config_path.glob("*.json"))
        if possible_configs:
            config_path = possible_configs[0]

    if not config_path.exists():
        console.print(f"[red]âŒ é…ç½®ä¸å­˜åœ¨: {config}[/red]")
        raise typer.Exit(1)

    console.print("[bold]ğŸš€ å¯åŠ¨è®­ç»ƒ[/bold]")
    console.print(f"é…ç½®: [cyan]{config_path}[/cyan]\n")

    start_training(config_path, use_native)


@app.command("list")
def list_outputs(directory: str | None = typer.Option(None, "--dir", "-d")):
    """ğŸ“‹ åˆ—å‡ºæ‰€æœ‰å¾®è°ƒè¾“å‡º"""
    output_dir = Path(directory) if directory else get_finetune_output_dir()

    if not output_dir.exists():
        console.print(f"[yellow]âš ï¸  ç›®å½•ä¸å­˜åœ¨: {output_dir}[/yellow]")
        return

    meta_files = list(output_dir.glob("**/finetune_meta.json"))

    if not meta_files:
        console.print("[yellow]ğŸ“­ æ²¡æœ‰æ‰¾åˆ°å¾®è°ƒä»»åŠ¡[/yellow]")
        return

    table = Table(title=f"å¾®è°ƒä»»åŠ¡åˆ—è¡¨ ({len(meta_files)} ä¸ª)")
    table.add_column("åºå·", style="cyan")
    table.add_column("æ¨¡å‹", style="green")
    table.add_column("ä»»åŠ¡", style="yellow")
    table.add_column("è¾“å‡ºç›®å½•", style="blue")

    for i, meta_file in enumerate(meta_files, 1):
        try:
            with open(meta_file) as f:
                meta = json.load(f)
            table.add_row(
                str(i),
                meta.get("model", "N/A"),
                meta.get("task_type", "N/A"),
                Path(meta.get("output_dir", "")).name,
            )
        except Exception as e:
            console.print(f"[red]è¯»å–å¤±è´¥: {e}[/red]")

    console.print(table)


@app.command("clean")
def clean_outputs(
    directory: str | None = typer.Option(None, "--dir", "-d"),
    force: bool = typer.Option(False, "--force", "-f"),
):
    """ğŸ§¹ æ¸…ç†å¾®è°ƒè¾“å‡º"""
    output_dir = Path(directory) if directory else get_finetune_output_dir()

    if not output_dir.exists():
        console.print("[yellow]âš ï¸  ç›®å½•ä¸å­˜åœ¨[/yellow]")
        return

    console.print(f"å°†åˆ é™¤: [red]{output_dir}[/red]")

    if not force and not Confirm.ask("ç¡®è®¤åˆ é™¤?", default=False):
        console.print("[yellow]å·²å–æ¶ˆ[/yellow]")
        return

    shutil.rmtree(output_dir)
    console.print("[green]âœ… å·²åˆ é™¤[/green]")


@app.command("quickstart")
def quickstart(task: str = typer.Argument("code", help="ä»»åŠ¡ç±»å‹")):
    """ğŸš€ å¿«é€Ÿå¼€å§‹"""
    console.print(Panel.fit(f"[bold cyan]ğŸš€ å¿«é€Ÿå¼€å§‹ - {task}[/bold cyan]", border_style="cyan"))

    if task == "code":
        console.print("\n[bold green]ğŸ“š SAGEä»£ç ç†è§£å¿«é€Ÿå¾®è°ƒ[/bold green]")
        console.print("é»˜è®¤é…ç½®: Qwen/Qwen2.5-Coder-7B-Instruct\n")

        if Confirm.ask("ç¡®è®¤å¼€å§‹?", default=True):
            start_finetune(
                task="code",
                model="Qwen/Qwen2.5-Coder-7B-Instruct",
                framework="llama-factory",
                format="alpaca",
                auto=True,
                output=None,
                data=None,
                skip_install=True,
            )
    else:
        console.print(f"\n[yellow]âš ï¸  {task}ä»»åŠ¡éœ€è¦æ•°æ®æ–‡ä»¶[/yellow]")
        console.print(f"ä½¿ç”¨: [cyan]sage finetune start --task {task} --data <file>[/cyan]")


@app.command("merge")
def merge_lora(
    model_name: str = typer.Argument(..., help="æ¨¡å‹åç§°æˆ–è·¯å¾„"),
    output: str | None = typer.Option(None, "--output", "-o"),
):
    """ğŸ”€ åˆå¹¶ LoRA æƒé‡"""
    console.print("[bold]ğŸ”€ åˆå¹¶ LoRA æƒé‡[/bold]\n")

    checkpoint_path, base_model = _find_checkpoint(model_name)

    if not output:
        output_path = checkpoint_path.parent.parent / "merged_model"
    else:
        output_path = Path(output)

    output_path.mkdir(parents=True, exist_ok=True)

    if merge_lora_weights(checkpoint_path, base_model, output_path):
        console.print("\n[bold]ğŸ’¡ ä½¿ç”¨:[/bold]")
        console.print(f"[cyan]sage finetune chat {model_name}[/cyan]")


@app.command("serve")
def serve_model(
    model_name: str = typer.Argument(..., help="æ¨¡å‹åç§°"),
    port: int = typer.Option(8000, "--port", "-p"),
    host: str = typer.Option("0.0.0.0", "--host"),
    daemon: bool = typer.Option(False, "--daemon", "-d"),
    gpu_memory_utilization: float = typer.Option(0.9, "--gpu-util"),
):
    """ğŸš€ å¯åŠ¨æ¨¡å‹æœåŠ¡

    Deprecated: æ­¤å‘½ä»¤å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ç»Ÿä¸€çš„ vLLM æœåŠ¡ï¼š
        sage llm serve --model <model_path>
    """
    console.print("[yellow]âš ï¸  æ­¤å‘½ä»¤å·²åºŸå¼ƒ[/yellow]\n")
    console.print("è¯·ä½¿ç”¨ç»Ÿä¸€çš„ vLLM æœåŠ¡å‘½ä»¤ï¼š\n")

    model_path, use_lora, lora_path = _find_model_for_serving(model_name)

    cmd_parts = [
        "sage",
        "llm",
        "serve",
        "--model",
        str(model_path),
        "--port",
        str(port),
        "--host",
        host,
    ]

    if not daemon:
        cmd_parts.append("--blocking")

    if use_lora and lora_path:
        console.print(
            "[yellow]æ³¨æ„: LoRA æ”¯æŒéœ€è¦æ‰‹åŠ¨é…ç½®ï¼Œè¯·å‚è€ƒ sage llm serve --help[/yellow]\n"
        )

    console.print(f"[cyan]å»ºè®®å‘½ä»¤: {' '.join(cmd_parts)}[/cyan]\n")
    console.print("æ˜¯å¦æ‰§è¡Œ? [Y/n]: ", end="")

    if Confirm.ask("", default=True):
        subprocess.run(cmd_parts)


@app.command("chat")
def auto_chat(
    model_name: str = typer.Argument("sage_code_expert", help="æ¨¡å‹åç§°"),
    port: int = typer.Option(8000, "--port", "-p"),
):
    """ğŸ’¬ ä½¿ç”¨å¾®è°ƒæ¨¡å‹èŠå¤©ï¼ˆé‡å®šå‘åˆ° sage chatï¼‰"""
    console.print("[cyan]â„¹ï¸  é‡å®šå‘åˆ° sage chat...[/cyan]\n")

    try:
        subprocess.run(
            [
                "sage",
                "chat",
                "--backend",
                "finetune",
                "--finetune-model",
                model_name,
                "--finetune-port",
                str(port),
            ]
        )
    except KeyboardInterrupt:
        console.print("\n[yellow]ğŸ‘‹ é€€å‡º[/yellow]")
    except Exception as exc:
        console.print(f"[red]âŒ å¤±è´¥: {exc}[/red]")
        raise typer.Exit(1)


@app.command("examples")
def show_examples():
    """ğŸ“š æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹"""
    console.print(Panel.fit("[bold cyan]ğŸ“š ä½¿ç”¨ç¤ºä¾‹[/bold cyan]", border_style="cyan"))

    examples = [
        ("SAGEä»£ç ç†è§£", "sage finetune quickstart code"),
        ("é—®ç­”å¾®è°ƒ", "sage finetune start --task qa --data qa.json"),
        ("æŒ‡ä»¤å¾®è°ƒ", "sage finetune start --task instruction --data inst.json"),
        ("è¿è¡Œè®­ç»ƒ", "sage finetune run ~/.sage/finetune_output/code"),
        ("åˆå¹¶æ¨¡å‹", "sage finetune merge code"),
        ("å¯åŠ¨æœåŠ¡", "sage finetune serve code --port 8000"),
        ("èŠå¤©æµ‹è¯•", "sage finetune chat code"),
    ]

    table = Table(show_header=True)
    table.add_column("åœºæ™¯", style="cyan")
    table.add_column("å‘½ä»¤", style="green")

    for scene, cmd in examples:
        table.add_row(scene, cmd)

    console.print("\n", table, "\n")


# ========== è¾…åŠ©å‡½æ•° ==========


def _select_task() -> str:
    """äº¤äº’å¼é€‰æ‹©ä»»åŠ¡ç±»å‹"""
    table = Table(show_header=True, header_style="bold cyan")
    table.add_column("åºå·", width=6)
    table.add_column("ç±»å‹", width=15)
    table.add_column("è¯´æ˜")

    tasks = [
        ("1", "code", "ä»£ç ç†è§£å¾®è°ƒ"),
        ("2", "qa", "é—®ç­”å¯¹å¾®è°ƒ"),
        ("3", "instruction", "æŒ‡ä»¤å¾®è°ƒ"),
        ("4", "chat", "å¯¹è¯å¾®è°ƒ"),
        ("5", "custom", "è‡ªå®šä¹‰æ•°æ®é›†"),
    ]

    for num, typ, desc in tasks:
        table.add_row(num, typ, desc)

    console.print(table)
    choice = IntPrompt.ask("é€‰æ‹©ä»»åŠ¡ç±»å‹", default=1)

    task_map = {1: "code", 2: "qa", 3: "instruction", 4: "chat", 5: "custom"}
    return task_map.get(choice, "code")


def _select_model(task_type: FinetuneTask, auto: bool) -> str:
    """é€‰æ‹©åŸºç¡€æ¨¡å‹"""
    if auto:
        return (
            "Qwen/Qwen2.5-Coder-7B-Instruct"
            if task_type == FinetuneTask.CODE_UNDERSTANDING
            else "Qwen/Qwen2.5-7B-Instruct"
        )

    if task_type == FinetuneTask.CODE_UNDERSTANDING:
        console.print("æ¨è: Qwen/Qwen2.5-Coder-7B-Instruct (ä»£ç ä¸“ç²¾)")
        default = "Qwen/Qwen2.5-Coder-7B-Instruct"
    else:
        console.print("æ¨è: Qwen/Qwen2.5-7B-Instruct (é€šç”¨)")
        default = "Qwen/Qwen2.5-7B-Instruct"

    return Prompt.ask("æ¨¡å‹åç§°", default=default)


def _handle_data_source(task_type: FinetuneTask, data: str | None, auto: bool):
    """å¤„ç†æ•°æ®æº"""
    if task_type == FinetuneTask.CODE_UNDERSTANDING:
        sage_root = get_sage_root()
        if auto or Confirm.ask(f"ä½¿ç”¨SAGEä»£ç åº“? {sage_root}", default=True):
            return sage_root, None
        custom_path = Prompt.ask("ä»£ç åº“è·¯å¾„")
        return Path(custom_path), None
    else:
        if not data:
            data = Prompt.ask("æ•°æ®æ–‡ä»¶è·¯å¾„")
        custom_data_path = Path(data)
        if not custom_data_path.exists():
            console.print(f"[red]âŒ æ–‡ä»¶ä¸å­˜åœ¨: {data}[/red]")
            raise typer.Exit(1)
        return None, custom_data_path


def _save_meta(
    output_dir,
    task_type,
    model,
    framework,
    format,
    dataset_path,
    config_path,
    root_dir,
    custom_data_path,
):
    """ä¿å­˜å…ƒä¿¡æ¯"""
    meta = {
        "task_type": task_type.value,
        "model": model,
        "framework": framework,
        "format": format,
        "dataset": str(dataset_path),
        "config": str(config_path),
        "output_dir": str(output_dir),
    }

    if root_dir:
        meta["code_root"] = str(root_dir)
    if custom_data_path:
        meta["data_file"] = str(custom_data_path)

    meta_path = output_dir / "finetune_meta.json"
    with open(meta_path, "w") as f:
        json.dump(meta, f, indent=2)

    console.print(f"ğŸ’¾ å…ƒä¿¡æ¯: [cyan]{meta_path}[/cyan]")


def _show_next_steps(output_dir, config_path):
    """æ˜¾ç¤ºä¸‹ä¸€æ­¥æ“ä½œ"""
    console.print(
        Panel.fit(
            "[bold green]âœ… å‡†å¤‡å®Œæˆï¼[/bold green]\n\n"
            "[bold]ğŸš€ å¯åŠ¨è®­ç»ƒ:[/bold]\n"
            f"[cyan]sage finetune run {output_dir}[/cyan]\n\n"
            f"æˆ–: [cyan]python -m sage.libs.finetune.trainer {output_dir}[/cyan]",
            border_style="green",
        )
    )


def _find_checkpoint(model_name: str):
    """æŸ¥æ‰¾ checkpoint å’ŒåŸºç¡€æ¨¡å‹"""
    checkpoint_path = Path(model_name)

    if not checkpoint_path.exists():
        output_dir = get_finetune_output_dir()
        checkpoint_dir = output_dir / model_name / "checkpoints"

        if checkpoint_dir.exists():
            checkpoints = sorted(checkpoint_dir.glob("checkpoint-*"))
            if checkpoints:
                checkpoint_path = checkpoints[-1]
                console.print(f"âœ… Checkpoint: [cyan]{checkpoint_path}[/cyan]\n")
            else:
                console.print("[red]âŒ æœªæ‰¾åˆ°checkpoint[/red]")
                raise typer.Exit(1)
        else:
            console.print(f"[red]âŒ æœªæ‰¾åˆ°: {model_name}[/red]")
            raise typer.Exit(1)

    # è¯»å–meta
    meta_file = checkpoint_path.parent.parent / "finetune_meta.json"
    if meta_file.exists():
        with open(meta_file) as f:
            meta = json.load(f)
        base_model = meta.get("model", "")
        console.print(f"ğŸ“¦ åŸºç¡€æ¨¡å‹: [green]{base_model}[/green]\n")
        return checkpoint_path, base_model
    else:
        console.print("[yellow]âš ï¸  æœªæ‰¾åˆ°metaï¼Œéœ€æ‰‹åŠ¨æŒ‡å®šåŸºç¡€æ¨¡å‹[/yellow]")
        base_model = Prompt.ask("åŸºç¡€æ¨¡å‹åç§°")
        return checkpoint_path, base_model


def _find_model_for_serving(model_name: str):
    """æŸ¥æ‰¾ç”¨äºæœåŠ¡çš„æ¨¡å‹è·¯å¾„"""
    output_dir = get_finetune_output_dir()

    # ä¼˜å…ˆæŸ¥æ‰¾åˆå¹¶æ¨¡å‹
    merged_path = output_dir / model_name / "merged_model"
    checkpoint_path = output_dir / model_name / "checkpoints"

    if merged_path.exists():
        console.print(f"âœ… åˆå¹¶æ¨¡å‹: [cyan]{merged_path}[/cyan]\n")
        return merged_path, False, None
    elif checkpoint_path.exists():
        # ä½¿ç”¨ LoRA æ¨¡å¼
        checkpoints = sorted(checkpoint_path.glob("checkpoint-*"))
        if checkpoints:
            lora_path = checkpoints[-1]
            meta_file = checkpoint_path.parent / "finetune_meta.json"
            if meta_file.exists():
                with open(meta_file) as f:
                    meta = json.load(f)
                base_model = meta.get("model", "")
                console.print(f"âœ… LoRA: [cyan]{base_model}[/cyan] + [cyan]{lora_path}[/cyan]\n")
                return Path(base_model), True, lora_path

    console.print(f"[red]âŒ æœªæ‰¾åˆ°: {model_name}[/red]")
    console.print("[yellow]æç¤º: å…ˆè¿è¡Œ sage finetune merge[/yellow]")
    raise typer.Exit(1)
