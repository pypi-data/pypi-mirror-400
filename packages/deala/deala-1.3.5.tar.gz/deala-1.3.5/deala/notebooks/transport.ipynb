{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01e388e",
   "metadata": {},
   "source": [
    "# Notebook to create datasets to create DEALA activities for transport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2c1bed",
   "metadata": {},
   "source": [
    "## 1. Initalization of project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c889026",
   "metadata": {},
   "source": [
    "## 1.1 load python packages\n",
    "\n",
    "<p style=\"font-size:18px\">\n",
    "To load all required Python modules and packages.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c347732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializatiin of packages\n",
    "import brightway2 as bw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from bw2io import *\n",
    "from tqdm import *\n",
    "import toml\n",
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import deala as de\n",
    "from deala import deala_io\n",
    "deala_io_instance = deala_io()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4d99f",
   "metadata": {},
   "source": [
    "## 1.2 Set up project\n",
    "\n",
    "<p style=\"font-size:12px\">\n",
    "The following aspects are defined in this substep:\n",
    "</p>\n",
    "\n",
    "<ol style=\"font-size:12px; padding-left: 20px\">\n",
    "  <li><code>set_current</code>: Defines the name of the project and loads all associated data sets. In this assessment, the project is named <code>regiopremise</code>.</li><br><br>\n",
    "  <li><code>Client_ID</code>: Client ID for UN trade & development Data Hub</li><br><br>\n",
    "  <li><code>API_key</code>: API key for UN trade & development Data Hub</li><br><br>\n",
    "  <li><code>path_transport_data</code>: Path were data of UN trade and development are stored</li><br><br>\n",
    "  <li><code>dict_countries</code>: Defines the countries that produce the pans or represent the comsumer market.</li><br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b6c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create/load project\n",
    "project_name ='regiopremise_test_small2'\n",
    "bw.projects.set_current(project_name)\n",
    "\n",
    "# Client ID and API key for UN trade & development Data Hub\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\", \"key_transport_cost.toml\")\n",
    "config = toml.load(desktop_path)\n",
    "CLIENT_ID = config['auth']['CLIENT_ID']\n",
    "API_KEY = config['auth']['API_KEY']\n",
    "\n",
    "# Definition path to store downloaded data \n",
    "# Get the directory of the deala package\n",
    "directory_deala = os.path.dirname(de.__file__)\n",
    "path_transport_data=os.path.join(directory_deala, 'files', 'linking')\n",
    "\n",
    "# Definition path to store transport DEALA activity json files\n",
    "path_transport_json=os.path.join(directory_deala, 'files', 'DEALA_activities')\n",
    "\n",
    "#Definition of countries for production activities that should be regionalized and for the consumer markets\n",
    "dict_countries={\n",
    "    'China': 'CN',\n",
    "    'France': 'FR',\n",
    "    'Germany': 'DE',\n",
    "    'India': 'IN',\n",
    "    'Italy': 'IT',\n",
    "    'United States of America': 'US',\n",
    "    'Turkey': 'TR',\n",
    "    'Netherlands': 'NL',\n",
    "    'Poland': 'PL',\n",
    "    'Belgium': 'BE',\n",
    "    'Czechia': 'CZ',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f32331",
   "metadata": {},
   "source": [
    "## 2. Create data sets for transport in DEALA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b40dbb",
   "metadata": {},
   "source": [
    "## 2.1 Load all data from [UN trade & development Data Hub](https://unctadstat.unctad.org/datacentre/dataviewer/US.TransportCosts) via API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8927c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 712 parallel requests...\n",
      "10/712 completed\n",
      "20/712 completed\n",
      "30/712 completed\n",
      "40/712 completed\n",
      "50/712 completed\n",
      "60/712 completed\n",
      "70/712 completed\n",
      "80/712 completed\n",
      "90/712 completed\n",
      "100/712 completed\n",
      "110/712 completed\n",
      "120/712 completed\n",
      "130/712 completed\n",
      "140/712 completed\n",
      "150/712 completed\n",
      "160/712 completed\n",
      "170/712 completed\n",
      "180/712 completed\n",
      "190/712 completed\n",
      "200/712 completed\n",
      "210/712 completed\n",
      "220/712 completed\n",
      "230/712 completed\n",
      "240/712 completed\n",
      "250/712 completed\n",
      "260/712 completed\n",
      "270/712 completed\n",
      "280/712 completed\n",
      "290/712 completed\n",
      "300/712 completed\n",
      "310/712 completed\n",
      "320/712 completed\n",
      "330/712 completed\n",
      "340/712 completed\n",
      "350/712 completed\n",
      "360/712 completed\n",
      "370/712 completed\n",
      "380/712 completed\n",
      "390/712 completed\n",
      "400/712 completed\n",
      "410/712 completed\n",
      "420/712 completed\n",
      "430/712 completed\n",
      "440/712 completed\n",
      "450/712 completed\n",
      "460/712 completed\n",
      "470/712 completed\n",
      "480/712 completed\n",
      "490/712 completed\n",
      "500/712 completed\n",
      "510/712 completed\n",
      "520/712 completed\n",
      "530/712 completed\n",
      "540/712 completed\n",
      "550/712 completed\n",
      "560/712 completed\n",
      "570/712 completed\n",
      "580/712 completed\n",
      "590/712 completed\n",
      "600/712 completed\n",
      "610/712 completed\n",
      "620/712 completed\n",
      "630/712 completed\n",
      "640/712 completed\n",
      "650/712 completed\n",
      "660/712 completed\n",
      "670/712 completed\n",
      "680/712 completed\n",
      "690/712 completed\n",
      "700/712 completed\n",
      "710/712 completed\n",
      "Finished in 136.7 seconds\n",
      "âš ï¸ No 'World' entries found as Origin â€“ starting additional request for Origin/Code='001'...\n",
      "ðŸŒ Additional request progress: 2/4\n",
      "ðŸŒ Additional request progress: 4/4\n",
      "âš ï¸ No data with code '001' â€“ trying code '0'...\n",
      "ðŸŒ Additional request (0) progress: 2/4\n",
      "ðŸŒ Additional request (0) progress: 4/4\n",
      "âš ï¸ No 'World' data found, even after retrying with (001/0).\n",
      "âœ… File saved: unctad_transport_costs_fixed_pivot.csv\n",
      "ðŸŒ Origin labels containing 'World': []\n",
      "  Origin_Code Origin.Label Destination.Label TransportMode.Label   2016  \\\n",
      "0         004  Afghanistan            Africa                 Air  0.070   \n",
      "1         004  Afghanistan            Africa             Railway  0.056   \n",
      "2         004  Afghanistan            Africa                Road  0.015   \n",
      "3         004  Afghanistan            Africa                 Sea  0.020   \n",
      "4         004  Afghanistan           Algeria                 Air  1.399   \n",
      "5         004  Afghanistan           Algeria             Railway  0.071   \n",
      "6         004  Afghanistan           Algeria                Road  0.466   \n",
      "7         004  Afghanistan           Algeria                 Sea  0.040   \n",
      "8         004  Afghanistan          Americas                 Air  0.936   \n",
      "9         004  Afghanistan          Americas                Road  0.784   \n",
      "\n",
      "    2017   2018   2019   2020   2021  \n",
      "0  0.706  0.175  0.194  0.330  0.405  \n",
      "1  0.007  0.004  0.004  0.002  0.001  \n",
      "2  0.032  0.052  0.008  0.013  0.008  \n",
      "3  0.024  0.016  0.008  0.007  0.012  \n",
      "4  1.729  1.476  1.378  1.471  0.949  \n",
      "5  0.006  0.012  0.020  0.018  0.008  \n",
      "6  0.006  0.009  0.011  0.010  0.004  \n",
      "7  0.011  0.010  0.010  0.010  0.007  \n",
      "8  0.560  0.290  1.093  0.068  0.316  \n",
      "9  0.689  0.087  0.409  0.427  0.184  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# API CONFIGURATION\n",
    "# ============================================================================\n",
    "API_URL = \"https://unctadstat-user-api.unctad.org/US.TransportCosts/cur/Facts?culture=en\"\n",
    "CLIENT_ID = CLIENT_ID\n",
    "API_KEY = API_KEY\n",
    "HEADERS = {\"ClientId\": CLIENT_ID, \"ClientSecret\": API_KEY}\n",
    "\n",
    "# ============================================================================\n",
    "# ORIGINS and TRANSPORT MODES\n",
    "# ============================================================================\n",
    "origins = [\n",
    "    \"001\",  # ðŸŒ World (global origin)\n",
    "    '0001', '004','008','012','020','024','028','032', '050','051','533','036','040','031','044','048','052','112','056',\n",
    "    '084','204','060','068','070','072','076','096','100', '124', '854','108','132','116','120','136','140','152','156',\n",
    "    '344','446','170','174','178','180','188','384','191','196','203','208','214','218','818','222','233','748',\n",
    "    '231','242','246','251','258','266', '270','268','276','288','300','304','308','320','324','328','340','348','352',\n",
    "    '356','360','364','372','376','380','388','392','400','398','404','296','410','414','417','418','428','422',\n",
    "    '426','434','440','442','450','454','458','462','466','470','478','480', '484','498','496','499','500','504','508',\n",
    "    '104','516','524','528','554','558','562','566','807','579','512','586','585','591','600','604','608','616',\n",
    "    '620','634','642','643','646','659','662','670','882','678','682','686','688','690','694','702','703','705',\n",
    "    '090','724','144','275','710', '729','740','752','757','762','834','764','626','768','780','788','792','800','804',\n",
    "    '784','926','842','858','860','704','887','894','716', '178'\n",
    "]\n",
    "\n",
    "transport_modes = {\n",
    "    \"10\": \"Air\",\n",
    "    \"21\": \"Sea\",\n",
    "    \"31\": \"Railway\",\n",
    "    \"32\": \"Road\"\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# Helper function to fetch data from the API\n",
    "# ============================================================================\n",
    "def fetch_data(origin_code, transport_code):\n",
    "    filter_query = (\n",
    "        f\"TransportMode/Code eq '{transport_code}' and \"\n",
    "        f\"Origin/Code eq '{origin_code}' and \"\n",
    "        f\"Product/Code eq 'TOTAL' and \"\n",
    "        f\"Year in (2016,2017,2018,2019,2020,2021)\"\n",
    "    )\n",
    "\n",
    "    form_data = {\n",
    "        \"$select\": \"Origin/Label,Destination/Label,TransportMode/Label,Year,Transport_cost_intensity_in_US_per_tonkm_Value\",\n",
    "        \"$filter\": filter_query,\n",
    "        \"$orderby\": \"Destination/Order asc ,Year asc\",\n",
    "        \"$compute\": \"round(M1991/Value div 1, 3) as Transport_cost_intensity_in_US_per_tonkm_Value\",\n",
    "        \"$format\": \"csv\",\n",
    "        \"compress\": \"gz\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.post(API_URL, data=form_data, headers=HEADERS, timeout=90)\n",
    "        r.raise_for_status()\n",
    "\n",
    "        with gzip.open(BytesIO(r.content), \"rt\", encoding=\"utf-8\") as f:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "        if df.empty:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # Normalize column names\n",
    "        df.columns = [c.strip().replace(\"/\", \"_\").replace(\".\", \"_\") for c in df.columns]\n",
    "\n",
    "        df[\"Origin_Code\"] = origin_code\n",
    "        df[\"TransportMode_Code\"] = transport_code\n",
    "        df[\"TransportMode_Label\"] = transport_modes.get(transport_code, \"Unknown\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error for Origin {origin_code}, Mode {transport_code}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ============================================================================\n",
    "# Parallel data fetching\n",
    "# ============================================================================\n",
    "tasks = [(o, m) for o in origins for m in transport_modes.keys()]\n",
    "print(f\"Starting {len(tasks)} parallel requests...\")\n",
    "\n",
    "all_data = []\n",
    "start = time.time()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as pool:\n",
    "    futures = {pool.submit(fetch_data, o, m): (o, m) for o, m in tasks}\n",
    "    for i, fut in enumerate(as_completed(futures), 1):\n",
    "        df = fut.result()\n",
    "        if not df.empty:\n",
    "            all_data.append(df)\n",
    "        if i % 10 == 0:\n",
    "            print(f\"{i}/{len(futures)} completed\")\n",
    "\n",
    "print(f\"Finished in {round(time.time() - start, 1)} seconds\")\n",
    "\n",
    "# ============================================================================\n",
    "# Check for existence of \"World\" data\n",
    "# ============================================================================\n",
    "if all_data:\n",
    "    combined_test_df = pd.concat(all_data, ignore_index=True)\n",
    "    origins_in_data = combined_test_df[\"Origin_Label\"].unique().tolist()\n",
    "\n",
    "    if not any(\"World\" in str(x) for x in origins_in_data):\n",
    "        print(\"âš ï¸ No 'World' entries found as Origin â€“ starting additional request for Origin/Code='001'...\")\n",
    "\n",
    "        world_tasks = [(\"001\", m) for m in transport_modes.keys()]\n",
    "        world_data = []\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=4) as pool:\n",
    "            futures = {pool.submit(fetch_data, o, m): (o, m) for o, m in world_tasks}\n",
    "            for i, fut in enumerate(as_completed(futures), 1):\n",
    "                df = fut.result()\n",
    "                if not df.empty:\n",
    "                    world_data.append(df)\n",
    "                if i % 2 == 0:\n",
    "                    print(f\"ðŸŒ Additional request progress: {i}/{len(world_tasks)}\")\n",
    "\n",
    "        # Try code \"0\" if \"001\" gives no data\n",
    "        if not world_data:\n",
    "            print(\"âš ï¸ No data with code '001' â€“ trying code '0'...\")\n",
    "            world_tasks_zero = [(\"0\", m) for m in transport_modes.keys()]\n",
    "            with ThreadPoolExecutor(max_workers=4) as pool:\n",
    "                futures = {pool.submit(fetch_data, o, m): (o, m) for o, m in world_tasks_zero}\n",
    "                for i, fut in enumerate(as_completed(futures), 1):\n",
    "                    df = fut.result()\n",
    "                    if not df.empty:\n",
    "                        world_data.append(df)\n",
    "                    if i % 2 == 0:\n",
    "                        print(f\"ðŸŒ Additional request (0) progress: {i}/{len(world_tasks_zero)}\")\n",
    "\n",
    "        if world_data:\n",
    "            print(f\"âœ… Additional request successful: {len(world_data)} datasets found with 'World' as Origin.\")\n",
    "            all_data.extend(world_data)\n",
    "        else:\n",
    "            print(\"âš ï¸ No 'World' data found, even after retrying with (001/0).\")\n",
    "    else:\n",
    "        print(\"âœ… 'World' Origin data already present.\")\n",
    "else:\n",
    "    print(\"âš ï¸ No data loaded â€” skipping 'World' check.\")\n",
    "\n",
    "# ============================================================================\n",
    "# COMBINE AND PIVOT DATA\n",
    "# ============================================================================\n",
    "if not all_data:\n",
    "    raise ValueError(\"No data retrieved\")\n",
    "\n",
    "full = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Harmonize column names\n",
    "rename_map = {\n",
    "    \"Origin_Label\": \"Origin.Label\",\n",
    "    \"Destination_Label\": \"Destination.Label\",\n",
    "    \"TransportMode_Label\": \"TransportMode.Label\",\n",
    "    \"Transport_cost_intensity_in_US_per_tonkm_Value\": \"TransportCost\"\n",
    "}\n",
    "for old, new in rename_map.items():\n",
    "    if old in full.columns:\n",
    "        full.rename(columns={old: new}, inplace=True)\n",
    "    elif new not in full.columns:\n",
    "        full[new] = \"Unknown\"\n",
    "\n",
    "pivot = (\n",
    "    full.pivot_table(\n",
    "        index=[\"Origin_Code\", \"Origin.Label\", \"Destination.Label\", \"TransportMode.Label\"],\n",
    "        columns=\"Year\",\n",
    "        values=\"TransportCost\",\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "pivot.columns.name = None\n",
    "pivot.rename(columns=lambda c: f\"{c}\" if isinstance(c, int) else c, inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "pivot.to_csv(os.path.join(path_transport_data, \"unctad_transport_costs_fixed_pivot.csv\"), index=False)\n",
    "print(\"âœ… File saved: unctad_transport_costs_fixed_pivot.csv\")\n",
    "\n",
    "# Output short check\n",
    "print(\"ðŸŒ Origin labels containing 'World':\", [x for x in full[\"Origin.Label\"].unique() if \"World\" in str(x)])\n",
    "print(pivot.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a22c66",
   "metadata": {},
   "source": [
    "## 2.2 Create json file for transport DEALA activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db27ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒ Using 26 countries: ['GLO', 'BR', 'PL', 'US', 'RU', 'MX', 'CN', 'CD', 'RoW', 'NL', 'RER', 'JP', 'IN', 'IR', 'FR', 'DE', 'CZ', 'TR', 'CA', 'IT', 'DZ', 'RO', 'AE', 'BE', 'CL', 'KR']\n",
      "âœ… Added 100 domestic transport entries.\n",
      "âœ… Total records: 2139\n",
      "âœ… JSON file created: transport.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 0. Prepare country selection\n",
    "# ============================================================================\n",
    "# Read countries from input databases and include those defined manually\n",
    "\n",
    "list_countries = []\n",
    "for db in bw.databases:\n",
    "    if \"input\" in db:\n",
    "        for act in bw.Database(db):\n",
    "            country = act['location']\n",
    "            if country not in list_countries:\n",
    "                list_countries.append(country)\n",
    "\n",
    "# Add countries from dict_countries if not already included\n",
    "for country in dict_countries.keys():\n",
    "    if dict_countries[country] not in list_countries:\n",
    "        list_countries.append(dict_countries[country])\n",
    "\n",
    "print(f\"ðŸŒ Using {len(list_countries)} countries: {list_countries}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 1. Load input data\n",
    "# ============================================================================\n",
    "pivot = pd.read_csv(os.path.join(path_transport_data, \"unctad_transport_costs_fixed_pivot.csv\"))\n",
    "countries = pd.read_excel(\n",
    "    os.path.join(path_transport_data, \"countries.xlsx\"),\n",
    "    keep_default_na=False,\n",
    "    na_values=[],\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "# ============================================================================\n",
    "# 2. Main loop over all rows from the UNCTAD pivot file\n",
    "# ============================================================================\n",
    "for _, row in pivot.iterrows():\n",
    "    # Only 2019 is used here, but structure allows for extending year range\n",
    "    years = [str(y) for y in range(2019, 2020) if str(y) in pivot.columns]\n",
    "    costs = {str(y): row[str(y)] for y in years}\n",
    "\n",
    "    origin_label = row[\"Origin.Label\"]\n",
    "    dest_label = row[\"Destination.Label\"]\n",
    "\n",
    "    # Helper function: map country/region labels to ISO and REMIND codes\n",
    "    def get_country_info(label):\n",
    "        if label in countries[\"country\"].values:\n",
    "            iso = countries.loc[countries[\"country\"] == label, \"alpha-2\"].values[0]\n",
    "            remind = countries.loc[countries[\"country\"] == label, \"remind\"].values[0]\n",
    "        elif label in countries[\"region\"].values:\n",
    "            iso = countries.loc[countries[\"region\"] == label, \"alpha-2\"].values[0]\n",
    "            remind = countries.loc[countries[\"region\"] == label, \"remind\"].values[0]\n",
    "        elif label in countries[\"sub-region\"].values:\n",
    "            iso = countries.loc[countries[\"sub-region\"] == label, \"alpha-2\"].values[0]\n",
    "            remind = countries.loc[countries[\"sub-region\"] == label, \"remind\"].values[0]\n",
    "        else:\n",
    "            return None, None\n",
    "        return iso, remind\n",
    "\n",
    "    origin_iso, origin_remind = get_country_info(origin_label)\n",
    "    dest_iso, dest_remind = get_country_info(dest_label)\n",
    "\n",
    "    if not origin_iso or not dest_iso:\n",
    "        continue\n",
    "    if origin_iso not in list_countries or dest_iso not in list_countries:\n",
    "        continue\n",
    "\n",
    "    if pd.notna(costs[\"2019\"]):\n",
    "        cost_value = float(costs[\"2019\"])\n",
    "\n",
    "        # --- Standard record: Origin â†’ Destination ---\n",
    "        records.append({\n",
    "            \"Country\": origin_label,\n",
    "            \"ISO-3166-1 ALPHA-2\": origin_iso,\n",
    "            \"REMIND Region\": origin_remind,\n",
    "            \"Sector\": \"Transport\",\n",
    "            \"Type\": f\"Transport, {row['TransportMode.Label']}, from {origin_iso} to {dest_iso}\",\n",
    "            \"Costs per unit [USD/unit]\": cost_value,\n",
    "            \"Unit\": \"tkm\",\n",
    "            \"Base Year\": 2019,\n",
    "            \"Identifier\": \"transport\",\n",
    "            \"Years\": 0,\n",
    "            \"Description\": (\n",
    "                f\"This dataset describes the average transport cost per ton-kilometer \"\n",
    "                f\"via {row['TransportMode.Label']} from {origin_label} to {dest_label} \"\n",
    "                f\"(2019 data, source: UNCTAD).\"\n",
    "            ),\n",
    "            \"Code\": str(uuid.uuid4().hex)\n",
    "        })\n",
    "\n",
    "        # --- Additional record: Global (GLO) â†’ Origin (if destination is World) ---\n",
    "        if dest_label == \"World\":\n",
    "            records.append({\n",
    "                \"Country\": \"GLO\",\n",
    "                \"ISO-3166-1 ALPHA-2\": \"GLO\",\n",
    "                \"REMIND Region\": \"GLO\",\n",
    "                \"Sector\": \"Transport\",\n",
    "                \"Type\": f\"Transport, {row['TransportMode.Label']}, from GLO to {origin_iso}\",\n",
    "                \"Costs per unit [USD/unit]\": cost_value,\n",
    "                \"Unit\": \"tkm\",\n",
    "                \"Base Year\": 2019,\n",
    "                \"Identifier\": \"transport\",\n",
    "                \"Years\": 0,\n",
    "                \"Description\": (\n",
    "                    f\"Estimated transport cost from GLO to {origin_label}, \"\n",
    "                    f\"based on the inverse of {origin_label} to World for \"\n",
    "                    f\"{row['TransportMode.Label']} (2019, UNCTAD).\"\n",
    "                ),\n",
    "                \"Code\": str(uuid.uuid4().hex)\n",
    "            })\n",
    "\n",
    "# ============================================================================\n",
    "# 3. Add domestic transport entries (e.g., DE â†’ DE)\n",
    "# ============================================================================\n",
    "df_costs = pd.DataFrame(records)\n",
    "intra_added = 0\n",
    "\n",
    "for mode in df_costs[\"Type\"].apply(lambda x: x.split(\",\")[1].strip()).unique():\n",
    "    for country in list_countries:\n",
    "        subset = df_costs[df_costs[\"Type\"].str.contains(mode)]\n",
    "        subset = subset[subset[\"Type\"].str.contains(country)]\n",
    "        if subset.empty:\n",
    "            continue\n",
    "\n",
    "        min_cost = subset[\"Costs per unit [USD/unit]\"].replace(0, np.nan).min()\n",
    "        if pd.notna(min_cost) and min_cost > 0:\n",
    "            records.append({\n",
    "                \"Country\": country,\n",
    "                \"ISO-3166-1 ALPHA-2\": country,\n",
    "                \"REMIND Region\": countries.loc[countries[\"alpha-2\"] == country, \"remind\"].values[0],\n",
    "                \"Sector\": \"Transport\",\n",
    "                \"Type\": f\"Transport, {mode}, from {country} to {country}\",\n",
    "                \"Costs per unit [USD/unit]\": round(min_cost, 4),\n",
    "                \"Unit\": \"tkm\",\n",
    "                \"Base Year\": 2019,\n",
    "                \"Identifier\": \"transport\",\n",
    "                \"Years\": 0,\n",
    "                \"Description\": (\n",
    "                    f\"Estimated domestic transport within {country} via {mode}, \"\n",
    "                    f\"using the minimum observed cost among all international relations.\"\n",
    "                ),\n",
    "                \"Code\": str(uuid.uuid4().hex)\n",
    "            })\n",
    "            intra_added += 1\n",
    "\n",
    "print(f\"âœ… Added {intra_added} domestic transport entries.\")\n",
    "print(f\"âœ… Total records: {len(records)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. Save to JSON\n",
    "# ============================================================================\n",
    "with open(os.path.join(path_transport_json, \"transport.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… JSON file created: transport.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
