#!/usr/bin/env python3
"""
å®Œæ•´çš„æ–‡çŒ®åˆ†æåŠŸèƒ½æµ‹è¯•
æµ‹è¯•get_literature_relationså·¥å…·çš„æ‰€æœ‰åŠŸèƒ½å’Œåœºæ™¯
"""

import logging
import time

from src.article_mcp.tools.core import relation_tools

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)


# åˆ›å»ºæ¨¡æ‹Ÿçš„MCPå¯¹è±¡
class MockMCP:
    def __init__(self):
        self.tools = {}

    def tool(self):
        def decorator(func):
            self.tools[func.__name__] = func
            return func

        return decorator


class TestLogger:
    """è‡ªå®šä¹‰æµ‹è¯•æ—¥å¿—å™¨"""

    def info(self, msg):
        print(f"ğŸ“ INFO: {msg}")

    def warning(self, msg):
        print(f"âš ï¸  WARNING: {msg}")

    def error(self, msg):
        print(f"âŒ ERROR: {msg}")

    def debug(self, msg):
        print(f"ğŸ” DEBUG: {msg}")


def create_test_services():
    """åˆ›å»ºæµ‹è¯•æœåŠ¡å®ä¾‹"""
    print("ğŸ”§ åˆå§‹åŒ–æµ‹è¯•æœåŠ¡...")

    try:
        from src.article_mcp.services.crossref_service import CrossRefService
        from src.article_mcp.services.europe_pmc import create_europe_pmc_service
        from src.article_mcp.services.openalex_service import OpenAlexService
        from src.article_mcp.services.pubmed_search import create_pubmed_service

        test_logger = TestLogger()

        # åˆå§‹åŒ–æœåŠ¡
        crossref_service = CrossRefService(test_logger)
        openalex_service = OpenAlexService(test_logger)
        pubmed_service = create_pubmed_service(test_logger)
        europe_pmc_service = create_europe_pmc_service(test_logger, pubmed_service)

        mock_services = {
            "europe_pmc": europe_pmc_service,
            "pubmed": pubmed_service,
            "crossref": crossref_service,
            "openalex": openalex_service,
        }

        print("âœ… æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        return mock_services, test_logger

    except Exception as e:
        print(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return None, None


def test_single_doi_analysis():
    """æµ‹è¯•å•ä¸ªDOIæ–‡çŒ®çš„å®Œæ•´å…³ç³»åˆ†æ"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ æµ‹è¯•1: å•ä¸ªDOIæ–‡çŒ®çš„å®Œæ•´å…³ç³»åˆ†æ")
    print("=" * 80)

    # æµ‹è¯•ç”¨ä¾‹ï¼šä½¿ç”¨ä¸€äº›çœŸå®çš„DOI
    test_cases = [
        {
            "name": "Natureæ–‡ç« åˆ†æ",
            "doi": "10.1038/nature12373",
            "expected_results": ["references", "similar", "citing"],
        },
        {
            "name": "Scienceæ–‡ç« åˆ†æ",
            "doi": "10.1126/science.1258070",
            "expected_results": ["references"],
        },
        {
            "name": "é«˜å¼•ç”¨æ–‡ç« åˆ†æ",
            "doi": "10.1038/s41586-021-03819-2",
            "expected_results": ["citing"],
        },
        {
            "name": "åŒ»å­¦æ–‡ç« åˆ†æ",
            "doi": "10.1056/NEJMoa2030113",
            "expected_results": ["references", "similar"],
        },
    ]

    services, test_logger = create_test_services()
    if not services:
        print("âŒ æ— æ³•åˆå§‹åŒ–æœåŠ¡ï¼Œè·³è¿‡æµ‹è¯•")
        return

    # æ³¨å†Œå·¥å…·
    mock_mcp = MockMCP()
    relation_tools.register_relation_tools(mock_mcp, services, test_logger)

    total_tests = len(test_cases)
    successful_tests = 0

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª å­æµ‹è¯• {i}/{total_tests}: {test_case['name']}")
        print("-" * 60)

        start_time = time.time()

        try:
            result = mock_mcp.tools["get_literature_relations"](
                identifiers=test_case["doi"],
                id_type="doi",
                relation_types=test_case["expected_results"],
                max_results=5,
                sources=["crossref", "openalex", "pubmed"],
            )

            processing_time = time.time() - start_time

            # åˆ†æç»“æœ
            success = result.get("success", False)
            stats = result.get("statistics", {})
            relations = result.get("relations", {})

            print(f"âœ… æŸ¥è¯¢æˆåŠŸ: {success}")
            print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
            print(f"ğŸ“Š æ ‡è¯†ç¬¦: {result.get('identifier', 'N/A')}")
            print(f"ğŸ” æ ‡è¯†ç¬¦ç±»å‹: {result.get('id_type', 'N/A')}")

            print("\nğŸ“ˆ å…³ç³»ç»Ÿè®¡:")
            for rel_type in test_case["expected_results"]:
                count = stats.get(f"{rel_type}_count", 0)
                status = "âœ…" if count > 0 else "âš ï¸ "
                print(f"   {status} {rel_type}: {count} ç¯‡")

                if count > 0:
                    rel_data = relations.get(rel_type, [])[:2]
                    for j, item in enumerate(rel_data, 1):
                        title = item.get("title", "æ— æ ‡é¢˜")
                        if len(title) > 70:
                            title = title[:70] + "..."
                        doi = item.get("doi", "æ— DOI")
                        print(f"     {j}. {title}")
                        print(f"        DOI: {doi}")

            if success:
                successful_tests += 1
                print("ğŸ¯ æµ‹è¯•é€šè¿‡")
            else:
                error = result.get("error", "æœªçŸ¥é”™è¯¯")
                print(f"âŒ æµ‹è¯•å¤±è´¥: {error}")

        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback

            traceback.print_exc()

    print(f"\nğŸ“Š å•DOIæµ‹è¯•æ€»ç»“: {successful_tests}/{total_tests} é€šè¿‡")
    return successful_tests, total_tests


def test_identifier_conversion():
    """æµ‹è¯•æ ‡è¯†ç¬¦è½¬æ¢åŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("ğŸ”„ æµ‹è¯•2: æ ‡è¯†ç¬¦è½¬æ¢åŠŸèƒ½")
    print("=" * 80)

    test_cases = [
        # çœŸå®çš„PMIDï¼ˆå¯èƒ½è½¬æ¢æˆåŠŸï¼‰
        {"id": "32132209", "type": "pmid", "name": "COVID-19ç ”ç©¶"},
        {"id": "31832154", "type": "pmid", "name": "åŒ»å­¦æ–‡çŒ®"},
        # æµ‹è¯•ç”¨PMCIDï¼ˆå¯èƒ½ä¸å­˜åœ¨ï¼‰
        {"id": "PMC123456", "type": "pmcid", "name": "æµ‹è¯•PMCID"},
        # DOIç›´æ¥è¯†åˆ«
        {"id": "10.1038/nature12373", "type": "doi", "name": "Nature DOI"},
        # arXiv IDï¼ˆæš‚ä¸æ”¯æŒï¼‰
        {"id": "arXiv:2001.00001", "type": "arxiv_id", "name": "arXivè®ºæ–‡"},
    ]

    total_tests = len(test_cases)
    successful_conversions = 0

    for i, test_case in enumerate(test_cases, 1):
        print(f"\nğŸ§ª å­æµ‹è¯• {i}/{total_tests}: {test_case['name']}")
        print("-" * 60)

        try:
            test_logger = TestLogger()

            # æµ‹è¯•æ ‡è¯†ç¬¦è¯†åˆ«
            if test_case["type"] == "doi":
                doi = relation_tools._ensure_doi_identifier(
                    test_case["id"], test_case["type"], test_logger
                )
                print(f"ğŸ” DOIè¯†åˆ«: {test_case['id']} -> {doi}")

                if doi == test_case["id"]:
                    successful_conversions += 1
                    print("âœ… DOIè¯†åˆ«æ­£ç¡®")
                else:
                    print("âŒ DOIè¯†åˆ«å¤±è´¥")

            elif test_case["type"] == "pmid":
                print(f"ğŸ”„ PMIDè½¬æ¢: {test_case['id']}")
                doi = relation_tools._pmid_to_doi(test_case["id"], test_logger)

                if doi:
                    print(f"âœ… è½¬æ¢æˆåŠŸ: {doi}")
                    successful_conversions += 1

                    # æµ‹è¯•è½¬æ¢åçš„DOIæ˜¯å¦èƒ½æŸ¥è¯¢
                    print("ğŸ§ª æµ‹è¯•è½¬æ¢åDOIçš„æŸ¥è¯¢èƒ½åŠ›...")
                    services, logger = create_test_services()
                    if services:
                        mock_mcp = MockMCP()
                        relation_tools.register_relation_tools(mock_mcp, services, logger)

                        result = mock_mcp.tools["get_literature_relations"](
                            identifiers=doi,
                            id_type="doi",
                            relation_types=["references"],
                            max_results=2,
                        )

                        if result.get("success"):
                            print("âœ… è½¬æ¢åDOIæŸ¥è¯¢æˆåŠŸ")
                        else:
                            print("âš ï¸  è½¬æ¢åDOIæŸ¥è¯¢å¤±è´¥")
                else:
                    print("âŒ è½¬æ¢å¤±è´¥")

            elif test_case["type"] == "pmcid":
                print(f"ğŸ”„ PMCIDè½¬æ¢: {test_case['id']}")
                doi = relation_tools._pmcid_to_doi(test_case["id"], test_logger)

                if doi:
                    print(f"âœ… è½¬æ¢æˆåŠŸ: {doi}")
                    successful_conversions += 1
                else:
                    print("âŒ è½¬æ¢å¤±è´¥")

            elif test_case["type"] == "arxiv_id":
                print(f"ğŸ”„ arXivè½¬æ¢: {test_case['id']}")
                doi = relation_tools._ensure_doi_identifier(
                    test_case["id"], test_case["type"], test_logger
                )

                if not doi:
                    print("âš ï¸  arXivè½¬æ¢æš‚ä¸æ”¯æŒï¼ˆç¬¦åˆé¢„æœŸï¼‰")
                    successful_conversions += 1
                else:
                    print(f"æ„å¤–æˆåŠŸ: {doi}")

        except Exception as e:
            print(f"âŒ è½¬æ¢æµ‹è¯•å¼‚å¸¸: {e}")

    print(f"\nğŸ“Š æ ‡è¯†ç¬¦è½¬æ¢æµ‹è¯•æ€»ç»“: {successful_conversions}/{total_tests} é€šè¿‡")
    return successful_conversions, total_tests


def test_batch_analysis():
    """æµ‹è¯•æ‰¹é‡æ–‡çŒ®åˆ†æåŠŸèƒ½"""
    print("\n" + "=" * 80)
    print("ğŸ“¦ æµ‹è¯•3: æ‰¹é‡æ–‡çŒ®åˆ†æåŠŸèƒ½")
    print("=" * 80)

    # æ‰¹é‡æµ‹è¯•ç”¨ä¾‹
    batch_test_cases = [
        {
            "name": "æ‰¹é‡DOIåˆ†æ",
            "identifiers": ["10.1038/nature12373", "10.1126/science.1258070"],
            "id_type": "auto",
            "analysis_type": "basic",
        },
        {
            "name": "æ‰¹é‡ç½‘ç»œåˆ†æ",
            "identifiers": ["10.1038/nature12373"],
            "id_type": "doi",
            "analysis_type": "comprehensive",
        },
    ]

    services, test_logger = create_test_services()
    if not services:
        print("âŒ æ— æ³•åˆå§‹åŒ–æœåŠ¡ï¼Œè·³è¿‡æµ‹è¯•")
        return 0, 1

    # æ³¨å†Œå·¥å…·
    mock_mcp = MockMCP()
    relation_tools.register_relation_tools(mock_mcp, services, test_logger)

    total_tests = len(batch_test_cases)
    successful_tests = 0

    for i, test_case in enumerate(batch_test_cases, 1):
        print(f"\nğŸ§ª å­æµ‹è¯• {i}/{total_tests}: {test_case['name']}")
        print("-" * 60)

        start_time = time.time()

        try:
            result = mock_mcp.tools["get_literature_relations"](
                identifiers=test_case["identifiers"],
                id_type=test_case["id_type"],
                analysis_type=test_case["analysis_type"],
                max_results=3,
            )

            processing_time = time.time() - start_time

            # åˆ†æç»“æœ
            success = result.get("success", False)

            print(f"âœ… æŸ¥è¯¢æˆåŠŸ: {success}")
            print(f"â±ï¸  å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")

            if "total_identifiers" in result:
                # æ‰¹é‡åˆ†æç»“æœ
                total_ids = result.get("total_identifiers", 0)
                successful_analyses = result.get("successful_analyses", 0)
                success_rate = result.get("success_rate", 0)

                print("ğŸ“Š æ‰¹é‡ç»Ÿè®¡:")
                print(f"   - æ€»æ ‡è¯†ç¬¦æ•°: {total_ids}")
                print(f"   - æˆåŠŸåˆ†ææ•°: {successful_analyses}")
                print(f"   - æˆåŠŸç‡: {success_rate:.1%}")

                if success_rate > 0:
                    successful_tests += 1
                    print("ğŸ¯ æ‰¹é‡æµ‹è¯•é€šè¿‡")
                else:
                    print("âŒ æ‰¹é‡æµ‹è¯•å¤±è´¥")

            elif "network_data" in result:
                # ç½‘ç»œåˆ†æç»“æœ
                network_data = result.get("network_data", {})
                nodes = network_data.get("nodes", [])
                edges = network_data.get("edges", [])

                print("ğŸ“Š ç½‘ç»œç»Ÿè®¡:")
                print(f"   - èŠ‚ç‚¹æ•°: {len(nodes)}")
                print(f"   - è¾¹æ•°: {len(edges)}")
                print(f"   - åˆ†æç±»å‹: {network_data.get('analysis_type', 'N/A')}")

                if len(nodes) > 0:
                    successful_tests += 1
                    print("ğŸ¯ ç½‘ç»œæµ‹è¯•é€šè¿‡")
                else:
                    print("âŒ ç½‘ç»œæµ‹è¯•å¤±è´¥")

            else:
                print("âŒ æœªçŸ¥çš„æ‰¹é‡ç»“æœæ ¼å¼")

        except Exception as e:
            print(f"âŒ æ‰¹é‡æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback

            traceback.print_exc()

    print(f"\nğŸ“Š æ‰¹é‡åˆ†ææµ‹è¯•æ€»ç»“: {successful_tests}/{total_tests} é€šè¿‡")
    return successful_tests, total_tests


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ"""
    print("\n" + "=" * 80)
    print("ğŸ›¡ï¸  æµ‹è¯•4: é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ")
    print("=" * 80)

    error_test_cases = [
        {
            "name": "ç©ºæ ‡è¯†ç¬¦æµ‹è¯•",
            "params": {"identifiers": "", "id_type": "doi", "relation_types": ["references"]},
        },
        {
            "name": "æ— æ•ˆDOIæµ‹è¯•",
            "params": {
                "identifiers": "10.9999/invalid.doi",
                "id_type": "doi",
                "relation_types": ["references"],
            },
        },
        {
            "name": "ä¸å­˜åœ¨çš„PMIDæµ‹è¯•",
            "params": {
                "identifiers": "99999999",
                "id_type": "pmid",
                "relation_types": ["references"],
            },
        },
        {
            "name": "ç©ºå…³ç³»ç±»å‹æµ‹è¯•",
            "params": {
                "identifiers": "10.1038/nature12373",
                "id_type": "doi",
                "relation_types": [],
            },
        },
        {
            "name": "æ— æ•ˆæ•°æ®æºæµ‹è¯•",
            "params": {
                "identifiers": "10.1038/nature12373",
                "id_type": "doi",
                "relation_types": ["references"],
                "sources": ["invalid_source"],
            },
        },
    ]

    services, test_logger = create_test_services()
    if not services:
        print("âŒ æ— æ³•åˆå§‹åŒ–æœåŠ¡ï¼Œè·³è¿‡æµ‹è¯•")
        return 0, 1

    # æ³¨å†Œå·¥å…·
    mock_mcp = MockMCP()
    relation_tools.register_relation_tools(mock_mcp, services, test_logger)

    total_tests = len(error_test_cases)
    well_handled_tests = 0

    for i, test_case in enumerate(error_test_cases, 1):
        print(f"\nğŸ§ª å­æµ‹è¯• {i}/{total_tests}: {test_case['name']}")
        print("-" * 60)

        try:
            result = mock_mcp.tools["get_literature_relations"](**test_case["params"])

            success = result.get("success", False)
            error = result.get("error", "")

            if not success and error:
                print(f"âœ… é”™è¯¯æ­£ç¡®å¤„ç†: {error}")
                well_handled_tests += 1
            elif success:
                print("âš ï¸  æ„å¤–æˆåŠŸï¼ˆå¯èƒ½æ˜¯æµ‹è¯•æ•°æ®æœ‰æ•ˆï¼‰")
                well_handled_tests += 1
            else:
                print("âŒ é”™è¯¯å¤„ç†ä¸å®Œå–„")

        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„æœŸçš„å¼‚å¸¸
            if "ç©º" in test_case["name"] or "æ— æ•ˆ" in test_case["name"]:
                print(f"âœ… å¼‚å¸¸æ­£ç¡®æŠ›å‡º: {type(e).__name__}")
                well_handled_tests += 1
            else:
                print(f"âŒ æ„å¤–å¼‚å¸¸: {e}")

    print(f"\nğŸ“Š é”™è¯¯å¤„ç†æµ‹è¯•æ€»ç»“: {well_handled_tests}/{total_tests} é€šè¿‡")
    return well_handled_tests, total_tests


def test_data_quality():
    """æµ‹è¯•è¿”å›æ•°æ®çš„è´¨é‡å’Œæ ¼å¼"""
    print("\n" + "=" * 80)
    print("ğŸ” æµ‹è¯•5: æ•°æ®è´¨é‡å’Œæ ¼å¼éªŒè¯")
    print("=" * 80)

    services, test_logger = create_test_services()
    if not services:
        print("âŒ æ— æ³•åˆå§‹åŒ–æœåŠ¡ï¼Œè·³è¿‡æµ‹è¯•")
        return 0, 1

    # æ³¨å†Œå·¥å…·
    mock_mcp = MockMCP()
    relation_tools.register_relation_tools(mock_mcp, services, test_logger)

    try:
        print("ğŸ§ª æµ‹è¯•æ•°æ®è´¨é‡å’Œæ ¼å¼...")

        result = mock_mcp.tools["get_literature_relations"](
            identifiers="10.1038/nature12373",
            id_type="doi",
            relation_types=["references", "similar", "citing"],
            max_results=3,
        )

        quality_checks = []

        # æ£€æŸ¥åŸºæœ¬ç»“æ„
        required_fields = ["success", "identifier", "id_type", "relations", "statistics"]
        for field in required_fields:
            if field in result:
                quality_checks.append(f"âœ… åŒ…å«å­—æ®µ: {field}")
            else:
                quality_checks.append(f"âŒ ç¼ºå¤±å­—æ®µ: {field}")

        # æ£€æŸ¥å…³ç³»æ•°æ®è´¨é‡
        relations = result.get("relations", {})
        for rel_type, rel_data in relations.items():
            if rel_data and len(rel_data) > 0:
                quality_checks.append(f"âœ… {rel_type} æ•°æ®æœ‰æ•ˆ: {len(rel_data)} æ¡")

                # æ£€æŸ¥æ•°æ®å­—æ®µ
                sample_item = rel_data[0]
                important_fields = ["title", "doi", "authors", "journal"]
                for field in important_fields:
                    if field in sample_item and sample_item[field]:
                        quality_checks.append(f"âœ… {rel_type} åŒ…å« {field}")
                    else:
                        quality_checks.append(f"âš ï¸  {rel_type} ç¼ºå°‘ {field}")
            else:
                quality_checks.append(f"âš ï¸  {rel_type} æ— æ•°æ®")

        # æ£€æŸ¥ç»Ÿè®¡ä¿¡æ¯
        stats = result.get("statistics", {})
        expected_stats = ["references_count", "similar_count", "citing_count", "total_relations"]
        for stat in expected_stats:
            if stat in stats:
                quality_checks.append(f"âœ… åŒ…å«ç»Ÿè®¡: {stat}={stats[stat]}")

        # æ£€æŸ¥å¤„ç†æ—¶é—´
        if "processing_time" in result:
            processing_time = result["processing_time"]
            if processing_time > 0:
                quality_checks.append(f"âœ… å¤„ç†æ—¶é—´: {processing_time} ç§’")

        # è¾“å‡ºè´¨é‡æ£€æŸ¥ç»“æœ
        for check in quality_checks:
            print(f"   {check}")

        # è®¡ç®—è´¨é‡è¯„åˆ†
        total_checks = len(quality_checks)
        passed_checks = len([c for c in quality_checks if c.startswith("âœ…")])
        quality_score = passed_checks / total_checks if total_checks > 0 else 0

        print(f"\nğŸ“Š æ•°æ®è´¨é‡è¯„åˆ†: {quality_score:.1%} ({passed_checks}/{total_checks})")

        return passed_checks, total_checks

    except Exception as e:
        print(f"âŒ æ•°æ®è´¨é‡æµ‹è¯•å¼‚å¸¸: {e}")
        return 0, 1


def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ å®Œæ•´æµ‹è¯•æŠ¥å‘Š")
    print("=" * 80)

    total_tests = sum(result[1] for result in results)
    successful_tests = sum(result[0] for result in results)
    overall_success_rate = successful_tests / total_tests if total_tests > 0 else 0

    test_categories = [
        ("å•DOIæ–‡çŒ®åˆ†æ", results[0]),
        ("æ ‡è¯†ç¬¦è½¬æ¢", results[1]),
        ("æ‰¹é‡æ–‡çŒ®åˆ†æ", results[2]),
        ("é”™è¯¯å¤„ç†", results[3]),
        ("æ•°æ®è´¨é‡", results[4]),
    ]

    print("\nğŸ¯ æ€»ä½“æµ‹è¯•ç»“æœ:")
    print(f"   - æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"   - é€šè¿‡æµ‹è¯•æ•°: {successful_tests}")
    print(f"   - æˆåŠŸç‡: {overall_success_rate:.1%}")

    print("\nğŸ“Š åˆ†ç±»æµ‹è¯•ç»“æœ:")
    for category, (passed, total) in test_categories:
        rate = passed / total if total > 0 else 0
        status = "âœ…" if rate >= 0.8 else "âš ï¸ " if rate >= 0.6 else "âŒ"
        print(f"   {status} {category}: {passed}/{total} ({rate:.1%})")

    print("\nğŸ” åŠŸèƒ½è¯„ä¼°:")
    if overall_success_rate >= 0.8:
        print("   ğŸ‰ ä¼˜ç§€ï¼åŠŸèƒ½åŸºæœ¬å¯ç”¨ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨")
    elif overall_success_rate >= 0.6:
        print("   ğŸ‘ è‰¯å¥½ï¼å¤§éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œéœ€è¦å°å¹…ä¼˜åŒ–")
    elif overall_success_rate >= 0.4:
        print("   âš ï¸  ä¸€èˆ¬ï¼éƒ¨åˆ†åŠŸèƒ½æ­£å¸¸ï¼Œéœ€è¦é‡ç‚¹ä¼˜åŒ–")
    else:
        print("   âŒ éœ€è¦æ”¹è¿›ï¼åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦å¤§å¹…ä¼˜åŒ–")

    print("\nğŸ’¡ å»ºè®®:")
    if overall_success_rate >= 0.8:
        print("   - å¯ä»¥å¼€å§‹ç”¨æˆ·æµ‹è¯•")
        print("   - ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ€§èƒ½")
        print("   - æ”¶é›†ç”¨æˆ·åé¦ˆ")
    else:
        print("   - ä¼˜å…ˆä¿®å¤å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹")
        print("   - æ£€æŸ¥APIè¿æ¥å’Œæƒé™")
        print("   - æ”¹è¿›é”™è¯¯å¤„ç†æœºåˆ¶")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹å®Œæ•´çš„æ–‡çŒ®åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("=" * 80)

    start_time = time.time()

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    test_results = []

    try:
        # æµ‹è¯•1: å•DOIæ–‡çŒ®åˆ†æ
        result = test_single_doi_analysis()
        test_results.append(result)

        # æµ‹è¯•2: æ ‡è¯†ç¬¦è½¬æ¢
        result = test_identifier_conversion()
        test_results.append(result)

        # æµ‹è¯•3: æ‰¹é‡æ–‡çŒ®åˆ†æ
        result = test_batch_analysis()
        test_results.append(result)

        # æµ‹è¯•4: é”™è¯¯å¤„ç†
        result = test_error_handling()
        test_results.append(result)

        # æµ‹è¯•5: æ•°æ®è´¨é‡
        result = test_data_quality()
        test_results.append(result)

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    generate_test_report(test_results)

    total_time = time.time() - start_time
    print(f"\nâ±ï¸  æ€»æµ‹è¯•æ—¶é—´: {total_time:.2f} ç§’")
    print("ğŸ æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
