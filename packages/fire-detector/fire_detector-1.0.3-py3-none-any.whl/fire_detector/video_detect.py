import os
import cv2
import torch
from torchvision import transforms
from PIL import Image
from .model_loader import load_model
from .path_utils import resolve_model_path


class VideoFireDetector:
    def __init__(self, model_path=None, threshold=0.5):
        resolved = resolve_model_path("fire_resnet18_fp16.pth", model_path)
        if not resolved:
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path or 'fire_resnet18_fp16.pth'}")
        self.model, self.device = load_model(resolved)
        self.threshold = threshold  # ç«ç„°åˆ¤å®šç½®ä¿¡åº¦é˜ˆå€¼

        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

    def predict_frame(self, frame):
        """å¯¹å•å¸§å›¾åƒè¿›è¡Œæ¨ç†"""
        image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        img = self.transform(image).unsqueeze(0).to(self.device)

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦ä¸ºåŠç²¾åº¦ï¼ˆFP16ï¼‰
        is_fp16 = next(self.model.parameters()).dtype == torch.float16
        if is_fp16:
            img = img.half()

        with torch.no_grad():
            outputs = self.model(img)
            probabilities = torch.softmax(outputs, dim=1)
            fire_prob = probabilities[0][1].item()

        return fire_prob

    def detect_video(self, video_path):
        """éå†è§†é¢‘æ‰€æœ‰å¸§æ¨ç†ç«ç„°æ¦‚ç‡"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise RuntimeError("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ï¼š" + video_path)

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fire_frames = 0

        print(f"â–¶ å¼€å§‹æ£€æµ‹ï¼š{video_path}")
        print(f"ğŸ“½ æ€»å¸§æ•°ï¼š{total_frames}")

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            fire_prob = self.predict_frame(frame)

            if fire_prob >= self.threshold:
                fire_frames += 1
                print(f"ğŸ”¥ æ£€æµ‹åˆ°ç«ç„° | ç½®ä¿¡åº¦ = {fire_prob:.4f}")
            else:
                print(f"âŒ æ— ç«ç„° | ç½®ä¿¡åº¦ = {fire_prob:.4f}")

        cap.release()

        fire_rate = fire_frames / total_frames * 100
        print(f"======== æ£€æµ‹ç»“æŸ ========")
        print(f"ğŸ”¥ ç«ç„°å¸§æ•°ï¼š{fire_frames} / {total_frames} ({fire_rate:.2f}%)")

        return {
            "total_frames": total_frames,
            "fire_frames": fire_frames,
            "fire_rate": fire_rate
        }


if __name__ == "__main__":
    # é»˜è®¤æ¨¡å‹è·¯å¾„æ— éœ€æ‰‹åŠ¨ä¼ å…¥
    detector = VideoFireDetector()
    video_path = "test_video.mp4"
    results = detector.detect_video(video_path)
    print(results)
