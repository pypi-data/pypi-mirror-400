{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from example_models import get_linear_chain_2v\n",
    "from mxlpy import Simulator, fit, make_protocol, plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting\n",
    "\n",
    "Almost every model at some point needs to be fitted to experimental data to be **validated**.  \n",
    "\n",
    "<img src=\"assets/fitting.png\" style=\"max-height: 175px;\" />\n",
    "\n",
    "*mxlpy* offers highly customisable local and global routines for fitting either **time series** or **steady-states**.  \n",
    "\n",
    "The entire set of currently supported routines is\n",
    "\n",
    "Single model, single data routines\n",
    "\n",
    "- `steady_state`\n",
    "- `time_course`\n",
    "- `protocol_time_course`\n",
    "\n",
    "Multiple model, single data routines\n",
    "\n",
    "- `ensemble_steady_state`\n",
    "- `ensemble_time_course`\n",
    "- `ensemble_protocol_time_course`\n",
    "\n",
    "A carousel is a special case of an ensemble, where the general\n",
    "structure (e.g. stoichiometries) is the same, while the reactions kinetics\n",
    "can vary\n",
    "- `carousel_steady_state`\n",
    "- `carousel_time_course`\n",
    "- `carousel_protocol_time_course`\n",
    "\n",
    "Multiple model, multiple data\n",
    "\n",
    "- `joint_steady_state`\n",
    "- `joint_time_course`\n",
    "- `joint_protocol_time_course`\n",
    "\n",
    "Multiple model, multiple data, multiple methods\n",
    "\n",
    "Here we also allow to run different methods (e.g. steady-state vs time courses)\n",
    "for each combination of model:data.\n",
    "\n",
    "- `joint_mixed`\n",
    "\n",
    "Minimizers\n",
    "----------\n",
    "- LocalScipyMinimizer, including common methods such as Nelder-Mead or L-BFGS-B\n",
    "- GlobalScipyMinimizer, including common methods such as basin hopping or dual annealing\n",
    "\n",
    "For this tutorial we are going to use the `fit` module to optimise our parameter values and the `plot` module to plot some results.  \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating synthetic data\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, for the sake of simplicity, we will generate some synthetic data.  \n",
    "\n",
    "Checkout the [basics tutorial](basics.ipynb) if you need a refresher on building and simulating models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a small trick, let's define a variable for the model function\n",
    "# That way, we can re-use it all over the file and easily replace\n",
    "# it with another model\n",
    "model_fn = get_linear_chain_2v\n",
    "\n",
    "res = (\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_time_course(np.linspace(0, 10, 101))\n",
    "    .get_result()\n",
    "    .unwrap_or_err()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steady-states\n",
    "\n",
    "For the steady-state fit we need two inputs:\n",
    "\n",
    "1. the steady state data, which we supply as a `pandas.Series`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will compare all data contained in that series to the model output.  \n",
    "\n",
    "> Note that the data both contains concentrations and fluxes!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.iloc[-1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = fit.steady_state(\n",
    "    model_fn(),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=res.iloc[-1],\n",
    "    minimizer=fit.LocalScipyMinimizer(),\n",
    ").unwrap_or_err()\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If only some of the data is required, you can use a subset of it.  \n",
    "The fitting routine will only try to fit concentrations and fluxes contained in that series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = fit.steady_state(\n",
    "    model_fn(),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=data.loc[[\"x\", \"y\"]],\n",
    "    minimizer=fit.LocalScipyMinimizer(),\n",
    ").unwrap_or_err()\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By default, mxlpy will apply standard scaling to all fitting functions.  \n",
    "\n",
    "Specifically, it will calculate `loss_fn(data - data.mean()) / data.std()`, `(pred - data.mean()) / data.std())`.\n",
    "\n",
    "To turn off this behaviour, set `standard_scale=False` in the fit functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = fit.steady_state(\n",
    "    model_fn(),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=data.loc[[\"x\", \"y\"]],\n",
    "    minimizer=fit.LocalScipyMinimizer(),\n",
    "    standard_scale=False,  # opt-out of standard scaling\n",
    ").unwrap_or_err()\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course\n",
    "\n",
    "For the time course fit we need again need two inputs\n",
    "\n",
    "1. the time course data, which we supply as a `pandas.DataFrame`\n",
    "2. an initial parameter guess\n",
    "\n",
    "The fitting routine will create data at every time points specified in the `DataFrame` and compare all of them.  \n",
    "\n",
    "Other than that, the same rules of the steady-state fitting apply.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = fit.time_course(\n",
    "    model_fn(),\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    data=res,\n",
    "    minimizer=fit.LocalScipyMinimizer(),\n",
    ").unwrap_or_err()\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protocol time courses\n",
    "\n",
    "\n",
    "Normally, you would fit your model to experimental data.  \n",
    "Here, again, for the sake of simplicity, we will generate some synthetic data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol = make_protocol(\n",
    "    [\n",
    "        (1, {\"k1\": 1.0}),\n",
    "        (1, {\"k1\": 2.0}),\n",
    "        (1, {\"k1\": 1.0}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "res_protocol = (\n",
    "    Simulator(model_fn())\n",
    "    .update_parameters({\"k1\": 1.0, \"k2\": 2.0, \"k3\": 1.0})\n",
    "    .simulate_protocol(\n",
    "        protocol,\n",
    "        time_points_per_step=10,\n",
    "    )\n",
    "    .get_result()\n",
    "    .unwrap_or_err()\n",
    ").get_combined()\n",
    "\n",
    "fig, ax = plot.lines(res_protocol)\n",
    "ax.set(xlabel=\"time / a.u.\", ylabel=\"Conc. & Flux / a.u.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the protocol time course fit we need three inputs\n",
    "\n",
    "1. an initial parameter guess\n",
    "2. the time course data, which we supply as a `pandas.DataFrame`\n",
    "3. the protocol, which we supply as a `pandas.DataFrame`\n",
    "\n",
    "> Note that the parameter given by the protocol cannot be fitted anymore  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = fit.protocol_time_course(\n",
    "    model_fn(),\n",
    "    p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol\n",
    "    data=res_protocol,\n",
    "    protocol=protocol,\n",
    "    minimizer=fit.LocalScipyMinimizer(),\n",
    ").unwrap_or_err()\n",
    "\n",
    "fit_result.best_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble fitting\n",
    "\n",
    "`mxlpy` supports ensebmle fitting, which is a **multi-model single data** approach, where shared parameters will be applied to all models at the same time.\n",
    "\n",
    "Here you supply an iterable of models instead of just one, otherwise the API stays the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_fit = fit.ensemble_steady_state(\n",
    "    [\n",
    "        model_fn(),\n",
    "        model_fn(),\n",
    "    ],\n",
    "    data=res.iloc[-1],\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the best fitting model, you can use `get_best_fit` on the ensemble fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result = ensemble_fit.get_best_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can of course also access all other fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.loss for i in ensemble_fit.fits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course\n",
    "\n",
    "Time course fits are adjusted just the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_fit = fit.ensemble_time_course(\n",
    "    [\n",
    "        model_fn(),\n",
    "        model_fn(),\n",
    "    ],\n",
    "    data=res,\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol time course\n",
    "\n",
    "As are protocol time courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_fit = fit.ensemble_protocol_time_course(\n",
    "    [\n",
    "        model_fn(),\n",
    "        model_fn(),\n",
    "    ],\n",
    "    data=res_protocol,\n",
    "    protocol=protocol,\n",
    "    p0={\"k2\": 1.87, \"k3\": 1.093},  # note that k1 is given by the protocol\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint fitting\n",
    "\n",
    "Next, we support joint fitting, which is a combined **multi-model multi-data** approach, where shared parameters will be applied to all models at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.joint_steady_state(\n",
    "    [\n",
    "        fit.FitSettings(model=model_fn(), data=res.iloc[-1]),\n",
    "        fit.FitSettings(model=model_fn(), data=res.iloc[-1]),\n",
    "    ],\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.joint_time_course(\n",
    "    [\n",
    "        fit.FitSettings(model=model_fn(), data=res),\n",
    "        fit.FitSettings(model=model_fn(), data=res),\n",
    "    ],\n",
    "    p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.joint_protocol_time_course(\n",
    "    [\n",
    "        fit.FitSettings(model=model_fn(), data=res_protocol, protocol=protocol),\n",
    "        fit.FitSettings(model=model_fn(), data=res_protocol, protocol=protocol),\n",
    "    ],\n",
    "    p0={\"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed joint fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we support mixed-joint fitting, where each analysis takes it's own residual function to allow fitting both time series and steady-state data for multiple models at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.joint_mixed(\n",
    "    [\n",
    "        fit.MixedSettings(\n",
    "            model=model_fn(),\n",
    "            data=res.iloc[-1],\n",
    "            residual_fn=fit.steady_state_residual,\n",
    "        ),\n",
    "        fit.MixedSettings(\n",
    "            model=model_fn(),\n",
    "            data=res,\n",
    "            residual_fn=fit.time_course_residual,\n",
    "        ),\n",
    "        fit.MixedSettings(\n",
    "            model=model_fn(),\n",
    "            data=res_protocol,\n",
    "            protocol=protocol,\n",
    "            residual_fn=fit.protocol_time_course_residual,\n",
    "        ),\n",
    "    ],\n",
    "    p0={\"k2\": 1.87, \"k3\": 1.093},\n",
    "    minimizer=fit.LocalScipyMinimizer(tol=1e-6),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #ffffff; background-color: #04AA6D; padding: 3rem 1rem 3rem 1rem; box-sizing: border-box\">\n",
    "    <h2>First finish line</h2>\n",
    "    With that you now know most of what you will need from a day-to-day basis about fitting in mxlpy.\n",
    "    <br />\n",
    "    <br />\n",
    "    Congratulations!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced topics / customisation\n",
    "\n",
    "\n",
    "All fitting routines internally are build in a way that they will call a tree of functions. \n",
    "\n",
    "- `minimizer`\n",
    "  - `residual_fn`\n",
    "    - `integrator`\n",
    "    - `loss_fn`\n",
    "  \n",
    "\n",
    "You can therefore use dependency injection to overwrite the minimisation function, the loss function, the residual function and the integrator if need be.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import TYPE_CHECKING, cast\n",
    "\n",
    "from mxlpy.integrators import Scipy\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterising scipy optimise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = fit.LocalScipyMinimizer(tol=1e-6, method=\"Nelder-Mead\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom loss function\n",
    "\n",
    "You can change the loss function that is being passed to the minimsation function using the `loss_fn` keyword.  \n",
    "Depending on the use case (time course vs steady state) this function will be passed two pandas `DataFrame`s or `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(\n",
    "    x: pd.DataFrame | pd.Series,\n",
    "    y: pd.DataFrame | pd.Series,\n",
    ") -> float:\n",
    "    \"\"\"Mean absolute error between two dataframes.\"\"\"\n",
    "    return cast(float, np.mean(np.abs(x - y)))\n",
    "\n",
    "\n",
    "(\n",
    "    fit.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        loss_fn=mean_absolute_error,\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    "    .unwrap_or_err()\n",
    "    .best_pars\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom integrator\n",
    "\n",
    "You can change the default integrator to an integrator of your choice by partially application of the class of any of the existing ones.  \n",
    "\n",
    "Here, for example, we choose the `Scipy` solver suite and set the default relative and absolute tolerances to `1e-6` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    fit.time_course(\n",
    "        model_fn(),\n",
    "        p0={\"k1\": 1.038, \"k2\": 1.87, \"k3\": 1.093},\n",
    "        data=res,\n",
    "        integrator=partial(Scipy, rtol=1e-6, atol=1e-6),\n",
    "        minimizer=fit.LocalScipyMinimizer(),\n",
    "    )\n",
    "    .unwrap_or_err()\n",
    "    .best_pars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxlpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
