# LlamaIndex ATI Example

This example demonstrates how to instrument LlamaIndex RAG pipelines with IOcane ATI.

## Prerequisites

- Python 3.10+
- An IOcane account (run `iocane connect` to setup your environment)

## Setup

1.  **Install Dependencies**
    ```bash
    pip install llama-index llama-index-core
    pip install opentelemetry-sdk opentelemetry-exporter-otlp
    # Install ATI SDK and Integration
    pip install ati-sdk ati-integrations-llamaindex
    ```

2.  **Configure Environment**
    Get your API Key and Environment ID from `.env.iocane` (generated by `iocane connect`) or the IOcane Dashboard.

    ```bash
    # Linux/Mac
    export OPENAI_API_KEY="sk-..." 
    export OTEL_SERVICE_NAME="llamaindex-example"
    export OTEL_EXPORTER_OTLP_ENDPOINT="https://api.iocane.ai/v1/traces"
    export OTEL_EXPORTER_OTLP_HEADERS="x-iocane-key=<YOUR_KEY>,x-ati-env=<YOUR_ENV_ID>"
    ```

## Running the Example

```bash
python query_engine.py
```

## Expected Output

You will see the output of the query.
In the IOcane Dashboard:
- **Query/Agent Spans**: High-level operation.
- **Retrieval Spans**: Embedding/retrieval steps (`ati.span.type=io`).
- **LLM Spans**: Synthesis steps.
