{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "-daj2vsU4r3T",
        "chatbot-definition",
        "RmSZEz9w5lU4",
        "od8TV8Yl5uyv",
        "nsM7Tvjc58iG"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ LevelApp Framework - Conversation Simulator Tutorial\n",
        "\n",
        "---\n",
        "\n",
        "Welcome to the **LevelApp Conversation Simulator** tutorial! This interactive notebook will guide you through evaluating conversational AI systems using the LevelApp framework.\n",
        "\n",
        "## üìö What is LevelApp?\n",
        "\n",
        "**LevelApp** is a powerful Python framework designed for **automated testing and evaluation of dialogue systems**. It helps you:\n",
        "- ü§ñ Simulate realistic conversations with your chatbot\n",
        "- üìä Evaluate response quality using AI judges\n",
        "- üîç Monitor performance metrics and identify issues\n",
        "- ‚úÖ Validate that your chatbot behaves as expected\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "1. ‚úÖ Install and configure the LevelApp framework\n",
        "2. ‚úÖ Set up a simple FastAPI chatbot application **OR** Test your own conversational AI system\n",
        "3. ‚úÖ Create conversation scripts for testing\n",
        "4. ‚úÖ Configure evaluation workflows with YAML\n",
        "5. ‚úÖ Run automated conversation simulations\n",
        "6. ‚úÖ Interpret evaluation results and metrics\n",
        "\n",
        "## üìã Prerequisites\n",
        "\n",
        "Before starting, make sure you have:\n",
        "- ‚úÖ A Google Colab account (you're already here!)\n",
        "- ‚úÖ An **OpenAI API key** ([Get one here](https://platform.openai.com/api-keys))\n",
        "- ‚úÖ An **Ngrok account** ([Sign up here](https://ngrok.com/))\n",
        "- ‚úÖ Basic Python knowledge\n",
        "- ‚è±Ô∏è **Estimated time**: 30-45 minutes\n",
        "\n",
        "## üèóÔ∏è What We'll Build\n",
        "\n",
        "In this tutorial, we'll create a **dental clinic appointment booking chatbot** and test it using LevelApp's Conversation Simulator. The chatbot will:\n",
        "- Answer questions about dental services\n",
        "- Book appointments with specific doctors\n",
        "- Return structured metadata (appointment type, date, doctor name)\n",
        "\n",
        "---\n",
        "\n",
        "Let's get started! üéâ"
      ],
      "metadata": {
        "id": "GfjBvWEF0-9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üì¶ Step 1: Installation\n",
        "\n",
        "First, we'll install LevelApp and all required dependencies."
      ],
      "metadata": {
        "id": "E3V2Z6Fr2baW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Install LevelApp Framework\n"
      ],
      "metadata": {
        "id": "install-levelapp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install levelapp -q"
      ],
      "metadata": {
        "id": "8RoS7gsEw1_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the installation by checking the version\n",
        "!uv pip list | grep levelapp"
      ],
      "metadata": {
        "id": "W-4NNLfKAri4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Install Additional Dependencies\n",
        "\n",
        "We need several packages to run our chatbot and expose it via a public URL:\n",
        "\n",
        "\n",
        "- **fastapi**: Web framework for building the chatbot API\n",
        "- **uvicorn**: ASGI server to run FastAPI\n",
        "- **pyngrok**: Create a public tunnel to our local server\n",
        "- **openai**: OpenAI API client for the chatbot's LLM\n",
        "- **pydantic**: Data validation for API requests/responses\n",
        "- **gdown**: Download configuration files from Google Drive [Optional]"
      ],
      "metadata": {
        "id": "GNIefPL-2rih"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d603da44"
      },
      "source": [
        "!uv pip install dotenv gdown fastapi uvicorn pyngrok openai pydantic -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üì• Step 2: Download Configuration Files\n",
        "\n",
        "We'll download pre-configured files from Google Drive that include:\n",
        "- **workflow_configuration.yaml**: LevelApp workflow settings\n",
        "- **conversation_script.json**: Test conversation scenarios\n",
        "- **example_chatbot.py**: Sample chatbot implementation"
      ],
      "metadata": {
        "id": "kMemL4te3l0X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52c021c0"
      },
      "source": [
        "import gdown\n",
        "\n",
        "# Google Drive folder containing example files\n",
        "folder_id = '1CylixxBt8gQZ3KyLeQPLOkxA_NnpoDli'\n",
        "output_dir = './levelapp-examples'\n",
        "\n",
        "# Download the folder\n",
        "gdown.download_folder(id=folder_id, output=output_dir, quiet=False, use_cookies=False)\n",
        "print(f\"‚úÖ Downloaded configuration files to '{output_dir}'\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÇ Verify Downloaded Files\n",
        "\n",
        "Mainly, you will find in the downloaded folder 3 files:\n",
        "- `workflow_configuration.yaml`: The YAML file containing the configuration for the evaluation process.\n",
        "- `conversation_script.json`: The reference data file that contains the simulation scripts.\n",
        "- `example_chatbot.py`: [Bonus] the chatbot app starter script."
      ],
      "metadata": {
        "id": "raBiJTrQBd7Z"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5de0535f"
      },
      "source": [
        "import os\n",
        "\n",
        "folder_path = './levelapp-examples'\n",
        "\n",
        "if os.path.exists(folder_path):\n",
        "    print(f\"üìÇ Contents of '{folder_path}':\")\n",
        "    for root, dirs, files in os.walk(folder_path):\n",
        "        level = root.replace(folder_path, '').count(os.sep)\n",
        "        indent = ' ' * 4 * (level)\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        subindent = ' ' * 4 * (level + 1)\n",
        "        for f in files:\n",
        "            print(f\"{subindent}üìÑ {f}\")\n",
        "else:\n",
        "    print(f\"‚ùå Folder '{folder_path}' not found.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ü§ñ Step 3: Create the Chatbot Application [Optional]\n",
        "\n",
        "In case you don't have a deployed conversation AI system to test, you can simply build a **dental clinic chatbot** using FastAPI and OpenAI, deploy is using Ngrok, and test it. This chatbot will:\n",
        "- Answer questions about dental services\n",
        "- Book appointments with the appropriate doctor\n",
        "- Return structured metadata for bookings"
      ],
      "metadata": {
        "id": "-daj2vsU4r3T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîê Configure API Keys\n",
        "\n",
        "‚ö†Ô∏è **IMPORTANT**: You need to add your OpenAI API key to Google Colab secrets:\n",
        "\n",
        "1. Click the **üîë key icon** in the left sidebar\n",
        "2. Click **\"Add new secret\"**\n",
        "3. Name: `OPENAI_API_KEY`\n",
        "4. Value: Your OpenAI API key\n",
        "5. Enable notebook access\n",
        "\n",
        "üö® **Never hardcode API keys in your code!**"
      ],
      "metadata": {
        "id": "29Et2T_E41LG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Define the Chatbot Application\n",
        "\n",
        "This FastAPI app creates a chatbot with two endpoints:\n",
        "- **POST /chat**: Main chatbot endpoint that processes messages\n",
        "- **GET /healthz**: Health check endpoint for connectivity testing\n",
        "\n",
        "### üè• Chatbot Behavior:\n",
        "- **Dr. Tony Tony Chopper** ‚Üí ROUTINE appointments\n",
        "- **Dr. Trafalgar D. Water Law** ‚Üí SURGICAL appointments\n",
        "- **Dr. Crocus** ‚Üí RESTORATIVE appointments"
      ],
      "metadata": {
        "id": "chatbot-definition"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from typing import Dict, Any\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from fastapi import FastAPI, HTTPException\n",
        "\n",
        "\n",
        "# Get API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI(title=\"Dental Clinic Chatbot\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# System prompt that defines chatbot behavior\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a medical assistant for a dental clinic,\n",
        "helping patients book appointments and answer inquiries about medical services.\n",
        "\n",
        "## Behavior:\n",
        "- Always reply in a convivial, professional tone.\n",
        "- Be concise and clear.\n",
        "\n",
        "## Instructions:\n",
        "1. Identify the type of appointment the user requires based on their request.\n",
        "2. If the user asks to book an appointment, return the booking information in a structured JSON format.\n",
        "   - The JSON must include:\n",
        "     - `reply_text`: A friendly confirmation message.\n",
        "     - `metadata`: A dict containing the following info:\n",
        "        1. `appointment_type`: One of \"ROUTINE\", \"SURGICAL\", or \"RESTORATIVE\".\n",
        "        2. `appointment_date`: The date of the appointment (format: YYYY-MM-DD).\n",
        "        3. `doctor_name`: One of \"Dr. Tony Tony Chopper\", \"Dr. Trafalgar D. Water Law\", or \"Dr. Crocus\".\n",
        "   - Example JSON output:\n",
        "     ```json\n",
        "     {\n",
        "       \"reply_text\": \"Your ROUTINE appointment with Dr. Tony Tony Chopper is booked for 2025-12-01.\",\n",
        "       \"appointment_type\": \"ROUTINE\",\n",
        "       \"appointment_date\": \"2025-12-01\",\n",
        "       \"doctor_name\": \"Dr. Tony Tony Chopper\"\n",
        "     }\n",
        "     ```\n",
        "3. If the user does not request a booking, return only the \"reply_text\".\n",
        "\n",
        "## Additional Information:\n",
        "- Dr. Tony Tony Chopper handles ROUTINE appointments.\n",
        "- Dr. Trafalgar D. Water Law handles SURGICAL appointments.\n",
        "- Dr. Crocus handles RESTORATIVE appointments.\n",
        "\"\"\"\n",
        "\n",
        "# Pydantic models for request/response validation\n",
        "class ChatRequest(BaseModel):\n",
        "  message: str\n",
        "\n",
        "class Metadata(BaseModel):\n",
        "  appointment_type: str = \"\"\n",
        "  appointment_date: str = \"\"\n",
        "  doctor_name: str = \"\"\n",
        "\n",
        "class ChatResponse(BaseModel):\n",
        "  reply_text: str\n",
        "  metadata: Metadata = {}\n",
        "\n",
        "def generate_reply(user_message: str) -> str:\n",
        "  \"\"\"Generate a reply using OpenAI's API with structured output.\"\"\"\n",
        "  try:\n",
        "      resp = client.chat.completions.parse(\n",
        "          model=\"gpt-4o-mini\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "              {\"role\": \"user\", \"content\": user_message},\n",
        "          ],\n",
        "          temperature=0.3,\n",
        "          response_format=ChatResponse\n",
        "      )\n",
        "      return resp.choices[0].message.parsed\n",
        "  except Exception as e:\n",
        "      raise RuntimeError(f\"LLM error: {e}\")\n",
        "\n",
        "# API Endpoints\n",
        "@app.post(\"/chat\", response_model=ChatResponse)\n",
        "def chat(req: ChatRequest):\n",
        "  \"\"\"Main chat endpoint that processes user messages.\"\"\"\n",
        "  if not req.message:\n",
        "      raise HTTPException(status_code=400, detail=\"`message` is required.\")\n",
        "  try:\n",
        "      reply = generate_reply(req.message)\n",
        "      return reply\n",
        "  except Exception as e:\n",
        "      raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.get(\"/healthz\")\n",
        "def health():\n",
        "  \"\"\"Health check endpoint.\"\"\"\n",
        "  return {\"status\": \"ok\"}\n",
        "\n",
        "print(\"‚úÖ Chatbot application defined successfully!\")"
      ],
      "metadata": {
        "id": "a4GzTKt1SLgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Start the FastAPI Server\n",
        "\n",
        "We'll run the FastAPI app in a background thread so it doesn't block the notebook."
      ],
      "metadata": {
        "id": "RmSZEz9w5lU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "def run_fastapi():\n",
        "  \"\"\"Run FastAPI server in background.\"\"\"\n",
        "  uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start server in a daemon thread\n",
        "thread = threading.Thread(target=run_fastapi, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Give the server a moment to start\n",
        "time.sleep(2)\n",
        "print(\"‚úÖ FastAPI server started on port 8000\")"
      ],
      "metadata": {
        "id": "2bKg5lCXStcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Expose the Server with Ngrok\n",
        "\n",
        "Since our server is running locally in Colab, we need **Ngrok** to create a public URL that LevelApp can access.\n",
        "\n",
        "### üîê Setup Ngrok:\n",
        "1. Sign up at [ngrok.com](https://ngrok.com/)\n",
        "2. Get your auth token from the dashboard\n",
        "3. Replace `YOUR_NGROK_TOKEN` below with your actual token\n",
        "\n",
        "‚ö†Ô∏è **Security Note**: For production use, store the Ngrok token in Colab secrets, not in the code!"
      ],
      "metadata": {
        "id": "od8TV8Yl5uyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "\n",
        "#  Kill any existing ngrok processes first!\n",
        "ngrok.kill()\n",
        "time.sleep(5) # Add a small delay to ensure resources are released\n",
        "\n",
        "# ‚îú‚î¨‚îÄ REPLACE THIS with your Ngrok auth token!\n",
        "# Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "NGROK_TOKEN = userdata.get('NGROK_TOKEN').strip()\n",
        "\n",
        "# Set auth token\n",
        "!ngrok authtoken {NGROK_TOKEN}\n",
        "\n",
        "# Create public tunnel\n",
        "public_url = ngrok.connect(addr=\"8000\", proto=\"http\")\n",
        "print(f\"\\n‚úÖ Public URL created: {public_url}\")\n",
        "print(f\"\\nüåê Your chatbot is now accessible at: {public_url.public_url}\")"
      ],
      "metadata": {
        "id": "s002dlsTTSjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Test the Chatbot\n",
        "\n",
        "Let's verify our chatbot is working correctly by testing both endpoints."
      ],
      "metadata": {
        "id": "nsM7Tvjc58iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "base_url = \"http://0.0.0.0:8000\" # public_url.public_url\n",
        "\n",
        "# Test 1: Health check\n",
        "print(\"üîç Testing health endpoint...\")\n",
        "healthcheck_url = base_url + \"/healthz\"\n",
        "response = requests.get(healthcheck_url)\n",
        "print(f\"‚úÖ Health check [status: {response.status_code}]: {response.json()}\\n\")\n",
        "\n",
        "# Test 2: Chat endpoint with appointment booking\n",
        "print(\"üîç Testing chat endpoint with appointment booking...\")\n",
        "chat_url = base_url + \"/chat\"\n",
        "data = {\"message\": \"I want to book an appointment next Monday to remove my wisdom tooth.\"}\n",
        "response = requests.post(chat_url, json=data)\n",
        "print(f\"‚úÖ Chatbot response [status: {response.status_code}]:\")\n",
        "print(f\"   Reply: {response.json()['reply_text']}\")\n",
        "print(f\"   Metadata: {response.json()['metadata']}\")"
      ],
      "metadata": {
        "id": "PyrT5g6hVkks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Update Configuration with Ngrok URL\n",
        "\n",
        "The workflow configuration file needs to know where our chatbot is hosted. We'll update it with the Ngrok URL."
      ],
      "metadata": {
        "id": "nR7wrRM-6cza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "workflow_config_path = '/content/levelapp-examples/conversation-simulator/workflow_configuration.yaml'\n",
        "\n",
        "# Load the YAML configuration\n",
        "with open(workflow_config_path, 'r') as file:\n",
        "    workflow_config = yaml.safe_load(file)\n",
        "\n",
        "# Update the base URL with our Ngrok URL\n",
        "if 'endpoint' in workflow_config and 'base_url' in workflow_config['endpoint']:\n",
        "    workflow_config['endpoint']['base_url'] = base_url\n",
        "    print(f\"‚úÖ Updated endpoint base_url to: {workflow_config['endpoint']['base_url']}\")\n",
        "else:\n",
        "    print(\"‚ùå Could not find 'endpoint.base_url' in the YAML file.\")\n",
        "\n",
        "# Save the updated configuration\n",
        "with open(workflow_config_path, 'w') as file:\n",
        "    yaml.dump(workflow_config, file, sort_keys=False)\n",
        "\n",
        "print(\"‚úÖ Configuration file updated successfully.\")"
      ],
      "metadata": {
        "id": "8KwX73piVzGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# ‚öôÔ∏è Step 4: Configure LevelApp Evaluation\n",
        "\n",
        "Otherwise, if you have a live conversation AI system, you can set up the configuration and load the reference data using the provided UI widgets."
      ],
      "metadata": {
        "id": "K-oeVj-g6OqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LevelApp Configuration UI\n",
        "\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import yaml\n",
        "import json\n",
        "\n",
        "class ConfigUIManager:\n",
        "    def __init__(self, initial_config=None):\n",
        "        if initial_config is None:\n",
        "            initial_config = {\n",
        "                'process': {\n",
        "                    'project_name': \"colab-evaluation\",\n",
        "                    'workflow_type': \"SIMULATOR\",\n",
        "                    'evaluation_params': {\n",
        "                        'attempts': 2,\n",
        "                    }\n",
        "                },\n",
        "                'evaluation': {\n",
        "                    'evaluators': [\"JUDGE\", \"REFERENCE\"],\n",
        "                    'providers': [\"openai\", \"ionos\"],\n",
        "                    'metrics_map': {\n",
        "                        'appointment_type': \"EXACT\",\n",
        "                        'appointment_date': \"TOKEN_BASED\",\n",
        "                        'doctor_name': \"TOKEN_BASED\"\n",
        "                    }\n",
        "                },\n",
        "                'reference_data': {\n",
        "                    'path': \"conversation_script.json\",\n",
        "                    'data': {}\n",
        "                },\n",
        "                'endpoint': {\n",
        "                    'name': \"example\",\n",
        "                    'base_url': \"http://127.0.0.1:8000\",\n",
        "                    'path': \"chat\",\n",
        "                    'method': \"POST\",\n",
        "                    'timeout': 60,\n",
        "                    'retry_count': 3,\n",
        "                    'retry_backoff': 0.5,\n",
        "                    'headers': [\n",
        "                        {\n",
        "                            'name': \"Content-type\",\n",
        "                            'value': \"application/json\",\n",
        "                            'secure': False\n",
        "                        }\n",
        "                    ],\n",
        "                    'request_schema': [\n",
        "                        {\n",
        "                            'field_path': \"message\",\n",
        "                            'value': \"user_message\",\n",
        "                            'value_type': \"dynamic\",\n",
        "                            'required': True\n",
        "                        }\n",
        "                    ],\n",
        "                    'response_mapping': [\n",
        "                        {\n",
        "                            'field_path': \"reply_text\",\n",
        "                            'extract_as': \"agent_reply\"\n",
        "                        },\n",
        "                        {\n",
        "                            'field_path': \"metadata\",\n",
        "                            'extract_as': \"metadata\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                'repository': {\n",
        "                    'type': \"FIRESTORE\",\n",
        "                    'project_id': \"\",\n",
        "                    'database_name': \"\",\n",
        "                    'source': \"LOCAL\"\n",
        "                }\n",
        "            }\n",
        "\n",
        "        self.widgets = {}\n",
        "        self.output_area = widgets.Output()\n",
        "\n",
        "        # --- Process Section ---\n",
        "        self.widgets['process_project_name'] = widgets.Text(\n",
        "            value=initial_config['process']['project_name'],\n",
        "            description='Project Name:',\n",
        "            placeholder='e.g., chatbot-evaluation',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['process_workflow_type'] = widgets.Dropdown(\n",
        "            options=['SIMULATOR'],\n",
        "            value=initial_config['process']['workflow_type'],\n",
        "            description='Workflow Type:',\n",
        "            disabled=True, # Fixed for this tutorial\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['process_attempts'] = widgets.IntSlider(\n",
        "            value=initial_config['process']['evaluation_params']['attempts'],\n",
        "            min=1, max=10, step=1,\n",
        "            description='Attempts:',\n",
        "            continuous_update=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        process_section_widgets = widgets.VBox([\n",
        "            self.widgets['process_project_name'],\n",
        "            self.widgets['process_workflow_type'],\n",
        "            widgets.Label(value=\"Evaluation Parameters:\", layout=widgets.Layout(margin='10px 0 0 0')),\n",
        "            self.widgets['process_attempts'],\n",
        "        ])\n",
        "\n",
        "        # --- Evaluation Section ---\n",
        "        self.widgets['eval_evaluators'] = widgets.SelectMultiple(\n",
        "            options=['JUDGE', 'REFERENCE'],\n",
        "            value=initial_config['evaluation']['evaluators'],\n",
        "            description='Evaluators:',\n",
        "            disabled=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['eval_providers'] = widgets.SelectMultiple(\n",
        "            options=['openai', 'ionos', 'mistral', 'anthropic', 'groq', 'gemini'],\n",
        "            value=initial_config['evaluation']['providers'],\n",
        "            description='Providers:',\n",
        "            disabled=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['eval_metrics_map_app_type'] = widgets.Dropdown(\n",
        "            options=['EXACT', 'TOKEN_BASED'],\n",
        "            value=initial_config['evaluation']['metrics_map'].get('appointment_type', 'EXACT'),\n",
        "            description='Appt. Type Metric:',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['eval_metrics_map_app_date'] = widgets.Dropdown(\n",
        "            options=['EXACT', 'TOKEN_BASED'],\n",
        "            value=initial_config['evaluation']['metrics_map'].get('appointment_date', 'TOKEN_BASED'),\n",
        "            description='Appt. Date Metric:',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['eval_metrics_map_doctor_name'] = widgets.Dropdown(\n",
        "            options=['EXACT', 'TOKEN_BASED'],\n",
        "            value=initial_config['evaluation']['metrics_map'].get('doctor_name', 'TOKEN_BASED'),\n",
        "            description='Doctor Name Metric:',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        eval_section_widgets = widgets.VBox([\n",
        "            self.widgets['eval_evaluators'],\n",
        "            self.widgets['eval_providers'],\n",
        "            widgets.Label(value=\"Metrics Map:\", layout=widgets.Layout(margin='10px 0 0 0')),\n",
        "            self.widgets['eval_metrics_map_app_type'],\n",
        "            self.widgets['eval_metrics_map_app_date'],\n",
        "            self.widgets['eval_metrics_map_doctor_name']\n",
        "        ])\n",
        "\n",
        "        # --- Reference Data Section ---\n",
        "        self.widgets['ref_data_path'] = widgets.Text(\n",
        "            value=initial_config['reference_data']['path'],\n",
        "            description='Path:',\n",
        "            placeholder='e.g., conversation_script.json',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['ref_data_data'] = widgets.Textarea(\n",
        "            value=json.dumps(initial_config['reference_data']['data'], indent=2),\n",
        "            description='Data (JSON):',\n",
        "            placeholder='Enter JSON object for reference data',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto', height='100px')\n",
        "        )\n",
        "        ref_data_section_widgets = widgets.VBox([\n",
        "            self.widgets['ref_data_path'],\n",
        "            self.widgets['ref_data_data']\n",
        "        ])\n",
        "\n",
        "        # --- Endpoint Section ---\n",
        "        self.widgets['endpoint_name'] = widgets.Text(\n",
        "            value=initial_config['endpoint']['name'],\n",
        "            description='Name:',\n",
        "            placeholder='e.g., example',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_base_url'] = widgets.Text(\n",
        "            value=initial_config['endpoint']['base_url'],\n",
        "            description='Base URL:',\n",
        "            placeholder='e.g., http://127.0.0.1:8000',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_path'] = widgets.Text(\n",
        "            value=initial_config['endpoint']['path'],\n",
        "            description='Path:',\n",
        "            placeholder='e.g., chat',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_method'] = widgets.Dropdown(\n",
        "            options=['POST', 'GET', 'PUT', 'DELETE'],\n",
        "            value=initial_config['endpoint']['method'],\n",
        "            description='Method:',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_timeout'] = widgets.IntSlider(\n",
        "            value=initial_config['endpoint']['timeout'],\n",
        "            min=10, max=300, step=10,\n",
        "            description='Timeout (s):',\n",
        "            continuous_update=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_retry_count'] = widgets.IntSlider(\n",
        "            value=initial_config['endpoint']['retry_count'],\n",
        "            min=0, max=10, step=1,\n",
        "            description='Retry Count:',\n",
        "            continuous_update=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['endpoint_retry_backoff'] = widgets.FloatSlider(\n",
        "            value=initial_config['endpoint']['retry_backoff'],\n",
        "            min=0.1, max=5.0, step=0.1,\n",
        "            description='Retry Backoff:',\n",
        "            continuous_update=False,\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "\n",
        "        # Complex inputs for headers, request_schema, response_mapping\n",
        "        self.widgets['endpoint_headers'] = widgets.Textarea(\n",
        "            value=json.dumps(initial_config['endpoint']['headers'], indent=2),\n",
        "            description='Headers (JSON):',\n",
        "            placeholder='Enter JSON array of header objects',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto', height='100px')\n",
        "        )\n",
        "        self.widgets['endpoint_request_schema'] = widgets.Textarea(\n",
        "            value=json.dumps(initial_config['endpoint']['request_schema'], indent=2),\n",
        "            description='Request Schema (JSON):',\n",
        "            placeholder='Enter JSON array of request schema objects',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto', height='100px')\n",
        "        )\n",
        "        self.widgets['endpoint_response_mapping'] = widgets.Textarea(\n",
        "            value=json.dumps(initial_config['endpoint']['response_mapping'], indent=2),\n",
        "            description='Response Mapping (JSON):',\n",
        "            placeholder='Enter JSON array of response mapping objects',\n",
        "            style={'description_width': 'initial', 'description_color': 'white', 'handle_color': 'blue'},\n",
        "            layout=widgets.Layout(width='auto', height='100px')\n",
        "        )\n",
        "\n",
        "        endpoint_section_widgets = widgets.VBox([\n",
        "            self.widgets['endpoint_name'],\n",
        "            self.widgets['endpoint_base_url'],\n",
        "            self.widgets['endpoint_path'],\n",
        "            self.widgets['endpoint_method'],\n",
        "            self.widgets['endpoint_timeout'],\n",
        "            self.widgets['endpoint_retry_count'],\n",
        "            self.widgets['endpoint_retry_backoff'],\n",
        "            self.widgets['endpoint_headers'],\n",
        "            self.widgets['endpoint_request_schema'],\n",
        "            self.widgets['endpoint_response_mapping']\n",
        "        ])\n",
        "\n",
        "        # --- Repository Section ---\n",
        "        self.widgets['repo_type'] = widgets.Dropdown(\n",
        "            options=['FIRESTORE'],\n",
        "            value=initial_config['repository']['type'],\n",
        "            description='Type:',\n",
        "            disabled=True, # Fixed for now\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['repo_project_id'] = widgets.Text(\n",
        "            value=initial_config['repository']['project_id'],\n",
        "            description='Project ID:',\n",
        "            placeholder='Your Google Cloud Project ID',\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['repo_database_name'] = widgets.Text(\n",
        "            value=initial_config['repository']['database_name'],\n",
        "            description='Database Name:',\n",
        "            placeholder='Your Firestore database name',\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        self.widgets['repo_source'] = widgets.Dropdown(\n",
        "            options=['LOCAL', 'GCS', 'S3'],\n",
        "            value=initial_config['repository']['source'],\n",
        "            description='Source:',\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        repo_section_widgets = widgets.VBox([\n",
        "            self.widgets['repo_type'],\n",
        "            self.widgets['repo_project_id'],\n",
        "            self.widgets['repo_database_name'],\n",
        "            self.widgets['repo_source']\n",
        "        ])\n",
        "\n",
        "        # --- Main Accordion for sections ---\n",
        "        self.accordion = widgets.Accordion(children=[\n",
        "            process_section_widgets,\n",
        "            eval_section_widgets,\n",
        "            ref_data_section_widgets,\n",
        "            endpoint_section_widgets,\n",
        "            repo_section_widgets\n",
        "        ])\n",
        "        self.accordion.set_title(0, '1. Process Configuration')\n",
        "        self.accordion.set_title(1, '2. Evaluation Configuration')\n",
        "        self.accordion.set_title(2, '3. Reference Data')\n",
        "        self.accordion.set_title(3, '4. Endpoint Configuration')\n",
        "        self.accordion.set_title(4, '5. Repository Configuration')\n",
        "\n",
        "        # --- Generate Button ---\n",
        "        self.generate_button = widgets.Button(description='Generate YAML', button_style='success')\n",
        "        self.generate_button.on_click(self._on_generate_button_clicked)\n",
        "\n",
        "    def _on_generate_button_clicked(self, b):\n",
        "        with self.output_area:\n",
        "            self.output_area.clear_output()\n",
        "            config = self.get_current_config()\n",
        "            if config:\n",
        "                generated_yaml = yaml.dump(config, sort_keys=False, indent=2)\n",
        "                print(generated_yaml)\n",
        "\n",
        "    def get_current_config(self):\n",
        "        config = {\n",
        "            'process': {\n",
        "                'project_name': self.widgets['process_project_name'].value,\n",
        "                'workflow_type': self.widgets['process_workflow_type'].value,\n",
        "                'evaluation_params': {\n",
        "                    'attempts': self.widgets['process_attempts'].value,\n",
        "                }\n",
        "            },\n",
        "            'evaluation': {\n",
        "                'evaluators': list(self.widgets['eval_evaluators'].value),\n",
        "                'providers': list(self.widgets['eval_providers'].value),\n",
        "                'metrics_map': {\n",
        "                    'appointment_type': self.widgets['eval_metrics_map_app_type'].value,\n",
        "                    'appointment_date': self.widgets['eval_metrics_map_app_date'].value,\n",
        "                    'doctor_name': self.widgets['eval_metrics_map_doctor_name'].value\n",
        "                }\n",
        "            },\n",
        "            'reference_data': {\n",
        "                'path': self.widgets['ref_data_path'].value,\n",
        "                'data': {}\n",
        "            },\n",
        "            'endpoint': {\n",
        "                'name': self.widgets['endpoint_name'].value,\n",
        "                'base_url': self.widgets['endpoint_base_url'].value,\n",
        "                'path': self.widgets['endpoint_path'].value,\n",
        "                'method': self.widgets['endpoint_method'].value,\n",
        "                'timeout': self.widgets['endpoint_timeout'].value,\n",
        "                'retry_count': self.widgets['endpoint_retry_count'].value,\n",
        "                'retry_backoff': self.widgets['endpoint_retry_backoff'].value,\n",
        "                'headers': [],\n",
        "                'request_schema': [],\n",
        "                'response_mapping': []\n",
        "            },\n",
        "            'repository': {\n",
        "                'type': self.widgets['repo_type'].value,\n",
        "                'project_id': self.widgets['repo_project_id'].value,\n",
        "                'database_name': self.widgets['repo_database_name'].value,\n",
        "                'source': self.widgets['repo_source'].value\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Handle JSON string inputs for complex fields\n",
        "        try:\n",
        "            if self.widgets['ref_data_data'].value:\n",
        "                config['reference_data']['data'] = json.loads(self.widgets['ref_data_data'].value)\n",
        "        except json.JSONDecodeError:\n",
        "            with self.output_area:\n",
        "                print(\"Error: Invalid JSON in Reference Data (Data) field.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if self.widgets['endpoint_headers'].value:\n",
        "                config['endpoint']['headers'] = json.loads(self.widgets['endpoint_headers'].value)\n",
        "        except json.JSONDecodeError:\n",
        "            with self.output_area:\n",
        "                print(\"Error: Invalid JSON in Endpoint Headers field.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if self.widgets['endpoint_request_schema'].value:\n",
        "                config['endpoint']['request_schema'] = json.loads(self.widgets['endpoint_request_schema'].value)\n",
        "        except json.JSONDecodeError:\n",
        "            with self.output_area:\n",
        "                print(\"Error: Invalid JSON in Request Schema field.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if self.widgets['endpoint_response_mapping'].value:\n",
        "                config['endpoint']['response_mapping'] = json.loads(self.widgets['endpoint_response_mapping'].value)\n",
        "        except json.JSONDecodeError:\n",
        "            with self.output_area:\n",
        "                print(\"Error: Invalid JSON in Response Mapping field.\")\n",
        "            return None\n",
        "\n",
        "        return config\n",
        "\n",
        "    def display_ui(self):\n",
        "        display(self.accordion, self.generate_button, self.output_area)\n",
        "\n",
        "# Create an instance of the UI manager and display the UI\n",
        "ui_manager = ConfigUIManager()\n",
        "ui_manager.display_ui()"
      ],
      "metadata": {
        "id": "zGROr5MRLPvr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dac3762"
      },
      "source": [
        "# You can generate the configuration as a dict and use it directly:\n",
        "current_config_dict = ui_manager.get_current_config()\n",
        "\n",
        "if current_config_dict:\n",
        "    print(\"‚úÖ Current UI configuration as a dictionary:\")\n",
        "    from IPython.display import display\n",
        "    display(current_config_dict)\n",
        "else:\n",
        "    print(\"‚ùå Failed to retrieve configuration dictionary. Please check for any errors reported in the UI.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LevelApp Reference Data UI\n",
        "\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "import json\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "class ConversationScriptUIManager:\n",
        "    def __init__(self, json_file_path):\n",
        "        self.json_file_path = json_file_path\n",
        "        self.data = self._load_json_data()\n",
        "        self.output_area = widgets.Output()\n",
        "\n",
        "        if not self.data:\n",
        "            self.data = [] # Initialize with empty list if file is empty or invalid\n",
        "\n",
        "        self.scenario_dropdown = self._create_scenario_dropdown()\n",
        "        self.add_scenario_button = widgets.Button(description=\"Add Scenario\", button_style='info')\n",
        "        self.delete_scenario_button = widgets.Button(description=\"Delete Selected Scenario\", button_style='danger')\n",
        "        self.save_button = widgets.Button(description=\"Save to JSON\", button_style='success')\n",
        "\n",
        "        self.scenario_name_input = widgets.Text(description=\"Scenario Name:\", layout=widgets.Layout(width='auto'))\n",
        "        self.interactions_container = widgets.VBox([]) # To hold interaction widgets\n",
        "\n",
        "        self._wire_events()\n",
        "        self._update_ui_for_scenario()\n",
        "\n",
        "    def _load_json_data(self):\n",
        "        if os.path.exists(self.json_file_path):\n",
        "            try:\n",
        "                with open(self.json_file_path, 'r') as f:\n",
        "                    file_content = f.read().strip()\n",
        "                    if not file_content: # Handle empty file explicitly\n",
        "                        return [] # Return empty list if file is empty\n",
        "\n",
        "                    raw_data = json.loads(file_content, object_pairs_hook=OrderedDict)\n",
        "\n",
        "                    # Ensure raw_data is a list of dictionaries\n",
        "                    if isinstance(raw_data, dict):\n",
        "                        # If the top-level is a dictionary, check if it contains a 'conversation_scripts' key\n",
        "                        # Otherwise, assume it's a single scenario and wrap it.\n",
        "                        if 'conversation_scripts' in raw_data and isinstance(raw_data['conversation_scripts'], list):\n",
        "                            scenarios = raw_data['conversation_scripts']\n",
        "                        else:\n",
        "                            scenarios = [raw_data]\n",
        "                    elif isinstance(raw_data, list):\n",
        "                        scenarios = raw_data\n",
        "                    else:\n",
        "                        # If it's neither a list nor a dictionary (e.g., a simple string, number, boolean)\n",
        "                        with self.output_area:\n",
        "                            print(f\"Error loading JSON file: Expected a list of scenarios or a single scenario object, but got a top-level {type(raw_data).__name__}.\")\n",
        "                        return []\n",
        "\n",
        "                    # Now, process each scenario to ensure it's a dictionary and has required fields\n",
        "                    processed_scenarios = []\n",
        "                    for i, scenario in enumerate(scenarios):\n",
        "                        if not isinstance(scenario, dict):\n",
        "                            with self.output_area:\n",
        "                                print(f\"Warning: Skipping malformed scenario at index {i} (expected dictionary, got {type(scenario).__name__}). Content: {scenario}\")\n",
        "                            continue # Skip this malformed entry\n",
        "\n",
        "                        # Create a mutable copy if necessary to add 'id'\n",
        "                        # Using OrderedDict(scenario) ensures it's a dict and maintains order\n",
        "                        current_scenario = OrderedDict(scenario)\n",
        "\n",
        "                        if 'id' not in current_scenario:\n",
        "                            current_scenario['id'] = self._generate_uuid()\n",
        "\n",
        "                        if 'scenario_name' not in current_scenario:\n",
        "                            current_scenario['scenario_name'] = f\"Scenario {i+1}\"\n",
        "\n",
        "                        if 'interactions' not in current_scenario or not isinstance(current_scenario['interactions'], list):\n",
        "                            current_scenario['interactions'] = []\n",
        "\n",
        "                        processed_interactions = []\n",
        "                        for j, interaction in enumerate(current_scenario['interactions']):\n",
        "                            if not isinstance(interaction, dict):\n",
        "                                with self.output_area:\n",
        "                                    print(f\"Warning: Skipping malformed interaction at scenario '{current_scenario.get('scenario_name', f'index {i}')}', interaction {j}. Content: {interaction}\")\n",
        "                                continue\n",
        "\n",
        "                            # Create a mutable copy for the interaction as well\n",
        "                            current_interaction = OrderedDict(interaction)\n",
        "\n",
        "                            if 'interaction_id' not in current_interaction:\n",
        "                                current_interaction['interaction_id'] = self._generate_uuid()\n",
        "                            if 'user_message' not in current_interaction:\n",
        "                                current_interaction['user_message'] = \"\"\n",
        "                            if 'agent_reply' not in current_interaction:\n",
        "                                current_interaction['agent_reply'] = \"\"\n",
        "                            if 'metadata' not in current_interaction:\n",
        "                                current_interaction['metadata'] = {}\n",
        "                            processed_interactions.append(current_interaction)\n",
        "                        current_scenario['interactions'] = processed_interactions\n",
        "                        processed_scenarios.append(current_scenario)\n",
        "\n",
        "                    return processed_scenarios\n",
        "\n",
        "            except json.JSONDecodeError as e:\n",
        "                with self.output_area:\n",
        "                    print(f\"Error loading JSON file: Invalid JSON format - {e}\")\n",
        "                return []\n",
        "            except Exception as e:\n",
        "                with self.output_area:\n",
        "                    print(f\"An unexpected error occurred while loading or processing JSON: {e}\")\n",
        "                return []\n",
        "        return []\n",
        "\n",
        "    def _generate_uuid(self):\n",
        "        import uuid\n",
        "        return str(uuid.uuid4())\n",
        "\n",
        "    def _create_scenario_dropdown(self):\n",
        "        options = [(s.get('scenario_name', f\"Unnamed Scenario {i}\"), s['id']) for i, s in enumerate(self.data)]\n",
        "        if options:\n",
        "            dropdown = widgets.Dropdown(\n",
        "                options=options,\n",
        "                value=options[0][1], # Select the first scenario by default\n",
        "                description='Select Scenario:',\n",
        "                disabled=False,\n",
        "                layout=widgets.Layout(width='auto')\n",
        "            )\n",
        "        else:\n",
        "            dropdown = widgets.Dropdown(\n",
        "                options=[],\n",
        "                description='Select Scenario:',\n",
        "                disabled=True,\n",
        "                layout=widgets.Layout(width='auto')\n",
        "            )\n",
        "        return dropdown\n",
        "\n",
        "    def _update_scenario_dropdown(self):\n",
        "        options = [(s.get('scenario_name', f\"Unnamed Scenario {i}\"), s['id']) for i, s in enumerate(self.data)]\n",
        "        if options:\n",
        "            self.scenario_dropdown.options = options\n",
        "            # Keep the currently selected scenario if it still exists\n",
        "            current_value = self.scenario_dropdown.value\n",
        "            if current_value not in [opt[1] for opt in options]:\n",
        "                self.scenario_dropdown.value = options[0][1]\n",
        "            self.scenario_dropdown.disabled = False\n",
        "        else:\n",
        "            self.scenario_dropdown.options = []\n",
        "            self.scenario_dropdown.value = None\n",
        "            self.scenario_dropdown.disabled = True\n",
        "        self._update_ui_for_scenario()\n",
        "\n",
        "    def _wire_events(self):\n",
        "        self.scenario_dropdown.observe(self._on_scenario_selected, names='value')\n",
        "        self.scenario_name_input.observe(self._on_scenario_name_change, names='value')\n",
        "        self.add_scenario_button.on_click(self._on_add_scenario_button_clicked)\n",
        "        self.delete_scenario_button.on_click(self._on_delete_scenario_button_clicked)\n",
        "        self.save_button.on_click(self._on_save_button_clicked)\n",
        "\n",
        "    def _get_current_scenario_index(self):\n",
        "        if not self.scenario_dropdown.value:\n",
        "            return -1\n",
        "        for i, scenario in enumerate(self.data):\n",
        "            if scenario['id'] == self.scenario_dropdown.value:\n",
        "                return i\n",
        "        return -1\n",
        "\n",
        "    def _update_ui_for_scenario(self):\n",
        "        with self.output_area:\n",
        "            self.output_area.clear_output()\n",
        "\n",
        "        scenario_idx = self._get_current_scenario_index()\n",
        "        if scenario_idx == -1 or not self.data:\n",
        "            self.scenario_name_input.value = \"\"\n",
        "            self.scenario_name_input.disabled = True\n",
        "            self.interactions_container.children = [widgets.HTML(\"<i>No scenario selected. Add a new scenario to begin.</i>\")]\n",
        "            return\n",
        "\n",
        "        scenario = self.data[scenario_idx]\n",
        "        self.scenario_name_input.value = scenario.get('scenario_name', '')\n",
        "        self.scenario_name_input.disabled = False\n",
        "\n",
        "        interaction_widgets = []\n",
        "        for i, interaction in enumerate(scenario.get('interactions', [])):\n",
        "            interaction_widgets.append(self._create_interaction_block(scenario_idx, i, interaction))\n",
        "\n",
        "        add_interaction_button = widgets.Button(description=\"Add Interaction\", button_style='primary', layout=widgets.Layout(width='auto'))\n",
        "        add_interaction_button.on_click(lambda b: self._on_add_interaction_button_clicked(scenario_idx))\n",
        "        interaction_widgets.append(add_interaction_button)\n",
        "\n",
        "        self.interactions_container.children = tuple(interaction_widgets)\n",
        "\n",
        "    def _create_interaction_block(self, scenario_idx, interaction_idx, interaction_data):\n",
        "        user_msg_input = widgets.Textarea(\n",
        "            value=interaction_data.get('user_message', ''),\n",
        "            description=f'User Message {interaction_idx + 1}:',\n",
        "            layout=widgets.Layout(width='auto', height='80px')\n",
        "        )\n",
        "        agent_reply_input = widgets.Textarea(\n",
        "            value=interaction_data.get('agent_reply', ''),\n",
        "            description=f'Agent Reply {interaction_idx + 1}:',\n",
        "            layout=widgets.Layout(width='auto', height='80px')\n",
        "        )\n",
        "        metadata_input = widgets.Textarea(\n",
        "            value=json.dumps(interaction_data.get('metadata', {}), indent=2),\n",
        "            description=f'Metadata {interaction_idx + 1} (JSON):',\n",
        "            layout=widgets.Layout(width='auto', height='120px')\n",
        "        )\n",
        "\n",
        "        user_msg_input.tag = ('user_message', scenario_idx, interaction_idx)\n",
        "        agent_reply_input.tag = ('agent_reply', scenario_idx, interaction_idx)\n",
        "        metadata_input.tag = ('metadata', scenario_idx, interaction_idx)\n",
        "\n",
        "        user_msg_input.observe(self._on_interaction_field_change, names='value')\n",
        "        agent_reply_input.observe(self._on_interaction_field_change, names='value')\n",
        "        metadata_input.observe(self._on_interaction_field_change, names='value')\n",
        "\n",
        "        delete_interaction_button = widgets.Button(\n",
        "            description=f\"Delete Interaction {interaction_idx + 1}\",\n",
        "            button_style='warning',\n",
        "            layout=widgets.Layout(width='auto')\n",
        "        )\n",
        "        delete_interaction_button.on_click(\n",
        "            lambda b, s_idx=scenario_idx, i_idx=interaction_idx: self._on_delete_interaction_button_clicked(s_idx, i_idx)\n",
        "        )\n",
        "\n",
        "        return widgets.VBox([\n",
        "            widgets.HTML(f\"<h4>Interaction {interaction_idx + 1}</h4>\"),\n",
        "            user_msg_input,\n",
        "            agent_reply_input,\n",
        "            metadata_input,\n",
        "            delete_interaction_button,\n",
        "            widgets.HTML(value='<hr>'), # A visual separator\n",
        "        ], layout=widgets.Layout(border='1px solid lightgray', padding='10px', margin='5px 0'))\n",
        "\n",
        "    def _on_scenario_selected(self, change):\n",
        "        if change['new'] is not None:\n",
        "            self._update_ui_for_scenario()\n",
        "\n",
        "    def _on_scenario_name_change(self, change):\n",
        "        scenario_idx = self._get_current_scenario_index()\n",
        "        if scenario_idx != -1:\n",
        "            self.data[scenario_idx]['scenario_name'] = change['new']\n",
        "            self._update_scenario_dropdown() # Update dropdown to reflect new name\n",
        "            # Preserve selection after update\n",
        "            self.scenario_dropdown.value = self.data[scenario_idx]['id']\n",
        "\n",
        "\n",
        "    def _on_interaction_field_change(self, change):\n",
        "        field_type, scenario_idx, interaction_idx = change.owner.tag\n",
        "        if scenario_idx != -1 and interaction_idx < len(self.data[scenario_idx]['interactions']):\n",
        "            if field_type == 'metadata':\n",
        "                try:\n",
        "                    self.data[scenario_idx]['interactions'][interaction_idx][field_type] = json.loads(change['new'])\n",
        "                except json.JSONDecodeError:\n",
        "                    with self.output_area:\n",
        "                        print(f\"Invalid JSON for metadata in Interaction {interaction_idx + 1}. Please correct it.\")\n",
        "            else:\n",
        "                self.data[scenario_idx]['interactions'][interaction_idx][field_type] = change['new']\n",
        "\n",
        "    def _on_add_scenario_button_clicked(self, b):\n",
        "        new_scenario_id = self._generate_uuid()\n",
        "        new_scenario_name = f\"New Scenario {len(self.data) + 1}\"\n",
        "        new_scenario = OrderedDict([\n",
        "            (\"id\", new_scenario_id),\n",
        "            (\"scenario_name\", new_scenario_name),\n",
        "            (\"interactions\", [])\n",
        "        ])\n",
        "        self.data.append(new_scenario)\n",
        "        self._update_scenario_dropdown()\n",
        "        self.scenario_dropdown.value = new_scenario_id # Select the newly added scenario\n",
        "\n",
        "    def _on_delete_scenario_button_clicked(self, b):\n",
        "        scenario_idx = self._get_current_scenario_index()\n",
        "        if scenario_idx != -1:\n",
        "            with self.output_area:\n",
        "                print(f\"Deleting scenario: {self.data[scenario_idx]['scenario_name']}\")\n",
        "            del self.data[scenario_idx]\n",
        "            self._update_scenario_dropdown()\n",
        "            if self.data:\n",
        "                self.scenario_dropdown.value = self.data[0]['id'] # Select first scenario if available\n",
        "            else:\n",
        "                self.scenario_dropdown.value = None # No scenarios left\n",
        "\n",
        "    def _on_add_interaction_button_clicked(self, scenario_idx):\n",
        "        if scenario_idx != -1:\n",
        "            new_interaction = OrderedDict([\n",
        "                (\"interaction_id\", self._generate_uuid()),\n",
        "                (\"user_message\", \"\"),\n",
        "                (\"agent_reply\", \"\"),\n",
        "                (\"metadata\", {})\n",
        "            ])\n",
        "            self.data[scenario_idx]['interactions'].append(new_interaction)\n",
        "            self._update_ui_for_scenario() # Re-render to show new interaction\n",
        "\n",
        "    def _on_delete_interaction_button_clicked(self, scenario_idx, interaction_idx):\n",
        "        if scenario_idx != -1 and interaction_idx < len(self.data[scenario_idx]['interactions']):\n",
        "            with self.output_area:\n",
        "                print(f\"Deleting interaction {interaction_idx + 1} from scenario: {self.data[scenario_idx]['scenario_name']}\")\n",
        "            del self.data[scenario_idx]['interactions'][interaction_idx]\n",
        "            self._update_ui_for_scenario() # Re-render to reflect deletion\n",
        "\n",
        "    def _on_save_button_clicked(self, b):\n",
        "        try:\n",
        "            cleaned_data = []\n",
        "            for scenario in self.data:\n",
        "                cleaned_scenario = OrderedDict()\n",
        "                cleaned_scenario[\"description\"] = scenario.get(\"scenario_name\", \"\")\n",
        "                cleaned_scenario[\"details\"] = {\"context\": \"Medical chatbot\"}  # Default or customizable\n",
        "                cleaned_interactions = []\n",
        "                for interaction in scenario.get(\"interactions\", []):\n",
        "                    cleaned_interaction = OrderedDict()\n",
        "                    cleaned_interaction[\"user_message_path\"] = \"\"  # Default or customizable\n",
        "                    cleaned_interaction[\"user_message\"] = interaction.get(\"user_message\", \"\")\n",
        "                    cleaned_interaction[\"reference_reply\"] = interaction.get(\"agent_reply\", \"\")\n",
        "                    cleaned_interaction[\"interaction_type\"] = \"initial\"  # Default or customizable\n",
        "                    cleaned_interaction[\"reference_metadata\"] = interaction.get(\"metadata\", {})\n",
        "                    cleaned_interaction[\"guardrail_flag\"] = False  # Default or customizable\n",
        "                    cleaned_interactions.append(cleaned_interaction)\n",
        "                cleaned_scenario[\"interactions\"] = cleaned_interactions\n",
        "                cleaned_data.append(cleaned_scenario)\n",
        "            final_output_data = {\"scripts\": cleaned_data}\n",
        "            with open(self.json_file_path, 'w') as f:\n",
        "                json.dump(final_output_data, f, indent=2)\n",
        "            with self.output_area:\n",
        "                print(f\"‚úÖ Conversation script saved to '{self.json_file_path}' successfully!\")\n",
        "        except Exception as e:\n",
        "            with self.output_area:\n",
        "                print(f\"‚ùå Error saving JSON file: {e}\")\n",
        "\n",
        "\n",
        "    def display_ui(self):\n",
        "        scenario_controls = widgets.HBox([\n",
        "            self.scenario_dropdown,\n",
        "            self.add_scenario_button,\n",
        "            self.delete_scenario_button\n",
        "        ])\n",
        "\n",
        "        top_level_ui = widgets.VBox([\n",
        "            widgets.HTML(\"<h2>Conversation Script Editor</h2>\"),\n",
        "            scenario_controls,\n",
        "            self.scenario_name_input,\n",
        "            widgets.HTML(\"<h3>Interactions:</h3>\"),\n",
        "            self.interactions_container,\n",
        "            self.save_button,\n",
        "            self.output_area\n",
        "        ])\n",
        "        display(top_level_ui)\n",
        "\n",
        "# Instantiate and display the UI manager\n",
        "json_file_to_edit = '/content/levelapp-examples/conversation-simulator/conversation_script.json'\n",
        "ui_manager = ConversationScriptUIManager(json_file_to_edit)\n",
        "ui_manager.display_ui()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0V_dciB5gYMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0072160d"
      },
      "source": [
        "import json\n",
        "\n",
        "json_file_path = '/content/levelapp-examples/conversation-simulator/conversation_script.json'\n",
        "\n",
        "try:\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        loaded_data = json.load(f)\n",
        "    print(f\"‚úÖ Successfully loaded data from '{json_file_path}':\")\n",
        "    from IPython.display import display\n",
        "    display(loaded_data)\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: The file '{json_file_path}' was not found. Please ensure you have saved the conversation script using the UI.\")\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"‚ùå Error decoding JSON from '{json_file_path}': {e}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå An unexpected error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fcc74af"
      },
      "source": [
        "import json\n",
        "from levelapp.workflow import WorkflowConfig\n",
        "from levelapp.core.session import EvaluationSession\n",
        "\n",
        "# Load workflow configuration from YAML\n",
        "# config = WorkflowConfig.load(path=workflow_config_path)\n",
        "\n",
        "# Load workflow configuration from UI generated dict\n",
        "config = WorkflowConfig.from_dict(content=current_config_dict)\n",
        "\n",
        "# Load reference conversation data from JSON\n",
        "json_file_path = '/content/levelapp-examples/conversation-simulator/conversation_script.json'\n",
        "with open(json_file_path, 'r') as f:\n",
        "    reference_data = json.load(f)\n",
        "\n",
        "# Set the reference data loaded from the JSON file\n",
        "# config.set_reference_data(content=reference_data)\n",
        "\n",
        "# Set the reference data generated by the UI\n",
        "config.set_reference_data(content=loaded_data)\n",
        "\n",
        "print(\"‚úÖ LevelApp configuration loaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Configure API Keys for Evaluators\n",
        "\n",
        "LevelApp uses AI \"judges\" to evaluate chatbot responses. We need to provide API keys for these evaluators.\n",
        "\n",
        "### Required:\n",
        "- **OpenAI API Key**: Already configured in Colab secrets\n",
        "\n",
        "### Optional:\n",
        "- **IONOS API Key**: For additional evaluation (can be skipped)\n",
        "\n",
        "If you have IONOS credentials, add them to Colab secrets:\n",
        "- `IONOS_API_KEY`\n",
        "- `IONOS_BASE_URL`\n",
        "- `IONOS_MODEL_ID`"
      ],
      "metadata": {
        "id": "1m-RB4vQ7VRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from levelapp.core.session import EvaluationSession\n",
        "\n",
        "# Set API keys for the LLM providers\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['MISTRAL_API_KEY'] = userdata.get('MISTRAL_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# Set the models used for each provider\n",
        "os.environ['OPENAI_MODEL'] = \"gpt-4o-mini\"\n",
        "os.environ['GROK_MODEL'] = \"llama-3.3-70b-versatile\"\n",
        "os.environ['GEMINI_MODEL'] = \"gemini-2.5-flash\"\n",
        "\n",
        "\n",
        "# Set IONOS credentials if available (optional)\n",
        "try:\n",
        "  if userdata.get('IONOS_API_KEY') is not None:\n",
        "    os.environ['IONOS_API_KEY'] = userdata.get('IONOS_API_KEY')\n",
        "    os.environ['IONOS_BASE_URL'] = userdata.get('IONOS_BASE_URL')\n",
        "    os.environ['IONOS_MODEL_ID'] = userdata.get('IONOS_MODEL_ID')\n",
        "    print(\"‚úÖ IONOS credentials configured\")\n",
        "except Exception as e:\n",
        "  print(\"‚ÑπÔ∏è  IONOS credentials not available (optional)\")\n",
        "\n",
        "# Create an evaluation session\n",
        "evaluation_session = EvaluationSession(\n",
        "    session_name=\"dental-chatbot-evaluation\",\n",
        "    workflow_config=config,\n",
        "    enable_monitoring=True  # Enable performance monitoring\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Evaluation session created successfully!\")"
      ],
      "metadata": {
        "id": "QvvkI53nbJGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üß™ Step 5: Run the Evaluation\n",
        "\n",
        "Time to test our chatbot! LevelApp will:\n",
        "1. Send test messages to the chatbot\n",
        "2. Compare responses against expected outputs\n",
        "3. Evaluate quality using AI judges\n",
        "4. Generate detailed metrics and reports"
      ],
      "metadata": {
        "id": "JUL45Zs59RAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Run Connectivity Test\n",
        "\n",
        "First, let's verify LevelApp can communicate with our chatbot."
      ],
      "metadata": {
        "id": "connectivity-test"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()  # Required for async operations in Jupyter\n",
        "\n",
        "with evaluation_session as session:\n",
        "  # Test connectivity with a simple message\n",
        "  connectivity_test = session.run_connectivity_test(\n",
        "      context={\"user_message\": \"Hello, how can I help you?\"}\n",
        "  )\n",
        "\n",
        "  if connectivity_test['success']:\n",
        "    print(\"‚úÖ Connectivity test PASSED\")\n",
        "    print(f\"   Status code: {connectivity_test['status_code']}\")\n",
        "    print(f\"   Agent reply: {connectivity_test['extracted_data']['agent_reply']}\")\n",
        "  else:\n",
        "    print(\"‚ùå Connectivity test FAILED\")\n",
        "    print(f\"   Error: {connectivity_test}\")"
      ],
      "metadata": {
        "id": "connectivity-test-cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Run Full Evaluation\n",
        "\n",
        "Now let's run the complete evaluation with our test conversation scripts.\n",
        "\n",
        "**What happens during evaluation:**\n",
        "1. üì§ LevelApp sends each message from the conversation script\n",
        "2. ü§ñ Your chatbot generates a response\n",
        "3. üîç AI judges compare the response to the expected output\n",
        "4. üìä Scores are calculated (0-3 scale: Poor, Fair, Good, Excellent)\n",
        "5. üìà Metrics are aggregated across all interactions"
      ],
      "metadata": {
        "id": "BA00G5rN9W_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with evaluation_session as session:\n",
        "  print(\"üöÄ Starting evaluation...\\n\")\n",
        "\n",
        "  # Run the evaluation\n",
        "  session.run()\n",
        "\n",
        "  # Collect results\n",
        "  results = session.workflow.collect_results()"
      ],
      "metadata": {
        "id": "KSIJH0vsbWqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)"
      ],
      "metadata": {
        "id": "MP0Foa2vyUHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "results = json.loads(results)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä EVALUATION RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Display average scores\n",
        "avg_scores = results['average_scores']\n",
        "print(\"\\nüìà Average Scores:\")\n",
        "for metric, score in avg_scores.items():\n",
        "  if metric != 'processing_time':\n",
        "    print(f\"   {metric.capitalize()}: {score:.2f}\")\n",
        "  else:\n",
        "    print(f\"   Processing Time: {score:.2f}s\")\n",
        "\n",
        "# Display evaluation summary\n",
        "print(\"\\nüìù Evaluation Summary:\")\n",
        "for judge, feedback in results['evaluation_summary'].items():\n",
        "  print(f\"\\n   {judge.upper()} Judge:\")\n",
        "  for comment in feedback:\n",
        "    print(f\"   ‚Ä¢ {comment}\")\n",
        "\n",
        "# Get detailed statistics\n",
        "stats = session.get_stats()\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä SESSION STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nSession: {stats['session']['name']}\")\n",
        "print(f\"Duration: {stats['session']['duration']}\")\n",
        "print(f\"Total Steps: {stats['session']['steps']}\")\n",
        "print(f\"Errors: {stats['session']['errors']}\")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation completed successfully!\")"
      ],
      "metadata": {
        "id": "V1d20Wtyx8N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# üìä Understanding the Results\n",
        "\n",
        "## Scoring System\n",
        "\n",
        "LevelApp uses a **0-3 scale** for evaluation:\n",
        "- **3 (Excellent)**: Response matches expected output perfectly or semantically equivalent\n",
        "- **2 (Good)**: Minor differences but covers all key points\n",
        "- **1 (Fair)**: Missing some information or has inaccuracies\n",
        "- **0 (Poor)**: Significant errors or completely wrong\n",
        "\n",
        "## Key Metrics\n",
        "\n",
        "- **Judge Scores**: Evaluation from different AI judges (OpenAI, IONOS)\n",
        "- **Guardrail Flag**: Binary check if response is safe/appropriate (1=pass, 0=fail)\n",
        "- **Metadata Score**: Accuracy of structured data (appointment type, date, doctor)\n",
        "- **Processing Time**: How long the chatbot took to respond\n",
        "\n",
        "## What to Look For\n",
        "\n",
        "‚úÖ **Good signs:**\n",
        "- Average scores ‚â• 2.5\n",
        "- Guardrail flag = 1.0\n",
        "- Metadata scores = 1.0 for booking interactions\n",
        "- Consistent scores across different judges\n",
        "\n",
        "‚ö†Ô∏è **Warning signs:**\n",
        "- Scores < 2.0\n",
        "- Guardrail failures\n",
        "- Metadata mismatches\n",
        "- High variance between judges"
      ],
      "metadata": {
        "id": "understanding-results"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Any\n",
        "\n",
        "class InteractionResult(BaseModel):\n",
        "  conversation_id: str\n",
        "  user_message: str\n",
        "  generated_reply: str\n",
        "  reference_reply: str\n",
        "  generated_metadata: Dict[str, Any]\n",
        "  reference_metadata: Dict[str, Any]\n",
        "  guardrail_detail: bool = False\n",
        "  evaluation_results: Dict[str, Any]\n",
        "\n",
        "class AttemptResults(BaseModel):\n",
        "  attempt: int\n",
        "  attempt_id: str\n",
        "  script_id: str\n",
        "  total_duration: float\n",
        "  interaction_results: List[InteractionResult]\n",
        "  evaluation_verdicts: Dict[str, Any]\n",
        "  average_scores: Dict[str, Any]\n",
        "\n",
        "class InteractionResult(BaseModel):\n",
        "  script_id: str\n",
        "  attempts: List[AttemptResults]\n",
        "  average_scores: Dict[str, Any]\n",
        "\n",
        "class SimulationResults(BaseModel):\n",
        "  started_at: str\n",
        "  finished_at: str\n",
        "  evaluation_summary: Dict[str, Any]\n",
        "  average_scores: Dict[str, Any]\n",
        "  interaction_results: List[InteractionResult]\n",
        "  batch_id: str\n",
        "  elapsed_time: float\n",
        "\n",
        "sim_results = SimulationResults.model_validate(results)"
      ],
      "metadata": {
        "id": "9mD1E-kQzjVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of scripts: {len(sim_results.interaction_results)}\")\n",
        "print(f\"Number of attempts: {len(sim_results.interaction_results[0].attempts)}\")"
      ],
      "metadata": {
        "id": "1bhX5eZl8lsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8dc938d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Prepare a list to hold all the extracted average scores\n",
        "all_attempt_scores = []\n",
        "\n",
        "# Iterate through each interaction result in the simulation results\n",
        "for interaction_result in sim_results.interaction_results:\n",
        "    script_id = interaction_result.script_id\n",
        "\n",
        "    # Iterate through each attempt within the current interaction result\n",
        "    for attempt in interaction_result.attempts:\n",
        "        attempt_id = attempt.attempt_id\n",
        "        average_scores = attempt.average_scores\n",
        "\n",
        "        # Create a dictionary for the current attempt's scores\n",
        "        attempt_data = {\n",
        "            'script_id': script_id,\n",
        "            'attempt_id': attempt_id\n",
        "        }\n",
        "        attempt_data.update(average_scores) # Add all average scores\n",
        "\n",
        "        # Append the dictionary to our list\n",
        "        all_attempt_scores.append(attempt_data)\n",
        "\n",
        "# Create a pandas DataFrame from the collected data\n",
        "scores_df = pd.DataFrame(all_attempt_scores)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(scores_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1726176f"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Identify actual judge columns present in the scores_df\n",
        "# Exclude 'script_id', 'attempt_id', 'guardrail', 'metadata', and 'processing_time'\n",
        "available_judges = [col for col in scores_df.columns if col not in ['script_id', 'attempt_id', 'guardrail', 'metadata', 'processing_time']]\n",
        "\n",
        "# Melt the scores_df to have 'provider' and 'score' columns\n",
        "scores_melted = scores_df.melt(id_vars=['script_id', 'attempt_id'],\n",
        "                               value_vars=available_judges,\n",
        "                               var_name='provider',\n",
        "                               value_name='score')\n",
        "\n",
        "# Visualize the scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=scores_melted, x='script_id', y='score', hue='provider', palette='viridis')\n",
        "\n",
        "plt.title('Average Judge Scores per Script and Attempt')\n",
        "plt.xlabel('Script ID')\n",
        "plt.ylabel('Average Score')\n",
        "plt.ylim(0, 3.5) # Scores are on a 0-3 scale\n",
        "plt.xticks(rotation=0, ha='right')\n",
        "plt.legend(title='Evaluator')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "display(scores_melted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ensure sim_results is a dictionary (from previous steps if not yet validated into Pydantic model)\n",
        "if isinstance(sim_results, SimulationResults):\n",
        "    sim_results_dict = sim_results.model_dump()\n",
        "else:\n",
        "    sim_results_dict = sim_results\n",
        "\n",
        "all_interaction_scores = []\n",
        "\n",
        "# Loop through each script's results\n",
        "for script_data in sim_results_dict['interaction_results']:\n",
        "    script_id = script_data['script_id']\n",
        "\n",
        "    # Loop through each attempt within the script\n",
        "    for attempt_data in script_data['attempts']:\n",
        "        attempt_id = attempt_data['attempt_id']\n",
        "\n",
        "        # Loop through each individual interaction within the attempt\n",
        "        for i, interaction in enumerate(attempt_data['interaction_results']):\n",
        "            conversation_id = interaction['conversation_id']\n",
        "            user_message = interaction['user_message']\n",
        "\n",
        "            eval_results = interaction['evaluation_results']\n",
        "\n",
        "            # Extract judge evaluations (e.g., openai, ionos)\n",
        "            for judge, details in eval_results['judge_evaluations'].items():\n",
        "                score = details['score']\n",
        "                # Normalize judge scores from 0-3 to percentage\n",
        "                percentage_score = (score / 3.0) * 100\n",
        "                all_interaction_scores.append({\n",
        "                    'script_id': script_id,\n",
        "                    'attempt_id': attempt_id,\n",
        "                    'conversation_id': conversation_id,\n",
        "                    'interaction_index': i,\n",
        "                    'user_message': user_message,\n",
        "                    'evaluator': judge,\n",
        "                    'score': score,\n",
        "                    'percentage_score': percentage_score\n",
        "                })\n",
        "\n",
        "            # Extract metadata evaluation\n",
        "            metadata_scores = eval_results['metadata_evaluation']\n",
        "            if metadata_scores: # Only add if metadata evaluation was performed and has scores\n",
        "                # Calculate the average metadata score for this interaction\n",
        "                avg_metadata_score = sum(metadata_scores.values()) / len(metadata_scores)\n",
        "                # Normalize metadata scores from 0-1 to percentage\n",
        "                percentage_score = avg_metadata_score * 100\n",
        "                all_interaction_scores.append({\n",
        "                    'script_id': script_id,\n",
        "                    'attempt_id': attempt_id,\n",
        "                    'conversation_id': conversation_id,\n",
        "                    'interaction_index': i,\n",
        "                    'user_message': user_message,\n",
        "                    'evaluator': 'metadata',\n",
        "                    'score': avg_metadata_score,\n",
        "                    'percentage_score': percentage_score\n",
        "                })\n",
        "\n",
        "            # Extract guardrail flag\n",
        "            # Guardrail flag is typically 1 (pass) or 0 (fail)\n",
        "            guardrail_score = eval_results['guardrail_flag']\n",
        "            # Normalize guardrail scores from 0-1 to percentage\n",
        "            percentage_score = guardrail_score * 100\n",
        "            all_interaction_scores.append({\n",
        "                'script_id': script_id,\n",
        "                'attempt_id': attempt_id,\n",
        "                'conversation_id': conversation_id,\n",
        "                'interaction_index': i,\n",
        "                'user_message': user_message,\n",
        "                'evaluator': 'guardrail',\n",
        "                'score': guardrail_score,\n",
        "                'percentage_score': percentage_score\n",
        "            })\n",
        "\n",
        "# Create DataFrame from the collected scores\n",
        "scores_df_detailed = pd.DataFrame(all_interaction_scores)\n",
        "\n",
        "# Visualize the scores as percentages\n",
        "plt.figure(figsize=(14, 7))\n",
        "sns.barplot(data=scores_df_detailed, x='interaction_index', y='percentage_score', hue='evaluator', palette='viridis')\n",
        "\n",
        "plt.title(f'Evaluation Scores per Interaction (Script: {script_id}, Attempt: {attempt_id[:8]}...)')\n",
        "plt.xlabel('Interaction Index (0-based)')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylim(0, 105) # Set y-axis limit to 105% for better visualization\n",
        "plt.legend(title='Evaluator')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "display(scores_df_detailed)"
      ],
      "metadata": {
        "id": "W6-6cA__y9NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3fbd4d0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Prepare a list to hold all the extracted token data\n",
        "all_token_data = []\n",
        "\n",
        "# Iterate through each interaction result in the simulation results\n",
        "for interaction_result in sim_results.interaction_results:\n",
        "    script_id = interaction_result.script_id\n",
        "\n",
        "    # Iterate through each attempt within the current interaction result\n",
        "    for attempt in interaction_result.attempts:\n",
        "        attempt_id = attempt.attempt_id\n",
        "\n",
        "        # Iterate through each interaction within the attempt\n",
        "        for interaction in attempt.interaction_results:\n",
        "            # Check for judge evaluations and extract token data\n",
        "            if 'judge_evaluations' in interaction.evaluation_results:\n",
        "                for provider, eval_data in interaction.evaluation_results['judge_evaluations'].items():\n",
        "                    if 'metadata' in eval_data:\n",
        "                        metadata = eval_data['metadata']\n",
        "                        token_data = {\n",
        "                            'script_id': script_id,\n",
        "                            'attempt_id': attempt_id,\n",
        "                            'provider': provider,\n",
        "                            'input_tokens': metadata.get('input_tokens'),\n",
        "                            'output_tokens': metadata.get('output_tokens')\n",
        "                        }\n",
        "                        all_token_data.append(token_data)\n",
        "\n",
        "# Create a pandas DataFrame from the collected data\n",
        "token_df = pd.DataFrame(all_token_data)\n",
        "\n",
        "# Display the DataFrame\n",
        "display(token_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate total tokens\n",
        "token_df['total_tokens'] = token_df['input_tokens'] + token_df['output_tokens']\n",
        "\n",
        "# Group by script_id, attempt_id, and provider to sum tokens\n",
        "grouped_tokens = token_df.groupby(['script_id', 'attempt_id', 'provider'])['total_tokens'].sum().reset_index()\n",
        "\n",
        "# Set up the plot\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(data=grouped_tokens, x='script_id', y='total_tokens', hue='provider', palette='viridis')\n",
        "\n",
        "plt.title('Total Tokens per Provider by Script and Attempt')\n",
        "plt.xlabel('Script ID (and Attempt ID implicit)')\n",
        "plt.ylabel('Total Tokens')\n",
        "plt.xticks(rotation=0, ha='right')\n",
        "plt.legend(title='Provider')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7xjpUuARBX5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}