#!/usr/bin/env python3
"""
æ•°æ®é¢„å¤„ç†è„šæœ¬
å°†ä¸‹è½½çš„æ•°æ®é›†è½¬æ¢ä¸ºè®­ç»ƒ/æµ‹è¯•é›†ï¼Œå¹¶ç”Ÿæˆæ¨¡æ‹Ÿçš„è¯Šæ–­æŠ¥å‘Š
"""

import json
import random
import sys
from pathlib import Path

from datasets import load_from_disk
from PIL import Image
from sklearn.model_selection import train_test_split

# Note: This script assumes sage-apps package is installed
# Install with: cd sage-apps && pip install -e .


# ç–¾ç—…ç±»åˆ«æ˜ å°„ (æ¨¡æ‹Ÿ)
DISEASE_MAPPING = {
    0: {"name": "æ­£å¸¸", "severity": "æ— ", "description": "æœªè§æ˜æ˜¾å¼‚å¸¸"},
    1: {
        "name": "è½»åº¦é€€è¡Œæ€§å˜",
        "severity": "è½»åº¦",
        "description": "L4/L5æ¤é—´ç›˜è½»åº¦é€€è¡Œæ€§å˜",
    },
    2: {
        "name": "æ¤é—´ç›˜çªå‡º",
        "severity": "ä¸­åº¦",
        "description": "L4/L5æ¤é—´ç›˜å‘åçªå‡º,å‹è¿«ç¡¬è†œå›Š",
    },
    3: {
        "name": "å¤šèŠ‚æ®µé€€è¡Œæ€§å˜",
        "severity": "ä¸­åº¦",
        "description": "L3/L4, L4/L5, L5/S1å¤šèŠ‚æ®µé€€è¡Œæ€§å˜",
    },
    4: {
        "name": "æ¤ç®¡ç‹­çª„",
        "severity": "é‡åº¦",
        "description": "L4/L5æ¤ç®¡ç‹­çª„,ç¡¬è†œå›Šå—å‹",
    },
    5: {
        "name": "æ¤é—´ç›˜è„±å‡º",
        "severity": "é‡åº¦",
        "description": "L5/S1æ¤é—´ç›˜è„±å‡º,æ¸¸ç¦»åˆ°æ¤ç®¡å†…",
    },
    6: {"name": "éª¨è´¨å¢ç”Ÿ", "severity": "è½»åº¦", "description": "L3-L5æ¤ä½“ç¼˜éª¨è´¨å¢ç”Ÿ"},
    7: {"name": "æ¤ä½“æ»‘è„±", "severity": "ä¸­åº¦", "description": "L4æ¤ä½“å‰ç§»,Iåº¦æ»‘è„±"},
    8: {"name": "éŸ§å¸¦é’™åŒ–", "severity": "è½»åº¦", "description": "åçºµéŸ§å¸¦é’™åŒ–"},
}


def generate_mock_report(label: int, patient_info: dict) -> str:
    """ç”Ÿæˆæ¨¡æ‹Ÿè¯Šæ–­æŠ¥å‘Š"""

    disease_info = DISEASE_MAPPING.get(label, DISEASE_MAPPING[0])

    age = patient_info.get("age", 45)
    gender = patient_info.get("gender", "ç”·")

    # æ ¹æ®ç–¾ç—…ç”Ÿæˆç—‡çŠ¶
    if label == 0:
        symptoms = "æ— æ˜æ˜¾ä¸é€‚"
        findings = "è…°æ¤MRI T2åŠ æƒçŸ¢çŠ¶ä½: æœªè§æ˜æ˜¾å¼‚å¸¸ã€‚å„æ¤é—´ç›˜ä¿¡å·æ­£å¸¸ï¼Œæ¤ä½“æ’åˆ—æ•´é½ï¼Œæ¤ç®¡é€šç•…ã€‚"
        conclusion = "å½±åƒå­¦æœªè§æ˜æ˜¾å¼‚å¸¸ã€‚"
        recommendations = "å®šæœŸä½“æ£€ï¼Œä¿æŒè‰¯å¥½çš„ç”Ÿæ´»ä¹ æƒ¯ã€‚"
    elif label in [1, 6, 8]:
        symptoms = "å¶å°”è…°éƒ¨é…¸ç—›"
        findings = (
            f"è…°æ¤MRI T2åŠ æƒçŸ¢çŠ¶ä½: {disease_info['description']}ã€‚æ¤ç®¡å°šé€šç•…ï¼Œæœªè§æ˜æ˜¾ç¥ç»æ ¹å—å‹ã€‚"
        )
        conclusion = f"{disease_info['name']}ï¼Œç¨‹åº¦{disease_info['severity']}ã€‚"
        recommendations = (
            "é€‚å½“ä¼‘æ¯ï¼Œé¿å…ä¹…åä¹…ç«™ã€‚å¯è¿›è¡Œè…°èƒŒè‚Œé”»ç‚¼ï¼Œå¦‚æ¸¸æ³³ã€æ™®æ‹‰æç­‰ã€‚å¿…è¦æ—¶ç‰©ç†æ²»ç–—ã€‚"
        )
    elif label in [2, 3]:
        symptoms = "è…°ç—›ä¼´å³ä¸‹è‚¢æ”¾å°„ç—›3å‘¨"
        findings = f"è…°æ¤MRI T2åŠ æƒçŸ¢çŠ¶ä½: {disease_info['description']}ã€‚ç›¸åº”èŠ‚æ®µæ¤ç®¡å˜çª„ï¼Œç¥ç»æ ¹å¯èƒ½å—å‹ã€‚"
        conclusion = f"{disease_info['name']}ï¼Œç¨‹åº¦{disease_info['severity']}ã€‚"
        recommendations = "å»ºè®®å§åºŠä¼‘æ¯2-3å‘¨ï¼Œç‰µå¼•æ²»ç–—ã€‚å£æœéç”¾ä½“æŠ—ç‚è¯åŠç¥ç»è¥å…»è¯ç‰©ã€‚ä¿å®ˆæ²»ç–—æ— æ•ˆæ—¶è€ƒè™‘æ‰‹æœ¯æ²»ç–—ã€‚"
    elif label == 7:
        symptoms = "è…°éƒ¨ç–¼ç—›ï¼Œæ´»åŠ¨å—é™"
        findings = f"è…°æ¤MRI T2åŠ æƒçŸ¢çŠ¶ä½: {disease_info['description']}ã€‚ç›¸åº”èŠ‚æ®µä¸ç¨³å®šã€‚"
        conclusion = f"{disease_info['name']}ï¼Œç¨‹åº¦{disease_info['severity']}ã€‚"
        recommendations = "é¿å…é‡ä½“åŠ›åŠ³åŠ¨ï¼Œä½©æˆ´è…°å›´ä¿æŠ¤ã€‚æ ¸å¿ƒè‚Œç¾¤è®­ç»ƒã€‚ç—‡çŠ¶æ˜æ˜¾æ—¶è€ƒè™‘æ‰‹æœ¯å›ºå®šã€‚"
    else:  # é‡åº¦ (4, 5)
        symptoms = "è…°ç—›ä¼´åŒä¸‹è‚¢éº»æœ¨ã€æ— åŠ›2æœˆ"
        findings = f"è…°æ¤MRI T2åŠ æƒçŸ¢çŠ¶ä½: {disease_info['description']}ã€‚é©¬å°¾ç¥ç»å—å‹ã€‚"
        conclusion = f"{disease_info['name']}ï¼Œç¨‹åº¦{disease_info['severity']}ã€‚"
        recommendations = (
            "å»ºè®®å°½æ—©æ‰‹æœ¯æ²»ç–—(æ¤é—´ç›˜æ‘˜é™¤æœ¯æˆ–æ¤ç®¡å‡å‹æœ¯)ï¼Œä»¥è§£é™¤ç¥ç»å‹è¿«ã€‚æœ¯ååº·å¤è®­ç»ƒã€‚"
        )

    report = f"""æ‚£è€…ä¿¡æ¯:
  å¹´é¾„: {age}å²
  æ€§åˆ«: {gender}
  ä¸»è¯‰: {symptoms}

å½±åƒæè¿°:
  {findings}

ä¸»è¦å‘ç°:
  - ç—…å˜èŠ‚æ®µ: {"å¤šèŠ‚æ®µ" if label == 3 else "L4/L5æˆ–L5/S1"}
  - ç—…å˜ç±»å‹: {disease_info["name"]}
  - ä¸¥é‡ç¨‹åº¦: {disease_info["severity"]}

è¯Šæ–­ç»“è®º:
  {conclusion}

æ²»ç–—å»ºè®®:
  {recommendations}

æ³¨: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œè¯·ç»“åˆä¸´åºŠç—‡çŠ¶å’Œå…¶ä»–æ£€æŸ¥ç»“æœç»¼åˆåˆ¤æ–­ã€‚
"""

    return report


def prepare_dataset():
    """å‡†å¤‡æ•°æ®é›†"""

    dataset_path = project_root / "data" / "medical" / "lumbar-spine-mri" / "cache"
    output_dir = project_root / "examples" / "medical_diagnosis" / "data" / "processed"
    output_dir.mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("ğŸ“Š æ•°æ®é¢„å¤„ç†")
    print("=" * 80)

    # åŠ è½½æ•°æ®é›†
    print("\nğŸ“‚ åŠ è½½æ•°æ®é›†...")
    dataset = load_from_disk(str(dataset_path))
    print(f"   âœ“ å·²åŠ è½½ {len(dataset)} ä¸ªæ ·æœ¬")

    # å‡†å¤‡æ•°æ®
    print("\nğŸ”„ å‡†å¤‡æ•°æ®...")

    samples = []
    for i, sample in enumerate(dataset):  # type: ignore[arg-type]
        if not isinstance(sample, dict):
            continue
        label = sample["label"]
        image = sample["image"]

        # ç”Ÿæˆæ‚£è€…ä¿¡æ¯
        age = random.randint(25, 75)
        gender = random.choice(["ç”·", "å¥³"])

        patient_info = {
            "age": age,
            "gender": gender,
            "patient_id": f"P{i + 1:04d}",
        }

        # ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š
        report = generate_mock_report(label, patient_info)

        # ä¿å­˜å›¾åƒ
        image_filename = f"case_{i + 1:04d}_label{label}.jpg"
        image_path = output_dir / "images" / image_filename
        image_path.parent.mkdir(exist_ok=True)

        if isinstance(image, Image.Image):
            # ç»Ÿä¸€resizeåˆ°512x512
            image_resized = image.resize((512, 512), Image.Resampling.LANCZOS)
            image_resized.save(image_path, quality=95)

        # ä¿å­˜æŠ¥å‘Š
        report_filename = f"case_{i + 1:04d}_report.txt"
        report_path = output_dir / "reports" / report_filename
        report_path.parent.mkdir(exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)

        # è®°å½•æ ·æœ¬ä¿¡æ¯
        disease_info = DISEASE_MAPPING.get(label, DISEASE_MAPPING[0])
        samples.append(
            {
                "case_id": f"case_{i + 1:04d}",
                "patient_id": patient_info["patient_id"],
                "age": age,
                "gender": gender,
                "label": label,
                "disease": disease_info["name"],
                "severity": disease_info["severity"],
                "image_path": str(image_path.relative_to(output_dir)),
                "report_path": str(report_path.relative_to(output_dir)),
            }
        )

        if (i + 1) % 20 == 0:
            print(f"   å¤„ç†è¿›åº¦: {i + 1}/{len(dataset)}")

    print(f"   âœ“ å·²å¤„ç† {len(samples)} ä¸ªç—…ä¾‹")

    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† (80/20)
    print("\nâœ‚ï¸  åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†...")

    train_samples, test_samples = train_test_split(
        samples, test_size=0.2, random_state=42, stratify=[s["label"] for s in samples]
    )

    print(f"   âœ“ è®­ç»ƒé›†: {len(train_samples)} æ ·æœ¬")
    print(f"   âœ“ æµ‹è¯•é›†: {len(test_samples)} æ ·æœ¬")

    # ä¿å­˜ç´¢å¼•æ–‡ä»¶
    print("\nğŸ’¾ ä¿å­˜ç´¢å¼•æ–‡ä»¶...")

    # ä¿å­˜JSONæ ¼å¼
    with open(output_dir / "train_index.json", "w", encoding="utf-8") as f:
        json.dump(train_samples, f, ensure_ascii=False, indent=2)

    with open(output_dir / "test_index.json", "w", encoding="utf-8") as f:
        json.dump(test_samples, f, ensure_ascii=False, indent=2)

    with open(output_dir / "all_cases.json", "w", encoding="utf-8") as f:
        json.dump(samples, f, ensure_ascii=False, indent=2)

    print("   âœ“ train_index.json")
    print("   âœ“ test_index.json")
    print("   âœ“ all_cases.json")

    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š...")

    stats = {
        "total_samples": len(samples),
        "train_samples": len(train_samples),
        "test_samples": len(test_samples),
        "label_distribution": {},
        "disease_distribution": {},
        "severity_distribution": {},
        "age_range": [min(s["age"] for s in samples), max(s["age"] for s in samples)],
        "gender_distribution": {
            "ç”·": sum(1 for s in samples if s["gender"] == "ç”·"),
            "å¥³": sum(1 for s in samples if s["gender"] == "å¥³"),
        },
    }

    for sample in samples:
        label = sample["label"]
        disease = sample["disease"]
        severity = sample["severity"]

        stats["label_distribution"][label] = stats["label_distribution"].get(label, 0) + 1
        stats["disease_distribution"][disease] = stats["disease_distribution"].get(disease, 0) + 1
        stats["severity_distribution"][severity] = (
            stats["severity_distribution"].get(severity, 0) + 1
        )

    with open(output_dir / "stats.json", "w", encoding="utf-8") as f:
        json.dump(stats, f, ensure_ascii=False, indent=2)

    # ç”Ÿæˆå¯è¯»çš„ç»Ÿè®¡æŠ¥å‘Š
    with open(output_dir / "README.txt", "w", encoding="utf-8") as f:
        f.write("è…°æ¤MRIæ•°æ®é›† - å¤„ç†å\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"æ€»æ ·æœ¬æ•°: {stats['total_samples']}\n")
        f.write(f"è®­ç»ƒé›†: {stats['train_samples']}\n")
        f.write(f"æµ‹è¯•é›†: {stats['test_samples']}\n\n")

        f.write("ç–¾ç—…åˆ†å¸ƒ:\n")
        for disease, count in sorted(stats["disease_distribution"].items(), key=lambda x: -x[1]):
            percentage = count / stats["total_samples"] * 100
            f.write(f"  - {disease}: {count} ({percentage:.1f}%)\n")

        f.write("\nä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ:\n")
        for severity, count in stats["severity_distribution"].items():
            percentage = count / stats["total_samples"] * 100
            f.write(f"  - {severity}: {count} ({percentage:.1f}%)\n")

        f.write(f"\nå¹´é¾„èŒƒå›´: {stats['age_range'][0]} - {stats['age_range'][1]} å²\n")
        f.write("\næ€§åˆ«åˆ†å¸ƒ:\n")
        for gender, count in stats["gender_distribution"].items():
            percentage = count / stats["total_samples"] * 100
            f.write(f"  - {gender}: {count} ({percentage:.1f}%)\n")

        f.write("\nç›®å½•ç»“æ„:\n")
        f.write("  - images/: MRIå½±åƒæ–‡ä»¶ (512x512 JPG)\n")
        f.write("  - reports/: è¯Šæ–­æŠ¥å‘Šæ–‡ä»¶ (TXT)\n")
        f.write("  - train_index.json: è®­ç»ƒé›†ç´¢å¼•\n")
        f.write("  - test_index.json: æµ‹è¯•é›†ç´¢å¼•\n")
        f.write("  - all_cases.json: æ‰€æœ‰ç—…ä¾‹ç´¢å¼•\n")
        f.write("  - stats.json: ç»Ÿè®¡ä¿¡æ¯ (JSON)\n")
        f.write("  - README.txt: æœ¬æ–‡ä»¶\n")

    print("   âœ“ stats.json")
    print("   âœ“ README.txt")

    print("\n" + "=" * 80)
    print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆ!")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("=" * 80)

    # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
    print(f"   - æ€»æ ·æœ¬: {stats['total_samples']}")
    print(f"   - è®­ç»ƒé›†: {stats['train_samples']}")
    print(f"   - æµ‹è¯•é›†: {stats['test_samples']}")
    print(f"\nğŸ¥ ç–¾ç—…ç±»å‹: {len(stats['disease_distribution'])} ç§")
    for disease, count in sorted(stats["disease_distribution"].items(), key=lambda x: -x[1])[:5]:
        print(f"   - {disease}: {count}")


if __name__ == "__main__":
    prepare_dataset()
