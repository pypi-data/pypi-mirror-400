llama-stack==0.2.22
llama-stack-client==0.2.22
httpx
pydantic>=2.10.6
litellm>=1.75.5.post1
sqlalchemy>=2.0.0
mcp

[dev]
black>=25.1.0
ruff>=0.8.0

[test]
behave>=1.2.6
requests>=2.31.0
parse>=1.19.0
parse-type>=0.6.0
pytest>=8.3.2
pytest-cov>=5.0.0
pytest-mock>=3.14.0
pytest-asyncio>=1.0.0
