from __future__ import annotations
import httpx
from pentestai.ai.providers.base import AIProvider

class GeminiProvider(AIProvider):
    def __init__(self, api_key: str, base_url: str, model: str):
        self.name = "gemini"
        self.model = model
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")

    async def chat(self, system: str, user: str, temperature: float = 0.2, max_tokens: int = 1400) -> str:
        url = f"{self.base_url}/v1beta/models/{self.model}:generateContent"
        params = {"key": self.api_key}
        payload = {
            "systemInstruction": {"parts": [{"text": system}]},
            "contents": [{"role": "user", "parts": [{"text": user}]}],
            "generationConfig": {"temperature": temperature, "maxOutputTokens": max_tokens},
        }
        async with httpx.AsyncClient(timeout=60) as client:
            r = await client.post(url, params=params, json=payload)
            r.raise_for_status()
            data = r.json()

        parts = []
        for cand in data.get("candidates", []):
            content = cand.get("content", {})
            for p in content.get("parts", []):
                t = p.get("text")
                if t:
                    parts.append(t)
        return "\n".join(parts).strip()
