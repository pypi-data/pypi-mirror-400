{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive SFT Training Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to Supervised Fine-Tuning (SFT) using the training_hub library. We'll cover:\n",
    "\n",
    "- **All available parameters** and their detailed explanations\n",
    "- **Single-node and multi-node training** configurations\n",
    "- **Popular model examples** (Qwen 2.5 7B Instruct, Llama 3.1 8B Instruct, Phi 4 Mini, etc.)\n",
    "- **Best practices and troubleshooting**\n",
    "\n",
    "This tutorial serves as both a learning resource and a template you can adapt for your specific fine-tuning needs.\n",
    "\n",
    "**Note:** For production workflows, we also provide focused example scripts for popular models: `scripts/sft_qwen_example.py`, `scripts/sft_llama_example.py`, and `scripts/sft_phi_example.py` with better logging consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training_hub for SFT training\n",
    "from training_hub import sft\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Data Format Requirements\n\nBefore configuring your training, ensure your data is in the correct format. Training Hub uses the instructlab-training backend, which expects data in a specific **messages format**.\n\n### Required Format: JSONL with Messages\n\nYour training data must be a **JSON Lines (.jsonl)** file where each line contains a conversation sample:\n\n```json\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Hello, how are you?\"}, {\"role\": \"assistant\", \"content\": \"I'm doing well, thank you! How can I help you today?\"}]}\n{\"messages\": [{\"role\": \"user\", \"content\": \"What is machine learning?\"}, {\"role\": \"assistant\", \"content\": \"Machine learning is a subset of artificial intelligence...\"}]}\n```\n\n### Message Structure\n\nEach conversation contains a `messages` array with message objects having:\n- **`role`**: One of `\"system\"`, `\"user\"`, `\"assistant\"`, or `\"pretraining\"`\n- **`content`**: The text content of the message\n- **`reasoning_content`** (optional): Additional reasoning traces\n\n### Masking Behavior with `unmask` Field\n\nYou can control which parts of the conversation are used for training loss by adding an `unmask` metadata field:\n\n#### Standard Instruction Tuning (default)\n```json\n{\"messages\": [...]}\n```\nor\n```json\n{\"messages\": [...], \"unmask\": false}\n```\n- **Trains only on assistant responses** (standard instruction-following)\n- System messages are always masked (ignored for loss)\n- User messages are masked\n- Assistant messages are unmasked (used for loss calculation)\n\n#### Pretraining Mode\n```json\n{\"messages\": [...], \"unmask\": true}\n```\n- **Trains on all content except system messages**\n- System messages are always masked\n- User and assistant messages are both unmasked\n- Useful for pretraining-style data where the model should learn from all text\n\n### Example Data Formats\n\n**Standard SFT (instruction-following):**\n```json\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are a coding assistant.\"}, {\"role\": \"user\", \"content\": \"Write a Python function to calculate factorial\"}, {\"role\": \"assistant\", \"content\": \"Here's a Python function to calculate factorial:\\n\\n```python\\ndef factorial(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    return n * factorial(n - 1)\\n```\"}]}\n```\n\n**Pretraining-style (learn from all content):**\n```json\n{\"messages\": [{\"role\": \"user\", \"content\": \"The capital of France is\"}, {\"role\": \"assistant\", \"content\": \"Paris.\"}], \"unmask\": true}\n```\n\n### Data Path Configuration\n\nWhen configuring your training, point to your JSONL file:\n\n```python\ndata_path = \"/path/to/your/training_data.jsonl\"  # Your messages-format JSONL file\n```\n\nThe training pipeline will automatically:\n1. Load and validate your JSONL data\n2. Apply chat templates based on your model\n3. Handle masking according to the `unmask` setting\n4. Process the data for efficient training",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration Examples\n",
    "\n",
    "Here are configuration examples for popular models. These serve as starting points - adjust based on your specific hardware and requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL CONFIGURATION EXAMPLES\n",
    "# These are example configurations - adjust based on your hardware and requirements\n",
    "# =============================================================================\n",
    "\n",
    "# Example 1: Qwen 2.5 7B Instruct\n",
    "qwen_example = {\n",
    "    \"model_name\": \"Qwen 2.5 7B Instruct\",\n",
    "    \"model_path\": \"Qwen/Qwen2.5-7B-Instruct\",  # HuggingFace model name or local path\n",
    "    \"example_max_tokens_per_gpu\": 20000,\n",
    "    \"example_max_seq_len\": 16384,\n",
    "    \"example_batch_size\": 128,\n",
    "    \"example_learning_rate\": 1e-5,\n",
    "}\n",
    "\n",
    "# Example 2: Llama 3.1 8B Instruct\n",
    "llama_example = {\n",
    "    \"model_name\": \"Llama 3.1 8B Instruct\",\n",
    "    \"model_path\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",  # HuggingFace model name or local path\n",
    "    \"example_max_tokens_per_gpu\": 18000,\n",
    "    \"example_max_seq_len\": 16384,\n",
    "    \"example_batch_size\": 128,\n",
    "    \"example_learning_rate\": 1e-5,\n",
    "}\n",
    "\n",
    "# Example 3: Phi 4 Mini\n",
    "phi_example = {\n",
    "    \"model_name\": \"Phi 4 Mini\",\n",
    "    \"model_path\": \"microsoft/Phi-4-mini-instruct\",  # HuggingFace model name or local path\n",
    "    \"example_max_tokens_per_gpu\": 25000,\n",
    "    \"example_max_seq_len\": 8192,\n",
    "    \"example_batch_size\": 64,\n",
    "    \"example_learning_rate\": 5e-6,\n",
    "}\n",
    "\n",
    "# Example 4: Generic 7B Base Model\n",
    "generic_7b_example = {\n",
    "    \"model_name\": \"Generic 7B Base\",\n",
    "    \"model_path\": \"/path/to/your-7b-model\",  # Local path to model directory\n",
    "    \"example_max_tokens_per_gpu\": 25000,\n",
    "    \"example_max_seq_len\": 20000,\n",
    "    \"example_batch_size\": 256,\n",
    "    \"example_learning_rate\": 2e-5,\n",
    "}\n",
    "\n",
    "# Example 5: Smaller Model (1B-3B)\n",
    "small_model_example = {\n",
    "    \"model_name\": \"Small Model (1B-3B)\",\n",
    "    \"model_path\": \"/path/to/small-model\",  # Local path or HuggingFace name\n",
    "    \"example_max_tokens_per_gpu\": 40000,\n",
    "    \"example_max_seq_len\": 32768,\n",
    "    \"example_batch_size\": 512,\n",
    "    \"example_learning_rate\": 3e-5,\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# SELECT YOUR CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Choose one of the examples above as a starting point\n",
    "selected_example = qwen_example  # Change this to your preferred example\n",
    "\n",
    "print(f\"Selected Example: {selected_example['model_name']}\")\n",
    "print(f\"Model Path: {selected_example['model_path']}\")\n",
    "print(f\"Example Max Tokens per GPU: {selected_example['example_max_tokens_per_gpu']:,}\")\n",
    "print(f\"Example Max Sequence Length: {selected_example['example_max_seq_len']:,}\")\n",
    "print(f\"Example Batch Size: {selected_example['example_batch_size']:,}\")\n",
    "print(f\"Example Learning Rate: {selected_example['example_learning_rate']}\")\n",
    "print(f\"Notes: {selected_example['notes']}\")\n",
    "print(\"\\nüí° Remember: These are example configurations. Adjust based on your hardware and requirements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Parameter Reference\n",
    "\n",
    "Let's configure all available SFT parameters with detailed explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPLETE SFT PARAMETER CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Experiment identification\n",
    "experiment_name = \"sft_comprehensive_example\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "full_experiment_name = f\"{experiment_name}_{timestamp}\"\n",
    "\n",
    "# =============================================================================\n",
    "# REQUIRED PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "model_path = selected_example[\"model_path\"]  # HuggingFace model name or local path\n",
    "data_path = \"/path/to/your/training_data.jsonl\"  # Path to training data in JSONL format\n",
    "ckpt_output_dir = f\"/path/to/checkpoints/{full_experiment_name}\"  # Where to save checkpoints\n",
    "\n",
    "print(\"üìã Required Parameters:\")\n",
    "print(f\"  model_path: Path to the model to fine-tune (HuggingFace name or local path)\")\n",
    "print(f\"  data_path: Path to the training data (JSONL format)\")\n",
    "print(f\"  ckpt_output_dir: Directory to save checkpoints\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# CORE TRAINING PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "num_epochs = 3  # Number of training epochs\n",
    "effective_batch_size = selected_example[\"example_batch_size\"]  # Effective batch size for training\n",
    "learning_rate = selected_example[\"example_learning_rate\"]  # Learning rate for training\n",
    "max_seq_len = selected_example[\"example_max_seq_len\"]  # Maximum sequence length\n",
    "max_tokens_per_gpu = selected_example[\"example_max_tokens_per_gpu\"]  # Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs)\n",
    "\n",
    "print(\"üéØ Core Training Parameters:\")\n",
    "print(f\"  num_epochs: {num_epochs} - Number of training epochs\")\n",
    "print(f\"  effective_batch_size: {effective_batch_size} - Effective batch size for training\")\n",
    "print(f\"  learning_rate: {learning_rate} - Learning rate for training\")\n",
    "print(f\"  max_seq_len: {max_seq_len:,} - Maximum sequence length\")\n",
    "print(f\"  max_tokens_per_gpu: {max_tokens_per_gpu:,} - Maximum tokens per GPU in a mini-batch (hard-cap for memory to avoid OOMs). Used to automatically calculate mini-batch size and gradient accumulation to maintain the desired effective_batch_size while staying within memory limits.\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# DATA AND PROCESSING PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "data_output_dir = \"/dev/shm\"  # Directory to save processed data\n",
    "warmup_steps = 100  # Number of warmup steps\n",
    "\n",
    "print(\"üíæ Data Processing Parameters:\")\n",
    "print(f\"  data_output_dir: '{data_output_dir}' - Directory to save processed data\")\n",
    "print(f\"  warmup_steps: {warmup_steps} - Number of warmup steps\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# CHECKPOINTING PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "save_samples = 0  # Number of samples to save after training (0 disables saving based on sample count)\n",
    "checkpoint_at_epoch = True  # Whether to checkpoint at each epoch\n",
    "accelerate_full_state_at_epoch = True  # Whether to save full state at epoch for automatic checkpoint resumption\n",
    "\n",
    "print(\"üíæ Checkpointing Parameters:\")\n",
    "print(f\"  save_samples: {save_samples} - Number of samples to save after training (0 disables saving based on sample count)\")\n",
    "print(f\"  checkpoint_at_epoch: {checkpoint_at_epoch} - Whether to checkpoint at each epoch\")\n",
    "print(f\"  accelerate_full_state_at_epoch: {accelerate_full_state_at_epoch} - Whether to save full state at epoch for automatic checkpoint resumption\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training Configuration\n",
    "\n",
    "Configure distributed training for both single-node and multi-node setups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DISTRIBUTED TRAINING PARAMETERS\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration options for different setups\n",
    "distributed_configs = {\n",
    "    \"single_gpu_dev\": {\n",
    "        \"nproc_per_node\": 1,\n",
    "        \"nnodes\": 1,\n",
    "        \"node_rank\": 0,\n",
    "        \"rdzv_id\": 1,\n",
    "        \"rdzv_endpoint\": \"127.0.0.1:29500\",\n",
    "        \"description\": \"Development setup with single GPU\"\n",
    "    },\n",
    "    \"single_node_8gpu\": {\n",
    "        \"nproc_per_node\": 8,\n",
    "        \"nnodes\": 1,\n",
    "        \"node_rank\": 0,\n",
    "        \"rdzv_id\": 100,\n",
    "        \"rdzv_endpoint\": \"127.0.0.1:29500\",\n",
    "        \"description\": \"Single node with 8 GPUs\"\n",
    "    },\n",
    "    \"multi_node_master\": {\n",
    "        \"nproc_per_node\": 8,\n",
    "        \"nnodes\": 4,\n",
    "        \"node_rank\": 0,\n",
    "        \"rdzv_id\": 42,\n",
    "        \"rdzv_endpoint\": \"10.0.0.1:29500\",  # Replace with actual master IP\n",
    "        \"description\": \"Multi-node master (rank 0) - 4 nodes total\"\n",
    "    },\n",
    "    \"multi_node_worker\": {\n",
    "        \"nproc_per_node\": 8,\n",
    "        \"nnodes\": 4,\n",
    "        \"node_rank\": 1,  # Change this for each worker node (1, 2, 3, ...)\n",
    "        \"rdzv_id\": 42,\n",
    "        \"rdzv_endpoint\": \"10.0.0.1:29500\",  # Same as master\n",
    "        \"description\": \"Multi-node worker (rank 1) - change rank for each worker\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select your distributed configuration\n",
    "selected_distributed = \"single_node_8gpu\"  # Change this to match your setup\n",
    "dist_config = distributed_configs[selected_distributed]\n",
    "\n",
    "# Extract distributed training parameters\n",
    "nproc_per_node = dist_config[\"nproc_per_node\"]  # Number of processes (GPUs) per node\n",
    "nnodes = dist_config[\"nnodes\"]  # Total number of nodes\n",
    "node_rank = dist_config[\"node_rank\"]  # Rank of this node (0 to nnodes-1)\n",
    "rdzv_id = dist_config[\"rdzv_id\"]  # Unique job ID for rendezvous\n",
    "rdzv_endpoint = dist_config[\"rdzv_endpoint\"]  # Master node endpoint for multi-node training\n",
    "\n",
    "# Calculate total resources\n",
    "total_gpus = nproc_per_node * nnodes\n",
    "per_gpu_batch_size = effective_batch_size // total_gpus\n",
    "\n",
    "print(\"üñ•Ô∏è  Distributed Training Parameters:\")\n",
    "print(f\"  Configuration: {dist_config['description']}\")\n",
    "print(f\"  nproc_per_node: {nproc_per_node} - Number of processes (GPUs) per node\")\n",
    "print(f\"  nnodes: {nnodes} - Total number of nodes\")\n",
    "print(f\"  node_rank: {node_rank} - Rank of this node (0 to nnodes-1)\")\n",
    "print(f\"  rdzv_id: {rdzv_id} - Unique job ID for rendezvous\")\n",
    "print(f\"  rdzv_endpoint: '{rdzv_endpoint}' - Master node endpoint for multi-node training\")\n",
    "print()\n",
    "print(f\"üìä Resource Calculation:\")\n",
    "print(f\"  Total GPUs: {total_gpus} ({nproc_per_node} √ó {nnodes})\")\n",
    "print(f\"  Effective batch size: {effective_batch_size}\")\n",
    "print(f\"  Approximate per-GPU batch size: {per_gpu_batch_size}\")\n",
    "print(f\"  (Actual micro-batch size determined automatically by gradient accumulation)\")\n",
    "print()\n",
    "\n",
    "# Multi-node setup instructions\n",
    "if nnodes > 1:\n",
    "    print(\"üîß Multi-Node Setup Instructions:\")\n",
    "    print(f\"  1. Ensure all nodes can reach the master at {rdzv_endpoint}\")\n",
    "    print(f\"  2. Use the same rdzv_id ({rdzv_id}) on all nodes\")\n",
    "    print(f\"  3. Set node_rank to 0 for master, 1,2,3... for workers\")\n",
    "    print(f\"  4. Start training on ALL nodes simultaneously\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training\n",
    "\n",
    "Now let's run the actual SFT training with all our configured parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAINING EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üöÄ Starting SFT Training\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Experiment: {full_experiment_name}\")\n",
    "print(f\"Model: {selected_example['model_name']}\")\n",
    "print(f\"Total GPUs: {total_gpus} ({nproc_per_node} per node √ó {nnodes} nodes)\")\n",
    "print(f\"Configuration: {dist_config['description']}\")\n",
    "print()\n",
    "\n",
    "# Prepare all training parameters\n",
    "training_params = {\n",
    "    # Required parameters\n",
    "    'model_path': model_path,\n",
    "    'data_path': data_path,\n",
    "    'ckpt_output_dir': ckpt_output_dir,\n",
    "    \n",
    "    # Core training parameters\n",
    "    'num_epochs': num_epochs,\n",
    "    'effective_batch_size': effective_batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'max_seq_len': max_seq_len,\n",
    "    'max_tokens_per_gpu': max_tokens_per_gpu,\n",
    "    \n",
    "    # Data and processing parameters\n",
    "    'data_output_dir': data_output_dir,\n",
    "    'warmup_steps': warmup_steps,\n",
    "    'save_samples': save_samples,\n",
    "    \n",
    "    # Checkpointing parameters\n",
    "    'checkpoint_at_epoch': checkpoint_at_epoch,\n",
    "    'accelerate_full_state_at_epoch': accelerate_full_state_at_epoch,\n",
    "    \n",
    "    # Distributed training parameters\n",
    "    'nproc_per_node': nproc_per_node,\n",
    "    'nnodes': nnodes,\n",
    "    'node_rank': node_rank,\n",
    "    'rdzv_id': rdzv_id,\n",
    "    'rdzv_endpoint': rdzv_endpoint,\n",
    "}\n",
    "\n",
    "# Display final configuration summary\n",
    "print(\"üìã Final Training Configuration:\")\n",
    "for key, value in training_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚è≥ Training starting...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Execute training\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    result = sft(**training_params)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ Training completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Total duration: {duration/3600:.2f} hours ({duration/60:.1f} minutes)\")\n",
    "    print(f\"üìÅ Checkpoints saved to: {ckpt_output_dir}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "except Exception as e:\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚ùå Training failed after {duration/60:.1f} minutes\")\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüîç Quick Troubleshooting Checklist:\")\n",
    "    print(\"  ‚ñ° Check that model_path exists or is a valid HuggingFace model name\")\n",
    "    print(\"  ‚ñ° Verify data_path points to valid JSONL file\")\n",
    "    print(\"  ‚ñ° Ensure ckpt_output_dir parent directory exists and is writable\")\n",
    "    print(\"  ‚ñ° Try reducing max_tokens_per_gpu if you see OOM errors\")\n",
    "    print(\"  ‚ñ° For multi-node: verify network connectivity and endpoints\")\n",
    "    print(\"  ‚ñ° Check that all file paths are accessible from the training process\")\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training Analysis\n",
    "\n",
    "After training completes, let's analyze the results and provide guidance for next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# POST-TRAINING ANALYSIS AND NEXT STEPS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"üìä Post-Training Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for saved checkpoints\n",
    "checkpoint_dir = f\"{ckpt_output_dir}/hf_format\"\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    checkpoints = [d for d in os.listdir(checkpoint_dir) \n",
    "                  if os.path.isdir(os.path.join(checkpoint_dir, d))]\n",
    "    \n",
    "    if checkpoints:\n",
    "        print(f\"‚úÖ Found {len(checkpoints)} checkpoint(s):\")\n",
    "        for ckpt in sorted(checkpoints):\n",
    "            ckpt_path = os.path.join(checkpoint_dir, ckpt)\n",
    "            print(f\"  üìÅ {ckpt}\")\n",
    "        \n",
    "        # Identify the final checkpoint\n",
    "        final_checkpoint = sorted(checkpoints)[-1]\n",
    "        final_checkpoint_path = os.path.join(checkpoint_dir, final_checkpoint)\n",
    "        \n",
    "        print(f\"\\nüéØ Final model checkpoint: {final_checkpoint_path}\")\n",
    "        \n",
    "        # Provide model loading example\n",
    "        print(f\"\\nüíª Model Loading Example:\")\n",
    "        print(f\"```python\")\n",
    "        print(f\"from transformers import AutoModelForCausalLM, AutoTokenizer\")\n",
    "        print(f\"\")\n",
    "        print(f\"# Load your fine-tuned model\")\n",
    "        print(f\"model = AutoModelForCausalLM.from_pretrained('{final_checkpoint_path}')\")\n",
    "        print(f\"tokenizer = AutoTokenizer.from_pretrained('{final_checkpoint_path}')\")\n",
    "        print(f\"\")\n",
    "        print(f\"# Generate text\")\n",
    "        print(f\"inputs = tokenizer('Your prompt here:', return_tensors='pt')\")\n",
    "        print(f\"outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True)\")\n",
    "        print(f\"response = tokenizer.decode(outputs[0], skip_special_tokens=True)\")\n",
    "        print(f\"print(response)\")\n",
    "        print(f\"```\")\n",
    "    else:\n",
    "        print(f\"‚ùå No checkpoints found in {checkpoint_dir}\")\n",
    "else:\n",
    "    print(f\"‚ùå Checkpoint directory not found: {checkpoint_dir}\")\n",
    "\n",
    "# Training summary\n",
    "print(f\"\\nüìà Training Summary:\")\n",
    "print(f\"  Model: {selected_example['model_name']}\")\n",
    "print(f\"  Epochs: {num_epochs}\")\n",
    "print(f\"  Global Batch Size: {effective_batch_size}\")\n",
    "print(f\"  Learning Rate: {learning_rate}\")\n",
    "print(f\"  Max Tokens per GPU: {max_tokens_per_gpu:,}\")\n",
    "print(f\"  Max Sequence Length: {max_seq_len:,}\")\n",
    "print(f\"  Total GPUs: {total_gpus}\")\n",
    "print(f\"  Distributed Config: {dist_config['description']}\")\n",
    "\n",
    "# Next steps recommendations\n",
    "print(f\"\\nüöÄ Recommended Next Steps:\")\n",
    "print(f\"  1. üß™ Test your model with sample inputs to verify it's working\")\n",
    "print(f\"  2. üìä Evaluate performance on your validation/test datasets\")\n",
    "print(f\"  3. üîÑ Compare outputs with the original base model\")\n",
    "print(f\"  4. üéØ Fine-tune hyperparameters if needed (learning rate, batch size)\")\n",
    "print(f\"  5. üìù Document your configuration and results for reproducibility\")\n",
    "print(f\"  6. üö¢ Deploy for inference using your preferred serving framework\")\n",
    "\n",
    "# Performance optimization tips\n",
    "print(f\"\\n‚ö° Performance Optimization Tips:\")\n",
    "print(f\"  ‚Ä¢ If training was slow: increase max_tokens_per_gpu or effective_batch_size\")\n",
    "print(f\"  ‚Ä¢ If you hit OOM errors: reduce max_tokens_per_gpu or effective_batch_size\")\n",
    "print(f\"  ‚Ä¢ For better convergence: try different learning rates or warmup_steps\")\n",
    "print(f\"  ‚Ä¢ For production training: consider using the script version for better logging\")\n",
    "\n",
    "print(f\"\\n‚ú® SFT Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Reference Summary\n",
    "\n",
    "Quick reference for all SFT parameters and their purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Core Parameters\n\n| Parameter | Required | Description | Example Values |\n|-----------|----------|-------------|----------------|\n| `model_path` | ‚úÖ | Path to the model to fine-tune | `\"Qwen/Qwen2.5-7B\"`, `\"/path/to/model\"` |\n| `data_path` | ‚úÖ | Path to the training data | `\"/path/to/train.jsonl\"` |\n| `ckpt_output_dir` | ‚úÖ | Directory to save checkpoints | `\"/path/to/checkpoints\"` |\n| `num_epochs` | ‚ùå | Number of training epochs | `1`, `3`, `5` |\n| `effective_batch_size` | ‚ùå | Effective batch size for training | `64`, `128`, `256` |\n| `learning_rate` | ‚ùå | Learning rate for training | `1e-5`, `2e-5`, `5e-6` |\n| `max_seq_len` | ‚ùå | Maximum sequence length | `2048`, `8192`, `16384` |\n| `max_tokens_per_gpu` | ‚ùå | Maximum tokens per GPU in a mini-batch (hard-cap for memory) | `15000`, `25000`, `40000` |\n\n### Data Processing Parameters\n\n| Parameter | Description | Default/Example |\n|-----------|-------------|------------------|\n| `data_output_dir` | Directory to save processed data | `\"/dev/shm\"` (RAM disk) |\n| `warmup_steps` | Number of warmup steps | `100`, `500` |\n\n### Checkpointing Parameters\n\n| Parameter | Description | Recommended |\n|-----------|-------------|-------------|\n| `checkpoint_at_epoch` | Whether to checkpoint at each epoch | `True` |\n| `accelerate_full_state_at_epoch` | Whether to save full state at epoch for automatic checkpoint resumption | `True` |\n| `save_samples` | Number of samples to save after training (0 disables) | `1000`, `0` (disabled) |\n\n### Distributed Training Parameters\n\n| Parameter | Description | Example Values |\n|-----------|-------------|----------------|\n| `nproc_per_node` | Number of processes (GPUs) per node | `1`, `4`, `8` |\n| `nnodes` | Total number of nodes | `1`, `2`, `4` |\n| `node_rank` | Rank of this node (0 to nnodes-1) | `0` (master), `1`, `2`... |\n| `rdzv_id` | Unique job ID for rendezvous | `42`, `100` |\n| `rdzv_endpoint` | Master node endpoint for multi-node training | `\"127.0.0.1:29500\"` |\n\n### Memory Optimization Guidelines\n\n- **Start conservative**: Begin with lower `max_tokens_per_gpu` values and increase gradually\n- **Monitor usage**: Watch GPU memory during training and adjust accordingly\n- **Balance batch size**: Larger `effective_batch_size` can improve training stability\n- **Use RAM disk**: Set `data_output_dir=\"/dev/shm\"` for faster data loading\n\n### Multi-Node Setup Checklist\n\n1. ‚úÖ Ensure network connectivity between all nodes\n2. ‚úÖ Use the same `rdzv_id` and `rdzv_endpoint` on all nodes\n3. ‚úÖ Set unique `node_rank` for each node (0, 1, 2, ...)\n4. ‚úÖ Verify all nodes can access model and data paths\n5. ‚úÖ Start training simultaneously on all nodes\n\n### Popular Model Examples\n\n| Model | HuggingFace Path | Example Config |\n|-------|------------------|----------------|\n| Qwen 2.5 7B | `Qwen/Qwen2.5-7B-Instruct` | `max_tokens_per_gpu=20000` |\n| Llama 3.1 8B | `meta-llama/Meta-Llama-3.1-8B-Instruct` | `max_tokens_per_gpu=18000` |\n| Phi 4 Mini | `microsoft/Phi-4-mini-instruct` | `max_tokens_per_gpu=25000` |\n\n### Script Alternative\n\nFor production workloads or long-running training, use the script version:\n\n```bash\npython scripts/sft_qwen_example.py \\\n  --data-path /path/to/data.jsonl \\\n  --ckpt-output-dir /path/to/checkpoints\n\npython scripts/sft_llama_example.py \\\n  --data-path /path/to/data.jsonl \\\n  --ckpt-output-dir /path/to/checkpoints\n\npython scripts/sft_phi_example.py \\\n  --data-path /path/to/data.jsonl \\\n  --ckpt-output-dir /path/to/checkpoints\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}