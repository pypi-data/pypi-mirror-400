---
title: KohakuBoard - Getting Started
description: Quick start guide for experiment tracking with KohakuBoard
icon: i-carbon-analytics
---

# Getting Started with KohakuBoard

High-performance, non-blocking experiment logging for ML training workflows.

---

## üöÄ Quick Start

### Installation

```bash
# From KohakuHub repository
cd /path/to/KohakuHub
pip install -e src/kohakuboard/

# Or install from source
pip install kohakuboard  # (when published)
```

### Your First Experiment

```python
from kohakuboard.client import Board

# Create a board (auto-creates directory structure)
board = Board(
    name="my-first-experiment",
    config={
        "learning_rate": 0.001,
        "batch_size": 32,
        "model": "ResNet-50"
    }
)

# Training loop
for epoch in range(10):
    for batch_idx, (data, target) in enumerate(train_loader):
        loss = train_step(data, target)

        # Increment ONCE per optimizer/batch update
        board.step()

        # Log metrics (non-blocking!)
        board.log(
            loss=loss,
            lr=optimizer.param_groups[0]['lr']
        )

# Auto-saves on exit (via atexit hook)
```

**That's it!** Your metrics are saved to `./kohakuboard/{board_id}/data/`

---

## üìä Rich Data Types

KohakuBoard supports 6 data types in a unified API:

### 1. Scalars (metrics)

```python
board.log(
    loss=0.5,
    accuracy=0.95,
    learning_rate=0.001
)

# Namespaces (creates tabs in UI)
board.log(**{
    "train/loss": 0.5,
    "val/accuracy": 0.95
})
```

### 2. Media (images, video, audio)

```python
from kohakuboard.client import Media

# Images
board.log(
    sample_image=Media(image_array),  # numpy, PIL, torch tensor
    predictions=Media(pred_image, caption="Predicted: cat")
)

# Video
board.log(
    training_video=Media("output.mp4", media_type="video")
)
```

### 3. Tables (structured data)

```python
from kohakuboard.client import Table

# From list of dicts
results = Table([
    {"name": "Alice", "score": 95, "pass": True},
    {"name": "Bob", "score": 87, "pass": True},
])
board.log(student_results=results)

# Tables with embedded images
predictions = Table([
    {"image": Media(img), "label": "cat", "confidence": 0.95},
    {"image": Media(img2), "label": "dog", "confidence": 0.87},
])
board.log(val_predictions=predictions)
```

### 4. Histograms (distributions)

```python
from kohakuboard.client import Histogram

# Log gradient distributions
board.log(
    gradients=Histogram(param.grad),
    weights=Histogram(param.data)
)

# Precompute for efficiency (optional)
hist = Histogram(gradients).compute_bins()
board.log(grad_distribution=hist)
```

### 5. Tensor Logs (high-dimensional arrays)

```python
from kohakuboard.client import TensorLog

# Store tensors exactly once, reader fetches lazily
board.log(
    attention_map=TensorLog(tensor, namespace="layer3", metadata={"head": 2})
)
```

### 6. Kernel Density Estimates

```python
from kohakuboard.client import KernelDensity

# Either pass raw values or precomputed grid/density
board.log(
    val_logits=KernelDensity(values=logits.cpu().numpy(), grid_size=256)
)
```

---

## üéØ Key Features

### No Step Inflation!

**Problem:** Logging multiple histograms causes step inflation
```python
# BAD: Each call increments step separately
for name, param in model.named_parameters():
    board.log_histogram(f"gradients/{name}", param.grad)
# Result: 50 histograms = 50 different steps! ‚ùå
```

**Solution:** Unified `.log()` API
```python
# GOOD: All histograms share same step
histogram_data = {}
for name, param in model.named_parameters():
    histogram_data[f"gradients/{name}"] = Histogram(param.grad)

board.log(**histogram_data)
# Result: 50 histograms = 1 step! ‚úÖ
```

### Mixed Type Logging

Log scalars, histograms, tables, and media together:

```python
board.log(
    loss=0.5,                      # Scalar
    sample_img=Media(image),       # Image
    results=Table(data),           # Table
    gradients=Histogram(grads),    # Histogram
)
# All logged at the SAME step with 1 queue message!
```

### Non-Blocking Writes

```python
board.log(loss=0.5)  # Returns immediately!
# Background writer process handles disk I/O
```

**Architecture:**
```
Main Thread              Background Process
     ‚îÇ                           ‚îÇ
     ‚îú‚îÄ log(loss=0.5)            ‚îÇ
     ‚îÇ  ‚îî‚îÄ> Queue.put()          ‚îÇ
     ‚îÇ      (non-blocking!)      ‚îÇ
     ‚îú‚îÄ Continue training...     ‚îú‚îÄ Queue.get()
     ‚îÇ                           ‚îú‚îÄ Write to disk
     ‚îÇ                           ‚îî‚îÄ Flush
```

---

## üéì Complete Example

```python
from kohakuboard.client import Board, Histogram, Table, Media
import torch
from torch import nn, optim

# Initialize board
board = Board(
    name="cifar10-resnet18",
    config={
        "lr": 0.001,
        "batch_size": 128,
        "epochs": 100,
        "optimizer": "AdamW"
    }
)

# Training loop
for epoch in range(100):
    # Training phase
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        board.step()  # Increment ONCE per optimizer step

        # Log training metrics
        board.log(**{
            "train/loss": loss.item(),
            "train/lr": optimizer.param_groups[0]['lr']
        })

    # Log gradients every epoch (not every batch!)
    if epoch % 1 == 0:
        grad_data = {}
        for name, param in model.named_parameters():
            if param.grad is not None:
                grad_data[f"gradients/{name}"] = Histogram(param.grad).compute_bins()
        board.log(**grad_data)

    # Validation phase
    model.eval()
    val_loss = 0
    correct = 0
    predictions_table = []

    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(val_loader):
            output = model(data)
            val_loss += criterion(output, target).item()
            pred = output.argmax(dim=1)
            correct += (pred == target).sum().item()

            # Collect sample predictions (first batch only)
            if batch_idx == 0:
                for i in range(min(8, len(data))):
                    predictions_table.append({
                        "image": Media(data[i].cpu().numpy()),
                        "true": class_names[target[i]],
                        "pred": class_names[pred[i]],
                        "correct": "‚úì" if pred[i] == target[i] else "‚úó"
                    })

    # Log validation results (scalars + table together!)
    board.log(**{
        "val/loss": val_loss / len(val_loader),
        "val/accuracy": correct / len(val_loader.dataset),
        "val/predictions": Table(predictions_table)
    })

# Auto-cleanup on exit (atexit hook)
```

---

## üìÇ Directory Structure

KohakuBoard creates this structure automatically:

```
kohakuboard/
‚îî‚îÄ‚îÄ {board_id}/                           # e.g., 20250129_150423_abc123
    ‚îú‚îÄ‚îÄ metadata.json                     # Board config
    ‚îú‚îÄ‚îÄ data/                             # Storage backend files
    ‚îÇ   ‚îú‚îÄ‚îÄ metrics/                      # (hybrid) KohakuVault DB files
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train__loss.db
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val__accuracy.db
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îÇ   ‚îú‚îÄ‚îÄ metadata.db                   # (hybrid) SQLite metadata
    ‚îÇ   ‚îî‚îÄ‚îÄ histograms/
    ‚îÇ       ‚îú‚îÄ‚îÄ gradients_i32.db       # int32 precision
    ‚îÇ       ‚îî‚îÄ‚îÄ params_u8.db           # uint8 precision
    ‚îú‚îÄ‚îÄ media/                            # Images, videos, audio
    ‚îÇ   ‚îú‚îÄ‚îÄ sample_image_00000000_a1b2c3d4.png
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ logs/
        ‚îú‚îÄ‚îÄ output.log                    # Captured stdout/stderr
        ‚îî‚îÄ‚îÄ writer.log                    # Background writer logs
```

---

## ‚öôÔ∏è Configuration

### Storage Layout

Modern boards always use the hybrid KohakuVault + SQLite architecture:

- **`data/metrics/*.db`** ‚Äì KohakuVault ColumnVault files (one per metric).
- **`data/metadata.db`** ‚Äì SQLite tables for media/table/tensor metadata.
- **`media/blobs.db` + files** ‚Äì Content-addressed blobs, deduplicated by hash.
- **`data/tensors/*.db`** ‚Äì Optional KVault stores for `TensorLog`.

This layout is identical on laptops, servers, and CI. Sharing a run is as easy as copying the `{project}/{run_id}` folder to another machine. See the [Usage Manual](/docs/kohakuboard/usage-manual) for copy/rsync examples.

### Context Manager

Ensure cleanup with context manager:

```python
with Board(name="experiment") as board:
    board.log(loss=0.5)
    # Automatic flush() and finish() on exit
```

### Manual Control

```python
board = Board(name="experiment")

# Explicit flush (blocks until all writes complete)
board.flush()

# Manual finish (called automatically via atexit)
board.finish()
```

---

## üöõ Sharing Runs Between Machines

Local mode (`kobo open`) and the authenticated server (`kobo-serve`) read the exact same folder structure. To share a run:

1. Copy the run folder:
   ```bash
   rsync -a ./kohakuboard/default/20250201_120301_xyz \
         server:/var/kohakuboard/default/
   ```
2. Ensure file permissions allow the server/viewer to read the files.
3. Restart or refresh the viewer. The run appears immediately (no import needed).

> The legacy `kobo sync` command still targets the old DuckDB exporter and will fail on new boards. Stick to manual copy/rsync until the refreshed sync API ships.

---

## üîß Advanced Features

### Step Control

```python
# Auto-increment (default)
board.log(loss=0.5, auto_step=True)

# Manual control
board.log(loss=0.5, auto_step=False)  # No step increment

# Global step for optimizer steps (recommended)
for batch in train_loader:
    board.step()  # Increment ONCE per optimizer update
    board.log(loss=loss)
```

```python
# If you really need manual control (e.g., gradient accumulation)
if (batch_idx + 1) % accumulation_steps == 0:
    board.step(increment=1)
else:
    board.log(loss=loss, auto_step=False)  # same global_step
```

### Histogram Optimization

```python
# Default: compute in writer process
board.log(gradients=Histogram(param.grad))

# Precompute client-side (reduces queue size)
hist = Histogram(param.grad).compute_bins()
board.log(gradients=hist)

# Compact precision (75% size reduction, ~1% accuracy loss)
hist = Histogram(param.grad, precision="compact")
board.log(gradients=hist)
```

### Output Capture

```python
# Enabled by default
board = Board(name="exp", capture_output=True)

# Stdout/stderr saved to logs/output.log
print("Training started...")  # Captured!
```

---

## üìö Next Steps

- **[API Reference](/docs/kohakuboard/api)** - Complete API documentation
- **[Configuration](/docs/kohakuboard/configuration)** - Storage backends, performance tuning
- **[Examples](/docs/kohakuboard/examples)** - Real-world usage patterns
- **[Best Practices](/docs/kohakuboard/best-practices)** - Performance tips and optimization

---

## üí° Tips

‚úÖ **DO:**
- Use unified `.log()` for all types
- Log histograms every N epochs (not every batch)
- Precompute histograms if CPU available
- Use namespaces for organization (`train/`, `val/`)

‚ùå **DON'T:**
- Mix `.log()` and `.log_histogram()` (causes step inflation)
- Log images/videos every batch (queue overload)
- Forget to call `board.step()` at epoch boundaries

---

## üêõ Troubleshooting

### Queue Size Warning

```
WARNING: Queue size is 40000 (80% capacity)
```

**Fix:** Reduce logging frequency or precompute histograms

### Step Inflation

**Problem:** Multiple histograms logged separately
```python
# BAD
board.log_histogram("grad1", grad1)  # step 100
board.log_histogram("grad2", grad2)  # step 101
```

**Fix:** Use unified API
```python
# GOOD
board.log(grad1=Histogram(grad1), grad2=Histogram(grad2))  # step 100
```

---

## üìñ Further Reading

- [Storage Backend Comparison](/docs/kohakuboard/configuration#storage-backends)
- [Performance Optimization](/docs/kohakuboard/best-practices#performance)
- [CIFAR-10 Training Example](https://github.com/KohakuBlueleaf/KohakuHub/blob/main/examples/kohakuboard_cifar_training.py)
