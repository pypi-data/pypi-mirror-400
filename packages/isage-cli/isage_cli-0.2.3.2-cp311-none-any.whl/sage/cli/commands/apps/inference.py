#!/usr/bin/env python3
"""Unified Inference service management commands for SAGE.

This module provides CLI commands to manage the unified inference service,
which combines LLM and Embedding capabilities in a single OpenAI-compatible API.

Commands:
    - start: Start the unified inference server
    - stop: Stop the unified inference server
    - status: Check the status of the unified inference server
    - config: Manage configuration

Example:
    sage inference start --llm-model Qwen/Qwen2.5-7B-Instruct --embedding-model BAAI/bge-m3
    sage inference stop
    sage inference status
"""

from __future__ import annotations

import json
import subprocess
import sys
import time
from pathlib import Path
from typing import Any

import psutil
import typer
from rich.console import Console
from rich.table import Table

console = Console()
app = typer.Typer(help="ğŸ”® ç»Ÿä¸€æ¨ç†æœåŠ¡ç®¡ç† - LLM å’Œ Embedding æ··åˆè°ƒåº¦")

# PID file location
PID_FILE = Path.home() / ".sage" / "inference_server.pid"
CONFIG_FILE = Path.home() / ".sage" / "inference_server.json"
LOG_FILE = Path.home() / ".sage" / "logs" / "inference_server.log"


# =============================================================================
# Helper Functions
# =============================================================================


def _is_port_in_use(port: int) -> bool:
    """Check if a port is in use.

    Note:
        This is a wrapper around sage.common.utils.system.network.is_port_occupied
    """
    from sage.common.utils.system.network import is_port_occupied

    return is_port_occupied("localhost", port)


def _get_running_pid() -> int | None:
    """Get the PID of the running server from PID file."""
    if not PID_FILE.exists():
        return None

    try:
        pid = int(PID_FILE.read_text().strip())
        # Check if process is still running
        if psutil.pid_exists(pid):
            try:
                proc = psutil.Process(pid)
                # Verify it's our process by checking command line
                cmdline = " ".join(proc.cmdline())
                if "unified_api_server" in cmdline or "sage" in cmdline.lower():
                    return pid
            except (psutil.NoSuchProcess, psutil.AccessDenied):
                pass
        # PID file exists but process is not running, clean up
        PID_FILE.unlink()
    except (ValueError, OSError):
        pass

    return None


def _save_pid(pid: int) -> None:
    """Save the server PID to file."""
    PID_FILE.parent.mkdir(parents=True, exist_ok=True)
    PID_FILE.write_text(str(pid))


def _save_config(config: dict[str, Any]) -> None:
    """Save the server configuration to file."""
    CONFIG_FILE.parent.mkdir(parents=True, exist_ok=True)
    CONFIG_FILE.write_text(json.dumps(config, indent=2))


def _load_config() -> dict[str, Any] | None:
    """Load the server configuration from file."""
    if not CONFIG_FILE.exists():
        return None
    try:
        return json.loads(CONFIG_FILE.read_text())
    except (json.JSONDecodeError, OSError):
        return None


def _test_api_health(port: int, timeout: float = 2.0) -> dict[str, Any] | None:
    """Test the API health endpoint."""
    import urllib.error
    import urllib.request

    try:
        url = f"http://localhost:{port}/health"
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, timeout=timeout) as response:
            return json.loads(response.read().decode())
    except Exception:
        return None


# =============================================================================
# Start Command
# =============================================================================


@app.command("start")
def start_server(
    llm_model: str | None = typer.Option(
        None,
        "--llm-model",
        "-l",
        help="LLM æ¨¡å‹åç§°",
    ),
    embedding_model: str | None = typer.Option(
        None,
        "--embedding-model",
        "-e",
        help="Embedding æ¨¡å‹åç§°",
    ),
    llm_backend: str | None = typer.Option(
        None,
        "--llm-backend",
        help="LLM åç«¯ URL (ä¾‹å¦‚ http://localhost:8001)",
    ),
    embedding_backend: str | None = typer.Option(
        None,
        "--embedding-backend",
        help="Embedding åç«¯ URL (ä¾‹å¦‚ http://localhost:8090)",
    ),
    port: int = typer.Option(
        8000,
        "--port",
        "-p",
        help="æœåŠ¡ç›‘å¬ç«¯å£",
    ),
    host: str = typer.Option(
        "0.0.0.0",
        "--host",
        "-h",
        help="æœåŠ¡ç›‘å¬åœ°å€",
    ),
    scheduling_policy: str = typer.Option(
        "adaptive",
        "--scheduling-policy",
        "-s",
        help="è°ƒåº¦ç­–ç•¥ (fifo, priority, slo_aware, adaptive, hybrid)",
    ),
    background: bool = typer.Option(
        False,
        "--background",
        "-b",
        help="åå°è¿è¡ŒæœåŠ¡",
    ),
    config_file: Path | None = typer.Option(
        None,
        "--config",
        "-c",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (YAML/JSON)",
    ),
    log_level: str = typer.Option(
        "info",
        "--log-level",
        help="æ—¥å¿—çº§åˆ« (debug, info, warning, error)",
    ),
):
    """å¯åŠ¨ç»Ÿä¸€æ¨ç†æœåŠ¡ã€‚

    è¯¥æœåŠ¡æä¾› OpenAI å…¼å®¹çš„ APIï¼ŒåŒæ—¶æ”¯æŒ LLM å’Œ Embedding è¯·æ±‚ã€‚
    å†…éƒ¨é€šè¿‡æ··åˆè°ƒåº¦å™¨æ™ºèƒ½åˆ†é…è¯·æ±‚åˆ°ä¸åŒçš„åç«¯å®ä¾‹ã€‚

    ç¤ºä¾‹ï¼š
        # å¯åŠ¨åŸºæœ¬æœåŠ¡ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„é»˜è®¤åç«¯ï¼‰
        sage inference start

        # æŒ‡å®šåç«¯ URL
        sage inference start --llm-backend http://localhost:8001 --embedding-backend http://localhost:8090

        # ä½¿ç”¨æ··åˆè°ƒåº¦ç­–ç•¥
        sage inference start --scheduling-policy hybrid

        # åå°è¿è¡Œ
        sage inference start --background

        # ä½¿ç”¨é…ç½®æ–‡ä»¶
        sage inference start --config inference-config.yaml

    ç¯å¢ƒå˜é‡ï¼š
        SAGE_LLM_PORT=8001              # é»˜è®¤ LLM åç«¯ç«¯å£
        SAGE_EMBEDDING_PORT=8090        # é»˜è®¤ Embedding åç«¯ç«¯å£
        SAGE_CHAT_MODEL=model_name      # é»˜è®¤ LLM æ¨¡å‹
        SAGE_EMBEDDING_MODEL=model_name # é»˜è®¤ Embedding æ¨¡å‹
    """
    console.print("[blue]ğŸš€ å¯åŠ¨ç»Ÿä¸€æ¨ç†æœåŠ¡...[/blue]")

    # Check if already running
    existing_pid = _get_running_pid()
    if existing_pid:
        console.print(f"[yellow]âš ï¸ æœåŠ¡å·²åœ¨è¿è¡Œä¸­ (PID: {existing_pid})[/yellow]")
        console.print("   ä½¿ç”¨ 'sage inference stop' åœæ­¢æœåŠ¡")
        raise typer.Exit(1)

    # Check port availability
    if _is_port_in_use(port):
        console.print(f"[red]âŒ ç«¯å£ {port} å·²è¢«å ç”¨[/red]")
        console.print("   è¯·ä½¿ç”¨å…¶ä»–ç«¯å£æˆ–åœæ­¢å ç”¨è¯¥ç«¯å£çš„æœåŠ¡")
        raise typer.Exit(1)

    # Load configuration from file if specified
    file_config: dict[str, Any] = {}
    if config_file and config_file.exists():
        try:
            if config_file.suffix in (".yaml", ".yml"):
                import yaml  # type: ignore[import-untyped]

                file_config = yaml.safe_load(config_file.read_text())
            else:
                file_config = json.loads(config_file.read_text())
            console.print(f"[green]âœ“[/green] åŠ è½½é…ç½®æ–‡ä»¶: {config_file}")
        except Exception as e:
            console.print(f"[red]âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶: {e}[/red]")
            raise typer.Exit(1)

    # Merge configuration (CLI args > file config > env vars > defaults)
    final_config = {
        "host": host,
        "port": port,
        "llm_model": llm_model or file_config.get("llm", {}).get("model"),
        "llm_backend": llm_backend or file_config.get("llm", {}).get("backend"),
        "embedding_model": embedding_model or file_config.get("embedding", {}).get("model"),
        "embedding_backend": embedding_backend or file_config.get("embedding", {}).get("backend"),
        "scheduling_policy": scheduling_policy
        or file_config.get("scheduling", {}).get("policy", "adaptive"),
        "log_level": log_level,
    }

    # Build command to run the server
    cmd = [
        sys.executable,
        "-m",
        "sage.llm.unified_api_server",
        "--host",
        final_config["host"],
        "--port",
        str(final_config["port"]),
        "--scheduling-policy",
        final_config["scheduling_policy"],
        "--log-level",
        final_config["log_level"],
    ]

    if final_config.get("llm_model"):
        cmd.extend(["--llm-model", final_config["llm_model"]])
    if final_config.get("llm_backend"):
        cmd.extend(["--llm-backend", final_config["llm_backend"]])
    if final_config.get("embedding_model"):
        cmd.extend(["--embedding-model", final_config["embedding_model"]])
    if final_config.get("embedding_backend"):
        cmd.extend(["--embedding-backend", final_config["embedding_backend"]])

    console.print(f"[dim]å‘½ä»¤: {' '.join(cmd[:6])}...[/dim]")

    try:
        if background:
            # Background mode
            LOG_FILE.parent.mkdir(parents=True, exist_ok=True)
            log_handle = open(LOG_FILE, "w")

            process = subprocess.Popen(
                cmd,
                stdout=log_handle,
                stderr=subprocess.STDOUT,
                start_new_session=True,
            )

            _save_pid(process.pid)
            _save_config(final_config)

            console.print("[green]âœ… æœåŠ¡å·²åœ¨åå°å¯åŠ¨[/green]")
            console.print(f"   PID: {process.pid}")
            console.print(f"   ç«¯å£: {final_config['port']}")
            console.print(f"   æ—¥å¿—: {LOG_FILE}")
            console.print()
            console.print("[dim]API ç«¯ç‚¹:[/dim]")
            console.print(
                f"   Chat:      http://localhost:{final_config['port']}/v1/chat/completions"
            )
            console.print(f"   Completion: http://localhost:{final_config['port']}/v1/completions")
            console.print(f"   Embedding: http://localhost:{final_config['port']}/v1/embeddings")
            console.print(f"   Models:    http://localhost:{final_config['port']}/v1/models")
            console.print(f"   Health:    http://localhost:{final_config['port']}/health")
            console.print()
            console.print("[dim]ä½¿ç”¨ 'sage inference status' æŸ¥çœ‹æœåŠ¡çŠ¶æ€[/dim]")

        else:
            # Foreground mode
            console.print("[dim]æŒ‰ Ctrl+C åœæ­¢æœåŠ¡[/dim]")
            console.print()

            _save_config(final_config)

            process: subprocess.Popen[bytes] | None = None
            try:
                # Run in foreground
                process = subprocess.Popen(cmd)
                _save_pid(process.pid)

                # Wait for process
                process.wait()

            except KeyboardInterrupt:
                console.print("\n[yellow]ğŸ›‘ æ­£åœ¨åœæ­¢æœåŠ¡...[/yellow]")
                if process is not None:
                    process.terminate()
                    try:
                        process.wait(timeout=5)
                    except subprocess.TimeoutExpired:
                        process.kill()

            finally:
                # Clean up PID file
                if PID_FILE.exists():
                    PID_FILE.unlink()

    except Exception as e:
        console.print(f"[red]âŒ å¯åŠ¨å¤±è´¥: {e}[/red]")
        raise typer.Exit(1)


# =============================================================================
# Stop Command
# =============================================================================


@app.command("stop")
def stop_server(
    force: bool = typer.Option(
        False,
        "--force",
        "-f",
        help="å¼ºåˆ¶åœæ­¢æœåŠ¡",
    ),
    port: int | None = typer.Option(
        None,
        "--port",
        "-p",
        help="æŒ‡å®šç«¯å£ï¼ˆç”¨äºæŸ¥æ‰¾è¿›ç¨‹ï¼‰",
    ),
):
    """åœæ­¢ç»Ÿä¸€æ¨ç†æœåŠ¡ã€‚

    ç¤ºä¾‹ï¼š
        sage inference stop          # åœæ­¢æœåŠ¡
        sage inference stop --force  # å¼ºåˆ¶åœæ­¢
    """
    console.print("[blue]ğŸ›‘ åœæ­¢ç»Ÿä¸€æ¨ç†æœåŠ¡...[/blue]")

    pid = _get_running_pid()

    if not pid:
        # Try to find by port
        if port:
            for proc in psutil.process_iter(["pid", "cmdline"]):
                try:
                    cmdline = " ".join(proc.info.get("cmdline") or [])
                    if "unified_api_server" in cmdline and str(port) in cmdline:
                        pid = proc.pid
                        break
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

    if not pid:
        console.print("[yellow]âš ï¸ æœªæ‰¾åˆ°è¿è¡Œä¸­çš„æœåŠ¡[/yellow]")
        # Clean up stale PID file
        if PID_FILE.exists():
            PID_FILE.unlink()
        raise typer.Exit(0)

    try:
        proc = psutil.Process(pid)
        console.print(f"[dim]æ‰¾åˆ°è¿›ç¨‹ PID: {pid}[/dim]")

        if force:
            proc.kill()
            console.print("[green]âœ… æœåŠ¡å·²å¼ºåˆ¶åœæ­¢[/green]")
        else:
            proc.terminate()
            try:
                proc.wait(timeout=10)
                console.print("[green]âœ… æœåŠ¡å·²åœæ­¢[/green]")
            except psutil.TimeoutExpired:
                console.print("[yellow]âš ï¸ æœåŠ¡æœªå“åº”ï¼Œå¼ºåˆ¶åœæ­¢...[/yellow]")
                proc.kill()
                console.print("[green]âœ… æœåŠ¡å·²å¼ºåˆ¶åœæ­¢[/green]")

    except psutil.NoSuchProcess:
        console.print("[yellow]âš ï¸ è¿›ç¨‹å·²ä¸å­˜åœ¨[/yellow]")
    except psutil.AccessDenied:
        console.print("[red]âŒ æ— æƒé™åœæ­¢è¿›ç¨‹ï¼Œè¯·ä½¿ç”¨ sudo[/red]")
        raise typer.Exit(1)
    finally:
        # Clean up PID file
        if PID_FILE.exists():
            PID_FILE.unlink()


# =============================================================================
# Status Command
# =============================================================================


@app.command("status")
def server_status(
    port: int = typer.Option(
        8000,
        "--port",
        "-p",
        help="æœåŠ¡ç«¯å£",
    ),
    json_output: bool = typer.Option(
        False,
        "--json",
        help="ä»¥ JSON æ ¼å¼è¾“å‡º",
    ),
):
    """æŸ¥çœ‹ç»Ÿä¸€æ¨ç†æœåŠ¡çŠ¶æ€ã€‚

    ç¤ºä¾‹ï¼š
        sage inference status          # æŸ¥çœ‹çŠ¶æ€
        sage inference status --json   # JSON æ ¼å¼è¾“å‡º
    """
    pid = _get_running_pid()
    config = _load_config()
    port_to_check = config.get("port", port) if config else port

    # Gather status information
    status_info: dict[str, Any] = {
        "running": False,
        "pid": None,
        "port": port_to_check,
        "health": None,
        "uptime": None,
        "config": config,
    }

    if pid:
        try:
            proc = psutil.Process(pid)
            status_info["running"] = proc.is_running()
            status_info["pid"] = pid
            status_info["uptime"] = time.time() - proc.create_time()
            status_info["memory_mb"] = proc.memory_info().rss / 1024 / 1024
            status_info["cpu_percent"] = proc.cpu_percent()
        except psutil.NoSuchProcess:
            pass

    # Check health endpoint
    if _is_port_in_use(port_to_check):
        health = _test_api_health(port_to_check)
        status_info["health"] = health
        if not status_info["running"]:
            status_info["running"] = health is not None

    if json_output:
        console.print_json(json.dumps(status_info, indent=2, default=str))
        return

    # Pretty print status
    console.print()
    console.print("[bold]ğŸ”® ç»Ÿä¸€æ¨ç†æœåŠ¡çŠ¶æ€[/bold]")
    console.print()

    if status_info["running"]:
        console.print("[green]â— è¿è¡Œä¸­[/green]")
        console.print(f"   PID: {status_info.get('pid', 'N/A')}")
        console.print(f"   ç«¯å£: {status_info['port']}")

        if status_info.get("uptime"):
            uptime_hours = status_info["uptime"] / 3600
            console.print(f"   è¿è¡Œæ—¶é—´: {uptime_hours:.2f} å°æ—¶")

        if status_info.get("memory_mb"):
            console.print(f"   å†…å­˜ä½¿ç”¨: {status_info['memory_mb']:.1f} MB")

        # Health status
        health = status_info.get("health")
        if health:
            console.print()
            console.print("[bold]å¥åº·çŠ¶æ€:[/bold]")
            console.print(f"   çŠ¶æ€: {health.get('status', 'unknown')}")
            backends = health.get("backends", {})
            if backends:
                llm_status = "âœ…" if backends.get("llm", {}).get("healthy") else "âŒ"
                embed_status = "âœ…" if backends.get("embedding", {}).get("healthy") else "âŒ"
                console.print(f"   LLM åç«¯: {llm_status}")
                console.print(f"   Embedding åç«¯: {embed_status}")

        # Configuration
        if config:
            console.print()
            console.print("[bold]é…ç½®:[/bold]")
            if config.get("llm_model"):
                console.print(f"   LLM æ¨¡å‹: {config['llm_model']}")
            if config.get("llm_backend"):
                console.print(f"   LLM åç«¯: {config['llm_backend']}")
            if config.get("embedding_model"):
                console.print(f"   Embedding æ¨¡å‹: {config['embedding_model']}")
            if config.get("embedding_backend"):
                console.print(f"   Embedding åç«¯: {config['embedding_backend']}")
            if config.get("scheduling_policy"):
                console.print(f"   è°ƒåº¦ç­–ç•¥: {config['scheduling_policy']}")

        console.print()
        console.print("[dim]API ç«¯ç‚¹:[/dim]")
        console.print(f"   http://localhost:{status_info['port']}/v1/chat/completions")
        console.print(f"   http://localhost:{status_info['port']}/v1/embeddings")
        console.print(f"   http://localhost:{status_info['port']}/v1/models")

    else:
        console.print("[red]â— æœªè¿è¡Œ[/red]")
        console.print()
        console.print("[dim]ä½¿ç”¨ 'sage inference start' å¯åŠ¨æœåŠ¡[/dim]")


# =============================================================================
# Config Command
# =============================================================================


@app.command("config")
def show_config(
    output: str = typer.Option(
        "table",
        "--output",
        "-o",
        help="è¾“å‡ºæ ¼å¼ (table, json, yaml)",
    ),
):
    """æ˜¾ç¤ºå½“å‰é…ç½®ã€‚

    ç¤ºä¾‹ï¼š
        sage inference config              # è¡¨æ ¼æ ¼å¼
        sage inference config --output json   # JSON æ ¼å¼
    """
    config = _load_config()

    if not config:
        console.print("[yellow]âš ï¸ æš‚æ— ä¿å­˜çš„é…ç½®[/yellow]")
        console.print("[dim]ä½¿ç”¨ 'sage inference start' é¦–æ¬¡å¯åŠ¨åä¼šç”Ÿæˆé…ç½®[/dim]")
        return

    if output == "json":
        console.print_json(json.dumps(config, indent=2))
    elif output == "yaml":
        try:
            import yaml  # type: ignore[import-untyped]

            console.print(yaml.dump(config, default_flow_style=False))
        except ImportError:
            console.print("[red]éœ€è¦å®‰è£… PyYAML: pip install pyyaml[/red]")
    else:
        # Table format
        table = Table(title="ç»Ÿä¸€æ¨ç†æœåŠ¡é…ç½®")
        table.add_column("é…ç½®é¡¹", style="cyan")
        table.add_column("å€¼", style="green")

        table.add_row("æœåŠ¡åœ°å€", f"{config.get('host', 'N/A')}:{config.get('port', 'N/A')}")
        table.add_row("LLM æ¨¡å‹", config.get("llm_model") or "(é»˜è®¤)")
        table.add_row("LLM åç«¯", config.get("llm_backend") or "(é»˜è®¤)")
        table.add_row("Embedding æ¨¡å‹", config.get("embedding_model") or "(é»˜è®¤)")
        table.add_row("Embedding åç«¯", config.get("embedding_backend") or "(é»˜è®¤)")
        table.add_row("è°ƒåº¦ç­–ç•¥", config.get("scheduling_policy", "adaptive"))
        table.add_row("æ—¥å¿—çº§åˆ«", config.get("log_level", "info"))

        console.print(table)


# =============================================================================
# Logs Command
# =============================================================================


@app.command("logs")
def show_logs(
    follow: bool = typer.Option(
        False,
        "--follow",
        "-f",
        help="æŒç»­è¾“å‡ºæ—¥å¿—",
    ),
    lines: int = typer.Option(
        50,
        "--lines",
        "-n",
        help="æ˜¾ç¤ºæœ€å N è¡Œ",
    ),
):
    """æŸ¥çœ‹æœåŠ¡æ—¥å¿—ã€‚

    ç¤ºä¾‹ï¼š
        sage inference logs           # æ˜¾ç¤ºæœ€å 50 è¡Œ
        sage inference logs -n 100    # æ˜¾ç¤ºæœ€å 100 è¡Œ
        sage inference logs -f        # æŒç»­è¾“å‡º
    """
    if not LOG_FILE.exists():
        console.print("[yellow]âš ï¸ æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨[/yellow]")
        console.print(f"[dim]é¢„æœŸè·¯å¾„: {LOG_FILE}[/dim]")
        return

    if follow:
        # Follow mode - like tail -f
        console.print(f"[dim]è·Ÿè¸ªæ—¥å¿—æ–‡ä»¶: {LOG_FILE}[/dim]")
        console.print("[dim]æŒ‰ Ctrl+C é€€å‡º[/dim]")
        console.print()

        try:
            import subprocess

            subprocess.run(["tail", "-f", str(LOG_FILE)])
        except KeyboardInterrupt:
            pass
    else:
        # Show last N lines
        try:
            with open(LOG_FILE) as f:
                all_lines = f.readlines()
                last_lines = all_lines[-lines:]
                for line in last_lines:
                    console.print(line.rstrip())
        except Exception as e:
            console.print(f"[red]âŒ æ— æ³•è¯»å–æ—¥å¿—: {e}[/red]")


if __name__ == "__main__":
    app()
