Metadata-Version: 2.4
Name: nsfwguard
Version: 1.0.1
Summary: GPU-accelerated NSFW content detection for images, videos, and URLs
Author: LISA-KOREA
License: MIT
Project-URL: Homepage, https://github.com/LISA-KOREA
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: torch
Requires-Dist: torchvision
Requires-Dist: nudenet
Requires-Dist: opencv-python
Requires-Dist: pillow
Requires-Dist: requests
Requires-Dist: fastapi
Requires-Dist: uvicorn
Provides-Extra: telegram
Requires-Dist: pyrofork; extra == "telegram"
Dynamic: license-file

# nsfwguard



ğŸš¨ **GPU-accelerated NSFW content detection** for **images, videos, and URLs**.

`nsfwguard` is a Python tool designed for developers who need fast and reliable NSFW moderation for
bots, websites, APIs, and content pipelines.

---

## âœ¨ Features

- ğŸ–¼ï¸ Image NSFW detection  
- ğŸ¥ Video NSFW detection (frame-based analysis)  
- ğŸŒ URL scanning  
- âš¡ GPU acceleration (automatic CUDA detection)  
- ğŸ“¦ Batch scanning  
- ğŸ’» CLI support  
- ğŸ¤– Telegram bot integration  
- ğŸ” Policy-based actions (ALLOW / WARN / BLOCK / BAN)

---

## ğŸš€ Installation

```bash
pip install nsfwguard
```


---

## Example: Scan image 

```python
from nsfwguard import scan_image

result = scan_image("image.jpg")
print(result)
```

## Example: Scan a video file

```python
from nsfwguard import scan_video

result = scan_video("video.mp4")
print(result)
```

## Example: Scan any URL
```python
from nsfwguard import scan_url

result = scan_url("https://example.com/file.jpg")
print(result)
```
