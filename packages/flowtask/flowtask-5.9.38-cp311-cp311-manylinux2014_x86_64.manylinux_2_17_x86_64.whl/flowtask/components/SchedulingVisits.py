from collections.abc import Callable
import asyncio
import contextlib
from datetime import datetime, date, timedelta, time
from pathlib import Path
from typing import Any, Dict
import math
import numpy as np
import pandas as pd
import calendar
import requests
from sklearn.neighbors import BallTree
from geopy.distance import geodesic  # For calculating distances
from ..exceptions import DataNotFound, ComponentError, ConfigError
from .flow import FlowComponent


# OSRM base URL for routing requests
OSRM_BASE_URL = "http://router.project-osrm.org"

class SchedulingVisits(FlowComponent):
    """
    Generating the Schedule of Employee Visits with Market Constraints and Visit Cadence.

    Overview:
        The SchedulingVisits class is a Flowtask component for generating a schedule of employee visits based on
        a set of rules and constraints. This component can be used to optimize the order of visits,
        minimize travel time, and balance workloads across employees.
        The schedule is generated by solving a combinatorial optimization
        problem with support for custom objective functions and constraints.

        Example of row consumed:
        ```
        associate_oid -> object -> G3Q86F5E1JXN1XVM
        corporate_email -> object -> buko@trocglobal.com
        employee_position -> object -> (3442724.8764311927, -10973885.176252203)
        store_id -> object -> BBY0178
        store_position -> object -> (3564143.804984759, -10887222.41833608)
        market -> object -> Market1
        visit_rule -> int64 -> 2
        visit_frequency -> object -> Monthly
        ```

        Example of Row Generated:
        ```

        ```


        Example:


        Note:
        - If 'ghost_employees_column' exists in the dataframe, it will use that value for each market
        - If the column doesn't exist or has null values, it will fall back to the 'ghost_employees' parameter
        - The 'ghost_domain' parameter allows you to customize the email domain for ghost employees
        - Ghost employee emails will be generated as: ghost_1@domain, ghost_2@domain, etc.
        - The 'start_hour' parameter sets when employees begin their workday (default: 9 AM)

        When roundtrip=True:
        - Reduces effective daily capacity (time/distance used for return trips)
        - More realistic scheduling for depot-based operations
        - Employees always end day at their starting hub/depot
        - May increase unscheduled stores due to return trip constraints

        When to use roundtrip=True:
        - Employees must return to central depot/hub
        - Vehicle check-in/check-out required
        - Union/labor requirements for end-of-day location
        - Security/safety requirements

        When to use roundtrip=False (default):
        - Employees can end day anywhere
        - Maximum coverage/efficiency desired
        - Field-based operations without central depot

    |---|---|---|
    | version | No | version of component |


        Example:

        | Name | Required | Summary |
    |---|---|---|
    | version | No | version of component |


        Example:

        ```yaml
          SchedulingVisits:
          use_ghost_employees: true
          ghost_employees: 1
          ghost_employees_column: 'ghost_employees'  # Column name in dataframe for dynamic ghost employees count
          ghost_domain: 'company.com'  # Domain for ghost employee emails
          in_store_percentage: 0.6
          in_store_visit: 0.75
          max_visits_per_day: 4
          max_distance: 120
          year: 2024
          month: 12
          start_hour: 9  # Start working at 9:00 AM
          exception_dates:
          - '2024-12-25'
          exceptions_filename: /home/ubuntu/symbits/Scheduling-Visits-Exceptions.xlsx
        ```
    """
    _version = "1.0.0"
    def __init__(
        self,
        loop: asyncio.AbstractEventLoop = None,
        job: Callable = None,
        stat: Callable = None,
        **kwargs,
    ):
        # TODO: add support for Masks
        # total hours worked per day
        self.day_duration: float = kwargs.pop('day_duration', 8.0)
        # 60% of the day in store
        self.in_store_percentage: float = kwargs.pop('in_store_percentage', 0.6)
        # near to 45 minutes in store
        self.in_store_visit_hours: float = kwargs.pop('in_store_visit', 0.75)  # Default 45 minutes
        self.in_store_visit_minutes: float = kwargs.pop('in_store_visit_minutes', None)
        self.in_store_visit_column: str = kwargs.pop('in_store_visit_column', 'in_store_visit')
        self._market_name: str = kwargs.pop('market_name', 'market')
        self._employee_column: str = kwargs.pop('employee_column', 'associate_oid')
        self.max_visits_per_day: int = kwargs.pop('max_visits_per_day', 4)
        # no more than 600 miles covered at day
        self.max_distance: int = kwargs.pop('max_distance', 600)
        # Average Speed:
        self.average_speed: float = kwargs.pop('average_speed', 40)
        # âœ… Roundtrip: if True, the route will be calculated as a round trip
        self.roundtrip: bool = kwargs.pop('roundtrip', False)
        # NEW: Start hour (when employees begin work)
        self.start_hour: int = kwargs.pop('start_hour', 9)  # Default 9:00 AM
        # Objective function: minimize total travel time
        self.use_ghost_employees: bool = kwargs.pop('use_ghost_employees', False)
        # Using 3 ghost employees per market if no employees are available.
        self.ghost_employees: int = kwargs.pop('ghost_employees', 3)
        # Column name for ghost_employees in dataframe (if exists)
        self.ghost_employees_column: str = kwargs.pop('ghost_employees_column', 'ghost_employees')
        # Visit Rule and frequency by default:
        self.visit_rule: int = kwargs.pop('visit_rule', 2)  # Default visit rule
        self.visit_frequency: str = kwargs.pop('visit_frequency', 'Monthly')  # Default visit frequency
        # calculate year and month of current day:
        today = date.today()
        self._today = today
        self.year: int = kwargs.pop('year', today.year)
        self.month: int = kwargs.pop('month', today.month)
        self.market_analysis = None
        super(SchedulingVisits, self).__init__(
            loop=loop,
            job=job,
            stat=stat,
            **kwargs
        )
        # If minutes specified, convert to hours and override
        if self.in_store_visit_minutes is not None:
            self.in_store_visit_hours = self.in_store_visit_minutes / 60
            self._logger.info(
                f"Using in_store_visit_minutes: {self.in_store_visit_minutes} min = {self.in_store_visit_hours:.4f} hours"  # noqa
            )
        else:
            self._logger.info(
                f"Using in_store_visit: {self.in_store_visit_hours} hours = {self.in_store_visit_hours * 60:.1f} minutes"  # noqa
            )
        # For backward compatibility, keep the original attribute name
        self.in_store_visit = self.in_store_visit_hours
        # Ghost Domain for email generation
        self.ghost_domain: str = kwargs.pop('ghost_domain', 'company.com')
        # Ghost Account template with configurable domain
        self._ghost_account = kwargs.pop('ghost_account', f'ghost_{{}}@{self.ghost_domain}')
        # exception days:
        self._exception_dates = kwargs.pop('exception_dates', [])

        # Log start hour configuration
        self._logger.info(f"Work day starts at: {self.start_hour:02d}:00")

        # Log roundtrip configuration
        if self.roundtrip:
            self._logger.info(
                "âœ… Roundtrip mode enabled - employees will return to start position each day"
            )
        else:
            self._logger.info(
                "ðŸ“ One-way mode - employees end day at last store location"
            )

    def _get_ghost_employees_count(self, market_data):
        """Get the number of ghost employees for a market.
        Priority: 1. Column in dataframe, 2. kwarg parameter, . default value"""
        if self.ghost_employees_column in market_data.columns:
            # Get the first non-null value from the column
            ghost_count = market_data[self.ghost_employees_column].dropna().iloc[0]
            if pd.isna(ghost_count):
                return self.ghost_employees
            return int(ghost_count)
        return self.ghost_employees

    def _calculate_visit_time(self, start_time: time, elapsed_minutes: float) -> time:
        """Calculate the visit time by adding elapsed minutes to start time."""
        start_datetime = datetime.combine(date.today(), start_time)
        visit_datetime = start_datetime + timedelta(minutes=elapsed_minutes)
        return visit_datetime.time()

    def _format_time(self, time_obj: time) -> str:
        """Format time as HH:MM AM/PM."""
        return time_obj.strftime("%I:%M %p")

    def get_workdays(self, year: int, month: int, exception_dates: list = None):
        """Get all workdays (Monday to Friday) in a given month, excluding exception dates."""
        first_day = date(year, month, 1)
        last_day = date(year, month, calendar.monthrange(year, month)[1])
        workdays = pd.bdate_range(first_day, last_day)
        if exception_dates:
            # Convert exception_dates to datetime
            exception_dates = pd.to_datetime(exception_dates)
            workdays = workdays.difference(exception_dates)
        return workdays

    def _get_fdom(self, year, month):
        """Function to get the first Monday of a given month
        (which is Labor Day in the US)."""
        cal = calendar.Calendar()
        first_monday = None
        for day in cal.itermonthdays2(year, month):
            if day[0] != 0 and day[1] == 0:  # day[1] == 0 means Monday
                first_monday = day[0]
                break
        return datetime(year, month, first_monday)

    def get_distance(self, coord1, coord2):
        """Function to calculate distance
        between two points (latitude, longitude)."""
        return geodesic(coord1, coord2).miles

    def to_miles(self, distance) -> float:
        return distance * 0.621371  # Convert to miles

    def to_hours(self, minutes) -> float:
        return minutes / 60  # Convert to hours

    def get_labor_days(self, year: int = 2024, month: int = 9):
        """Function to get all workdays (Monday to Friday) in a given month."""
        # Get first Labor Day (first Monday) of the month
        labor_day = self._get_fdom(year, month)
        # Generate list of weekdays (excluding weekends) starting from Labor Day
        workdays = []
        current_day = labor_day
        while current_day.month == month:
            if current_day.weekday() < 5:  # Only Monday to Friday (weekday < 5)
                workdays.append(current_day)
            current_day += timedelta(days=1)
        return workdays

    def get_travel(self, waypoints, transportation: str = 'driving'):
        # Build the request URL for OSRM driving route
        # including all waypoints
        osrm_url = f"{OSRM_BASE_URL}/route/v1/{transportation}/{waypoints}?overview=false"
        # Send the request to OSRM API
        response = requests.get(osrm_url)
        # Check if the request was successful
        if response.status_code == 200:
            route_data = response.json()
            # Extract total travel duration and distance (in seconds and meters)
            # Total duration
            duration_seconds = route_data['routes'][0]['duration']
            # Total distance
            distance_meters = route_data['routes'][0]['distance']
            # Convert to more readable formats
            duration_minutes = duration_seconds / 60
            distance_km = distance_meters / 1000
            return duration_minutes, distance_km
        else:
            return 0, 0

    def get_travel_duration(self, origin, destination):
        """Helper function to get distance and duration between two points.
        """
        waypoints = f"{origin[1]},{origin[0]};{destination[1]},{destination[0]}"
        duration_minutes, distance_km = self.get_travel(waypoints, transportation='driving')
        distance_miles = self.to_miles(distance_km)
        return distance_miles, duration_minutes

    def get_scheduled_dates(
        self,
        cadence: str,
        visit_rule: float,
        visit_frequency: Any,
        workdays: pd.DatetimeIndex,
        store_index: int
    ):
        """Given the visit_rule and visit_frequency,
        return a list of scheduled dates for the visits."""
        scheduled_dates = []

        if len(workdays) == 0:
            return scheduled_dates

        # Set visit_frequency and visit_rule based on cadence if provided
        if cadence:
            cadence = cadence.lower()
            if 'xweek' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'weekly'
            elif 'xmonth' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'monthly'
            elif 'xqtr' in cadence:
                num = int(cadence[0])
                visit_rule = num
                visit_frequency = 'quarterly'

        if visit_frequency.lower() == 'quarterly':
            # For simplicity, schedule as monthly with 1 visit per month
            visit_frequency = 'monthly'
            visit_rule = 1

        # Normalize visit_rule to a usable numeric form
        try:
            visit_rule_value = float(visit_rule)
        except (TypeError, ValueError):
            visit_rule_value = 0.0

        if math.isnan(visit_rule_value):
            visit_rule_value = 0.0

        visit_iterations = int(math.ceil(visit_rule_value)) if visit_rule_value > 0 else 0

        if visit_frequency.lower() == 'weekly':
            # FIXED: Proper indentation for weekly scheduling
            workdays_df = pd.DataFrame({'date': workdays})
            workdays_df['week'] = workdays_df['date'].dt.isocalendar().week
            weeks = sorted(workdays_df['week'].unique())

            for week in weeks:  # This loop was missing proper indentation
                week_days = workdays_df[workdays_df['week'] == week]['date'].sort_values().reset_index(drop=True)
                num_days = len(week_days)
                if num_days == 0:
                    continue

                # Ensure we don't exceed available days
                num_visits = min(visit_iterations, num_days)

                # Distribute visits evenly within the week
                for i in range(num_visits):
                    if i < num_days:
                        # Use store_index to stagger start days for different stores
                        day_index = (store_index + i) % num_days
                        scheduled_date = week_days[day_index]
                        scheduled_dates.append(scheduled_date)

        elif visit_frequency.lower() == 'monthly':
            # Improved monthly scheduling
            total_days = len(workdays)
            if visit_iterations == 0:
                visit_iterations = 1
                visit_rule_value = max(visit_rule_value, 1.0)
            if visit_rule_value > total_days:
                # If we need more visits than available days, schedule one per day
                scheduled_dates = list(workdays)
            else:
                # Distribute visits evenly across the month
                interval = total_days / max(visit_rule_value, 1.0)
                for i in range(visit_iterations):
                    # Calculate target day index with small offset based on store
                    target_index = int(i * interval + (store_index % 5))
                    # Ensure we don't exceed array bounds
                    day_index = min(target_index, total_days - 1)
                    # Avoid duplicate dates
                    candidate_date = workdays[day_index]
                    if candidate_date not in scheduled_dates:
                        scheduled_dates.append(candidate_date)
                    else:
                        # Find next available date
                        for offset in range(1, total_days):
                            alt_index = (day_index + offset) % total_days
                            alt_date = workdays[alt_index]
                            if alt_date not in scheduled_dates:
                                scheduled_dates.append(alt_date)
                                break
        else:
            # Default fallback to monthly behavior
            total_days = len(workdays)
            visits_to_schedule = visit_iterations if visit_iterations > 0 else 1
            interval = total_days / max(visit_rule_value, 1.0)
            for i in range(visits_to_schedule):
                day_index = min(int(i * interval), total_days - 1)
                scheduled_dates.append(workdays[day_index])

        return sorted(scheduled_dates)

    def analyze_market_capacity(self, df):
        """Analyze each market's capacity requirements using actual assigned employees."""
        market_analysis = {}
        total_employees_needed = 0

        self._logger.info("=== MARKET CAPACITY ANALYSIS ===")

        for market in df['market'].unique():
            market_data = df[df['market'] == market]
            store_count = len(market_data)

            # Calculate visits needed per month
            total_visits = 0
            for _, store in market_data.iterrows():
                visit_rule = store.get('visit_rule', self.visit_rule)
                visit_frequency = store.get('visit_frequency', self.visit_frequency).lower()

                if visit_frequency == 'weekly':
                    # 4-5 weeks per month
                    monthly_visits = visit_rule * 4.3
                elif visit_frequency == 'monthly':
                    monthly_visits = visit_rule
                else:
                    monthly_visits = visit_rule

                total_visits += monthly_visits

            # Calculate employees needed (assuming max capacity per employee per month)
            max_visits_per_employee = self.max_visits_per_day * len(
                self.get_workdays(self.year, self.month, self._exception_dates)
            )
            employees_needed = np.ceil(total_visits / max_visits_per_employee)
            total_employees_needed += employees_needed

            # Count ACTUAL assigned employees for this market
            if 'associate_oid' in market_data.columns:
                # Count unique employees assigned to this market
                actual_employees = market_data['associate_oid'].nunique()
                # Filter out null/None values
                actual_employees = len(
                    [emp for emp in market_data['associate_oid'].unique() if emp is not None and pd.notna(emp)])
            else:
                # If no employees assigned yet, use the prediction method
                actual_employees = self._get_ghost_employees_count(market_data)

            market_analysis[market] = {
                'store_count': store_count,
                'total_monthly_visits': int(total_visits),
                'employees_needed': int(employees_needed),
                'current_employees': actual_employees
            }

            self._logger.info(f"Market: {market}")
            self._logger.info(f"  Stores: {store_count}, Visits needed: {int(total_visits)}")
            self._logger.info(f"  Employees needed: {int(employees_needed)}, Current: {actual_employees}")

            if employees_needed > actual_employees:
                self._logger.warning(f"  âš ï¸  Market {market} is UNDER-STAFFED!")
            elif actual_employees == 0:
                self._logger.error(f"  âŒ Market {market} has NO EMPLOYEES assigned!")
            else:
                self._logger.info(f"  âœ… Market {market} is adequately staffed")

        self._logger.info(
            f"Total employees needed across all markets: {int(total_employees_needed)}"
        )
        return market_analysis

    async def start(self, **kwargs):
        if self.previous:
            self.data: pd.DataFrame = self.input
            if not isinstance(self.data, pd.DataFrame):
                raise ConfigError(
                    "Incompatible Pandas Dataframe", status=404
                )
        else:
            raise DataNotFound(
                "Data Not Found", status=404
            )
        await super().start(**kwargs)
        # if dataframe doesn't have a store_position attribute
        if 'store_position' not in self.data.columns:
            # Create the store_position column
            self.data['store_position'] = self.data.apply(
                lambda row: (row['latitude'], row['longitude']),
                axis=1
            )
        # Exceptions Filename:
        self._exceptions_file = None
        if hasattr(self, 'exceptions_filename'):
            self._exceptions_file = Path(self.exceptions_filename).resolve()
        return True

    async def close(self):
        pass

    def debug_scheduling_progress(self, schedule_df, exception_df):
        """Enhanced debug method with duplicate store visit detection."""
        self._logger.info("=== SCHEDULING DEBUG INFO ===")

        if len(schedule_df) > 0:
            min_date = schedule_df['day'].min()
            max_date = schedule_df['day'].max()
            unique_days = schedule_df['day'].nunique()

            workdays = self.get_workdays(self.year, self.month, self._exception_dates)
            expected_business_days = len(workdays)

            self._logger.info(f"Schedule date range: {min_date.date()} to {max_date.date()}")
            self._logger.info(f"Unique days scheduled: {unique_days}")
            self._logger.info(f"Expected business days in month: {expected_business_days}")

            # âœ… NEW: Check for duplicate store visits
            self._logger.info("\n=== DUPLICATE STORE VISIT ANALYSIS ===")

            # Count visits per store across all employees
            all_store_visits = {}
            employee_store_visits = {}

            for _, row in schedule_df.iterrows():
                employee_id = row['associate_oid']
                day = row['day']

                if 'store_ids' in row and row['store_ids']:
                    for store_id in row['store_ids']:
                        # Track overall visits
                        if store_id not in all_store_visits:
                            all_store_visits[store_id] = []
                        all_store_visits[store_id].append((employee_id, day))

                        # Track per employee
                        if employee_id not in employee_store_visits:
                            employee_store_visits[employee_id] = {}
                        if store_id not in employee_store_visits[employee_id]:
                            employee_store_visits[employee_id][store_id] = []
                        employee_store_visits[employee_id][store_id].append(day)

            # Find stores visited more than their required number of times
            over_visited_stores = []
            for store_id, visits in all_store_visits.items():
                # Get required visits for this store
                store_data = self.data[self.data['store_id'] == store_id]
                if len(store_data) > 0:
                    required_visits = store_data.iloc[0].get('visit_rule', 2)
                    actual_visits = len(visits)

                    if actual_visits > required_visits:
                        over_visited_stores.append({
                            'store_id': store_id,
                            'required': required_visits,
                            'actual': actual_visits,
                            'excess': actual_visits - required_visits,
                            'visits': visits
                        })

            if over_visited_stores:
                self._logger.warning(
                    f"âŒ Found {len(over_visited_stores)} over-visited stores:"
                )
                for store_info in over_visited_stores[:10]:  # Show top 10
                    store_id = store_info['store_id']
                    self._logger.warning(
                        f"  Store {store_id}: {store_info['actual']}/{store_info['required']} visits "
                        f"(+{store_info['excess']} excess)"
                    )

                    # Show which days it was visited
                    visit_days = [visit[1].strftime('%Y-%m-%d') for visit in store_info['visits']]
                    self._logger.warning(f"    Visited on: {', '.join(visit_days)}")
            else:
                self._logger.info("âœ… No over-visited stores detected")

            # Check for same store visited on same day by same employee
            same_day_duplicates = []
            for employee_id, stores in employee_store_visits.items():
                for store_id, visit_days in stores.items():
                    if len(visit_days) != len(set(visit_days)):
                        # Same store visited multiple times on same day
                        from collections import Counter
                        day_counts = Counter(visit_days)
                        duplicate_days = {day: count for day, count in day_counts.items() if count > 1}
                        same_day_duplicates.append({
                            'employee_id': employee_id,
                            'store_id': store_id,
                            'duplicate_days': duplicate_days
                        })

            if same_day_duplicates:
                self._logger.error(f"âŒ Found {len(same_day_duplicates)} same-day duplicate visits:")
                for dup in same_day_duplicates:
                    self._logger.error(
                        f"  Employee {dup['employee_id']}, Store {dup['store_id']}: "
                        f"{dup['duplicate_days']}"
                    )
            else:
                self._logger.info("âœ… No same-day duplicate visits detected")

            # Regular capacity analysis
            daily_stats = schedule_df.groupby('day').agg({
                'stores_visited_count': 'sum',
                'total_distance': 'mean',
                'total_time_hours': 'mean'
            }).round(2)

            avg_stores_per_day = daily_stats['stores_visited_count'].mean()
            max_stores_in_day = daily_stats['stores_visited_count'].max()

            self._logger.info("\n=== CAPACITY ANALYSIS ===")
            self._logger.info(f"Average stores per day: {avg_stores_per_day:.1f}")
            self._logger.info(f"Maximum stores in a day: {max_stores_in_day}")
            self._logger.info(
                f"Average distance per employee per day: {daily_stats['total_distance'].mean():.1f} miles"
            )
            self._logger.info(
                f"Average hours per employee per day: {daily_stats['total_time_hours'].mean():.1f} hours"
            )

            # Check capacity utilization
            theoretical_max_visits = len(schedule_df) * self.max_visits_per_day
            actual_visits = daily_stats['stores_visited_count'].sum()
            utilization = (actual_visits / theoretical_max_visits) * 100

            self._logger.info(
                f"Capacity utilization: {utilization:.1f}% ({actual_visits:,}/{theoretical_max_visits:,})"
            )

            # Check for missed days
            scheduled_days = set(schedule_df['day'].dt.date)
            missing_days = [day.date() for day in workdays if day.date() not in scheduled_days]

            if missing_days:
                self._logger.warning(f"Days with NO visits: {missing_days}")
            else:
                self._logger.info("âœ… All business days utilized")

        else:
            self._logger.error("âŒ No visits scheduled!")

        # Exception analysis (existing code)
        if len(exception_df) > 0:
            self._logger.info("\n=== EXCEPTION ANALYSIS ===")
            self._logger.info(f"Unscheduled visits: {len(exception_df):,}")

            # Analyze constraint failures
            constraint_analysis = {
                'no_capacity': 0,
                'max_stores': 0,
                'time_limit': 0,
                'distance_limit': 0,
                'already_visited': 0
            }

            for reason in exception_df['reason']:
                if 'No capacity' in reason or 'No more workdays' in reason:
                    constraint_analysis['no_capacity'] += 1
                elif 'store visited' in reason:
                    constraint_analysis['already_visited'] += 1
                elif 'Max stores reached' in reason:
                    constraint_analysis['max_stores'] += 1
                elif 'Time limit exceeded' in reason or 'day duration' in reason:
                    constraint_analysis['time_limit'] += 1
                elif 'Distance limit exceeded' in reason or 'distance' in reason:
                    constraint_analysis['distance_limit'] += 1

            self._logger.info("Exception reason breakdown:")
            for constraint, count in constraint_analysis.items():
                if count > 0:
                    percentage = (count / len(exception_df)) * 100
                    self._logger.info(
                        f"  {constraint.replace('_', ' ').title()}: {count:,} ({percentage:.1f}%)"
                    )

        else:
            self._logger.info("âœ… All visits successfully scheduled!")

    def log_roundtrip_summary(self, schedule_df):
        """Log summary statistics about roundtrip scheduling."""
        if not self.roundtrip or len(schedule_df) == 0:
            return

        self._logger.info("=== ROUNDTRIP ANALYSIS ===")

        # Calculate roundtrip statistics
        total_return_distance = schedule_df['return_trip_distance'].sum()
        total_return_time = schedule_df['return_trip_time'].sum()
        avg_return_distance = schedule_df['return_trip_distance'].mean()
        avg_return_time = schedule_df['return_trip_time'].mean()

        # Days with/without visits
        days_with_visits = len(schedule_df)

        self._logger.info(f"Return trips scheduled: {days_with_visits:,} days")
        self._logger.info(f"Total return distance: {total_return_distance:.1f} miles")
        self._logger.info(f"Total return time: {total_return_time:.1f} minutes ({total_return_time/60:.1f} hours)")
        self._logger.info(f"Average return distance per day: {avg_return_distance:.1f} miles")
        self._logger.info(f"Average return time per day: {avg_return_time:.1f} minutes")

        # Impact analysis
        total_travel_time = schedule_df['total_travel_time'].sum()
        return_percentage = (total_return_time / total_travel_time) * 100 if total_travel_time > 0 else 0

        total_distance = schedule_df['total_distance'].sum()
        return_distance_percentage = (total_return_distance / total_distance) * 100 if total_distance > 0 else 0

        self._logger.info(
            f"Return trips represent {return_percentage:.1f}% of total travel time"
        )
        self._logger.info(
            f"Return trips represent {return_distance_percentage:.1f}% of total distance"
        )

        # Constraint impact
        max_return_time = schedule_df['return_trip_time'].max()
        max_return_distance = schedule_df['return_trip_distance'].max()

        self._logger.info(
            f"Longest return trip: {max_return_distance:.1f} miles, {max_return_time:.1f} minutes"
        )

        # Check if return trips are causing capacity issues
        tight_time_days = len(schedule_df[schedule_df['total_time_hours'] > (self.day_duration * 0.9)])
        if tight_time_days > 0:
            self._logger.warning(
                f"âš ï¸  {tight_time_days} days use >90% of available time (return trips may be limiting capacity)"
            )

        tight_distance_days = len(schedule_df[schedule_df['total_distance'] > (self.max_distance * 0.9)])
        if tight_distance_days > 0:
            self._logger.warning(
                f"âš ï¸  {tight_distance_days} days use >90% of max distance (return trips may be limiting capacity)"
            )

    def _calculate_employee_position(self, employee_data: Dict) -> tuple:
        """Calculate the employee's position.
            If employee_position exists, use it.
            Otherwise, calculate the centroid of assigned stores.
        """
        if 'employee_position' in employee_data and pd.notna(employee_data['employee_position']):
            return employee_data['employee_position']
        else:
            # Calculate centroid of assigned stores
            positions = np.array([pos for pos in employee_data['store_position']])
            mean_position = positions.mean(axis=0)
            lat_offset = np.random.uniform(-0.00045, 0.00045)
            lon_offset = np.random.uniform(-0.00045, 0.00045)

            if len(positions) == 0:
                raise ValueError(
                    "No store positions available to calculate centroid."
                )
            return (mean_position[0] + lat_offset, mean_position[1] + lon_offset)

    async def run(self):
        self._logger.debug('=== RUNNING FUNCTION SCHEDULING VISITS ===')

        # STEP 1: Analyze market capacity requirements FIRST
        self._logger.info("Analyzing market capacity requirements...")

        # Track store counts per market for downstream reporting
        if self._market_name in self.data.columns:
            if 'store_id' in self.data.columns:
                market_counts = (
                    self.data.groupby(self._market_name)['store_id']
                    .transform('nunique')
                )
            else:
                market_counts = (
                    self.data.groupby(self._market_name)[self._market_name]
                    .transform('count')
                )
            self.data['market_count'] = market_counts.fillna(0).astype(int)
        else:
            self._logger.warning(
                "Market column '%s' not present; unable to compute market counts.",
                self._market_name,
            )

        # Get workdays
        workdays = self.get_workdays(self.year, self.month, self._exception_dates)
        self._logger.info(
            f"Working with {len(workdays)} business days in {self.year}-{self.month}"
        )

        # Initialize a dictionary to keep track of assignments and exceptions
        schedule_rows = []
        exception_rows = []

        if self.use_ghost_employees or 'associate_oid' not in self.data.columns:
            # Create multiple ghost employees per market
            self._logger.info("Using ghost employees for scheduling...")
            markets = self.data[self._market_name].unique()
            ghost_employees = {}
            self.data['associate_oid'] = None  # Initialize associate_oid column

            for market in markets:
                market_data = self.data[self.data[self._market_name] == market]
                positions = np.array([pos for pos in market_data['store_position']])
                mean_position = positions.mean(axis=0)

                # Get dynamic ghost employees count for this market
                ghost_employees_count = self._get_ghost_employees_count(market_data)
                if ghost_employees_count < 1:
                    ghost_employees_count = self.ghost_employees

                # Create ghost_employees_count ghost employees per market
                ghost_employee_ids = [f'{market}_ghost_{i+1}' for i in range(ghost_employees_count)]
                # Generate unique emails for ghost employees
                ghost_employee_emails = [self._ghost_account.format(i + 1) for i in range(ghost_employees_count)]
                # Generate positions with small variations
                ghost_employee_positions = []
                for i in range(ghost_employees_count):
                    # Generate small random offsets in degrees (~50 meters variation)
                    # 1 degree latitude ~ 111 km, so 50 meters ~ 0.00045 degrees
                    lat_offset = np.random.uniform(-0.00045, 0.00045)
                    lon_offset = np.random.uniform(-0.00045, 0.00045)
                    ghost_position = (mean_position[0] + lat_offset, mean_position[1] + lon_offset)
                    ghost_employee_positions.append(ghost_position)

                # Assign stores to ghost employees in a round-robin fashion
                market_store_indices = market_data.index
                num_stores = len(market_store_indices)
                for idx, store_idx in enumerate(market_store_indices):
                    try:
                        assigned_employee_index = idx % ghost_employees_count
                    except ZeroDivisionError:
                        assigned_employee_index = idx % self.ghost_employees
                    assigned_employee_id = ghost_employee_ids[assigned_employee_index]
                    self.data.at[store_idx, 'associate_oid'] = assigned_employee_id

                # Store the email and position for each ghost employee
                for i, assigned_employee_id in enumerate(ghost_employee_ids):
                    ghost_employees[assigned_employee_id] = {
                        'position': ghost_employee_positions[i],
                        'email': ghost_employee_emails[i],
                        'market': market
                    }

            # After assigning stores to ghost employees
            store_assignments = self.data.groupby('store_id')['associate_oid'].nunique()
            overlapping_stores = store_assignments[store_assignments > 1]
            if not overlapping_stores.empty:
                print("Stores assigned to multiple employees:")
                print(overlapping_stores)
            else:
                print("All stores uniquely assigned.")

            # Now group by associate_oid
            employee_groups = self.data.groupby('associate_oid')

        # Check if employee information is available
        elif self._employee_column in self.data.columns:
            employee_groups = self.data.groupby(self._employee_column)
            # Group the data by employee
            ghost_employees = {}  # Not needed but kept for consistency
        else:
            raise ComponentError(
                "No employee information available."
                " Please ensure 'associate_oid' or 'employee_column' is present in the data.",
            )

        # Doing the Market Capacity Analysis
        self._logger.info(
            "Analyzing market capacity with assigned employees..."
        )
        market_analysis = self.analyze_market_capacity(self.data)

        # Check if current configuration can handle the load
        total_employees_needed = sum(
            m['employees_needed'] for m in market_analysis.values()
        )
        total_current_employees = sum(
            m['current_employees'] for m in market_analysis.values()
        )

        self._logger.info(
            f"Total employees needed: {total_employees_needed}"
        )
        self._logger.info(
            f"Total current employees: {total_current_employees}"
        )

        if total_employees_needed > total_current_employees:
            self._logger.warning(
                f"CAPACITY WARNING: Need {total_employees_needed} employees but only have {total_current_employees}"  # noqa
            )
            self._logger.warning(
                "Consider increasing 'ghost_employees' parameter or adjusting constraints"
            )
        else:
            self._logger.info(
                "âœ… Sufficient employee capacity for all markets"
            )

        # Prepare a list to collect scheduled visits
        self._logger.info("Starting scheduling process...")

        all_required_visits = []

        for employee_id, employee_data in employee_groups:
            # Get employee information
            employee_info = employee_data.iloc[0]
            if 'corporate_email' in employee_info:
                employee_email = employee_info['corporate_email']
            else:
                employee_email = ghost_employees[employee_id]['email']

            if 'employee_position' in employee_info:
                employee_position = employee_info['employee_position']
            else:
                with contextlib.suppress(Exception):
                    employee_position = self._calculate_employee_position(employee_data)
                if 'position' in ghost_employees.get(employee_id, {}):
                    employee_position = ghost_employees[employee_id]['position']

            self._logger.notice(
                f'Employee {employee_email} ({employee_id}): position {employee_position}'
            )

            # Get unique stores for this employee (prevent duplicates)
            unique_stores = employee_data.drop_duplicates('store_id')

            self._logger.notice(
                f"Employee {employee_email}: processing {len(unique_stores)} stores"
            )

            # For each store, create the required visits
            for _, store_row in unique_stores.iterrows():
                visit_rule = store_row.get('visit_rule', self.visit_rule)
                visit_frequency = store_row.get('visit_frequency', self.visit_frequency)
                cadence = store_row.get('cadence', None)
                store_in_store_visit = self.in_store_visit
                if self.in_store_visit_column in store_row:
                    column_value = store_row.get(self.in_store_visit_column)
                    if pd.notna(column_value):
                        try:
                            store_in_store_visit = float(column_value)
                        except (TypeError, ValueError):
                            self._logger.warning(
                                "Invalid in_store_visit value '%s' for store %s. Using default %.2f hours.",
                                column_value,
                                store_row.get('store_id', 'Unknown'),
                                self.in_store_visit,
                            )

                # Generate scheduled dates for this store
                store_unique_id = hash(store_row['store_id']) % (10 ** 8)
                scheduled_dates = self.get_scheduled_dates(
                    cadence,
                    visit_rule,
                    visit_frequency,
                    workdays,
                    store_index=store_unique_id
                )

                # Create one visit record per scheduled date
                for scheduled_date in scheduled_dates:
                    visit_record = {
                        'associate_oid': employee_id,
                        'corporate_email': employee_email,
                        'employee_position': employee_position,
                        'store_id': store_row['store_id'],
                        'store_name': store_row.get('store_name', 'Unknown'),
                        'market': store_row['market'],
                        'store_position': store_row['store_position'],
                        'scheduled_date': scheduled_date,
                        'visit_rule': visit_rule,
                        'visit_frequency': visit_frequency,
                        'in_store_visit': store_in_store_visit
                    }
                    all_required_visits.append(visit_record)

        total_required_visits = len(all_required_visits)
        self._logger.info(f"Total visits to schedule: {total_required_visits:,}")

        # Step 2: Group visits by employee and schedule day by day
        schedule_rows = []
        exception_rows = []

        # Group required visits by employee
        visits_by_employee = {}
        for visit in all_required_visits:
            emp_id = visit['associate_oid']
            if emp_id not in visits_by_employee:
                visits_by_employee[emp_id] = []
            visits_by_employee[emp_id].append(visit)

        # Schedule each employee's visits
        for employee_id, employee_visits in visits_by_employee.items():
            self._logger.info(
                f"Scheduling {len(employee_visits)} visits for employee {employee_id}"
            )

            # Get employee info from first visit
            first_visit = employee_visits[0]
            employee_email = first_visit['corporate_email']
            employee_position = first_visit['employee_position']
            market = first_visit['market']

            # Track how many times each store has been visited for this employee
            store_visit_tracker = {}
            for visit in employee_visits:
                store_id = visit['store_id']
                visit_rule = visit['visit_rule']
                if store_id not in store_visit_tracker:
                    store_visit_tracker[store_id] = {
                        'required_visits': visit_rule,
                        'scheduled_visits': 0,
                        'store_info': visit
                    }

            # Sort visits by scheduled date (earliest first)
            employee_visits.sort(key=lambda x: x['scheduled_date'])

            # Schedule visits day by day
            current_workday_index = 0
            visit_index = 0

            while visit_index < len(employee_visits) and current_workday_index < len(workdays):
                current_day = workdays[current_workday_index]

                # Initialize day schedule
                day_schedule = {
                    'associate_oid': employee_id,
                    'corporate_email': employee_email,
                    'start_position': employee_position,
                    'market': market,
                    'day': current_day,
                    'month': self.month,
                    'year': self.year,
                    'work_start_time': time(self.start_hour, 0),  # NEW: Store work start time
                    'total_time_minutes': 0,
                    'total_time_hours': 0,
                    'total_in_store_time': 0,
                    'total_travel_time': 0,
                    'total_distance': 0,
                    'stores_visited_count': 0,
                    'visited_stores': {},
                    'store_ids': []
                }

                current_position = employee_position
                stores_scheduled_today = 0
                # NEW: Track cumulative time for visit scheduling
                cumulative_time_minutes = 0

                # Fill this day up to max_stores
                while stores_scheduled_today < self.max_visits_per_day and visit_index < len(employee_visits):
                    visit = employee_visits[visit_index]
                    store_id = visit['store_id']

                    # âœ… CHECK: Has this store already been visited enough times?
                    if store_visit_tracker[store_id]['scheduled_visits'] >= store_visit_tracker[store_id]['required_visits']:  # noqa
                        # Skip this visit - store already visited enough times
                        visit_index += 1
                        continue

                    # âœ… CHECK: Is this store already scheduled for today?
                    if store_id in day_schedule['store_ids']:
                        # Skip this visit - store already scheduled for today
                        visit_index += 1
                        continue

                    # Calculate travel requirements
                    distance_miles = self.get_distance(current_position, visit['store_position'])
                    travel_time = (distance_miles / self.average_speed) * 60  # minutes
                    visit_in_store_visit = visit.get('in_store_visit', self.in_store_visit)
                    if pd.isna(visit_in_store_visit):
                        visit_in_store_visit = self.in_store_visit
                    try:
                        time_in_store = float(visit_in_store_visit) * 60  # minutes
                    except (TypeError, ValueError):
                        self._logger.warning(
                            "Invalid in_store_visit '%s' for visit %s. Falling back to default %.2f hours.",
                            visit_in_store_visit,
                            visit.get('store_id', 'Unknown'),
                            self.in_store_visit,
                        )
                        time_in_store = self.in_store_visit * 60
                        visit_in_store_visit = self.in_store_visit

                    # âœ… Calculate return trip if roundtrip mode is enabled
                    return_distance = 0
                    return_travel_time = 0

                    if self.roundtrip:
                        # Calculate distance and time from this store back to start position
                        return_distance = self.get_distance(visit['store_position'], employee_position)
                        return_travel_time = (return_distance / self.average_speed) * 60  # minutes

                    # Total time needed including potential return trip
                    total_time_needed = travel_time + time_in_store + return_travel_time
                    total_distance_needed = distance_miles + return_distance

                    # Check if this visit fits in today's constraints (including return trip)
                    fits_time = (day_schedule['total_time_minutes'] + total_time_needed) <= (self.day_duration * 60)
                    fits_distance = (day_schedule['total_distance'] + total_distance_needed) <= self.max_distance

                    if fits_time and fits_distance:
                        # NEW: Calculate the actual visit time
                        arrival_time = self._calculate_visit_time(
                            day_schedule['work_start_time'],
                            cumulative_time_minutes + travel_time
                        )
                        departure_time = self._calculate_visit_time(
                            day_schedule['work_start_time'],
                            cumulative_time_minutes + travel_time + time_in_store
                        )

                        # âœ… SCHEDULE THIS VISIT (single update, no duplicates)
                        day_schedule['total_time_minutes'] += travel_time + time_in_store
                        day_schedule['total_distance'] += distance_miles  # Don't add return distance yet
                        day_schedule['total_in_store_time'] += time_in_store
                        day_schedule['total_travel_time'] += travel_time

                        # Add store information with NEW fields: visit_order and visit_time
                        visit_order = stores_scheduled_today + 1
                        day_schedule['visited_stores'][store_id] = {
                            'store_id': store_id,
                            'store_name': visit['store_name'],
                            'latitude': visit['store_position'][0],
                            'longitude': visit['store_position'][1],
                            'visit_rule': visit['visit_rule'],
                            'visit_frequency': visit['visit_frequency'],
                            'market': visit['market'],
                            # NEW: Visit order and timing information
                            'visit_order': visit_order,
                            'arrival_time': self._format_time(arrival_time),
                            'departure_time': self._format_time(departure_time),
                            'arrival_time_24h': arrival_time.strftime("%H:%M"),
                            'departure_time_24h': departure_time.strftime("%H:%M"),
                            'time_in_store_minutes': time_in_store,
                            'in_store_visit_hours': visit_in_store_visit,
                            'travel_time_to_store_minutes': travel_time,
                            'distance_to_store_miles': round(distance_miles, 2)
                        }

                        # Update visit tracking (single update)
                        day_schedule['store_ids'].append(store_id)
                        day_schedule['stores_visited_count'] = len(day_schedule['store_ids'])
                        store_visit_tracker[store_id]['scheduled_visits'] += 1

                        # Update position and counters
                        current_position = visit['store_position']
                        stores_scheduled_today += 1
                        visit_index += 1

                        # NEW: Update cumulative time for next visit calculation
                        cumulative_time_minutes += travel_time + time_in_store

                        self._logger.debug(
                            f"Scheduled store {store_id} on {current_day.date()} "
                            f"at {self._format_time(arrival_time)} (visit #{visit_order}) "
                            f"(visit {store_visit_tracker[store_id]['scheduled_visits']}"
                            f"/{store_visit_tracker[store_id]['required_visits']})"
                            f"{' + return trip' if self.roundtrip else ''}"
                        )
                    else:
                        # This visit doesn't fit today - move to next day
                        if not fits_time:
                            reason = f"time constraint (need {total_time_needed:.1f}min, have {(self.day_duration * 60) - day_schedule['total_time_minutes']:.1f}min)"  # noqa
                        else:
                            reason = f"distance constraint (need {total_distance_needed:.1f}mi, have {self.max_distance - day_schedule['total_distance']:.1f}mi)"  # noqa

                        self._logger.debug(
                            f"Store {store_id} doesn't fit on {current_day.date()}: {reason}"
                            f"{' (includes return trip)' if self.roundtrip else ''}"
                        )
                        break

                # Add this day's schedule if any visits were scheduled
                if day_schedule['stores_visited_count'] > 0:
                    if self.roundtrip:
                        # Calculate return trip from last store to start position
                        last_store_position = current_position  # This is the last store visited
                        final_return_distance = self.get_distance(last_store_position, employee_position)
                        final_return_time = (final_return_distance / self.average_speed) * 60  # minutes

                        # Calculate end of workday time
                        end_time = self._calculate_visit_time(
                            day_schedule['work_start_time'],
                            cumulative_time_minutes + final_return_time
                        )

                        # Add return trip to day totals
                        day_schedule['total_distance'] += final_return_distance
                        day_schedule['total_travel_time'] += final_return_time
                        day_schedule['total_time_minutes'] += final_return_time

                        # Add return trip information to day schedule
                        day_schedule['return_trip_distance'] = round(final_return_distance, 2)
                        day_schedule['return_trip_time'] = round(final_return_time, 1)
                        day_schedule['final_position'] = employee_position  # Employee ends where they started
                        day_schedule['work_end_time'] = self._format_time(end_time)
                        day_schedule['work_end_time_24h'] = end_time.strftime("%H:%M")

                        self._logger.debug(
                            f"Added return trip on {current_day.date()}: "
                            f"{final_return_distance:.1f} miles, {final_return_time:.1f} minutes, "
                            f"ending at {self._format_time(end_time)}"
                        )
                    else:
                        # No return trip - employee ends at last store
                        end_time = self._calculate_visit_time(
                            day_schedule['work_start_time'],
                            cumulative_time_minutes
                        )
                        day_schedule['return_trip_distance'] = 0
                        day_schedule['return_trip_time'] = 0
                        day_schedule['final_position'] = current_position  # Employee ends at last store
                        day_schedule['work_end_time'] = self._format_time(end_time)
                        day_schedule['work_end_time_24h'] = end_time.strftime("%H:%M")

                    # Calculate final day totals
                    day_schedule['total_time_hours'] = day_schedule['total_time_minutes'] / 60
                    schedule_rows.append(day_schedule)

                # Move to next workday
                current_workday_index += 1

            # Any remaining visits that couldn't be scheduled
            while visit_index < len(employee_visits):
                visit = employee_visits[visit_index]
                store_id = visit['store_id']

                # Only add to exceptions if the store hasn't been visited enough times
                if store_visit_tracker[store_id]['scheduled_visits'] < store_visit_tracker[store_id]['required_visits']:
                    # âœ…  Calculate distance from start point to unvisited store
                    distance_from_start = self.get_distance(employee_position, visit['store_position'])
                    exception_row = {
                        'associate_oid': employee_id,
                        'corporate_email': employee_email,
                        'market': visit['market'],
                        'year': self.year,
                        'month': self.month,
                        'store_id': store_id,
                        'store_name': visit['store_name'],
                        'store_position': visit['store_position'],
                        'store_latitude': visit['store_position'][0],
                        'store_longitude': visit['store_position'][1],
                        'scheduled_date': visit['scheduled_date'],
                        'reason': f"No capacity - store visited {store_visit_tracker[store_id]['scheduled_visits']}/{store_visit_tracker[store_id]['required_visits']} times",  # noqa
                        # âœ… NEW: Start point information
                        'employee_start_position': employee_position,
                        'start_latitude': employee_position[0],
                        'start_longitude': employee_position[1],
                        'distance_from_start_miles': round(distance_from_start, 2),
                        'visit_rule': visit['visit_rule'],
                        'visit_frequency': visit['visit_frequency'],
                        'visits_completed': store_visit_tracker[store_id]['scheduled_visits'],
                        'visits_required': store_visit_tracker[store_id]['required_visits'],
                        'visits_missing': store_visit_tracker[store_id]['required_visits'] - store_visit_tracker[store_id]['scheduled_visits']  # noqa
                    }
                    exception_rows.append(exception_row)

                visit_index += 1

        self._logger.info(f"Created {len(schedule_rows)} schedule rows")
        self._logger.info(f"Could not schedule {len(exception_rows)} visits")

        # Log summary for this employee
        total_stores_for_employee = len(store_visit_tracker)
        fully_visited_stores = sum(
            1 for tracker in store_visit_tracker.values() if tracker['scheduled_visits'] >= tracker['required_visits']  # noqa
        )
        partially_visited_stores = sum(
            1 for tracker in store_visit_tracker.values() if 0 < tracker['scheduled_visits'] < tracker['required_visits']  # noqa
        )
        unvisited_stores = sum(
            1 for tracker in store_visit_tracker.values() if tracker['scheduled_visits'] == 0
        )

        self._logger.info(
            f"Employee {employee_id}: {fully_visited_stores}/{total_stores_for_employee} stores fully visited"
        )
        self._logger.info(f"  - Fully visited: {fully_visited_stores}")
        self._logger.info(f"  - Partially visited: {partially_visited_stores}")
        self._logger.info(f"  - Unvisited: {unvisited_stores}")

        # ============
        # Save the schedule and exceptions
        schedule_df = pd.DataFrame(schedule_rows)
        if len(schedule_df) > 0 and 'store_ids' in schedule_df.columns:
            schedule_df['store_count'] = schedule_df['store_ids'].apply(lambda x: len(x) if x is not None else 0)
        else:
            schedule_df['store_count'] = 0

        exception_stores_df = pd.DataFrame(exception_rows)
        self._logger.info("Calculating coverage statistics...")

        # Calculate accurate statistics
        total_scheduled_visits = schedule_df['stores_visited_count'].sum() if len(schedule_df) > 0 else 0
        unscheduled_visits = len(exception_stores_df)

        # Count unique stores that received visits
        all_scheduled_store_ids = []
        if len(schedule_df) > 0:
            for _, row in schedule_df.iterrows():
                if 'store_ids' in row and row['store_ids']:
                    all_scheduled_store_ids.extend(row['store_ids'])

        unique_scheduled_stores = len(set(all_scheduled_store_ids))
        total_unique_stores = len(self.data['store_id'].unique())

        # Count stores with full required visits
        stores_with_full_visits = 0
        store_visit_counts = {}

        # Count visits per store
        for store_id in all_scheduled_store_ids:
            store_visit_counts[store_id] = store_visit_counts.get(store_id, 0) + 1

        # Check which stores got their full required visits
        for store_id in set(all_scheduled_store_ids):
            store_data = self.data[self.data['store_id'] == store_id]
            if len(store_data) > 0:
                required_visits = store_data.iloc[0].get('visit_rule', 2)
                actual_visits = store_visit_counts.get(store_id, 0)
                if actual_visits >= required_visits:
                    stores_with_full_visits += 1

        # Calculate percentages
        partial_coverage = (unique_scheduled_stores / total_unique_stores) * 100 if total_unique_stores > 0 else 0
        full_coverage = (stores_with_full_visits / total_unique_stores) * 100 if total_unique_stores > 0 else 0
        visit_efficiency = (total_scheduled_visits / total_required_visits) * 100 if total_required_visits > 0 else 0

        # Set the final results
        self.schedule_df = schedule_df
        self.exception_stores_df = exception_stores_df

        # Debug analysis
        self._logger.info("Analyzing scheduling results...")
        self.debug_scheduling_progress(schedule_df, exception_stores_df)

        # Store market analysis for reference
        self.market_analysis = market_analysis

        if self.roundtrip:
            self.log_roundtrip_summary(schedule_df)

        print("\n" + "=" * 50)
        print("FINAL SUMMARY")
        print("=" * 50)
        print(f"Total unique stores: {total_unique_stores:,}")
        print(f"Total required visits: {total_required_visits:,}")
        print("")
        print(f"âœ… Scheduled visits: {total_scheduled_visits:,}")
        print(f"âŒ Unscheduled visits: {unscheduled_visits:,}")
        print("")
        print(f"Stores with some visits: {unique_scheduled_stores:,} ({partial_coverage:.1f}%)")
        print(f"Stores with full visits: {stores_with_full_visits:,} ({full_coverage:.1f}%)")
        print(f"Stores Unvisited: {unvisited_stores}")
        print("")
        print(f"Visit efficiency: {visit_efficiency:.1f}%")

        if unique_scheduled_stores > 0:
            avg_visits_per_store = total_scheduled_visits / unique_scheduled_stores
            print(f"Average visits per scheduled store: {avg_visits_per_store:.1f}")

        # âœ… NEW: Roundtrip summary in final output
        if self.roundtrip and len(schedule_df) > 0:
            total_return_distance = schedule_df['return_trip_distance'].sum()
            total_return_time_hours = schedule_df['return_trip_time'].sum() / 60
            total_travel_time_hours = schedule_df['total_travel_time'].sum() / 60

            print("\nðŸ”„ ROUNDTRIP SUMMARY:")
            print(
                f"Roundtrip mode: {'ENABLED' if self.roundtrip else 'DISABLED'}"
            )
            print(
                f"Total return distance: {total_return_distance:.1f} miles"
            )
            print(
                f"Total return time: {total_return_time_hours:.1f} hours"
            )

            if total_travel_time_hours > 0:
                return_time_percentage = (total_return_time_hours / total_travel_time_hours) * 100
                print(
                    f"Return trips: {return_time_percentage:.1f}% of total travel time"
                )

            # Show impact on daily capacity
            avg_day_return_time = schedule_df['return_trip_time'].mean()
            capacity_impact = (avg_day_return_time / 60) / self.day_duration * 100
            print(
                f"Average daily return time: {avg_day_return_time:.1f} minutes ({capacity_impact:.1f}% of day duration)"
            )

        # NEW: Show timing summary
        if len(schedule_df) > 0:
            print("\nâ° TIMING SUMMARY:")
            print(f"Work starts at: {self.start_hour:02d}:00 AM")

            # Get average start and end times across all days
            if 'work_end_time_24h' in schedule_df.columns:
                avg_end_times = []
                for end_time_str in schedule_df['work_end_time_24h'].dropna():
                    try:
                        end_time = datetime.strptime(end_time_str, "%H:%M").time()
                        end_datetime = datetime.combine(date.today(), end_time)
                        avg_end_times.append(end_datetime)
                    except Exception as e:
                        print(f"Error parsing end time: {e}")
                        continue

                if avg_end_times:
                    avg_end_time = sum([dt.timestamp() for dt in avg_end_times]) / len(avg_end_times)
                    avg_end_time = datetime.fromtimestamp(avg_end_time).time()
                    print(f"Average work end time: {self._format_time(avg_end_time)}")

        # Verification
        print(f"\nSchedule rows created: {len(schedule_df):,}")
        if total_scheduled_visits <= total_required_visits:
            print("âœ… No over-scheduling detected")
        else:
            print(f"âš ï¸  Over-scheduling: {total_scheduled_visits - total_required_visits:,} extra visits")

        # Saving the Exception Stores Dataframe to filesystem:
        if self._exceptions_file:
            if self._exceptions_file.suffix == '.xlsx':
                exception_stores_df.to_excel(self._exceptions_file, index=False)
            else:
                exception_stores_df.to_csv(self._exceptions_file, index=False)

        self._result = schedule_df

        self._print_data_(self._result, 'Schedule')

        return self._result
