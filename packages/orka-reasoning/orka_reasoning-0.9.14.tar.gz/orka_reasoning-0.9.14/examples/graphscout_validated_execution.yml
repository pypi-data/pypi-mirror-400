# GraphScout Validated Execution
# ================================
#
# This demonstrates GraphScout in EXECUTION MODE where:
# 1. GraphScout proposes and EXECUTES a path
# 2. The path quality is monitored/validated during execution
# 3. Results are collected from the actual agent executions
#
# Key difference from validation-only examples:
# - GraphScout is in the MAIN orchestrator (not inside a loop)
# - The execution engine actually follows GraphScout's routing
# - Real agents are executed, not just proposed

orchestrator:
  id: graphscout-execution-demo
  strategy: sequential
  agents:
    - input_analyzer
    - graphscout_router  # GraphScout executes here, routing to selected agents
    - result_synthesizer

agents:
  # Step 1: Analyze input to guide routing
  - id: input_analyzer
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.3
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Analyze this request:
      {{ input }}
      
      Determine:
      1. Information needs (search, analysis, generation)
      2. Complexity level
      3. Required capabilities
      
      Return brief analysis.

  # Step 2: GraphScout routes and orchestrator EXECUTES the path
  - id: graphscout_router
    type: graph-scout
    params:
      k_beam: 5
      max_depth: 3
      commit_margin: 0.1
      require_terminal: true
      score_weights:
        llm: 0.50
        heuristics: 0.25
        prior: 0.15
        cost: 0.05
        latency: 0.05
      safety_profile: default
      cost_budget_tokens: 1500
      latency_budget_ms: 8000
      max_preview_tokens: 250
      evaluation_model: "local_llm"
      evaluation_model_name: "openai/gpt-oss-20b"
      validation_model: "local_llm"
      validation_model_name: "openai/gpt-oss-20b"
      llm_evaluation_enabled: true
      provider: lm_studio
      model_url: http://localhost:1234
      fallback_to_heuristics: true
    prompt: |
      Select and route to optimal agent path.
      
      Query: {{ input }}
      Analysis: {{ previous_outputs.input_analyzer.response }}
      
      **Available Agents:**
      
      **Data Retrieval:**
      - web_search: DuckDuckGo search for current information
      - memory_reader: Retrieve relevant past context
      
      **Analysis:**
      - deep_analyzer: Multi-perspective analysis
      - technical_expert: Technical domain expertise
      
      **Generation:**
      - content_synthesizer: Combine sources (terminal capable)
      - report_builder: Structured reports (terminal capable)
      
      **Guidelines:**
      1. Select minimum agents for completeness
      2. Ensure logical dependencies
      3. Must end with terminal agent
      4. Optimize for cost and latency
      
      **IMPORTANT**: The path you select WILL BE EXECUTED.
      The orchestrator will follow your routing decision.

  # Step 3: Synthesize results from executed path
  - id: result_synthesizer
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.3
    timeout: 60.0
    prompt: |
      # Execution Results Summary
      
      **Original Query:** {{ input }}
      
      ## GraphScout's Routing Decision
      {% if previous_outputs.graphscout_router %}
      {% set gs = previous_outputs.graphscout_router %}
      - Target: {{ gs.target | default(gs.response.target | default('N/A')) }}
      - Confidence: {{ gs.confidence | default(gs.response.confidence | default('N/A')) }}
      - Selected Path: {{ gs.selected_path | default(gs.response.selected_path | default('See routing results')) }}
      {% else %}
      - GraphScout routing completed (see details in previous_outputs)
      {% endif %}
      
      ## Analysis Context
      {% if previous_outputs.input_analyzer %}
      **Input Analysis:** {{ previous_outputs.input_analyzer.response | default(previous_outputs.input_analyzer) }}
      {% endif %}
      
      ## All Available Results
      {% for agent_id, output in previous_outputs.items() %}
      {% if agent_id not in ['input_analyzer', 'result_synthesizer'] %}
      ### {{ agent_id }}
      {{ output.response | default(output.result | default(output)) }}
      {% endif %}
      {% endfor %}
      
      ---
      
      Based on all the above results, provide a comprehensive final response to the original query.
      Synthesize the key findings and deliver a clear, actionable answer.

  # Supporting agents that GraphScout can route to
  - id: web_search
    type: duckduckgo
    capabilities: [data_retrieval, web_search]
    prompt: |
      {{ input }}

  - id: memory_reader
    type: memory
    namespace: graphscout_execution
    memory_preset: episodic
    config:
      operation: read
      vector: true
      top_k: 5
    prompt: |
      Retrieve context for: {{ input }}

  - id: deep_analyzer
    type: local_llm
    capabilities: [reasoning, analysis]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Deep analysis of: {{ input }}
      
      {% if previous_outputs.web_search %}
      Search Results: {{ previous_outputs.web_search.result }}
      {% endif %}
      
      {% if previous_outputs.memory_reader %}
      Historical Context: {{ previous_outputs.memory_reader }}
      {% endif %}
      
      Provide comprehensive multi-perspective analysis.

  - id: technical_expert
    type: local_llm
    capabilities: [technical_analysis, expertise]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Technical expert analysis for: {{ input }}
      
      Context: {{ previous_outputs }}
      
      Provide detailed technical insights.

  - id: content_synthesizer
    type: local_llm
    is_terminal: true  # Mark as terminal for GraphScout path completion
    capabilities: [answer_emit, synthesis]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Synthesize comprehensive response:
      
      Query: {{ input }}
      Available Data: {{ previous_outputs }}
      
      Create well-structured, complete answer.

  - id: report_builder
    type: local_llm
    is_terminal: true  # Mark as terminal for GraphScout path completion
    capabilities: [answer_emit, reporting]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Generate structured report:
      
      Topic: {{ input }}
      Data: {{ previous_outputs }}
      
      Format as professional report with sections.
