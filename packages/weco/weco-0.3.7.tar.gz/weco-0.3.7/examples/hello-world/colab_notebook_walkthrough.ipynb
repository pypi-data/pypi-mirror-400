{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RO1o5fS5W8xc"
   },
   "source": [
    "# Hello World ðŸ”¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yorBWlqGuC7-"
   },
   "source": [
    "<p align=\"left\">\n",
    "  <img src=\"https://raw.githubusercontent.com/WecoAI/weco-cli/main/assets/example-optimization.gif\"\n",
    "       alt=\"Optimization demo\"\n",
    "       width=\"720\">\n",
    "</p>\n",
    "\n",
    "## ðŸ–¥ï¸ Weco CLI Resources\n",
    "\n",
    "- ðŸ“– [CLI Reference](https://docs.weco.ai/cli/cli-reference) - Explore our docs for an in-depth look at what the tool can do\n",
    "- âœ¨ [Examples](https://docs.weco.ai/examples) - Explore automated R&D across kernel engineering, ML engineering and prompt engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BQGGqbJW2Eq"
   },
   "source": [
    "## Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89doT3fbWcGi"
   },
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "%pip install -q weco ipywidgets numpy torch\n",
    "\n",
    "# Enable custom widgets\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYxLwOXzfmiF"
   },
   "source": [
    "Now we need to determine what `DEVICE` we can run this on, a CPU or GPU..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFAn_bzAXLGO"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from rich import print as rprint\n",
    "\n",
    "# Check if you're connected to a GPU (it's free!)\n",
    "if not torch.cuda.is_available():\n",
    "    DEVICE = \"cpu\"\n",
    "    rprint(\n",
    "        \"\"\"\n",
    "[bold yellow]âš ï¸  GPU is not enabled.[/bold yellow] The notebook will fall back to [bold]CPU[/bold], but [italic]performance may be lower[/italic].\n",
    "\n",
    "[bold]ðŸ‘‰ To enable GPU (FREE):[/bold]\n",
    "â€¢ Go to [green]Runtime > Change runtime type[/green]\n",
    "â€¢ Set [bold]'Hardware Accelerator'[/bold] to [bold green]'GPU'[/bold green]\n",
    "â€¢ Click [bold]Save[/bold] and [bold]rerun all cells[/bold]\n",
    "\n",
    "[dim]Continuing with CPU for now...[/dim]\n",
    "\"\"\"\n",
    "    )\n",
    "else:\n",
    "    DEVICE = \"cuda\"\n",
    "    rprint(\"[bold green]âœ… GPU is enabled.[/bold green] Proceeding with [bold green]CUDA[/bold green]...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFGClqxpzwyM"
   },
   "outputs": [],
   "source": [
    "# Download the example files from CLI repo\n",
    "!wget https://github.com/WecoAI/weco-cli/archive/refs/heads/main.zip -O repo.zip\n",
    "!unzip -j repo.zip \"weco-cli-main/examples/hello-world/*\" -d .\n",
    "!rm repo.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbvA8oQceOt5"
   },
   "source": [
    "## Let's Start Optimizing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OjXTBkjc4Id"
   },
   "source": [
    "Now that we've got our dependecies, GPU and LLM API key sorted out, let's take a look at what code we're optimizing!\n",
    "\n",
    "Earlier, we downloaded two files:\n",
    "1. An evaluation script to help score *how good a solution is* (`evaluate.py`)\n",
    "2. A snippet of code we'd like to optimize (`module.py`)\n",
    "\n",
    "Let's take a look at what the code we want to optimize looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUTxqxWgcC34"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from pygments import highlight\n",
    "from pygments.lexers import PythonLexer\n",
    "from pygments.formatters import HtmlFormatter\n",
    "\n",
    "def view_code_block(path: str):\n",
    "    with open(path) as f:\n",
    "        display(HTML(highlight(f.read(), PythonLexer(), HtmlFormatter(full=True, style=\"monokai\"))))\n",
    "\n",
    "view_code_block(\"module.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5C5dvasXdmNw"
   },
   "source": [
    "Real-world code is often more complex but this is a good place to start. You can find more advanced examples [here](https://docs.weco.ai/examples), however, we'd recommend starting with this notebook as the optimization setup is the exact same, no matter the complexity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfDg-pP9fAdC"
   },
   "source": [
    "It's simple to start optimizing any piece of code! You just need to set:\n",
    "1. Path to source code - we can point this to our `module.py`\n",
    "2. Command to run evaluation - notice how we are using the `DEVICE` we setup earlier\n",
    "3. The metric we are optimizing for - in this case, the evaluation script (`evaluate.py`) prints the `'speedup'` achieved to the terminal\n",
    "4. Whether you want to maximize or minimize the metric you mentioned above - in our case, we want to make this code faster!\n",
    "5. Number of steps to optimize for - we'll keep it low to avoid any rate limits being hit on your free Gemini API key\n",
    "6. Additional context - anything information you think should guide the optimization process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbG_3nwEhs5G"
   },
   "source": [
    "Now let's get straight into it. Keep an eye on the `Best Solution` panel!\n",
    "\n",
    "Note that you can track the optimization in the logs directory (`.runs/`) and on our dashboard (links shown in the `Summary` panel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17YZ2euZplDJ"
   },
   "outputs": [],
   "source": [
    "import sys, weco.cli as weco_cli\n",
    "\n",
    "# When running in a terminal, you can use this instead:\n",
    "# weco run --source module.py \\\n",
    "#      --eval-command f\"python evaluate.py --path module.py --device {DEVICE}\" \\\n",
    "#      --metric speedup \\\n",
    "#      --goal maximize \\\n",
    "#      --steps 10 \\\n",
    "#      --additional-instructions \"Fuse operations in the forward method while ensuring the max float deviation remains small.\"\n",
    "\n",
    "sys.argv = [\n",
    "    \"weco\", \"run\",\n",
    "    \"--source\", \"module.py\",\n",
    "    \"--eval-command\", f\"python evaluate.py --path module.py --device {DEVICE}\",\n",
    "    \"--metric\", \"speedup\",\n",
    "    \"--goal\", \"maximize\",\n",
    "    \"--steps\", \"10\",\n",
    "    \"--additional-instructions\", \"Fuse operations in the forward method while ensuring the max float deviation remains small.\"\n",
    "]\n",
    "\n",
    "try: weco_cli.main()\n",
    "except SystemExit: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "990ueX_JsO_1"
   },
   "source": [
    "Let's take a look at what our optimized code looks like (`module.py`)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9dqfzXkajQKs"
   },
   "outputs": [],
   "source": [
    "view_code_block(\"module.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "17oICow9yjn8"
   },
   "source": [
    "Happy Optimizing from the [Weco](https://www.weco.ai/) Team!\n",
    "\n",
    "If you'd like to learn more about what Weco can do, here are some spots to check out:\n",
    "- ðŸ“– [CLI Reference](https://docs.weco.ai/cli/cli-reference) - Explore our docs for an in-depth look at what the tool can do\n",
    "- âœ¨ [Examples](https://docs.weco.ai/examples) - Explore automated R&D across kernel engineering, ML engineering and prompt engineering"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
