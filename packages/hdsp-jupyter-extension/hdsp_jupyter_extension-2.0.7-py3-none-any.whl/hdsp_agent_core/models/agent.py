"""
Agent API Pydantic models

Models for plan generation, refinement, replanning, and state verification.
"""

from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field

from .common import ErrorInfo, LLMConfig, NotebookContext, ToolCall

# ============ Plan Request/Response ============


class PlanStep(BaseModel):
    """Single step in an execution plan"""

    stepNumber: int = Field(description="Step number (1-based)")
    description: str = Field(description="Human-readable step description")
    toolCalls: List[ToolCall] = Field(
        default_factory=list, description="Tools to execute in this step"
    )
    expectedOutput: Optional[str] = Field(
        default=None, description="Expected output description"
    )


class ExecutionPlan(BaseModel):
    """Execution plan generated by the agent"""

    goal: str = Field(description="Overall goal description")
    totalSteps: int = Field(description="Total number of steps")
    steps: List[PlanStep] = Field(description="Ordered list of execution steps")


class PlanRequest(BaseModel):
    """Request body for plan generation"""

    request: str = Field(description="User's natural language request")
    notebookContext: NotebookContext = Field(
        default_factory=NotebookContext, description="Current notebook state"
    )
    llmConfig: Optional[LLMConfig] = Field(
        default=None, description="LLM configuration with API keys (client-provided)"
    )


class PlanResponse(BaseModel):
    """Response body for plan generation"""

    plan: ExecutionPlan = Field(description="Generated execution plan")
    reasoning: str = Field(default="", description="Agent's reasoning explanation")


# ============ Refine Request/Response ============


class RefineRequest(BaseModel):
    """Request body for code refinement"""

    step: Dict[str, Any] = Field(description="Current step being refined")
    error: ErrorInfo = Field(description="Error that triggered refinement")
    attempt: int = Field(default=1, description="Current attempt number")
    previousCode: Optional[str] = Field(
        default=None, description="Previously executed code"
    )
    llmConfig: Optional[LLMConfig] = Field(
        default=None, description="LLM configuration with API keys (client-provided)"
    )


class RefineResponse(BaseModel):
    """Response body for code refinement"""

    toolCalls: List[ToolCall] = Field(description="Refined tool calls")
    reasoning: str = Field(default="", description="Refinement reasoning")


# ============ Replan Request/Response ============


class ReplanRequest(BaseModel):
    """Request body for replanning"""

    originalPlan: ExecutionPlan = Field(description="Original execution plan")
    currentStepIndex: int = Field(description="Index of the failed step")
    error: ErrorInfo = Field(description="Error that triggered replan")
    executionHistory: List[Dict[str, Any]] = Field(
        default_factory=list, description="History of executed steps"
    )
    # LLM Fallback 관련 필드
    previousAttempts: int = Field(
        default=0, description="Number of previous attempts for the same error"
    )
    previousCodes: List[str] = Field(
        default_factory=list, description="Previously attempted codes"
    )
    useLlmFallback: bool = Field(
        default=True,
        description="Whether to use LLM fallback when pattern matching fails",
    )


class ReplanResponse(BaseModel):
    """Response body for replanning"""

    decision: str = Field(
        description="Replan decision type (refine/insert_steps/replace_step/replan_remaining)"
    )
    analysis: Dict[str, Any] = Field(description="Error analysis details")
    reasoning: str = Field(default="", description="Replan reasoning")
    changes: Dict[str, Any] = Field(
        default_factory=dict, description="Proposed changes"
    )
    usedLlm: bool = Field(
        default=False, description="Whether LLM fallback was used for error analysis"
    )
    confidence: float = Field(
        default=1.0,
        description="Analysis confidence (1.0 for pattern matching, 0.0-1.0 for LLM)",
    )


# ============ Reflect Request/Response ============


class ReflectionEvaluation(BaseModel):
    """Reflection evaluation result"""

    checkpoint_passed: bool = Field(description="Whether checkpoint criteria passed")
    output_matches_expected: bool = Field(
        description="Whether output matches expected outcome"
    )
    confidence_score: float = Field(description="Confidence score (0.0-1.0)")


class ReflectionAnalysis(BaseModel):
    """Reflection analysis details"""

    success_factors: List[str] = Field(
        default_factory=list, description="Factors contributing to success"
    )
    failure_factors: List[str] = Field(
        default_factory=list, description="Factors causing failure"
    )
    unexpected_outcomes: List[str] = Field(
        default_factory=list, description="Unexpected outcomes"
    )


class ReflectionImpact(BaseModel):
    """Impact on remaining steps"""

    affected_steps: List[int] = Field(
        default_factory=list, description="Step numbers affected"
    )
    severity: str = Field(
        description="Impact severity: none, minor, major, critical"
    )
    description: str = Field(description="Impact description")


class ReflectionAdjustment(BaseModel):
    """Recommended adjustment"""

    step_number: int = Field(description="Step number to adjust")
    change_type: str = Field(
        description="Change type: modify_code, add_step, remove_step, change_approach"
    )
    description: str = Field(description="Adjustment description")
    new_content: Optional[str] = Field(default=None, description="New content if applicable")


class ReflectionRecommendations(BaseModel):
    """Reflection recommendations"""

    action: str = Field(description="Recommended action: continue, adjust, retry, replan")
    adjustments: List[ReflectionAdjustment] = Field(
        default_factory=list, description="Specific adjustments"
    )
    reasoning: str = Field(description="Reasoning for recommendations")


class ReflectionResult(BaseModel):
    """Complete reflection result"""

    evaluation: ReflectionEvaluation = Field(description="Evaluation results")
    analysis: ReflectionAnalysis = Field(description="Analysis details")
    impact_on_remaining: ReflectionImpact = Field(description="Impact on remaining steps")
    recommendations: ReflectionRecommendations = Field(description="Recommendations")


class ReflectRequest(BaseModel):
    """Request body for step reflection"""

    stepNumber: int = Field(description="Step number being reflected on")
    stepDescription: str = Field(description="Step description")
    executedCode: str = Field(description="Code that was executed")
    executionStatus: str = Field(description="Execution status (success/error/warning)")
    executionOutput: str = Field(description="Output from execution")
    errorMessage: Optional[str] = Field(default=None, description="Error message if any")
    expectedOutcome: Optional[str] = Field(
        default=None, description="Expected outcome description"
    )
    validationCriteria: Optional[List[str]] = Field(
        default=None, description="Validation criteria"
    )
    remainingSteps: Optional[List[Dict[str, Any]]] = Field(
        default=None, description="Remaining steps in plan"
    )


class ReflectResponse(BaseModel):
    """Response body for step reflection"""

    reflection: ReflectionResult = Field(description="Reflection analysis result")


# ============ State Verification ============


class VerifyStateRequest(BaseModel):
    """Request body for state verification"""

    stepIndex: int = Field(description="Step index to verify")
    expectedChanges: Dict[str, Any] = Field(
        description="Expected state changes from the step"
    )
    actualOutput: str = Field(description="Actual output from execution")
    executionResult: Dict[str, Any] = Field(description="Full execution result")


class VerifyStateResponse(BaseModel):
    """Response body for state verification"""

    verified: bool = Field(description="Whether state matches expectations")
    discrepancies: List[str] = Field(
        default_factory=list, description="List of discrepancies found"
    )
    confidence: float = Field(default=0.0, description="Confidence score (0.0-1.0)")


# ============ Report Execution ============


class ReportExecutionRequest(BaseModel):
    """Request body for reporting tool execution results"""

    stepId: str = Field(description="Step identifier")
    result: Dict[str, Any] = Field(description="Execution result details")


class ReportExecutionResponse(BaseModel):
    """Response body for execution report"""

    acknowledged: bool = Field(default=True)
    nextAction: Optional[str] = Field(default=None, description="Suggested next action")


# ============ Code Validation ============


class ValidationIssue(BaseModel):
    """Code validation issue (syntax, undefined names, etc.)"""

    severity: str = Field(description="Issue severity: error, warning, info")
    category: str = Field(
        description="Issue category: syntax, undefined_name, unused_import, unused_variable, redefined, import_error, type_error"
    )
    message: str = Field(description="Issue description")
    line: Optional[int] = Field(default=None, description="Line number")
    column: Optional[int] = Field(default=None, description="Column number")
    code_snippet: Optional[str] = Field(default=None, description="Code snippet")


class DependencyInfo(BaseModel):
    """Code dependency information"""

    imports: List[str] = Field(default_factory=list, description="Import statements")
    from_imports: Dict[str, List[str]] = Field(
        default_factory=dict, description="From-import statements"
    )
    defined_names: List[str] = Field(
        default_factory=list, description="Defined variable/function names"
    )
    used_names: List[str] = Field(
        default_factory=list, description="Used variable/function names"
    )
    undefined_names: List[str] = Field(
        default_factory=list, description="Undefined names (potential errors)"
    )


class ValidateRequest(BaseModel):
    """Request body for code validation"""

    code: str = Field(description="Code to validate")
    notebookContext: Optional[NotebookContext] = Field(
        default=None, description="Current notebook context (for variable/import tracking)"
    )


class ValidateResponse(BaseModel):
    """Response body for code validation"""

    valid: bool = Field(description="Whether code is valid (no errors)")
    issues: List[ValidationIssue] = Field(
        default_factory=list, description="Validation issues"
    )
    dependencies: Optional[DependencyInfo] = Field(
        default=None, description="Code dependencies"
    )
    hasErrors: bool = Field(description="Whether there are any errors")
    hasWarnings: bool = Field(description="Whether there are any warnings")
    summary: str = Field(description="Validation summary")
