Metadata-Version: 2.1
Name: nagisa
Version: 0.2.11
Summary: A Japanese tokenizer based on recurrent neural networks
Home-page: https://github.com/taishi-i/nagisa
Author: Taishi Ikeda
Author-email: taishi.ikeda.0323@gmail.com
License: MIT License
Download-URL: https://github.com/taishi-i/nagisa/archive/0.2.11.tar.gz
Platform: Unix
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: Japanese
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Operating System :: Unix
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Classifier: Topic :: Text Processing :: Linguistic
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Description-Content-Type: text/markdown
Requires-Dist: six
Requires-Dist: numpy
Requires-Dist: DyNet

<p align="center"><img width="50%" src="/nagisa/data/nagisa_logo.png" /></p>

---

[![Python package](https://github.com/taishi-i/nagisa/actions/workflows/python-package.yml/badge.svg)](https://github.com/taishi-i/nagisa/actions/workflows/python-package.yml)
[![Coverage Status](https://coveralls.io/repos/github/taishi-i/nagisa/badge.svg?branch=master)](https://coveralls.io/github/taishi-i/nagisa?branch=master)
[![Documentation Status](https://readthedocs.org/projects/nagisa/badge/?version=latest)](https://nagisa.readthedocs.io/en/latest/?badge=latest)
![GitHub License](https://img.shields.io/github/license/taishi-i/nagisa)
[![PyPI](https://img.shields.io/pypi/v/nagisa.svg)](https://pypi.python.org/pypi/nagisa)
[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/taishi-i/nagisa-demo)
[![Downloads](https://static.pepy.tech/badge/nagisa)](https://pepy.tech/project/nagisa)


Nagisa is a python module for Japanese word segmentation/POS-tagging.

It is designed to be a simple and easy-to-use tool.

This tool has the following features.
-  Based on recurrent neural networks.
-  The word segmentation model uses character- and word-level features [[Ê±†Áî∞+]](http://www.anlp.jp/proceedings/annual_meeting/2017/pdf_dir/B6-2.pdf).
-  The POS-tagging model uses tag dictionary information [[Inoue+]](http://www.aclweb.org/anthology/K17-1042).

For more details refer to the following links.
-  The documentation is available [here](https://nagisa.readthedocs.io/en/latest/?badge=latest).
-  The article in Japanese is available [here](https://qiita.com/taishi-i/items/5b9275a606b392f7f58e).
-  The presentation slide at PyCon JP (2022) is available [here](https://speakerdeck.com/taishii/pycon-jp-2022).


Installation
=============

You can install nagisa using pip:

```bash
pip install nagisa
````

Supported Platforms:
- üêß Linux: Python 3.6 - 3.14
- üçé macOS: Python 3.9 - 3.14
- ü™ü Windows: Python 3.9 - 3.14

Basic usage
=============

Sample of word segmentation and POS-tagging for Japanese.

```python
import nagisa

text = 'Python„ÅßÁ∞°Âçò„Å´‰Ωø„Åà„Çã„ÉÑ„Éº„É´„Åß„Åô'
words = nagisa.tagging(text)
print(words)
#=> Python/ÂêçË©û „Åß/Âä©Ë©û Á∞°Âçò/ÂΩ¢Áä∂Ë©û „Å´/Âä©ÂãïË©û ‰Ωø„Åà„Çã/ÂãïË©û „ÉÑ„Éº„É´/ÂêçË©û „Åß„Åô/Âä©ÂãïË©û

# Get a list of words
print(words.words)
#=> ['Python', '„Åß', 'Á∞°Âçò', '„Å´', '‰Ωø„Åà„Çã', '„ÉÑ„Éº„É´', '„Åß„Åô']

# Get a list of POS-tags
print(words.postags)
#=> ['ÂêçË©û', 'Âä©Ë©û', 'ÂΩ¢Áä∂Ë©û', 'Âä©ÂãïË©û', 'ÂãïË©û', 'ÂêçË©û', 'Âä©ÂãïË©û']
```

Post-processing functions
=====

Filter and extarct words by the specific POS tags.
```python
import nagisa

# Filter the words of the specific POS tags.
words = nagisa.filter(text, filter_postags=['Âä©Ë©û', 'Âä©ÂãïË©û'])
print(words)
#=> Python/ÂêçË©û Á∞°Âçò/ÂΩ¢Áä∂Ë©û ‰Ωø„Åà„Çã/ÂãïË©û „ÉÑ„Éº„É´/ÂêçË©û

# Extarct only nouns.
words = nagisa.extract(text, extract_postags=['ÂêçË©û'])
print(words)
#=> Python/ÂêçË©û „ÉÑ„Éº„É´/ÂêçË©û

# This is a list of available POS-tags in nagisa.
print(nagisa.tagger.postags)
#=> ['Ë£úÂä©Ë®òÂè∑', 'ÂêçË©û', ... , 'URL']
```

Add the user dictionary in easy way.
```python
import nagisa

# default
text = "3Êúà„Å´Ë¶ã„Åü„Äå3Êúà„ÅÆ„É©„Ç§„Ç™„É≥„Äç"
print(nagisa.tagging(text))
#=> 3/ÂêçË©û Êúà/ÂêçË©û „Å´/Âä©Ë©û Ë¶ã/ÂãïË©û „Åü/Âä©ÂãïË©û „Äå/Ë£úÂä©Ë®òÂè∑ 3/ÂêçË©û Êúà/ÂêçË©û „ÅÆ/Âä©Ë©û „É©„Ç§„Ç™„É≥/ÂêçË©û „Äç/Ë£úÂä©Ë®òÂè∑

# If a word ("3Êúà„ÅÆ„É©„Ç§„Ç™„É≥") is included in the single_word_list, it is recognized as a single word.
new_tagger = nagisa.Tagger(single_word_list=['3Êúà„ÅÆ„É©„Ç§„Ç™„É≥'])
print(new_tagger.tagging(text))
#=> 3/ÂêçË©û Êúà/ÂêçË©û „Å´/Âä©Ë©û Ë¶ã/ÂãïË©û „Åü/Âä©ÂãïË©û „Äå/Ë£úÂä©Ë®òÂè∑ 3Êúà„ÅÆ„É©„Ç§„Ç™„É≥/ÂêçË©û „Äç/Ë£úÂä©Ë®òÂè∑
```


Train a model
======

Nagisa provides a simple train method
for a joint word segmentation and sequence labeling (e.g, POS-tagging, NER) model.

The format of the train/dev/test files is tsv.
Each line is `word`  and `tag` and one line is represented by `word` \t(tab) `tag`.
Note that you put EOS between sentences.
Refer to [sample datasets](/nagisa/data/sample_datasets) and [tutorial (Train a model for Universal Dependencies)](https://nagisa.readthedocs.io/en/latest/tutorial.html).


```
$ cat sample.train
ÂîØ‰∏Ä	NOUN
„ÅÆ	ADP
Ë∂£Âë≥	NOU
„ÅØ	ADP
ÊñôÁêÜ	NOUN
EOS
„Å®„Å¶„ÇÇ	ADV
„Åä„ÅÑ„Åó„Åã„Å£	ADJ
„Åü	AUX
„Åß„Åô	AUX
„ÄÇ	PUNCT
EOS
„Éâ„É´	NOUN
„ÅØ	ADP
‰∏ªË¶Å	ADJ
ÈÄöË≤®	NOUN
EOS
```

```python
import nagisa

# After finish training, save the three model files (*.vocabs, *.params, *.hp).
nagisa.fit(train_file="sample.train", dev_file="sample.dev", test_file="sample.test", model_name="sample")

# Build the tagger by loading the trained model files.
sample_tagger = nagisa.Tagger(vocabs='sample.vocabs', params='sample.params', hp='sample.hp')

text = "Á¶èÂ≤°„ÉªÂçöÂ§ö„ÅÆË¶≥ÂÖâÊÉÖÂ†±"
words = sample_tagger.tagging(text)
print(words)
#> Á¶èÂ≤°/PROPN „Éª/SYM ÂçöÂ§ö/PROPN „ÅÆ/ADP Ë¶≥ÂÖâ/NOUN ÊÉÖÂ†±/NOUN
```


