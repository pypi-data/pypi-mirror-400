# RAG Memory - Secrets Configuration
# ================================================================================
# This file stores ONLY secrets that should never be committed to git.
#
# USAGE:
# 1. Copy this file to .env
# 2. Add your OPENAI_API_KEY (get from https://platform.openai.com/api-keys)
# 3. For development: .env is loaded by conftest.py and local dev scripts
# 4. For system install: setup.py will prompt for this value interactively
#
# NEVER commit .env to git - it's already in .gitignore
# ================================================================================

# OpenAI API Key (required for all operations)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# ================================================================================
# Advanced Configuration (Optional)
# ================================================================================

# Graphiti Reflexion - Recursive Entity Extraction
# Number of reflexion iterations for entity/relationship extraction
# 0 = disabled (single-pass, faster, default)
# 1-3 = recursive extraction (higher quality, slower, more expensive)
# Each iteration adds ~30-60s and ~$0.01 per document
# NOTE: Only affects ingestion (ingest_text, ingest_url, etc.), not search
# MAX_REFLEXION_ITERATIONS=0

# Graphiti Knowledge Graph Models
# Override the models used for entity and relationship extraction
# GRAPHITI_MODEL=gpt-4o-mini         # Primary model for graph extraction (default: gpt-4o-mini)
# GRAPHITI_SMALL_MODEL=gpt-4o-mini   # Small model for lighter tasks (default: gpt-4o-mini)

# Dry Run Relevance Scoring Configuration
# These parameters control the LLM used for ingest_url dry_run mode (page relevance scoring)
# Dry run mode previews what pages would be ingested and scores their relevance to your topic
# DRY_RUN_MODEL=gpt-4o-mini          # Model for relevance scoring (default: gpt-4o-mini)
# DRY_RUN_TEMPERATURE=0.1            # Temperature for consistent scoring (default: 0.1)
# DRY_RUN_MAX_TOKENS=2000            # Max tokens for relevance analysis (default: 2000)
