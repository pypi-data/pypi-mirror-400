# Copyright (c) 2023-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import builtins
from typing import Literal, Optional, Union, overload
from typing import Any, List, Sequence

from nvidia.dali.types import DALIDataType, DALIImageType, DALIInterpType

from collections.abc import Iterable

from nvidia.dali._typing import TensorLike, TensorLikeArg
from nvidia.dali.experimental.dynamic._batch import Batch as Batch
from nvidia.dali.experimental.dynamic._device import Device as Device
from nvidia.dali.experimental.dynamic._eval_context import EvalContext as EvalContext
from nvidia.dali.experimental.dynamic._tensor import Tensor as Tensor
from nvidia.dali.experimental.dynamic._type import DType as DType

@overload
def image(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    cache_batch_copy: Optional[builtins.bool] = True,
    cache_debug: Optional[builtins.bool] = False,
    cache_size: Optional[int] = 0,
    cache_threshold: Optional[int] = 0,
    cache_type: Optional[str] = "",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Decodes images.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container

    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    cache_batch_copy : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, multiple images from the cache are copied with a batched copy kernel call.
        Otherwise, unless the order in the batch is the same as in the cache, each image is
        copied with ``cudaMemcpy``.
    cache_debug : bool, optional, default = `False`
        Applies **only** to the ``mixed`` backend type.

        Prints the debug information about the decoder cache.
    cache_size : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        Total size of the decoder cache in megabytes. When provided, the decoded images
        that are larger than `cache_threshold` will be cached in GPU memory.
    cache_threshold : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The size threshold, in bytes, for decoded images to be cached. When an image is cached, it no
        longer needs to be decoded when it is encountered at the operator input saving processing time.
    cache_type : str, optional, default = `''`
        Applies **only** to the ``mixed`` backend type.

        Here is a list of the available cache types:

        * | ``threshold``: caches every image with a size that is larger than `cache_threshold` until
          | the cache is full.

          The warm-up time for threshold policy is 1 epoch.
        * | ``largest``: stores the largest images that can fit in the cache.
          | The warm-up time for largest policy is 2 epochs

          .. note::
            To take advantage of caching, it is recommended to configure readers with `stick_to_shard=True`
            to limit the amount of unique images seen by each decoder instance in a multi node environment.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    batch_size: int,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    cache_batch_copy: Optional[builtins.bool] = True,
    cache_debug: Optional[builtins.bool] = False,
    cache_size: Optional[int] = 0,
    cache_threshold: Optional[int] = 0,
    cache_type: Optional[str] = "",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container

    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    cache_batch_copy : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, multiple images from the cache are copied with a batched copy kernel call.
        Otherwise, unless the order in the batch is the same as in the cache, each image is
        copied with ``cudaMemcpy``.
    cache_debug : bool, optional, default = `False`
        Applies **only** to the ``mixed`` backend type.

        Prints the debug information about the decoder cache.
    cache_size : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        Total size of the decoder cache in megabytes. When provided, the decoded images
        that are larger than `cache_threshold` will be cached in GPU memory.
    cache_threshold : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The size threshold, in bytes, for decoded images to be cached. When an image is cached, it no
        longer needs to be decoded when it is encountered at the operator input saving processing time.
    cache_type : str, optional, default = `''`
        Applies **only** to the ``mixed`` backend type.

        Here is a list of the available cache types:

        * | ``threshold``: caches every image with a size that is larger than `cache_threshold` until
          | the cache is full.

          The warm-up time for threshold policy is 1 epoch.
        * | ``largest``: stores the largest images that can fit in the cache.
          | The warm-up time for largest policy is 2 epochs

          .. note::
            To take advantage of caching, it is recommended to configure readers with `stick_to_shard=True`
            to limit the amount of unique images seen by each decoder instance in a multi node environment.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    cache_batch_copy: Optional[builtins.bool] = True,
    cache_debug: Optional[builtins.bool] = False,
    cache_size: Optional[int] = 0,
    cache_threshold: Optional[int] = 0,
    cache_type: Optional[str] = "",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container

    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    cache_batch_copy : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, multiple images from the cache are copied with a batched copy kernel call.
        Otherwise, unless the order in the batch is the same as in the cache, each image is
        copied with ``cudaMemcpy``.
    cache_debug : bool, optional, default = `False`
        Applies **only** to the ``mixed`` backend type.

        Prints the debug information about the decoder cache.
    cache_size : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        Total size of the decoder cache in megabytes. When provided, the decoded images
        that are larger than `cache_threshold` will be cached in GPU memory.
    cache_threshold : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The size threshold, in bytes, for decoded images to be cached. When an image is cached, it no
        longer needs to be decoded when it is encountered at the operator input saving processing time.
    cache_type : str, optional, default = `''`
        Applies **only** to the ``mixed`` backend type.

        Here is a list of the available cache types:

        * | ``threshold``: caches every image with a size that is larger than `cache_threshold` until
          | the cache is full.

          The warm-up time for threshold policy is 1 epoch.
        * | ``largest``: stores the largest images that can fit in the cache.
          | The warm-up time for largest policy is 2 epochs

          .. note::
            To take advantage of caching, it is recommended to configure readers with `stick_to_shard=True`
            to limit the amount of unique images seen by each decoder instance in a multi node environment.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_crop(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    crop: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    crop_d: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_h: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_pos_x: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_y: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_z: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_w: Union[TensorLikeArg, Batch, float, None] = 0.0,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rounding: Optional[str] = "round",
    use_fast_idct: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Decodes images and extracts regions-of-interest (ROI) that are specified
    by fixed window dimensions and variable anchors.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    crop : float or list of float or Tensor/Batch of float, optional
        Shape of the cropped image, specified as a list of values (for example,
        ``(crop_H, crop_W)`` for the 2D crop and ``(crop_D, crop_H, crop_W)`` for the volumetric crop).

        Providing crop argument is incompatible with providing separate arguments such as `crop_d`,
        `crop_h`, and `crop_w`.
    crop_d : float or Tensor/Batch of float, optional, default = `0.0`
        Applies **only** to volumetric inputs; cropping window depth (in voxels).

        `crop_w`, `crop_h`, and `crop_d` must be specified together. Providing values
        for `crop_w`, `crop_h`, and `crop_d` is incompatible with providing the fixed crop
        window dimensions (argument `crop`).
    crop_h : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping the window height (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop
        window dimensions (argument `crop`).
    crop_pos_x : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) horizontal position of the cropping window
        (upper left corner).

        The actual position is calculated as ``crop_x = crop_x_norm * (W - crop_W)``, where `crop_x_norm`
        is the normalized position, ``W`` is the width of the image, and ``crop_W`` is the width of the
        cropping window.

        See `rounding` argument for more details on how ``crop_x`` is converted to an integral value.
    crop_pos_y : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) vertical position of the start of
        the cropping window (typically, the upper left corner).

        The actual position is calculated as ``crop_y = crop_y_norm * (H - crop_H)``, where ``crop_y_norm``
        is the normalized position, `H` is the height of the image, and ``crop_H`` is the height of the
        cropping window.

        See `rounding` argument for more details on how ``crop_y`` is converted to an integral value.
    crop_pos_z : float or Tensor/Batch of float, optional, default = `0.5`
        Applies **only** to volumetric inputs.

        Normalized (0.0 - 1.0) normal position of the cropping window (front plane).
        The actual position is calculated as ``crop_z = crop_z_norm * (D - crop_D)``, where ``crop_z_norm``
        is the normalized position, ``D`` is the depth of the image and ``crop_D`` is the depth of the
        cropping window.

        See `rounding` argument for more details on how ``crop_z`` is converted to an integral value.
    crop_w : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping window width (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop window
        dimensions (argument `crop`).
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rounding : str, optional, default = `'round'`
        Determines the rounding function used to convert the starting coordinate
        of the window to an integral value (see `crop_pos_x`, `crop_pos_y`, `crop_pos_z`).

        Possible values are:

        * | ``"round"`` - Rounds to the nearest integer value, with halfway cases rounded away from zero.
        * | ``"truncate"`` - Discards the fractional part of the number (truncates towards zero).
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_crop(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    batch_size: int,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    crop: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    crop_d: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_h: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_pos_x: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_y: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_z: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_w: Union[TensorLikeArg, Batch, float, None] = 0.0,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rounding: Optional[str] = "round",
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and extracts regions-of-interest (ROI) that are specified
    by fixed window dimensions and variable anchors.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    crop : float or list of float or Tensor/Batch of float, optional
        Shape of the cropped image, specified as a list of values (for example,
        ``(crop_H, crop_W)`` for the 2D crop and ``(crop_D, crop_H, crop_W)`` for the volumetric crop).

        Providing crop argument is incompatible with providing separate arguments such as `crop_d`,
        `crop_h`, and `crop_w`.
    crop_d : float or Tensor/Batch of float, optional, default = `0.0`
        Applies **only** to volumetric inputs; cropping window depth (in voxels).

        `crop_w`, `crop_h`, and `crop_d` must be specified together. Providing values
        for `crop_w`, `crop_h`, and `crop_d` is incompatible with providing the fixed crop
        window dimensions (argument `crop`).
    crop_h : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping the window height (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop
        window dimensions (argument `crop`).
    crop_pos_x : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) horizontal position of the cropping window
        (upper left corner).

        The actual position is calculated as ``crop_x = crop_x_norm * (W - crop_W)``, where `crop_x_norm`
        is the normalized position, ``W`` is the width of the image, and ``crop_W`` is the width of the
        cropping window.

        See `rounding` argument for more details on how ``crop_x`` is converted to an integral value.
    crop_pos_y : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) vertical position of the start of
        the cropping window (typically, the upper left corner).

        The actual position is calculated as ``crop_y = crop_y_norm * (H - crop_H)``, where ``crop_y_norm``
        is the normalized position, `H` is the height of the image, and ``crop_H`` is the height of the
        cropping window.

        See `rounding` argument for more details on how ``crop_y`` is converted to an integral value.
    crop_pos_z : float or Tensor/Batch of float, optional, default = `0.5`
        Applies **only** to volumetric inputs.

        Normalized (0.0 - 1.0) normal position of the cropping window (front plane).
        The actual position is calculated as ``crop_z = crop_z_norm * (D - crop_D)``, where ``crop_z_norm``
        is the normalized position, ``D`` is the depth of the image and ``crop_D`` is the depth of the
        cropping window.

        See `rounding` argument for more details on how ``crop_z`` is converted to an integral value.
    crop_w : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping window width (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop window
        dimensions (argument `crop`).
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rounding : str, optional, default = `'round'`
        Determines the rounding function used to convert the starting coordinate
        of the window to an integral value (see `crop_pos_x`, `crop_pos_y`, `crop_pos_z`).

        Possible values are:

        * | ``"round"`` - Rounds to the nearest integer value, with halfway cases rounded away from zero.
        * | ``"truncate"`` - Discards the fractional part of the number (truncates towards zero).
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_crop(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    crop: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    crop_d: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_h: Union[TensorLikeArg, Batch, float, None] = 0.0,
    crop_pos_x: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_y: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_pos_z: Union[TensorLikeArg, Batch, float, None] = 0.5,
    crop_w: Union[TensorLikeArg, Batch, float, None] = 0.0,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rounding: Optional[str] = "round",
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and extracts regions-of-interest (ROI) that are specified
    by fixed window dimensions and variable anchors.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    crop : float or list of float or Tensor/Batch of float, optional
        Shape of the cropped image, specified as a list of values (for example,
        ``(crop_H, crop_W)`` for the 2D crop and ``(crop_D, crop_H, crop_W)`` for the volumetric crop).

        Providing crop argument is incompatible with providing separate arguments such as `crop_d`,
        `crop_h`, and `crop_w`.
    crop_d : float or Tensor/Batch of float, optional, default = `0.0`
        Applies **only** to volumetric inputs; cropping window depth (in voxels).

        `crop_w`, `crop_h`, and `crop_d` must be specified together. Providing values
        for `crop_w`, `crop_h`, and `crop_d` is incompatible with providing the fixed crop
        window dimensions (argument `crop`).
    crop_h : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping the window height (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop
        window dimensions (argument `crop`).
    crop_pos_x : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) horizontal position of the cropping window
        (upper left corner).

        The actual position is calculated as ``crop_x = crop_x_norm * (W - crop_W)``, where `crop_x_norm`
        is the normalized position, ``W`` is the width of the image, and ``crop_W`` is the width of the
        cropping window.

        See `rounding` argument for more details on how ``crop_x`` is converted to an integral value.
    crop_pos_y : float or Tensor/Batch of float, optional, default = `0.5`
        Normalized (0.0 - 1.0) vertical position of the start of
        the cropping window (typically, the upper left corner).

        The actual position is calculated as ``crop_y = crop_y_norm * (H - crop_H)``, where ``crop_y_norm``
        is the normalized position, `H` is the height of the image, and ``crop_H`` is the height of the
        cropping window.

        See `rounding` argument for more details on how ``crop_y`` is converted to an integral value.
    crop_pos_z : float or Tensor/Batch of float, optional, default = `0.5`
        Applies **only** to volumetric inputs.

        Normalized (0.0 - 1.0) normal position of the cropping window (front plane).
        The actual position is calculated as ``crop_z = crop_z_norm * (D - crop_D)``, where ``crop_z_norm``
        is the normalized position, ``D`` is the depth of the image and ``crop_D`` is the depth of the
        cropping window.

        See `rounding` argument for more details on how ``crop_z`` is converted to an integral value.
    crop_w : float or Tensor/Batch of float, optional, default = `0.0`
        Cropping window width (in pixels).

        Providing values for `crop_w` and `crop_h` is incompatible with providing fixed crop window
        dimensions (argument `crop`).
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rounding : str, optional, default = `'round'`
        Determines the rounding function used to convert the starting coordinate
        of the window to an integral value (see `crop_pos_x`, `crop_pos_y`, `crop_pos_z`).

        Possible values are:

        * | ``"round"`` - Rounds to the nearest integer value, with halfway cases rounded away from zero.
        * | ``"truncate"`` - Discards the fractional part of the number (truncates towards zero).
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_random_crop(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    num_attempts: Optional[int] = 10,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    random_area: Union[Sequence[float], float, None] = [0.08, 1.0],
    random_aspect_ratio: Union[Sequence[float], float, None] = [0.75, 1.333333],
    seed: Optional[int] = -1,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Decodes images and randomly crops them.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The cropping window's area (relative to the entire image) and aspect ratio can be restricted to
    a range of values specified by ``area`` and `aspect_ratio` arguments. respectively.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    num_attempts : int, optional, default = `10`
        Maximum number of attempts used to choose random area and aspect ratio.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    random_area : float or list of float, optional, default = `[0.08, 1.0]`
        Range from which to choose random area fraction ``A``.

        The cropped image's area will be equal to ``A`` * original image's area.
    random_aspect_ratio : float or list of float, optional, default = `[0.75, 1.333333]`
        Range from which to choose random aspect ratio (width/height).
    seed : int, optional, default = `-1`
        Random seed; if not set, one will be assigned automatically.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_random_crop(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    batch_size: int,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    num_attempts: Optional[int] = 10,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    random_area: Union[Sequence[float], float, None] = [0.08, 1.0],
    random_aspect_ratio: Union[Sequence[float], float, None] = [0.75, 1.333333],
    seed: Optional[int] = -1,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and randomly crops them.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The cropping window's area (relative to the entire image) and aspect ratio can be restricted to
    a range of values specified by ``area`` and `aspect_ratio` arguments. respectively.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    num_attempts : int, optional, default = `10`
        Maximum number of attempts used to choose random area and aspect ratio.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    random_area : float or list of float, optional, default = `[0.08, 1.0]`
        Range from which to choose random area fraction ``A``.

        The cropped image's area will be equal to ``A`` * original image's area.
    random_aspect_ratio : float or list of float, optional, default = `[0.75, 1.333333]`
        Range from which to choose random aspect ratio (width/height).
    seed : int, optional, default = `-1`
        Random seed; if not set, one will be assigned automatically.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_random_crop(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    num_attempts: Optional[int] = 10,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    random_area: Union[Sequence[float], float, None] = [0.08, 1.0],
    random_aspect_ratio: Union[Sequence[float], float, None] = [0.75, 1.333333],
    seed: Optional[int] = -1,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and randomly crops them.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The cropping window's area (relative to the entire image) and aspect ratio can be restricted to
    a range of values specified by ``area`` and `aspect_ratio` arguments. respectively.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    num_attempts : int, optional, default = `10`
        Maximum number of attempts used to choose random area and aspect ratio.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    random_area : float or list of float, optional, default = `[0.08, 1.0]`
        Range from which to choose random area fraction ``A``.

        The cropped image's area will be equal to ``A`` * original image's area.
    random_aspect_ratio : float or list of float, optional, default = `[0.75, 1.333333]`
        Range from which to choose random aspect ratio (width/height).
    seed : int, optional, default = `-1`
        Random seed; if not set, one will be assigned automatically.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_slice(
    data: Batch,
    anchor: Optional[Batch] = None,
    shape_input: Optional[Batch] = None,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    axes: Union[TensorLikeArg, Batch, Sequence[int], int, None] = [1, 0],
    axis_names: Optional[str] = "WH",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    end: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    normalized_anchor: Optional[builtins.bool] = True,
    normalized_shape: Optional[builtins.bool] = True,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rel_end: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_shape: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_start: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    shape: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    start: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and extracts regions of interest.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The slice can be specified by proving the start and end coordinates, or start coordinates
    and shape of the slice. Both coordinates and shapes can be provided in absolute or relative terms.

    The slice arguments can be specified by the following named arguments:

    #. `start`: Slice start coordinates (absolute)
    #. `rel_start`: Slice start coordinates (relative)
    #. `end`: Slice end coordinates (absolute)
    #. `rel_end`: Slice end coordinates (relative)
    #. `shape`: Slice shape (absolute)
    #. `rel_shape`: Slice shape (relative)

    The slice can be configured by providing start and end coordinates or start and shape.
    Relative and absolute arguments can be mixed (for example, `rel_start` can be used with `shape`)
    as long as start and shape or end are uniquely defined.

    Alternatively, two extra positional inputs can be provided, specifying `__anchor` and `__shape`.
    When using positional inputs, two extra boolean arguments `normalized_anchor`/`normalized_shape`
    can be used to specify the nature of the arguments provided. Using positional inputs for anchor
    and shape is incompatible with the named arguments specified above.

    The slice arguments should provide as many dimensions as specified by the `axis_names` or `axes`
    arguments.

    By default, the :meth:`nvidia.dali.fn.decoders.image_slice` operator uses normalized coordinates
    and "WH" order for the slice arguments.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    data : Tensor/Batch
        Batch that contains the input data.
    anchor : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the starting
        point of the slice (x0, x1, x2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_anchor`.
    shape_input : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the dimensions
        of the slice (s0, s1, s2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_shape`.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    axes : int or list of int or Tensor/Batch of int, optional, default = `[1, 0]`
        Order of dimensions used for the anchor and shape slice inputs as dimension
        indices.

        Negative values are interpreted as counting dimensions from the back.
        Valid range: ``[-ndim, ndim-1]``, where ndim is the number of dimensions in the input data.
    axis_names : :ref:`layout str<layout_str_doc>`, optional, default = `'WH'`
        Order of the dimensions used for the anchor and shape slice inputs,
        as described in layout.

        If a value is provided, `axis_names` will have a higher priority than `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    end : int or list of int or Tensor/Batch of int, optional
        End coordinates of the slice.

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    normalized_anchor : bool, optional, default = `True`
        Determines whether the anchor positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    normalized_shape : bool, optional, default = `True`
        Determines whether the shape positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rel_end : float or list of float or Tensor/Batch of float, optional
        End relative coordinates of the slice (range [0.0 - 1.0].

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_shape : float or list of float or Tensor/Batch of float, optional
        Relative shape of the slice (range [0.0 - 1.0]).

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_start : float or list of float or Tensor/Batch of float, optional
        Start relative coordinates of the slice (range [0.0 - 1.0]).

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    shape : int or list of int or Tensor/Batch of int, optional
        Shape of the slice.

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    start : int or list of int or Tensor/Batch of int, optional
        Start coordinates of the slice.

        Note: Providing named arguments `start`/`end` or `start`/`shape` is incompatible with
        providing positional inputs anchor and shape.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_slice(
    data: Union[TensorLike, Batch],
    anchor: Union[TensorLike, Batch, None] = None,
    shape_input: Union[TensorLike, Batch, None] = None,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    axes: Union[TensorLikeArg, Batch, Sequence[int], int, None] = [1, 0],
    axis_names: Optional[str] = "WH",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    end: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    normalized_anchor: Optional[builtins.bool] = True,
    normalized_shape: Optional[builtins.bool] = True,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rel_end: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_shape: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_start: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    shape: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    start: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Decodes images and extracts regions of interest.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The slice can be specified by proving the start and end coordinates, or start coordinates
    and shape of the slice. Both coordinates and shapes can be provided in absolute or relative terms.

    The slice arguments can be specified by the following named arguments:

    #. `start`: Slice start coordinates (absolute)
    #. `rel_start`: Slice start coordinates (relative)
    #. `end`: Slice end coordinates (absolute)
    #. `rel_end`: Slice end coordinates (relative)
    #. `shape`: Slice shape (absolute)
    #. `rel_shape`: Slice shape (relative)

    The slice can be configured by providing start and end coordinates or start and shape.
    Relative and absolute arguments can be mixed (for example, `rel_start` can be used with `shape`)
    as long as start and shape or end are uniquely defined.

    Alternatively, two extra positional inputs can be provided, specifying `__anchor` and `__shape`.
    When using positional inputs, two extra boolean arguments `normalized_anchor`/`normalized_shape`
    can be used to specify the nature of the arguments provided. Using positional inputs for anchor
    and shape is incompatible with the named arguments specified above.

    The slice arguments should provide as many dimensions as specified by the `axis_names` or `axes`
    arguments.

    By default, the :meth:`nvidia.dali.fn.decoders.image_slice` operator uses normalized coordinates
    and "WH" order for the slice arguments.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    data : Tensor/Batch
        Batch that contains the input data.
    anchor : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the starting
        point of the slice (x0, x1, x2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_anchor`.
    shape_input : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the dimensions
        of the slice (s0, s1, s2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_shape`.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    axes : int or list of int or Tensor/Batch of int, optional, default = `[1, 0]`
        Order of dimensions used for the anchor and shape slice inputs as dimension
        indices.

        Negative values are interpreted as counting dimensions from the back.
        Valid range: ``[-ndim, ndim-1]``, where ndim is the number of dimensions in the input data.
    axis_names : :ref:`layout str<layout_str_doc>`, optional, default = `'WH'`
        Order of the dimensions used for the anchor and shape slice inputs,
        as described in layout.

        If a value is provided, `axis_names` will have a higher priority than `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    end : int or list of int or Tensor/Batch of int, optional
        End coordinates of the slice.

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    normalized_anchor : bool, optional, default = `True`
        Determines whether the anchor positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    normalized_shape : bool, optional, default = `True`
        Determines whether the shape positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rel_end : float or list of float or Tensor/Batch of float, optional
        End relative coordinates of the slice (range [0.0 - 1.0].

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_shape : float or list of float or Tensor/Batch of float, optional
        Relative shape of the slice (range [0.0 - 1.0]).

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_start : float or list of float or Tensor/Batch of float, optional
        Start relative coordinates of the slice (range [0.0 - 1.0]).

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    shape : int or list of int or Tensor/Batch of int, optional
        Shape of the slice.

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    start : int or list of int or Tensor/Batch of int, optional
        Start coordinates of the slice.

        Note: Providing named arguments `start`/`end` or `start`/`shape` is incompatible with
        providing positional inputs anchor and shape.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def image_slice(
    data: Union[TensorLike, Batch],
    anchor: Union[TensorLike, Batch, None] = None,
    shape_input: Union[TensorLike, Batch, None] = None,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    batch_size: int,
    adjust_orientation: Optional[builtins.bool] = True,
    affine: Optional[builtins.bool] = True,
    axes: Union[TensorLikeArg, Batch, Sequence[int], int, None] = [1, 0],
    axis_names: Optional[str] = "WH",
    device_memory_padding: Optional[int] = 16777216,
    device_memory_padding_jpeg2k: Optional[int] = 0,
    dtype: Union[DALIDataType, DType, None] = DALIDataType.UINT8,
    end: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    host_memory_padding: Optional[int] = 8388608,
    host_memory_padding_jpeg2k: Optional[int] = 0,
    hw_decoder_load: Optional[float] = 0.9,
    hybrid_huffman_threshold: Optional[int] = 1000000,
    jpeg_fancy_upsampling: Optional[builtins.bool] = False,
    normalized_anchor: Optional[builtins.bool] = True,
    normalized_shape: Optional[builtins.bool] = True,
    output_type: Optional[DALIImageType] = DALIImageType.RGB,
    preallocate_height_hint: Optional[int] = 0,
    preallocate_width_hint: Optional[int] = 0,
    rel_end: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_shape: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    rel_start: Union[TensorLikeArg, Batch, Sequence[float], float, None] = None,
    shape: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    start: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    use_fast_idct: Optional[builtins.bool] = False,
) -> Batch:
    """
    Decodes images and extracts regions of interest.

    Supported formats: JPEG, JPEG 2000, TIFF, PNG, BMP, PNM, PPM, PGM, PBM, WebP.

    The output of the decoder is in *HWC* layout.

    The implementation uses NVIDIA nvImageCodec to decode images.

    The slice can be specified by proving the start and end coordinates, or start coordinates
    and shape of the slice. Both coordinates and shapes can be provided in absolute or relative terms.

    The slice arguments can be specified by the following named arguments:

    #. `start`: Slice start coordinates (absolute)
    #. `rel_start`: Slice start coordinates (relative)
    #. `end`: Slice end coordinates (absolute)
    #. `rel_end`: Slice end coordinates (relative)
    #. `shape`: Slice shape (absolute)
    #. `rel_shape`: Slice shape (relative)

    The slice can be configured by providing start and end coordinates or start and shape.
    Relative and absolute arguments can be mixed (for example, `rel_start` can be used with `shape`)
    as long as start and shape or end are uniquely defined.

    Alternatively, two extra positional inputs can be provided, specifying `__anchor` and `__shape`.
    When using positional inputs, two extra boolean arguments `normalized_anchor`/`normalized_shape`
    can be used to specify the nature of the arguments provided. Using positional inputs for anchor
    and shape is incompatible with the named arguments specified above.

    The slice arguments should provide as many dimensions as specified by the `axis_names` or `axes`
    arguments.

    By default, the :meth:`nvidia.dali.fn.decoders.image_slice` operator uses normalized coordinates
    and "WH" order for the slice arguments.

    When possible, the operator uses the ROI decoding, reducing the decoding time and memory consumption.

    .. note::
      GPU accelerated decoding is only available for a subset of the image formats (JPEG, and JPEG2000).
      For other formats, a CPU based decoder is used. For JPEG, a dedicated HW decoder will be used when
      available.

    .. note::
      WebP decoding currently only supports the simple file format (lossy and lossless compression).
      For details on the different WebP file formats, see
      https://developers.google.com/speed/webp/docs/riff_container



    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    data : Tensor/Batch
        Batch that contains the input data.
    anchor : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the starting
        point of the slice (x0, x1, x2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_anchor`.
    shape_input : 1D Tensor/Batch of float or int, optional
        Input that contains normalized or absolute coordinates for the dimensions
        of the slice (s0, s1, s2, ).

        Integer coordinates are interpreted as absolute coordinates, while float coordinates can be
        interpreted as absolute or relative coordinates, depending on the value of
        `normalized_shape`.


    Keyword args
    ------------
    adjust_orientation : bool, optional, default = `True`
        Use EXIF orientation metadata to rectify the images
    affine : bool, optional, default = `True`
        Applies **only** to the ``mixed`` backend type.

        If set to True, each thread in the internal thread pool will be tied to a specific CPU core.
        Otherwise, the threads can be reassigned to any CPU core by the operating system.
    axes : int or list of int or Tensor/Batch of int, optional, default = `[1, 0]`
        Order of dimensions used for the anchor and shape slice inputs as dimension
        indices.

        Negative values are interpreted as counting dimensions from the back.
        Valid range: ``[-ndim, ndim-1]``, where ndim is the number of dimensions in the input data.
    axis_names : :ref:`layout str<layout_str_doc>`, optional, default = `'WH'`
        Order of the dimensions used for the anchor and shape slice inputs,
        as described in layout.

        If a value is provided, `axis_names` will have a higher priority than `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    device_memory_padding : int, optional, default = `16777216`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates one device buffer of the
        requested size per thread. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    device_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's device memory allocations, in bytes. This parameter helps to avoid
        reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs to be
        reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional allocations
        will occur during the pipeline execution.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional, default = `DALIDataType.UINT8`
        Output data type of the image.

        Values will be converted to the dynamic range of the requested type.
    end : int or list of int or Tensor/Batch of int, optional
        End coordinates of the slice.

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    host_memory_padding : int, optional, default = `8388608`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates two (because of double-buffering)
        host-pinned buffers of the requested size per thread. If selected correctly, no additional
        allocations will occur during the pipeline execution.
    host_memory_padding_jpeg2k : int, optional, default = `0`
        Applies **only** to the ``mixed`` backend type.

        The padding for nvJPEG2k's host memory allocations, in bytes. This parameter helps to prevent
        the reallocation in nvJPEG2k when a larger image is encountered, and the internal buffer needs
        to be reallocated to decode the image.

        If a value greater than 0 is provided, the operator preallocates the necessary number of buffers
        according to the hint provided. If the value is correctly selected, no additional
        allocations will occur during the pipeline execution.
    hw_decoder_load : float, optional, default = `0.9`
        The percentage of the image data to be processed by the HW JPEG decoder.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        Determines the percentage of the workload that will be offloaded to the hardware decoder,
        if available. The optimal workload depends on the number of threads that are provided to
        the DALI pipeline and should be found empirically. More details can be found at
        https://developer.nvidia.com/blog/loading-data-fast-with-dali-and-new-jpeg-decoder-in-a100
    hybrid_huffman_threshold : int, optional, default = `1000000`
        Applies **only** to the ``mixed`` backend type.

        Images with a total number of pixels (``height * width``) that is higher than this threshold will
        use the nvJPEG hybrid Huffman decoder. Images that have fewer pixels will use the nvJPEG host-side
        Huffman decoder.

        .. note::
          Hybrid Huffman decoder still largely uses the CPU.
    jpeg_fancy_upsampling : bool, optional, default = `False`
        Make the ``mixed`` backend use the same chroma upsampling approach as the ``cpu`` one.

        The option corresponds to the `JPEG fancy upsampling` available in libjpegturbo or
        ImageMagick.
    memory_stats : bool, optional, default = `False`


        .. warning::

            The argument `memory_stats` is now deprecated and its usage is discouraged.
    normalized_anchor : bool, optional, default = `True`
        Determines whether the anchor positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    normalized_shape : bool, optional, default = `True`
        Determines whether the shape positional input should be interpreted as normalized
        (range [0.0, 1.0]) or as absolute coordinates.

        .. note::
          This argument is only relevant when anchor data type is ``float``. For integer types,
          the coordinates are always absolute.
    output_type : :class:`nvidia.dali.types.DALIImageType`, optional, default = `DALIImageType.RGB`
        The color space of the output image.

        Note: When decoding to YCbCr, the image will be decoded to RGB and then converted to YCbCr,
        following the YCbCr definition from ITU-R BT.601.
    preallocate_height_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preallocate_width_hint : int, optional, default = `0`
        Image width hint.

        Applies **only** to the ``mixed`` backend type in NVIDIA Ampere GPU architecture.

        The hint is used to preallocate memory for the HW JPEG decoder.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    rel_end : float or list of float or Tensor/Batch of float, optional
        End relative coordinates of the slice (range [0.0 - 1.0].

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_shape : float or list of float or Tensor/Batch of float, optional
        Relative shape of the slice (range [0.0 - 1.0]).

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    rel_start : float or list of float or Tensor/Batch of float, optional
        Start relative coordinates of the slice (range [0.0 - 1.0]).

        Note: Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    shape : int or list of int or Tensor/Batch of int, optional
        Shape of the slice.

        Providing named arguments `start`, `end`, `shape`, `rel_start`, `rel_end`, `rel_shape`
        is incompatible with providing positional inputs anchor and shape.
    split_stages : bool, optional, default = `False`


        .. warning::

            The argument `split_stages` is now deprecated and its usage is discouraged.
    start : int or list of int or Tensor/Batch of int, optional
        Start coordinates of the slice.

        Note: Providing named arguments `start`/`end` or `start`/`shape` is incompatible with
        providing positional inputs anchor and shape.
    use_chunk_allocator : bool, optional, default = `False`


        .. warning::

            The argument `use_chunk_allocator` is now deprecated and its usage is discouraged.
    use_fast_idct : bool, optional, default = `False`
        Enables fast IDCT in the libjpeg-turbo based CPU decoder, used when `device` is set
        to "cpu" or when the it is set to "mixed" but the particular image can not be handled by
        the GPU implementation.

        According to the libjpeg-turbo documentation, decompression performance is improved by up to 14%
        with little reduction in quality.

    """

@overload
def video(
    encoded: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    affine: Optional[builtins.bool] = True,
    build_index: Optional[builtins.bool] = True,
    end_frame: Union[TensorLikeArg, Batch, int, None] = None,
    fill_value: Union[Sequence[int], int, None] = [0],
    frames: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    pad_mode: Union[TensorLikeArg, Batch, str, None] = "constant",
    sequence_length: Union[TensorLikeArg, Batch, int, None] = None,
    start_frame: Union[TensorLikeArg, Batch, int, None] = None,
    stride: Union[TensorLikeArg, Batch, int, None] = None,
) -> Union[Tensor, Batch]:
    """
    Decodes videos from in-memory streams.

    The operator supports most common video container formats using libavformat (FFmpeg).
    The operator utilizes either libavcodec (FFmpeg) or NVIDIA Video Codec SDK (NVDEC) for decoding the frames.

    The following video codecs are supported by both CPU and Mixed backends:

    * H.264/AVC
    * H.265/HEVC
    * VP8
    * VP9
    * MJPEG

    The following codecs are supported by the Mixed backend only:

    * AV1
    * MPEG-4

    Each output sample is a sequence of frames with shape ``(F, H, W, C)`` where:

    * ``F`` is the number of frames in the sequence (can vary between samples)
    * ``H`` is the frame height in pixels
    * ``W`` is the frame width in pixels
    * ``C`` is the number of color channels

    The operator provides several ways to select which frames to extract from the video:

    * Using no frame selection arguments:

      * When no frame selection arguments are provided, all frames in the video are decoded
      * Frames are extracted sequentially from start to end with stride=1
      * For example, a 10-frame video would extract frames [0,1,2,3,4,5,6,7,8,9]

    * Using the ``frames`` argument:

      * Accepts a list of frame indices to extract from the video
      * Frame indices can be specified in any order and can repeat frames
      * Each index must be non-negative and may exceed the bounds of the video, if the ``pad_mode`` is not ``none``

    * Using ``start_frame``, ``end_frame`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``end_frame``: Last frame to extract (exclusive)
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts frames in the range [start_frame, end_frame) advancing by stride
      * For example, with start_frame=0, end_frame=10, stride=2 extracts frames [0,2,4,6,8]

    * Using ``start_frame``, ``sequence_length`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``sequence_length``: Number of frames to extract
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts sequence_length frames starting at start_frame, advancing by stride
      * For example, with start_frame=0, sequence_length=5, stride=2 extracts frames [0,2,4,6,8]

    If the requested frames exceed the bounds of the video, the behavior depends on
    ``pad_mode``. If pad_mode is ``none``, it causes an error. Otherwise, the sequence is padded according to the
    ``pad_mode`` argument (see ``pad_mode`` for details).

    Example 1: Extract a sequence of arbitrary frames:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.video(
            encoded=encoded_video,
            frames=[0, 10, 20, 30, 40, 50, 40, 30, 20, 10, 0]
            ...,
        )

    Example 2: Extract a sequence of evenly spaced frames, starting from frame 0,
    with a stride of 2, until frame 20 (exclusive):

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, end_frame=20, stride=2
            ...,
        )

    Example 3: Pad the sequence with the last frame in the video, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="edge"
            ...,
        )

    Example 4: Pad the sequence with a constant value of 128, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=128
            ...,

    Example 5: Pad the sequence with a constant RGB value of (118, 185, 0), until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=[118, 185, 0]
            ...,


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    encoded : Tensor/Batch
        Encoded video stream


    Keyword args
    ------------
    affine : bool, optional, default = `True`
        Whether to pin threads to CPU cores (mixed backend only).

        If True, each thread in the internal thread pool will be pinned to a specific CPU core.
        If False, threads can migrate between cores based on OS scheduling.
    build_index : bool, optional, default = `True`
        Controls whether to build a frame index during initialization.

        Building an index allows faster seeking to specific frames, but requires additional CPU memory
        to store frame metadata and longer initialization time to scan the entire video file. The index
        stores metadata, such as whether it is a key frame and the presentation timestamp (PTS).

        Building an index is particularly useful when decoding a small number of frames spaced far
        apart or starting playback from a frame deep into the video.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    end_frame : int or Tensor/Batch of int, optional
        Last frame to extract from each video (exclusive). Cannot be used with ``frames`` or ``sequence_length``.
    fill_value : int or list of int, optional, default = `[0]`
        Value(s) used to pad missing frames when ``pad_mode='constant'``'.

        Each value must be in range [0, 255].
        If a single value is provided, it will be used for all channels.
        Otherwise, the number of values must match the number of channels in the video.
    frames : int or list of int or Tensor/Batch of int, optional
        Specifies which frames to extract from each video by their indices.

        The indices can be provided in any order and can include duplicates. For example, ``[0,10,5,10]`` would extract:

        * Frame 0 (first frame)
        * Frame 10
        * Frame 5
        * Frame 10 (again)

        This argument cannot be used together with ``start_frame``, ``sequence_length``, ``stride``.
    pad_mode : str or Tensor/Batch of str, optional, default = `'constant'`
        How to handle videos with insufficient frames when using start_frame/sequence_length/stride:

        * ``'none'``: Return shorter sequences if not enough frames: ABC -> ABC
        * ``'constant'``: Pad with a fixed value (specified by ``pad_value``): ABC -> ABCPPP
        * ``'edge'`` or ``'repeat'``: Repeat the last valid frame: ABC -> ABCCCC
        * ``'reflect_1001'`` or ``'symmetric'``: Reflect padding, including the last element: ABC -> ABCCBA
        * ``'reflect_101'`` or ``'reflect'``: Reflect padding, not including the last element: ABC -> ABCBA

        Not relevant when using ``frames`` argument.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    sequence_length : int or Tensor/Batch of int, optional
        Number of frames to extract from each video. Cannot be used together with ``frames`` or ``end_frame`` arguments.
    start_frame : int or Tensor/Batch of int, optional
        Index of the first frame to extract from each video. Cannot be used together with ``frames`` argument.
    stride : int or Tensor/Batch of int, optional
        Number of frames to skip between each extracted frame. Cannot be used together with ``frames`` argument.

    """

@overload
def video(
    encoded: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    batch_size: int,
    affine: Optional[builtins.bool] = True,
    build_index: Optional[builtins.bool] = True,
    end_frame: Union[TensorLikeArg, Batch, int, None] = None,
    fill_value: Union[Sequence[int], int, None] = [0],
    frames: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    pad_mode: Union[TensorLikeArg, Batch, str, None] = "constant",
    sequence_length: Union[TensorLikeArg, Batch, int, None] = None,
    start_frame: Union[TensorLikeArg, Batch, int, None] = None,
    stride: Union[TensorLikeArg, Batch, int, None] = None,
) -> Batch:
    """
    Decodes videos from in-memory streams.

    The operator supports most common video container formats using libavformat (FFmpeg).
    The operator utilizes either libavcodec (FFmpeg) or NVIDIA Video Codec SDK (NVDEC) for decoding the frames.

    The following video codecs are supported by both CPU and Mixed backends:

    * H.264/AVC
    * H.265/HEVC
    * VP8
    * VP9
    * MJPEG

    The following codecs are supported by the Mixed backend only:

    * AV1
    * MPEG-4

    Each output sample is a sequence of frames with shape ``(F, H, W, C)`` where:

    * ``F`` is the number of frames in the sequence (can vary between samples)
    * ``H`` is the frame height in pixels
    * ``W`` is the frame width in pixels
    * ``C`` is the number of color channels

    The operator provides several ways to select which frames to extract from the video:

    * Using no frame selection arguments:

      * When no frame selection arguments are provided, all frames in the video are decoded
      * Frames are extracted sequentially from start to end with stride=1
      * For example, a 10-frame video would extract frames [0,1,2,3,4,5,6,7,8,9]

    * Using the ``frames`` argument:

      * Accepts a list of frame indices to extract from the video
      * Frame indices can be specified in any order and can repeat frames
      * Each index must be non-negative and may exceed the bounds of the video, if the ``pad_mode`` is not ``none``

    * Using ``start_frame``, ``end_frame`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``end_frame``: Last frame to extract (exclusive)
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts frames in the range [start_frame, end_frame) advancing by stride
      * For example, with start_frame=0, end_frame=10, stride=2 extracts frames [0,2,4,6,8]

    * Using ``start_frame``, ``sequence_length`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``sequence_length``: Number of frames to extract
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts sequence_length frames starting at start_frame, advancing by stride
      * For example, with start_frame=0, sequence_length=5, stride=2 extracts frames [0,2,4,6,8]

    If the requested frames exceed the bounds of the video, the behavior depends on
    ``pad_mode``. If pad_mode is ``none``, it causes an error. Otherwise, the sequence is padded according to the
    ``pad_mode`` argument (see ``pad_mode`` for details).

    Example 1: Extract a sequence of arbitrary frames:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.video(
            encoded=encoded_video,
            frames=[0, 10, 20, 30, 40, 50, 40, 30, 20, 10, 0]
            ...,
        )

    Example 2: Extract a sequence of evenly spaced frames, starting from frame 0,
    with a stride of 2, until frame 20 (exclusive):

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, end_frame=20, stride=2
            ...,
        )

    Example 3: Pad the sequence with the last frame in the video, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="edge"
            ...,
        )

    Example 4: Pad the sequence with a constant value of 128, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=128
            ...,

    Example 5: Pad the sequence with a constant RGB value of (118, 185, 0), until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=[118, 185, 0]
            ...,


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    encoded : Tensor/Batch
        Encoded video stream


    Keyword args
    ------------
    affine : bool, optional, default = `True`
        Whether to pin threads to CPU cores (mixed backend only).

        If True, each thread in the internal thread pool will be pinned to a specific CPU core.
        If False, threads can migrate between cores based on OS scheduling.
    build_index : bool, optional, default = `True`
        Controls whether to build a frame index during initialization.

        Building an index allows faster seeking to specific frames, but requires additional CPU memory
        to store frame metadata and longer initialization time to scan the entire video file. The index
        stores metadata, such as whether it is a key frame and the presentation timestamp (PTS).

        Building an index is particularly useful when decoding a small number of frames spaced far
        apart or starting playback from a frame deep into the video.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    end_frame : int or Tensor/Batch of int, optional
        Last frame to extract from each video (exclusive). Cannot be used with ``frames`` or ``sequence_length``.
    fill_value : int or list of int, optional, default = `[0]`
        Value(s) used to pad missing frames when ``pad_mode='constant'``'.

        Each value must be in range [0, 255].
        If a single value is provided, it will be used for all channels.
        Otherwise, the number of values must match the number of channels in the video.
    frames : int or list of int or Tensor/Batch of int, optional
        Specifies which frames to extract from each video by their indices.

        The indices can be provided in any order and can include duplicates. For example, ``[0,10,5,10]`` would extract:

        * Frame 0 (first frame)
        * Frame 10
        * Frame 5
        * Frame 10 (again)

        This argument cannot be used together with ``start_frame``, ``sequence_length``, ``stride``.
    pad_mode : str or Tensor/Batch of str, optional, default = `'constant'`
        How to handle videos with insufficient frames when using start_frame/sequence_length/stride:

        * ``'none'``: Return shorter sequences if not enough frames: ABC -> ABC
        * ``'constant'``: Pad with a fixed value (specified by ``pad_value``): ABC -> ABCPPP
        * ``'edge'`` or ``'repeat'``: Repeat the last valid frame: ABC -> ABCCCC
        * ``'reflect_1001'`` or ``'symmetric'``: Reflect padding, including the last element: ABC -> ABCCBA
        * ``'reflect_101'`` or ``'reflect'``: Reflect padding, not including the last element: ABC -> ABCBA

        Not relevant when using ``frames`` argument.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    sequence_length : int or Tensor/Batch of int, optional
        Number of frames to extract from each video. Cannot be used together with ``frames`` or ``end_frame`` arguments.
    start_frame : int or Tensor/Batch of int, optional
        Index of the first frame to extract from each video. Cannot be used together with ``frames`` argument.
    stride : int or Tensor/Batch of int, optional
        Number of frames to skip between each extracted frame. Cannot be used together with ``frames`` argument.

    """

@overload
def video(
    encoded: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "mixed", "gpu"]] = None,
    affine: Optional[builtins.bool] = True,
    build_index: Optional[builtins.bool] = True,
    end_frame: Union[TensorLikeArg, Batch, int, None] = None,
    fill_value: Union[Sequence[int], int, None] = [0],
    frames: Union[TensorLikeArg, Batch, Sequence[int], int, None] = None,
    pad_mode: Union[TensorLikeArg, Batch, str, None] = "constant",
    sequence_length: Union[TensorLikeArg, Batch, int, None] = None,
    start_frame: Union[TensorLikeArg, Batch, int, None] = None,
    stride: Union[TensorLikeArg, Batch, int, None] = None,
) -> Batch:
    """
    Decodes videos from in-memory streams.

    The operator supports most common video container formats using libavformat (FFmpeg).
    The operator utilizes either libavcodec (FFmpeg) or NVIDIA Video Codec SDK (NVDEC) for decoding the frames.

    The following video codecs are supported by both CPU and Mixed backends:

    * H.264/AVC
    * H.265/HEVC
    * VP8
    * VP9
    * MJPEG

    The following codecs are supported by the Mixed backend only:

    * AV1
    * MPEG-4

    Each output sample is a sequence of frames with shape ``(F, H, W, C)`` where:

    * ``F`` is the number of frames in the sequence (can vary between samples)
    * ``H`` is the frame height in pixels
    * ``W`` is the frame width in pixels
    * ``C`` is the number of color channels

    The operator provides several ways to select which frames to extract from the video:

    * Using no frame selection arguments:

      * When no frame selection arguments are provided, all frames in the video are decoded
      * Frames are extracted sequentially from start to end with stride=1
      * For example, a 10-frame video would extract frames [0,1,2,3,4,5,6,7,8,9]

    * Using the ``frames`` argument:

      * Accepts a list of frame indices to extract from the video
      * Frame indices can be specified in any order and can repeat frames
      * Each index must be non-negative and may exceed the bounds of the video, if the ``pad_mode`` is not ``none``

    * Using ``start_frame``, ``end_frame`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``end_frame``: Last frame to extract (exclusive)
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts frames in the range [start_frame, end_frame) advancing by stride
      * For example, with start_frame=0, end_frame=10, stride=2 extracts frames [0,2,4,6,8]

    * Using ``start_frame``, ``sequence_length`` and ``stride``:

      * ``start_frame``: First frame to extract (default: 0)
      * ``sequence_length``: Number of frames to extract
      * ``stride``: Number of frames to skip between each extracted frame (default: 1)
      * Extracts sequence_length frames starting at start_frame, advancing by stride
      * For example, with start_frame=0, sequence_length=5, stride=2 extracts frames [0,2,4,6,8]

    If the requested frames exceed the bounds of the video, the behavior depends on
    ``pad_mode``. If pad_mode is ``none``, it causes an error. Otherwise, the sequence is padded according to the
    ``pad_mode`` argument (see ``pad_mode`` for details).

    Example 1: Extract a sequence of arbitrary frames:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.video(
            encoded=encoded_video,
            frames=[0, 10, 20, 30, 40, 50, 40, 30, 20, 10, 0]
            ...,
        )

    Example 2: Extract a sequence of evenly spaced frames, starting from frame 0,
    with a stride of 2, until frame 20 (exclusive):

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, end_frame=20, stride=2
            ...,
        )

    Example 3: Pad the sequence with the last frame in the video, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="edge"
            ...,
        )

    Example 4: Pad the sequence with a constant value of 128, until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=128
            ...,

    Example 5: Pad the sequence with a constant RGB value of (118, 185, 0), until 100 frames are reached:

    .. code-block:: python

        video_decoder = dali.experimental.decoders.Video(
            encoded=encoded_video,
            start_frame=0, sequence_length=100, stride=2, pad_mode="constant", fill_value=[118, 185, 0]
            ...,


    Supported backends
     * 'cpu'
     * 'mixed'


    Args
    ----
    encoded : Tensor/Batch
        Encoded video stream


    Keyword args
    ------------
    affine : bool, optional, default = `True`
        Whether to pin threads to CPU cores (mixed backend only).

        If True, each thread in the internal thread pool will be pinned to a specific CPU core.
        If False, threads can migrate between cores based on OS scheduling.
    build_index : bool, optional, default = `True`
        Controls whether to build a frame index during initialization.

        Building an index allows faster seeking to specific frames, but requires additional CPU memory
        to store frame metadata and longer initialization time to scan the entire video file. The index
        stores metadata, such as whether it is a key frame and the presentation timestamp (PTS).

        Building an index is particularly useful when decoding a small number of frames spaced far
        apart or starting playback from a frame deep into the video.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    end_frame : int or Tensor/Batch of int, optional
        Last frame to extract from each video (exclusive). Cannot be used with ``frames`` or ``sequence_length``.
    fill_value : int or list of int, optional, default = `[0]`
        Value(s) used to pad missing frames when ``pad_mode='constant'``'.

        Each value must be in range [0, 255].
        If a single value is provided, it will be used for all channels.
        Otherwise, the number of values must match the number of channels in the video.
    frames : int or list of int or Tensor/Batch of int, optional
        Specifies which frames to extract from each video by their indices.

        The indices can be provided in any order and can include duplicates. For example, ``[0,10,5,10]`` would extract:

        * Frame 0 (first frame)
        * Frame 10
        * Frame 5
        * Frame 10 (again)

        This argument cannot be used together with ``start_frame``, ``sequence_length``, ``stride``.
    pad_mode : str or Tensor/Batch of str, optional, default = `'constant'`
        How to handle videos with insufficient frames when using start_frame/sequence_length/stride:

        * ``'none'``: Return shorter sequences if not enough frames: ABC -> ABC
        * ``'constant'``: Pad with a fixed value (specified by ``pad_value``): ABC -> ABCPPP
        * ``'edge'`` or ``'repeat'``: Repeat the last valid frame: ABC -> ABCCCC
        * ``'reflect_1001'`` or ``'symmetric'``: Reflect padding, including the last element: ABC -> ABCCBA
        * ``'reflect_101'`` or ``'reflect'``: Reflect padding, not including the last element: ABC -> ABCBA

        Not relevant when using ``frames`` argument.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.
    sequence_length : int or Tensor/Batch of int, optional
        Number of frames to extract from each video. Cannot be used together with ``frames`` or ``end_frame`` arguments.
    start_frame : int or Tensor/Batch of int, optional
        Index of the first frame to extract from each video. Cannot be used together with ``frames`` argument.
    stride : int or Tensor/Batch of int, optional
        Number of frames to skip between each extracted frame. Cannot be used together with ``frames`` argument.

    """
