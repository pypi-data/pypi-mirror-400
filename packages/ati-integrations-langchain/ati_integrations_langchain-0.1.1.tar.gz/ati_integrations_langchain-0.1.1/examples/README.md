# LangChain ATI Example

This example demonstrates how to instrument a LangChain agent with IOcane ATI.

## Prerequisites

- Python 3.10+
- An IOcane account (run `iocane connect` to setup your environment)

## Setup

1.  **Install Dependencies**
    ```bash
    pip install langchain langchain-openai
    pip install opentelemetry-sdk opentelemetry-exporter-otlp
    # Install ATI SDK and Integration (adjust paths if local)
    pip install ati-sdk ati-integrations-langchain
    ```

2.  **Configure Environment**
    Get your API Key and Environment ID from `.env.iocane` (generated by `iocane connect`) or the IOcane Dashboard.

    ```bash
    # Linux/Mac
    export OPENAI_API_KEY="sk-..."  # If using real LLM
    export OTEL_SERVICE_NAME="langchain-example-agent"
    export OTEL_EXPORTER_OTLP_ENDPOINT="https://api.iocane.ai/v1/traces"
    export OTEL_EXPORTER_OTLP_HEADERS="x-iocane-key=<YOUR_KEY>,x-ati-env=<YOUR_ENV_ID>"
    ```

## Running the Example

```bash
python minimal_agent.py
```

## Expected Output

You should see the agent executing steps in the console. 
In the IOcane Dashboard, you will see a trace representing the agent's execution, including:
- **Agent Span**: The main wrapper for the execution.
- **Step Spans**: Each "thought/action" cycle.
- **LLM Spans**: Calls to OpenAI.
- **Tool Spans**: Execution of tools (e.g., Search, Calculator).
