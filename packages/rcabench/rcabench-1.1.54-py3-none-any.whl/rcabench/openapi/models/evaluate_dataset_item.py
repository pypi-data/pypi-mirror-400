"""
RCABench API

RCABench - A comprehensive root cause analysis benchmarking platform for microservices

The version of the OpenAPI document: 1.1.54
Contact: team@rcabench.com
Generated by OpenAPI Generator (https://rcabench.openapi-generator.tech)

Do not edit the class manually.
"""  # noqa: E501

from __future__ import annotations

import json
import pprint
from typing import Any, ClassVar

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr
from typing_extensions import Self

from rcabench.openapi.models.evaluate_datapack_ref import EvaluateDatapackRef


class EvaluateDatasetItem(BaseModel):
    """
    EvaluateDatasetItem
    """  # noqa: E501

    algorithm: StrictStr | None = Field(default=None, description="Algorithm name")
    algorithm_version: StrictStr | None = Field(default=None, description="Algorithm version")
    dataset: StrictStr | None = Field(default=None, description="Dataset name")
    dataset_version: StrictStr | None = Field(default=None, description="Dataset version")
    evalaute_refs: list[EvaluateDatapackRef] | None = Field(
        default=None, description="Evaluation refs for each dataset"
    )
    not_executed_datapacks: list[StrictStr] | None = Field(default=None, description="Datapacks that were not executed")
    total_count: StrictInt | None = Field(default=None, description="Total number of datapacks in dataset")
    additional_properties: dict[str, Any] = {}
    __properties: ClassVar[list[str]] = [
        "algorithm",
        "algorithm_version",
        "dataset",
        "dataset_version",
        "evalaute_refs",
        "not_executed_datapacks",
        "total_count",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return self.model_dump_json(by_alias=True, exclude_unset=True)

    @classmethod
    def from_json(cls, json_str: str) -> Self | None:
        """Create an instance of EvaluateDatasetItem from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        * Fields in `self.additional_properties` are added to the output dict.
        """
        excluded_fields: set[str] = set(
            [
                "additional_properties",
            ]
        )

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in evalaute_refs (list)
        _items = []
        if self.evalaute_refs:
            for _item_evalaute_refs in self.evalaute_refs:
                if _item_evalaute_refs:
                    _items.append(_item_evalaute_refs.to_dict())
            _dict["evalaute_refs"] = _items
        # puts key-value pairs in additional_properties in the top level
        if self.additional_properties is not None:
            for _key, _value in self.additional_properties.items():
                _dict[_key] = _value

        return _dict

    @classmethod
    def from_dict(cls, obj: dict[str, Any] | None) -> Self | None:
        """Create an instance of EvaluateDatasetItem from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "algorithm": obj.get("algorithm"),
                "algorithm_version": obj.get("algorithm_version"),
                "dataset": obj.get("dataset"),
                "dataset_version": obj.get("dataset_version"),
                "evalaute_refs": [EvaluateDatapackRef.from_dict(_item) for _item in obj["evalaute_refs"]]
                if obj.get("evalaute_refs") is not None
                else None,
                "not_executed_datapacks": obj.get("not_executed_datapacks"),
                "total_count": obj.get("total_count"),
            }
        )
        # store additional fields in additional_properties
        for _key in obj.keys():
            if _key not in cls.__properties:
                _obj.additional_properties[_key] = obj.get(_key)

        return _obj
