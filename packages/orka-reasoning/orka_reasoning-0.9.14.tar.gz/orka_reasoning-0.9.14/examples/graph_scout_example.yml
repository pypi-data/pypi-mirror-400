# GraphScout Agent Example Configuration
# =====================================
#
# This example demonstrates how to use the GraphScout agent for intelligent
# path discovery and selection in complex workflows.
#
# SCORING MODES:
# ==============
# GraphScout supports two scoring modes:
#
# 1. NUMERIC MODE (default, used here):
#    - Continuous scores (0.0-1.0) with weighted criteria
#    - Fast, flexible, good for exploration and ranking
#    - Use for: Real-time routing, multi-criteria optimization
#
# 2. BOOLEAN MODE (deterministic, for compliance):
#    - Explicit pass/fail for each criterion with audit trails
#    - Deterministic, auditable, regulatory-ready
#    - Use for: Production safety gates, compliance, debugging
#
# To enable boolean mode, add to params:
#   scoring_mode: "boolean"
#   strict_mode: false
#   require_critical: true
#   important_threshold: 0.8
#
# See docs/SCORING_ARCHITECTURE.md for full details.

orchestrator:
  id: graph_scout_demo
  strategy: sequential
  queue: redis
  agents:
    - graph_scout_router

agents:
  # GraphScout agent for intelligent routing with two-stage LLM evaluation
  - id: graph_scout_router
    type: graph-scout
    params:
      k_beam: 5  # Limit to top 5 candidates for efficiency
      max_depth: 3  # Limit to 2-hop paths for faster evaluation
      commit_margin: 0.1
      require_terminal: true
      score_weights:
        llm: 0.5
        heuristics: 0.25
        prior: 0.15
        cost: 0.05
        latency: 0.05
      safety_profile: default
      cost_budget_tokens: 1000
      latency_budget_ms: 5000
      max_preview_tokens: 200
      # Two-stage LLM evaluation configuration (now configurable instead of hardcoded)
      evaluation_model: "local_llm"                # Fast local model for Stage 1
      evaluation_model_name: "openai/gpt-oss-20b"     # LM Studio model id
      validation_model: "local_llm"                # Fast local model for Stage 2
      validation_model_name: "openai/gpt-oss-20b"     # LM Studio model id
      # LLM provider and endpoint for SmartPathEvaluator
      provider: lm_studio
      model_url: http://localhost:1234
      llm_evaluation_enabled: true                 # Enable LLM-powered evaluation
      fallback_to_heuristics: true                 # Fallback if LLM fails
    prompt: |
      You are GraphScout, an intelligent routing agent.
      
      Analyze the question and available workflow paths:
      Question: {{ input }}
      Classification: {{ safe_get_response('input_classifier', 'Unknown', previous_outputs) }}
      
      Consider:
      - Question type and complexity
      - Required capabilities
      - Cost and latency constraints
      - Safety requirements
      
      Select the optimal next path based on relevance, efficiency, and safety.
      Return your decision as JSON with reasoning.

  # Input classification to understand the question type
  - id: input_classifier
    type: openai-classification
    prompt: |
      Classify this question into one of these categories:
      - factual: Questions asking for facts or information
      - analytical: Questions requiring analysis or reasoning
      - creative: Questions asking for creative content
      - technical: Technical or programming questions
      
      Question: {{ input }}
      
      Return only the category name.

  # Search agent for factual questions
  - id: search_agent
    type: duckduckgo
    capabilities: [data_retrieval, web_search]
    prompt: |
      {% if "news" in input.lower() or "today" in input.lower() %}
      latest news headlines today current events
      {% else %}
      {{ input }}
      {% endif %}

  # Analysis agent for complex reasoning
  - id: analysis_agent
    type: local_llm
    capabilities: [reasoning, analysis]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Provide a detailed analysis of this question:
      {{ input }}
      
      Consider multiple perspectives and provide reasoning.

  # Memory storage for important information
  - id: memory_writer
    type: memory
    namespace: graph_scout_demo
    memory_preset: "episodic"  # Personal narrative and interactions
    config:
      operation: write
      vector: true
    prompt: |
      {
        "type": "graph_scout_record",
        "question": {{ input | tojson }},
        "classification": {{ safe_get_response('input_classifier', 'Unknown', previous_outputs) | tojson }},
        "search_results": {{ safe_get_response('search_agent', 'No search results', previous_outputs) | tojson }},
        "analysis": {{ safe_get_response('analysis_agent', 'No analysis', previous_outputs) | tojson }}
      }
    metadata:
      category: stored
      source: graph_scout_example
    key_template: "graphscout_{{ input | truncate(60) }}"

  # Final response builder
  - id: response_builder
    type: local_llm
    is_terminal: true  # Mark as terminal for GraphScout path completion
    capabilities: [answer_emit, response_generation]
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    timeout: 60.0  # Increased timeout for slow gpt-oss:20b model
    prompt: |
      Create a comprehensive response based on the available information:
      
      Original Question: {{ input }}
      {% if previous_outputs.input_classifier %}
      Question Type: {{ safe_get_response('input_classifier', 'Unknown', previous_outputs) }}
      {% endif %}

      {% if previous_outputs.search_agent %}
      Search Information: {{ safe_get_response('search_agent', 'No search info', previous_outputs) }}
      {% endif %}

      {% if previous_outputs.analysis_agent %}
      Analysis: {{ safe_get_response('analysis_agent', 'No analysis', previous_outputs) }}
      {% endif %}

      {% if previous_outputs.memory_writer %}
      Memory Context: Information has been stored for future reference.
      {% endif %}

      Provide a clear, helpful response that addresses the user's question.
      Include sources if available and explain your reasoning.
