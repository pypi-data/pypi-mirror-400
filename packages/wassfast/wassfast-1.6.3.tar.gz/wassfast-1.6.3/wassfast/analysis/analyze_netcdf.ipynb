{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from mako.template import Template\n",
    "from tqdm import tqdm\n",
    "import dateutil.parser\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NCFILE = \"data.nc\"\n",
    "root = Dataset( NCFILE, \"r\", format=\"NETCDF4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nc_file_info( filename, root ):\n",
    "    S = \"\"\n",
    "    S += \"Dataset: %s\\n\"%filename\n",
    "    S += \"------------------------------------------------------\\n\"\n",
    "    S += \"/ Variables:\\n\"\n",
    "    for v in root.variables:\n",
    "        S += \" - %s\\n\"%v\n",
    "    S += \"Attributes:\\n\"\n",
    "    for a in root.ncattrs():\n",
    "        S += \" - %s = %s\\n\"%(a,root.getncattr(a))\n",
    "    S += \"Groups: \\n\"\n",
    "    for g in root.groups:\n",
    "        S += \" %s\\n\"%root[g].path\n",
    "        S += \"  Variables:\\n\"\n",
    "        for v in root[g].variables:\n",
    "            S += \"    - %s\\n\"%v\n",
    "        S += \"  ncattrs:\\n\"\n",
    "        for a in root[g].ncattrs():\n",
    "            S += \" - %s = %s\\n\"%(a,root[g].getncattr(a))\n",
    "    return S\n",
    "               \n",
    "print( nc_file_info( NCFILE, root )  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filetobase64( filename ):\n",
    "    import base64\n",
    "    with open(filename,'rb') as f:\n",
    "        \n",
    "        fb64 = base64.b64encode( f.read() )\n",
    "        return fb64\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    I0 = cv.imdecode( root[\"/cam0images\"][1], cv.IMREAD_GRAYSCALE )\n",
    "    I0 = cv.pyrDown(I0)\n",
    "    cv.imwrite(\"frame.jpg\",I0)\n",
    "except IndexError:\n",
    "    print(\"NetCDF file has no image data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "nsamples = root[\"/Z\"].shape[0]\n",
    "gridsize = root[\"/Z\"].shape[1:3]\n",
    "\n",
    "halfgridsize_i = int( gridsize[0]/2)\n",
    "halfgridsize_j = int( gridsize[1]/2)\n",
    "\n",
    "valid_samples_i = range( halfgridsize_i-5, halfgridsize_i+6 )\n",
    "valid_samples_j = range( halfgridsize_j-5, halfgridsize_j+6 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeserie = root[\"/Z\"][:,halfgridsize_i,halfgridsize_j] * 1E-3\n",
    "timeserie = timeserie - np.mean(timeserie)\n",
    "t = root[\"/time\"]\n",
    "\n",
    "def crossings_nonzero_pos2neg(data):\n",
    "    pos = data > 0\n",
    "    return (pos[:-1] & ~pos[1:]).nonzero()[0]\n",
    "\n",
    "crossings = crossings_nonzero_pos2neg(timeserie)\n",
    "\n",
    "dmins = []\n",
    "dmaxs = []\n",
    "for ii in range( np.size(crossings)-1 ):\n",
    "    datarange = np.arange(crossings[ii], crossings[ii+1])\n",
    "    data = timeserie[ datarange ]\n",
    "    dmax = np.argmax(data)\n",
    "    dmin = np.argmin(data)\n",
    "    dmins.append( datarange[dmin] )\n",
    "    dmaxs.append( datarange[dmax] )\n",
    "    \n",
    "waveheights = np.array(timeserie[dmaxs]) - np.array(timeserie[dmins])\n",
    "q = np.quantile( waveheights, 2.0/3.0)\n",
    "print(\"quantile: \", q)\n",
    "\n",
    "highestthirdwaves = waveheights[ waveheights>q ]\n",
    "H13 = np.mean(highestthirdwaves)\n",
    "print(\"H1/3: \", H13)\n",
    "\n",
    "plt.figure( figsize=(20,10))\n",
    "plt.plot(t, timeserie )\n",
    "plt.scatter( t[crossings], np.zeros_like(crossings), c=\"r\")\n",
    "plt.scatter( t[dmins], timeserie[dmins], c=\"b\")\n",
    "plt.scatter( t[dmaxs], timeserie[dmaxs], c=\"g\")\n",
    "plt.grid()\n",
    "plt.title(\"Timeserie at grid center. %d waves\"%np.size(waveheights))\n",
    "plt.xlabel(\"Time (secs.)\")\n",
    "plt.ylabel(\"Height (m)\")\n",
    "plt.savefig(\"timeserie.png\")\n",
    "\n",
    "\n",
    "Zcube = np.array( root[\"/Z\"][:,valid_samples_i,valid_samples_j] * 1E-3 )\n",
    "Hs = 4.0*np.std( Zcube-np.mean(Zcube) )\n",
    "print(\"Hs: \", Hs)\n",
    "\n",
    "#plt.figure( figsize=(10,10) )\n",
    "#plt.hist( waveheights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrum\n",
    "import scipy.signal\n",
    "\n",
    "dt = t[2]-t[1]\n",
    "print(\"dt: \",dt)\n",
    "\n",
    "f, S = scipy.signal.csd(timeserie, timeserie, 1.0/dt, nperseg=512 )\n",
    "for ii in valid_samples_i:\n",
    "    for jj in valid_samples_j:\n",
    "        timeserie_neigh = root[\"/Z\"][:,ii,jj] * 1E-3\n",
    "        timeserie_neigh = timeserie_neigh - np.mean(timeserie_neigh)\n",
    "        _, S_neig = scipy.signal.csd(timeserie_neigh, timeserie_neigh, 1.0/dt, nperseg=512 )\n",
    "        S += S_neig\n",
    "S = S / float( np.size(valid_samples_i)*np.size(valid_samples_j) + 1)\n",
    "\n",
    "# Using fft\n",
    "#Nt = np.size(timeserie)\n",
    "#dur=Nt*dt # s\n",
    "#df=1.0/dur\n",
    "#z_fft=np.fft.fftshift(np.fft.fft(timeserie) );\n",
    "#z_fft=z_fft/Nt;\n",
    "#z_fft=np.abs(z_fft)**2/df;\n",
    "#z_fft=z_fft*np.sqrt(8.0/3.0);\n",
    "#freq=np.linspace(-0.5,0.5,Nt)*(1/dt)\n",
    "\n",
    "plt.figure( figsize=(10,10) )\n",
    "plt.loglog( f, S)\n",
    "plt.xticks([1E-2,1E-1,1E0,1E1])\n",
    "plt.grid(which='minor')\n",
    "plt.ylabel(\"S (m^2 s)\")\n",
    "plt.xlabel(\"fa (Hz)\")\n",
    "plt.title(\"Spectrum (Welch method) averaged\\n in a central 11x11 grid region\")\n",
    "plt.savefig(\"spectrum.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Hs\n",
    "dFreq = np.gradient( f )\n",
    "m0 = np.sum( S*dFreq )\n",
    "m1 = np.sum( f*S*dFreq )\n",
    "Hm0 = 4.0 * np.sqrt( m0 )\n",
    "print(\"Hm0: \", Hm0)\n",
    "\n",
    "# Peak frequency\n",
    "pp = f[np.argmax( S )]\n",
    "print(\"Peak frequency (Hz): \", pp)\n",
    "\n",
    "# Average Period Tm01\n",
    "Tm01 = m0/m1\n",
    "print(\"Tm01: \", Tm01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Spectrum\n",
    "\n",
    "Z = root[\"/Z\"][3,:,:]\n",
    "N = Z.shape[0]\n",
    "Nm = int( N/2 )\n",
    "dy = (root[\"/Y_grid\"][2,0] - root[\"/Y_grid\"][1,0])/1000.0\n",
    "dx = (root[\"/X_grid\"][0,2] - root[\"/X_grid\"][0,1])/1000.0\n",
    "print(dx,dy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D directional spectrum using Welch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a central part of the Zcube\n",
    "N = 130\n",
    "\n",
    "sequence_length = np.size(timeserie)\n",
    "segments = 10\n",
    "Nt = int(sequence_length / segments)\n",
    "seg_shift = int(Nt/2)\n",
    "\n",
    "print(Nt)\n",
    "\n",
    "Zcube_mr = int( root[\"/Z\"].shape[1] / 2 )\n",
    "Zcube_mc = int( root[\"/Z\"].shape[2] / 2 )\n",
    "r_start, r_end = Zcube_mr-int(N/2)-50, Zcube_mr+int(N/2)-50+1\n",
    "c_start, c_end = Zcube_mc-int(N/2), Zcube_mc+int(N/2)+1 \n",
    "\n",
    "Nx = r_end - r_start\n",
    "print(\"Nx: \",Nx)\n",
    "Ny = c_end - c_start\n",
    "print(\"Ny: \",Ny)\n",
    "print(\"Nt: \",Nt)\n",
    "\n",
    "kx_max=(2.0*np.pi/dx)/2.0;\n",
    "ky_max=(2.0*np.pi/dy)/2.0;\n",
    "f_max= (1.0/dt)/2.0;\n",
    "dkx=2*np.pi/(dx*np.floor(Nx/2.0)*2.0); \n",
    "dky=2*np.pi/(dy*np.floor(Ny/2.0)*2.0);\n",
    "df =1.0/(dt*np.floor(Nt/2.0)*2.0);\n",
    "\n",
    "print( kx_max, ky_max, f_max, dkx, dky, df)\n",
    "\n",
    "assert( Nx%2 != 0)\n",
    "assert( Ny%2 != 0)\n",
    "assert( Nt%2 == 0)\n",
    "\n",
    "kx=np.arange(-kx_max,kx_max+dkx,dkx)\n",
    "ky=np.arange(-ky_max,ky_max+dky,dky)\n",
    "if Nt%2==0:\n",
    "    f=np.arange(-f_max, f_max, df);\n",
    "else:\n",
    "    f=np.arange(-f_max, f_max+df, df);\n",
    "\n",
    "KX, KY = np.meshgrid( kx, ky)\n",
    "dkx=kx[3]-kx[2];\n",
    "dky=ky[3]-ky[2];\n",
    "KXY=np.sqrt(KX**2+KY**2);\n",
    "print(dkx, dky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hanningx = scipy.signal.windows.hann(KX.shape[0])\n",
    "hanningy = scipy.signal.windows.hann(KX.shape[1])\n",
    "hanningt = scipy.signal.windows.hann(Nt)\n",
    "\n",
    "Win3Dhann = np.tile( np.expand_dims( hanningx, axis=-1) * hanningy, (Nt,1,1) ) *  np.tile( np.expand_dims( np.expand_dims( hanningt, axis=-1 ), axis=-1 ), (1, KX.shape[0], KX.shape[1]) )\n",
    "\n",
    "#  window correction factors\n",
    "wc2x = 1.0/np.mean(hanningx**2);\n",
    "wc2y = 1.0/np.mean(hanningy**2);\n",
    "wc2t = 1.0/np.mean(hanningt**2);\n",
    "wc2xy  = wc2x *wc2y;\n",
    "wc2xyt = wc2xy*wc2t;\n",
    "\n",
    "print(Win3Dhann.shape)\n",
    "print(KX.shape)\n",
    "\n",
    "Zcube_small = np.array( root[\"/Z\"][0:Nt, r_start:r_end, c_start:c_end ] )\n",
    "Zcube_small -= np.mean(Zcube_small)\n",
    "Zcube_w = Zcube_small * Win3Dhann\n",
    "\n",
    "print(dt, dkx, dky, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(10,10))\n",
    "plt.imshow(Zcube_small[20,:,:])\n",
    "plt.title(\"Original surface\")\n",
    "\n",
    "plt.figure( figsize=(10,10))\n",
    "plt.plot( np.squeeze( Zcube_w[:,60,60] ) )\n",
    "plt.title(\"Windowed timeserie\")\n",
    "plt.figure( figsize=(10,10))\n",
    "plt.imshow(Zcube_w[20,:,:])\n",
    "plt.title(\"Windowed surface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_welch = np.zeros_like( Win3Dhann )\n",
    "n_samples = 0\n",
    "print(\"Computing 3D fft via Welch's method\")\n",
    "for ii in tqdm(range(segments*2)):\n",
    "    #print(\"Welch sample %d/%d\"%(ii+1,segments*2))\n",
    "    Zcube_small = np.array( root[\"/Z\"][(ii*seg_shift):(ii*seg_shift+Nt), r_start:r_end, c_start:c_end ] )\n",
    "    if Zcube_small.shape[0] != Nt:\n",
    "        break\n",
    "        \n",
    "    Zcube_w = (Zcube_small - np.mean(Zcube_small) ) * Win3Dhann\n",
    "    \n",
    "    S = np.fft.fftshift( np.fft.fftn( Zcube_w, norm=\"ortho\" ) );\n",
    "    S /= (S.shape[0]*S.shape[1]*S.shape[2])\n",
    "    S = np.abs(S)**2 / (dkx*dky*df)\n",
    "    #-----------------------------\n",
    "    #%%%%% corrects for window\n",
    "    #----------------------------\n",
    "    #%% FABIEN\n",
    "    S *= wc2xyt\n",
    "    \n",
    "    # Store\n",
    "    S_welch += S    \n",
    "    n_samples += 1\n",
    "    \n",
    "S_welch /= n_samples    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 0.30\n",
    "max_freq = 0.8\n",
    "num_plots = 8\n",
    "\n",
    "start_freq_ii = np.argmin( np.abs(f-min_freq) )\n",
    "end_freq_ii = np.argmin( np.abs(f-max_freq) )\n",
    "indices = np.round( np.linspace(start_freq_ii, end_freq_ii, num_plots ) ).astype(np.uint32)\n",
    "\n",
    "for ii in indices:\n",
    "\n",
    "    plt.figure( figsize=(11,10))    \n",
    "\n",
    "    #dummy = np.flipud( 2* np.mean(S_welch[ mdt+ii-1:mdt+ii+2,:,:], axis=0) )    \n",
    "    dummy = 2* np.mean(S_welch[ ii-1:ii+2,:,:], axis=0) \n",
    "    \n",
    "    dummy_cen = np.copy(dummy)\n",
    "    dummy_cen[ int(dummy_cen.shape[0]/2)-1:int(dummy_cen.shape[0]/2)+1, int(dummy_cen.shape[1]/2)-1:int(dummy_cen.shape[1]/2)+1 ] = 0\n",
    "    maxidx = np.unravel_index( np.argmax(dummy_cen), dummy_cen.shape )\n",
    "    \n",
    "    qp=( np.arctan2( KY[ maxidx[0],maxidx[1] ], KX[ maxidx[0],maxidx[1] ]) )/np.pi*180.0\n",
    "    if qp<0:\n",
    "        qp=qp+360\n",
    "\n",
    "    kp=np.sqrt( KX[ maxidx[0],maxidx[1] ]**2 + KY[ maxidx[0],maxidx[1] ]**2 );\n",
    "\n",
    "    plt.pcolor(KX,KY, 10*np.log10(dummy) )\n",
    "    plt.clim( 10*np.array([-4.0 + np.amax(np.log10(dummy)), -0+np.amax(np.log10(dummy))]) )\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.scatter( [KX[ maxidx[0],maxidx[1] ]], [KY[ maxidx[0],maxidx[1] ]], marker=\"x\", s=100, c=\"k\" )\n",
    "\n",
    "    plt.ylim([-2.5,2.5])\n",
    "    plt.xlim([-2.5,2.5])\n",
    "\n",
    "    plt.xlabel(\"Kx (rad/m)\")\n",
    "    plt.ylabel(\"Ky (rad/m)\")\n",
    "    plt.title(\"S_kx_ky, fa=%3.2f (Hz).\\n Peak angle: %3.0fÂ°, mag: %2.3f (rad/m)\\n\"%( f[ii],qp,kp ) )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ncfilef = os.path.split(NCFILE)\n",
    "print(ncfilef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestring = root[\"/meta\"].getncattr(\"timestring\")\n",
    "print(timestring)\n",
    "datadatetime = dateutil.parser.parse(timestring)\n",
    "print(datadatetime.time())\n",
    "print(datadatetime.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytemplate = Template(filename=\"analysis_template.html\", strict_undefined=True)\n",
    "\n",
    "T = mytemplate.render( title=\"%s wave analysis\"%NCFILE,\n",
    "                       framedata=filetobase64(\"frame.jpg\").decode(\"ascii\"),\n",
    "                       timeseriedata=filetobase64(\"timeserie.png\").decode(\"ascii\"),\n",
    "                       spectrumdata=filetobase64(\"spectrum.png\").decode(\"ascii\"),\n",
    "                       dirspectrumdata=filetobase64(\"spectrum_dir.png\").decode(\"ascii\"),\n",
    "                       hs=\"%2.3f\"%Hs,\n",
    "                       hm0=\"%2.3f\"%Hm0,\n",
    "                       date=datadatetime.date(),\n",
    "                       time=datadatetime.time(),\n",
    "                       ncfile=\"%s (%s)\"%(ncfilef,root[\"/meta\"].getncattr(\"datafile\")),\n",
    "                       duration=\"%d secs.\"%(t[-1]-t[0]),\n",
    "                       fps=\"%3.1f\"%(root[\"/meta\"].getncattr(\"fps\")),\n",
    "                       meta=nc_file_info( NCFILE, root ).replace('\\n','<br />'))\n",
    "\n",
    "with open(\"analysis.html\",\"w\") as f:\n",
    "    f.write(T)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
