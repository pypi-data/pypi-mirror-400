orchestrator:
  id: orka-ui
  strategy: decision-tree
  queue: orka:generated
  memory_preset: "semantic"  # Use semantic memory for knowledge processing
  agents:
    - memory-reader
    - memory-check
    - router
    - memory-writer
    - final_summary
agents:
  - id: memory-reader
    type: memory
    memory_preset: "semantic"  # Facts and knowledge base (30 days)
    queue: orka:memory-reader
    config:
      operation: read
      memory_category_filter: stored
    namespace: landmarks
    prompt: Retrieve any stored memories about {{ get_input() }}. Return "NONE" if nothing matches.
  - id: memory-check
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.1
    queue: orka:memory-check
    prompt: |
      Check if the following memory data is relevant to the question and has high confidence. Question: {{ get_input() }} Memory: {{ get_agent_response('memory-reader') }} Return true if: 1) The memory contains relevant information about the question; 2) The memory has a confidence score higher than 0.89; 3) The memory is not "NONE". Return false otherwise. Answer with exactly 'true' or 'false' only.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: router
    type: router
    params:
      decision_key: memory-check
      routing_map:
        "true":
          - memory-path
          - memory-writer
        "false":
          - context-collector
          - answer-builder
          - validation-guard
          - memory-writer
    depends_on:
      - memory-check
  - id: memory-path
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.3
    queue: orka:memory-path
    prompt: Format the stored memory information about the {{ get_input() }} into a clear answer:{{ get_agent_response('memory-reader') if get_agent_response('memory-reader') else 'NONE' }}. Provide a well-structured response.
    depends_on:
      - router
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: context-collector
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.5
    queue: orka:context-collector
    prompt: Based on the question "{{ get_input() }}", collect relevant context and background information. Focus on gathering factual information that will help validate the answer. If no specific information is available, explain what type of information would be needed and suggest research directions. Do not return just "NONE" - provide a meaningful response about the information availability.
    depends_on:
      - router
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: answer-builder
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.7
    queue: orka:answer-builder
    prompt: "Using the context: {{ get_agent_response('context-collector') }} Provide a detailed answer to: {{ get_input() }}. If the context indicates no information is available, explain what is known and what would need to be researched. Do not return just 'NONE'. Be comprehensive and helpful."
    depends_on:
      - context-collector
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: validation-guard
    type: validate_and_structure
    queue: orka:validation-guard
    prompt: "Validate the answer and structure it into a memory format. Question: {{ get_input() }} Answer to validate: {{ get_agent_response('answer-builder') }}"
    depends_on:
      - answer-builder
      - context-collector
    store_structure: '{  "fact": "string",  "reason": "string",  "confidence": "number",  "source": "string"}'
  - id: memory-writer
    type: memory
    memory_preset: "semantic"  # Facts and knowledge base (30 days)
    queue: orka:memory-writer
    config:
      operation: write
    namespace: landmarks
    prompt: |
      {% set validation_result = get_agent_response('validation-guard') %}
      {% if validation_result %}
      {{ validation_result }}
      {% else %}
      Store information about: {{ get_input() }}
      {% endif %}
    metadata:
      source: validation-guard
      category: "stored"
    key_template: "{{ get_input() }}"
    
  - id: final_summary
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.7
    prompt: |
      Answer this question: "{{ get_input() }}"
      
      {% set memory_path_result = get_agent_response('memory-path') %}
      {% set answer_result = get_agent_response('answer-builder') %}
      {% set validation_result = get_agent_response('validation-guard') %}
      
      {% if memory_path_result %}
      {{ memory_path_result }}
      {% elif answer_result %}
      {{ answer_result }}
      {% else %}
      Let me provide the best answer I can based on the available information.
      {% endif %}
      
      {% if validation_result %}
      
      Additional validation: {{ validation_result }}
      {% endif %}
      
      Provide a thorough, accurate response to the user's question.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
