"""Code generated by Speakeasy (https://speakeasy.com). DO NOT EDIT."""

from __future__ import annotations
from .imageinput import ImageInput, ImageInputTypedDict
from friendli.core.types import (
    BaseModel,
    Nullable,
    OptionalNullable,
    UNSET,
    UNSET_SENTINEL,
)
from pydantic import model_serializer
from typing import List, Literal, Optional
from typing_extensions import NotRequired, TypedDict

DedicatedImageGenerationBodyResponseFormat = Literal["url", "raw", "png", "jpeg", "jpg"]


class DedicatedImageGenerationBodyTypedDict(TypedDict):
    model: str
    'ID of target endpoint. If you want to send request to specific adapter, use the format \\"YOUR_ENDPOINT_ID:YOUR_ADAPTER_ROUTE\\". Otherwise, you can just use \\"YOUR_ENDPOINT_ID\\" alone.'
    prompt: str
    "A text description of the desired image(s)."
    num_inference_steps: NotRequired[int]
    "The number of inference steps to use during image generation. Defaults to 20. Supported range: [1, 50]."
    guidance_scale: NotRequired[Nullable[float]]
    "Adjusts the alignment of the generated image with the input prompt. Higher values (e.g., 8-10) make the output more faithful to the prompt, while lower values (e.g., 1-5) encourage more creative freedom. This parameter may be irrelevant for certain models, such as `FLUX.Schnell`."
    seed: NotRequired[Nullable[int]]
    "The seed to use for image generation."
    response_format: NotRequired[Nullable[DedicatedImageGenerationBodyResponseFormat]]
    "The format in which the generated image(s) will be returned. One of `url(default)`, `raw`, `png`, `jpeg`, and `jpg`."
    control_images: NotRequired[Nullable[List[ImageInputTypedDict]]]
    "Optional input images used to condition or guide the generation process (e.g., for ControlNet or image editing models). This field is only applicable when using ControlNet or image editing models."
    controlnet_weights: NotRequired[Nullable[List[float]]]
    "A list of weights that determine the influence of each ControlNet model in the generation process. Each value must be within [0, 1], where 0 disables the corresponding ControlNet and 1 applies it fully. When multiple ControlNet models are used, the list length must match the number of control images. If omitted, all ControlNet models default to full influence (1.0). This field is only applicable when using ControlNet models."


class DedicatedImageGenerationBody(BaseModel):
    model: str
    'ID of target endpoint. If you want to send request to specific adapter, use the format \\"YOUR_ENDPOINT_ID:YOUR_ADAPTER_ROUTE\\". Otherwise, you can just use \\"YOUR_ENDPOINT_ID\\" alone.'
    prompt: str
    "A text description of the desired image(s)."
    num_inference_steps: Optional[int] = 20
    "The number of inference steps to use during image generation. Defaults to 20. Supported range: [1, 50]."
    guidance_scale: OptionalNullable[float] = UNSET
    "Adjusts the alignment of the generated image with the input prompt. Higher values (e.g., 8-10) make the output more faithful to the prompt, while lower values (e.g., 1-5) encourage more creative freedom. This parameter may be irrelevant for certain models, such as `FLUX.Schnell`."
    seed: OptionalNullable[int] = UNSET
    "The seed to use for image generation."
    response_format: OptionalNullable[DedicatedImageGenerationBodyResponseFormat] = (
        UNSET
    )
    "The format in which the generated image(s) will be returned. One of `url(default)`, `raw`, `png`, `jpeg`, and `jpg`."
    control_images: OptionalNullable[List[ImageInput]] = UNSET
    "Optional input images used to condition or guide the generation process (e.g., for ControlNet or image editing models). This field is only applicable when using ControlNet or image editing models."
    controlnet_weights: OptionalNullable[List[float]] = UNSET
    "A list of weights that determine the influence of each ControlNet model in the generation process. Each value must be within [0, 1], where 0 disables the corresponding ControlNet and 1 applies it fully. When multiple ControlNet models are used, the list length must match the number of control images. If omitted, all ControlNet models default to full influence (1.0). This field is only applicable when using ControlNet models."

    @model_serializer(mode="wrap")
    def serialize_model(self, handler):
        optional_fields = [
            "num_inference_steps",
            "guidance_scale",
            "seed",
            "response_format",
            "control_images",
            "controlnet_weights",
        ]
        nullable_fields = [
            "guidance_scale",
            "seed",
            "response_format",
            "control_images",
            "controlnet_weights",
        ]
        null_default_fields = []
        serialized = handler(self)
        m = {}
        for n, f in type(self).model_fields.items():
            k = f.alias or n
            val = serialized.get(k)
            serialized.pop(k, None)
            optional_nullable = k in optional_fields and k in nullable_fields
            is_set = (
                self.__pydantic_fields_set__.intersection({n})
                or k in null_default_fields
            )
            if val is not None and val != UNSET_SENTINEL:
                m[k] = val
            elif val != UNSET_SENTINEL and (
                k not in optional_fields or (optional_nullable and is_set)
            ):
                m[k] = val
        return m
