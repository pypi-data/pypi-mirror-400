# yaml-language-server: $schema=./schemas/bundle_config_schema.json

bundle:
  name: __APP_NAME__

artifacts:
  default:
    type: whl
    build: uv build
    path: .

variables:
  config_path:
    description: Path to the configuration file for the job.
  node_type: 
    description: The job compute node type (cloud-specific, set per target)
  cloud:
    description: Cloud provider (azure, aws, gcp) - auto-detected or set per target

resources:
  jobs:
    # The job name and bundle name are templated and replaced by CLI at deployment time
    # This allows multiple apps to coexist with separate bundle identities
    deploy_job:
      name: __APP_NAME__-job
      tags:
        app_name: __APP_NAME__
        config_path: ${var.config_path}
      job_clusters:
        - job_cluster_key: common-cluster
          new_cluster:
            node_type_id: ${var.node_type}
            spark_version: 16.2.x-scala2.12
            num_workers: 1
      environments:
        - environment_key: dao-ai-env
          spec:
            environment_version: "4"
            dependencies:
              - -r ${workspace.file_path}/requirements.txt
      tasks:
        - task_key: ingest-and-transform
          notebook_task:
            notebook_path: ./notebooks/01_ingest_and_transform.py
            base_parameters:
              config-path: ${var.config_path}
          job_cluster_key: common-cluster
        - task_key: provision-vector-search
          depends_on:
            - task_key: ingest-and-transform
          notebook_task:
            notebook_path: ./notebooks/02_provision_vector_search.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
        - task_key: provision-lakebase
          notebook_task:
            notebook_path: ./notebooks/03_provision_lakebase.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
        - task_key: generate-evaluation-data
          depends_on:
            - task_key: provision-vector-search
          notebook_task:
            notebook_path: ./notebooks/06_generate_evaluation_data.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
        - task_key: unity-catalog-tools
          depends_on:
            - task_key: provision-vector-search
            - task_key: provision-lakebase
          notebook_task:
            notebook_path: ./notebooks/04_unity_catalog_tools.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
        - task_key: deploy-agents
          depends_on:
            - task_key: unity-catalog-tools
          notebook_task:
            notebook_path: ./notebooks/05_deploy_agent.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
        - task_key: run-evaluation
          depends_on:
            - task_key: deploy-agents
            - task_key: generate-evaluation-data
          notebook_task:
            notebook_path: ./notebooks/07_run_evaluation.py
            base_parameters:
              config-path: ${var.config_path}
          environment_key: dao-ai-env
          
# Cloud-specific targets with appropriate node types
# The CLI auto-selects the target based on workspace cloud detection
targets:
  azure:
    mode: development
    variables:
      cloud: azure
      node_type: Standard_D4ads_v5
  
  aws:
    mode: development
    variables:
      cloud: aws
      node_type: i3.xlarge
  
  gcp:
    mode: development
    variables:
      cloud: gcp
      node_type: n1-standard-4
