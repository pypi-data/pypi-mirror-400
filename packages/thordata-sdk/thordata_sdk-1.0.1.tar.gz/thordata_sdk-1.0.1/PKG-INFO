Metadata-Version: 2.4
Name: thordata-sdk
Version: 1.0.1
Summary: The Official Python SDK for Thordata - AI Data Infrastructure & Proxy Network.
Author-email: Thordata Developer Team <support@thordata.com>
License: MIT
Project-URL: Homepage, https://www.thordata.com
Project-URL: Documentation, https://github.com/Thordata/thordata-python-sdk#readme
Project-URL: Source, https://github.com/Thordata/thordata-python-sdk
Project-URL: Tracker, https://github.com/Thordata/thordata-python-sdk/issues
Project-URL: Changelog, https://github.com/Thordata/thordata-python-sdk/blob/main/CHANGELOG.md
Keywords: web scraping,proxy,residential proxy,datacenter proxy,ai,llm,data-mining,serp,thordata,web scraper,anti-bot bypass
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Internet :: WWW/HTTP
Classifier: Topic :: Internet :: Proxy Servers
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Typing :: Typed
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.25.0
Requires-Dist: aiohttp>=3.9.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: pytest-httpserver>=1.0.0; extra == "dev"
Requires-Dist: python-dotenv>=1.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: types-requests>=2.28.0; extra == "dev"
Requires-Dist: aioresponses>=0.7.6; extra == "dev"
Dynamic: license-file

# Thordata Python SDK

<div align="center">

**Official Python client for Thordata's Proxy Network, SERP API, Web Unlocker, and Web Scraper API.**

*Async-ready, type-safe, built for AI agents and large-scale data collection.*

[![PyPI](https://img.shields.io/pypi/v/thordata-sdk?color=blue)](https://pypi.org/project/thordata-sdk/)
[![Python](https://img.shields.io/badge/python-3.9+-blue)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

[Documentation](https://doc.thordata.com) â€¢ [Dashboard](https://www.thordata.com) â€¢ [Examples](examples/)

</div>

---

## âœ¨ Features

- ðŸŒ **Proxy Network**: Residential, Mobile, Datacenter, ISP proxies with geo-targeting
- ðŸ” **SERP API**: Google, Bing, Yandex, DuckDuckGo search results
- ðŸ”“ **Web Unlocker**: Bypass Cloudflare, CAPTCHAs, anti-bot systems
- ðŸ•·ï¸ **Web Scraper API**: Async task-based scraping (Text & Video/Audio)
- ðŸ“Š **Account Management**: Usage stats, sub-users, IP whitelist
- âš¡ **Async Support**: Full async/await support with aiohttp
- ðŸ”„ **Auto Retry**: Configurable retry with exponential backoff

---

## ðŸ“¦ Installation

```bash
pip install thordata-sdk
```

---

## ðŸ” Configuration

Set environment variables:

```bash
# Required for Scraper APIs (SERP, Universal, Tasks)
export THORDATA_SCRAPER_TOKEN=your_token

# Public/Location APIs (Dashboard -> My account -> API)
export THORDATA_PUBLIC_TOKEN=your_public_token
export THORDATA_PUBLIC_KEY=your_public_key

```

---

## ðŸš€ Quick Start

```python
from thordata import ThordataClient, Engine

# Initialize (reads from env vars)
client = ThordataClient(
    scraper_token="your_token", 
    public_token="pub_token", 
    public_key="pub_key"
)

# SERP Search
results = client.serp_search("python tutorial", engine=Engine.GOOGLE)
print(f"Found {len(results.get('organic', []))} results")

# Universal Scrape
html = client.universal_scrape("https://httpbin.org/html")
print(html[:100])
```

---

## ðŸ“– Feature Guide

### SERP API

```python
from thordata import SerpRequest

# Advanced search
results = client.serp_search_advanced(SerpRequest(
    query="pizza",
    engine="google_local",
    country="us",
    location="New York",
    num=10
))
```

### Web Scraper API (Async Tasks)

**Create Task:**
```python
task_id = client.create_scraper_task(
    file_name="my_task",
    spider_id="universal",
    spider_name="universal",
    parameters={"url": "https://example.com"}
)
```

**Video Download (New):**
```python
from thordata import CommonSettings

task_id = client.create_video_task(
    file_name="{{VideoID}}",
    spider_id="youtube_video_by-url",
    spider_name="youtube.com",
    parameters={"url": "https://youtube.com/watch?v=..."},
    common_settings=CommonSettings(resolution="1080p")
)
```

**Wait & Download:**
```python
status = client.wait_for_task(task_id)
if status == "ready":
    url = client.get_task_result(task_id)
    print(url)
```

### Account Management

```python
# Usage Statistics
stats = client.get_usage_statistics("2024-01-01", "2024-01-31")
print(f"Balance: {stats.balance_gb():.2f} GB")

# Proxy Users
users = client.list_proxy_users()
print(f"Sub-users: {users.user_count}")

# Whitelist IP
client.add_whitelist_ip("1.2.3.4")
```

### Proxy Network

```python
from thordata import ProxyConfig

# Generate Proxy URL
proxy_url = client.build_proxy_url(
    username="proxy_user",
    password="proxy_pass",
    country="us",
    city="ny"
)

# Use with requests
import requests
requests.get("https://httpbin.org/ip", proxies={"http": proxy_url, "https": proxy_url})
```

---

## ðŸ“„ License

MIT License
