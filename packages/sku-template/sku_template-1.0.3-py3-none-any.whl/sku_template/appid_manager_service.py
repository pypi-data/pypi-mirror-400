"""
AppIDç®¡ç†HTTPæœåŠ¡
æä¾›AppIDçš„è·å–ã€é‡Šæ”¾å’ŒçŠ¶æ€æŸ¥è¯¢åŠŸèƒ½
æ”¯æŒå¹¶å‘è·å–ï¼Œè§£å†³AppIDèµ„æºç®¡ç†é—®é¢˜
æ”¯æŒå®šæ—¶ä»»åŠ¡ç›‘æ§å’ŒæŠ¥å‘Šç”Ÿæˆ
"""
import time
import threading
import os
import secrets
import string
import json
import uuid
import requests
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from datetime import datetime, timedelta
from typing import Dict, Any, Tuple, Optional, List
from pathlib import Path
from flask import Flask, request, jsonify, send_file
import argparse


class AppIdManager:
    """AppIDç®¡ç†å™¨"""
    
    def __init__(self):
        """
        åˆå§‹åŒ–AppIDç®¡ç†å™¨
        """
        self.appid_config = {}
        self.appid_status = {}
        self.test_results = {}  # å­˜å‚¨æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ® {product_name: {session_id: [test_results]}}
        self.lock = threading.Lock()
    
    def init_product(self, product_name: str, appids: Dict[str, str]) -> Tuple[bool, Dict[str, Any]]:
        """
        åˆå§‹åŒ–æˆ–é‡ç½®äº§å“AppIDé…ç½®
        
        Args:
            product_name: äº§å“åç§°
            appids: AppIDé…ç½® {appid: vid}
            
        Returns:
            (success, data): æˆåŠŸæ ‡å¿—å’Œæ•°æ®
        """
        with self.lock:
            # æ›´æ–°é…ç½®
            self.appid_config[product_name] = appids
            
            # ç§»é™¤è¯¥äº§å“ä¸‹æ‰€æœ‰ç°æœ‰çš„AppIDçŠ¶æ€
            removed_count = 0
            appids_to_remove = []
            for appid, status in self.appid_status.items():
                if status.get("productName") == product_name:
                    appids_to_remove.append(appid)
                    removed_count += 1
            
            for appid in appids_to_remove:
                del self.appid_status[appid]
            
            # æ·»åŠ æ–°çš„AppIDçŠ¶æ€
            added_count = 0
            for appid, vid in appids.items():
                self.appid_status[appid] = {
                    "starttime": None,
                    "stoptime": None,
                    "productName": product_name,
                    "vid": int(vid)
                }
                added_count += 1
            
            return True, {
                "success": True,
                "productName": product_name,
                "removed_count": removed_count,
                "added_count": added_count,
                "message": f"Product '{product_name}' initialized: removed {removed_count}, added {added_count} appids"
            }
    
    def _is_available(self, appid: str, status: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­AppIDæ˜¯å¦å¯ç”¨
        
        åˆ¤æ–­è§„åˆ™ï¼š
        - starttime=null, stoptime=null â†’ å¯ç”¨
        - starttime=null, stoptimeâ‰ null â†’ é”™è¯¯çŠ¶æ€ï¼ˆä¸åº”è¯¥å­˜åœ¨ï¼‰
        - starttimeâ‰ null, stoptime=null â†’ ä½¿ç”¨ä¸­ï¼Œä¸å¯ç”¨
        - starttimeâ‰ null, stoptimeâ‰ null â†’ æ£€æŸ¥stoptimeæ˜¯å¦åœ¨å½“å‰å°æ—¶å†…
        """
        starttime = status.get("starttime")
        stoptime = status.get("stoptime")
        
        # æœªä½¿ç”¨è¿‡
        if starttime is None and stoptime is None:
            return True
        
        # é”™è¯¯çŠ¶æ€
        if starttime is None and stoptime is not None:
            return False
        
        # ä½¿ç”¨ä¸­
        if starttime is not None and stoptime is None:
            return False
        
        # ä½¿ç”¨ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦åœ¨å½“å‰å°æ—¶å†…
        if starttime is not None and stoptime is not None:
            current_hour = self._get_current_hour()
            stoptime_hour = self._get_hour_of_timestamp(stoptime)
            # ä¸¥æ ¼æŒ‰å°æ—¶åˆ¤æ–­ï¼šstoptimeæ‰€åœ¨å°æ—¶ < å½“å‰å°æ—¶ â†’ å¯ç”¨
            # å³ï¼šstoptimeåœ¨ä¹‹å‰çš„å°æ—¶ï¼Œç°åœ¨è¿›å…¥æ–°å°æ—¶ï¼Œå¯ä»¥å†æ¬¡ä½¿ç”¨
            # å¦‚æœstoptimeæ‰€åœ¨å°æ—¶ == å½“å‰å°æ—¶ï¼Œè¯´æ˜åœ¨å½“å‰å°æ—¶å†…ä½¿ç”¨è¿‡ï¼Œä¸å¯é‡å¤ä½¿ç”¨
            is_available = stoptime_hour < current_hour
            return is_available
        
        # ç†è®ºä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œä½†ä¸ºäº†ç±»å‹æ£€æŸ¥ï¼Œè¿”å›False
        return False
    
    def _get_current_hour(self) -> int:
        """è·å–å½“å‰å°æ—¶ï¼ˆæ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰"""
        now = datetime.now()
        # è·å–å½“å‰å°æ—¶çš„å¼€å§‹æ—¶é—´
        hour_start = now.replace(minute=0, second=0, microsecond=0)
        return int(hour_start.timestamp() * 1000)
    
    def _get_hour_of_timestamp(self, timestamp: int) -> int:
        """è·å–æ—¶é—´æˆ³æ‰€åœ¨çš„å°æ—¶ï¼ˆæ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰"""
        dt = datetime.fromtimestamp(timestamp / 1000)
        hour_start = dt.replace(minute=0, second=0, microsecond=0)
        return int(hour_start.timestamp() * 1000)
    
    def _get_next_hour_start(self) -> int:
        """è·å–ä¸‹ä¸€ä¸ªå°æ—¶çš„å¼€å§‹æ—¶é—´ï¼ˆæ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰"""
        now = datetime.now()
        next_hour = now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
        return int(next_hour.timestamp() * 1000)
    
    def acquire_appid(self, product_name: str = "default", force_acquire: bool = False) -> Tuple[bool, Dict[str, Any]]:
        """
        è·å–å¯ç”¨çš„AppID
        
        Args:
            product_name: äº§å“åç§°ï¼Œç”¨äºéš”ç¦»ä¸åŒä¸šåŠ¡çš„AppID
            force_acquire: æ˜¯å¦å¼ºåˆ¶è·å–ï¼ˆå¿½ç•¥å°æ—¶å†…ä½¿ç”¨æ£€æŸ¥ï¼‰ï¼Œé»˜è®¤ä¸ºFalse
                         å¦‚æœä¸ºTrueï¼Œå³ä½¿AppIDåœ¨å½“å‰å°æ—¶å†…ä½¿ç”¨è¿‡ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è·å–
                         ä½†starttimeå’Œstoptimeä¾æ—§è¦å¡«
            
        Returns:
            (success, data): æˆåŠŸæ ‡å¿—å’Œæ•°æ®
        """
        with self.lock:
            # éå†æ‰¾å¯ç”¨AppIDï¼ˆåªæŸ¥æ‰¾æŒ‡å®šäº§å“çš„AppIDï¼‰
            for appid, status in self.appid_status.items():
                if status.get("productName") == product_name:
                    # å¦‚æœ force_acquire=Trueï¼Œåªè¦AppIDä¸åœ¨ä½¿ç”¨ä¸­ï¼ˆstoptime != Noneï¼‰ï¼Œå°±å¯ä»¥è·å–
                    # å¦‚æœ force_acquire=Falseï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼ˆåŒ…æ‹¬å°æ—¶å†…ä½¿ç”¨æ£€æŸ¥ï¼‰
                    if force_acquire:
                        # å¼ºåˆ¶è·å–ï¼šåªè¦ä¸åœ¨ä½¿ç”¨ä¸­ï¼ˆstoptime != Noneï¼‰ï¼Œå°±å¯ä»¥è·å–
                        # å³ä½¿åœ¨å½“å‰å°æ—¶å†…ä½¿ç”¨è¿‡ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è·å–
                        if status.get("stoptime") is not None:
                            # å·²é‡Šæ”¾ï¼Œå¯ä»¥è·å–ï¼ˆå¿½ç•¥å°æ—¶å†…ä½¿ç”¨æ£€æŸ¥ï¼‰
                            current_time = int(time.time() * 1000)
                            vid = status.get("vid")  # ä¿ç•™vidå­—æ®µ
                            self.appid_status[appid] = {
                                "starttime": current_time,
                                "stoptime": None,
                                "productName": product_name,
                                "vid": vid  # ä¿ç•™vidå­—æ®µ
                            }
                            
                            return True, {
                                "appid": appid,
                                "vid": vid,
                                "productName": product_name,
                                "starttime": current_time
                            }
                    else:
                        # æ­£å¸¸è·å–ï¼šéœ€è¦æ£€æŸ¥æ˜¯å¦å¯ç”¨ï¼ˆåŒ…æ‹¬å°æ—¶å†…ä½¿ç”¨æ£€æŸ¥ï¼‰
                        if self._is_available(appid, status):
                            # ç«‹å³æ ‡è®°ä¸ºä½¿ç”¨ä¸­ï¼ˆä¿ç•™vidå­—æ®µï¼‰
                            current_time = int(time.time() * 1000)
                            vid = status.get("vid")  # ä¿ç•™vidå­—æ®µ
                            self.appid_status[appid] = {
                                "starttime": current_time,
                                "stoptime": None,
                                "productName": product_name,
                                "vid": vid  # ä¿ç•™vidå­—æ®µ
                            }
                            
                            return True, {
                                "appid": appid,
                                "vid": vid,
                                "productName": product_name,
                                "starttime": current_time
                            }
            
            # æ‰€æœ‰AppIDéƒ½ä¸å¯ç”¨ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦ç­‰å¾…ï¼ˆåªæ£€æŸ¥æŒ‡å®šäº§å“çš„AppIDï¼‰
            # å¦‚æœ force_acquire=Trueï¼Œä½†æ‰€æœ‰AppIDéƒ½åœ¨ä½¿ç”¨ä¸­ï¼Œè¿”å›ç­‰å¾…
            current_hour = self._get_current_hour()
            all_in_current_hour = True
            has_released_appid = False  # æ˜¯å¦æœ‰å·²é‡Šæ”¾çš„AppID
            
            for status in self.appid_status.values():
                if status.get("productName") == product_name:
                    stoptime = status.get("stoptime")
                    if stoptime is not None:
                        # æœ‰å·²é‡Šæ”¾çš„AppID
                        has_released_appid = True
                        stoptime_hour = self._get_hour_of_timestamp(stoptime)
                        if stoptime_hour < current_hour:
                            # æœ‰AppIDçš„stoptimeåœ¨ä¹‹å‰çš„å°æ—¶ï¼Œåº”è¯¥å¯ç”¨
                            # ä½†éå†æ—¶æ²¡æ‰¾åˆ°ï¼Œå¯èƒ½æ˜¯åˆ¤æ–­é€»è¾‘æœ‰é—®é¢˜ï¼Œè¿”å›waitingè®©å…¶é‡è¯•
                            all_in_current_hour = False
                            break
                    elif status.get("starttime") is not None:
                        # æ­£åœ¨ä½¿ç”¨ä¸­çš„AppID
                        pass
            
            if all_in_current_hour and has_released_appid:
                # æ‰€æœ‰å·²é‡Šæ”¾AppIDçš„stoptimeéƒ½åœ¨å½“å‰å°æ—¶å†…ï¼Œéœ€è¦ç­‰å¾…åˆ°ä¸‹ä¸ªå°æ—¶
                next_hour_start = self._get_next_hour_start()
                current_time = int(time.time() * 1000)
                wait_seconds = (next_hour_start - current_time) / 1000
                
                return False, {
                    "error": "no_available",
                    "retry_after": min(int(wait_seconds), 300),  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
                    "message": f"All appids for product '{product_name}' are in use for current hour, wait {wait_seconds:.0f}s until next hour"
                }
            else:
                # å…¶ä»–æƒ…å†µï¼ŒçŸ­æ—¶é—´é‡è¯•
                # åŒ…æ‹¬ï¼š1) æ‰€æœ‰AppIDéƒ½åœ¨ä½¿ç”¨ä¸­ 2) æœ‰AppIDåº”è¯¥å¯ç”¨ä½†åˆ¤æ–­å¯èƒ½æœ‰é—®é¢˜
                return False, {
                    "error": "waiting",
                    "retry_after": 60,
                    "message": f"All appids for product '{product_name}' are in use, retry in 60s"
                }
    
    def release_appid(self, appid: str, product_name: str = "default") -> Tuple[bool, Dict[str, Any]]:
        """
        é‡Šæ”¾AppID
        
        Args:
            appid: è¦é‡Šæ”¾çš„AppID
            product_name: äº§å“åç§°ï¼Œç”¨äºéªŒè¯AppIDå½’å±
            
        Returns:
            (success, data): æˆåŠŸæ ‡å¿—å’Œæ•°æ®
        """
        with self.lock:
            if appid not in self.appid_status:
                return False, {"error": "appid_not_found", "message": f"AppID {appid} not found"}
            
            status = self.appid_status[appid]
            if status.get("productName") != product_name:
                return False, {"error": "product_mismatch", "message": f"AppID {appid} belongs to product '{status.get('productName')}', not '{product_name}'"}
            
            if status.get("stoptime") is not None:
                return False, {"error": "already_released", "message": f"AppID {appid} already released"}
            
            # æ ‡è®°ä¸ºå·²é‡Šæ”¾ï¼ˆä¿ç•™vidå­—æ®µï¼‰
            current_time = int(time.time() * 1000)
            vid = status.get("vid")  # ä¿ç•™vidå­—æ®µ
            self.appid_status[appid] = {
                "starttime": status.get("starttime"),
                "stoptime": current_time,
                "productName": product_name,
                "vid": vid  # ä¿ç•™vidå­—æ®µ
            }
            
            return True, {
                "success": True,
                "stoptime": current_time,
                "productName": product_name,
                "message": f"AppID {appid} released successfully"
            }
    
    def get_status(self, product_name: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–AppIDçŠ¶æ€ç»Ÿè®¡å’Œè¯¦ç»†ä¿¡æ¯
        
        Args:
            product_name: äº§å“åç§°ï¼Œå¦‚æœæŒ‡å®šåˆ™åªç»Ÿè®¡è¯¥äº§å“çš„AppID
            
        Returns:
            çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯å’Œæ¯ä¸ªAppIDçš„è¯¦ç»†ä¿¡æ¯
        """
        with self.lock:
            total = 0
            available = 0
            in_use = 0
            appid_details = []  # å­˜å‚¨æ¯ä¸ªAppIDçš„è¯¦ç»†ä¿¡æ¯
            
            # è·å–å½“å‰å°æ—¶ï¼Œç”¨äºåˆ¤æ–­å¯ç”¨æ€§
            current_hour = self._get_current_hour()
            
            for appid, status in self.appid_status.items():
                # å¦‚æœæŒ‡å®šäº†äº§å“åç§°ï¼Œåªç»Ÿè®¡è¯¥äº§å“çš„AppID
                if product_name and status.get("productName") != product_name:
                    continue
                
                total += 1
                
                # åˆ¤æ–­çŠ¶æ€
                is_available = self._is_available(appid, status)
                starttime = status.get("starttime")
                stoptime = status.get("stoptime")
                
                # è®¡ç®—stoptimeæ‰€åœ¨çš„å°æ—¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                stoptime_hour = None
                if stoptime is not None:
                    stoptime_hour = self._get_hour_of_timestamp(stoptime)
                
                if is_available:
                    status_str = "available"
                    available += 1
                elif stoptime is None:
                    status_str = "in_use"
                    in_use += 1
                else:
                    # æœ‰stoptimeï¼Œåˆ¤æ–­æ˜¯å¦åœ¨å½“å‰å°æ—¶å†…
                    if stoptime_hour == current_hour:
                        # åœ¨å½“å‰å°æ—¶å†…ä½¿ç”¨è¿‡ï¼Œè¢«è§†ä¸º"åœ¨å½“å‰å°æ—¶å†…å·²ä½¿ç”¨"
                        status_str = "used_in_current_hour"
                        in_use += 1  # ç»Ÿè®¡ä¸Šä¹Ÿç®—ä½œä½¿ç”¨ä¸­
                    else:
                        # åœ¨ä¹‹å‰çš„å°æ—¶ä½¿ç”¨è¿‡ï¼Œå·²é‡Šæ”¾
                        status_str = "released"
                
                # æ„å»ºAppIDè¯¦ç»†ä¿¡æ¯
                appid_info = {
                    "appid": appid,
                    "vid": status.get("vid"),
                    "productName": status.get("productName"),
                    "starttime": starttime,
                    "stoptime": stoptime,
                    "status": status_str,
                    "is_available": is_available,
                    "stoptime_hour": stoptime_hour,  # stoptimeæ‰€åœ¨çš„å°æ—¶ï¼ˆæ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰
                    "current_hour": current_hour  # å½“å‰å°æ—¶ï¼ˆæ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰
                }
                appid_details.append(appid_info)
            
            result = {
                "total": total,
                "available": available,
                "in_use": in_use,
                "released": total - available - in_use,
                "appids": appid_details  # æ‰€æœ‰AppIDçš„è¯¦ç»†ä¿¡æ¯
            }
            
            if product_name:
                result["productName"] = product_name
            
            return result
    
    def store_test_result(self, product_name: str, session_id: str, test_data: Dict[str, Any]) -> None:
        """
        å­˜å‚¨æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®
        
        Args:
            product_name: äº§å“åç§°ï¼ˆä¸šåŠ¡ç±»å‹ï¼‰
            session_id: æµ‹è¯•ä¼šè¯IDï¼ˆç”¨äºåŒºåˆ†ä¸åŒçš„æµ‹è¯•ä¼šè¯ï¼Œå¦‚pytest workerè¿›ç¨‹ï¼‰
            test_data: æµ‹è¯•ç”¨ä¾‹æ•°æ®å­—å…¸
        """
        with self.lock:
            # æŒ‰ä¸šåŠ¡ç±»å‹ç»„ç»‡æ•°æ®
            if product_name not in self.test_results:
                self.test_results[product_name] = {}
            
            if session_id not in self.test_results[product_name]:
                self.test_results[product_name][session_id] = []
            
            # æ·»åŠ æ—¶é—´æˆ³ï¼ˆå¦‚æœtest_dataä¸­æ²¡æœ‰ï¼‰
            if "_stored_at" not in test_data:
                test_data["_stored_at"] = int(time.time() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
            
            self.test_results[product_name][session_id].append(test_data)
    
    def get_test_results(self, product_name: Optional[str] = None, session_id: Optional[str] = None) -> Dict[str, Any]:
        """
        è·å–æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®
        
        Args:
            product_name: äº§å“åç§°ï¼ˆä¸šåŠ¡ç±»å‹ï¼‰ï¼Œå¦‚æœæŒ‡å®šåˆ™åªè¿”å›è¯¥ä¸šåŠ¡çš„æ•°æ®ï¼Œå¦åˆ™è¿”å›æ‰€æœ‰ä¸šåŠ¡çš„æ•°æ®
            session_id: æµ‹è¯•ä¼šè¯IDï¼Œå¦‚æœæŒ‡å®šåˆ™åªè¿”å›è¯¥ä¼šè¯çš„æ•°æ®ï¼Œå¦åˆ™è¿”å›æ‰€æœ‰ä¼šè¯çš„æ•°æ®
            
        Returns:
            æµ‹è¯•ç»“æœæ•°æ®å­—å…¸
        """
        with self.lock:
            if product_name:
                # è¿”å›æŒ‡å®šä¸šåŠ¡çš„æ•°æ®
                business_results = self.test_results.get(product_name, {})
                
                if session_id:
                    # è¿”å›æŒ‡å®šä¸šåŠ¡å’Œä¼šè¯çš„æ•°æ®
                    results = business_results.get(session_id, [])
                    return {
                        "product_name": product_name,
                        "session_id": session_id,
                        "results": results
                    }
                else:
                    # è¿”å›æŒ‡å®šä¸šåŠ¡çš„æ‰€æœ‰ä¼šè¯æ•°æ®
                    all_results = []
                    for results in business_results.values():
                        all_results.extend(results)
                    
                    return {
                        "product_name": product_name,
                        "results": all_results
                    }
            else:
                # è¿”å›æ‰€æœ‰ä¸šåŠ¡çš„æ•°æ®
                all_results = []
                for business_results in self.test_results.values():
                    for results in business_results.values():
                        all_results.extend(results)
                
                return {
                    "results": all_results
                }
    
    def clear_test_results(self, product_name: Optional[str] = None, session_id: Optional[str] = None) -> None:
        """
        æ¸…é™¤æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®
        
        Args:
            product_name: äº§å“åç§°ï¼ˆä¸šåŠ¡ç±»å‹ï¼‰ï¼Œå¦‚æœæŒ‡å®šåˆ™åªæ¸…é™¤è¯¥ä¸šåŠ¡çš„æ•°æ®ï¼Œå¦åˆ™æ¸…é™¤æ‰€æœ‰ä¸šåŠ¡çš„æ•°æ®
            session_id: æµ‹è¯•ä¼šè¯IDï¼Œå¦‚æœæŒ‡å®šåˆ™åªæ¸…é™¤è¯¥ä¼šè¯çš„æ•°æ®ï¼Œå¦åˆ™æ¸…é™¤æ‰€æœ‰ä¼šè¯çš„æ•°æ®
        """
        with self.lock:
            if product_name:
                if product_name not in self.test_results:
                    return
                
                business_results = self.test_results[product_name]
                
                if session_id:
                    # æ¸…é™¤æŒ‡å®šä¸šåŠ¡å’Œä¼šè¯çš„æ•°æ®
                    if session_id in business_results:
                        del business_results[session_id]
                    
                    # å¦‚æœè¯¥ä¸šåŠ¡ä¸‹æ²¡æœ‰ä¼šè¯äº†ï¼Œåˆ é™¤ä¸šåŠ¡
                    if not business_results:
                        del self.test_results[product_name]
                else:
                    # æ¸…é™¤æŒ‡å®šä¸šåŠ¡çš„æ‰€æœ‰ä¼šè¯æ•°æ®
                    del self.test_results[product_name]
            else:
                # æ¸…é™¤æ‰€æœ‰ä¸šåŠ¡çš„æ•°æ®
                self.test_results.clear()
    
    def clear_old_test_results(self, days: int = 14) -> Dict[str, Any]:
        """
        æ¸…é™¤æŒ‡å®šå¤©æ•°å‰çš„æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®
        
        Args:
            days: ä¿ç•™æœ€è¿‘Nå¤©çš„æ•°æ®ï¼Œé»˜è®¤14å¤©ï¼ˆ2å‘¨ï¼‰
            
        Returns:
            æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        from datetime import datetime, timedelta
        
        with self.lock:
            cutoff_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)  # æ¯«ç§’æ—¶é—´æˆ³
            total_removed = 0
            total_kept = 0
            removed_by_product = {}
            
            # éå†æ‰€æœ‰ä¸šåŠ¡
            products_to_remove = []
            for product_name, business_results in list(self.test_results.items()):
                sessions_to_remove = []
                product_removed = 0
                product_kept = 0
                
                # éå†æ‰€æœ‰ä¼šè¯
                for session_id, results in list(business_results.items()):
                    # è¿‡æ»¤å‡ºéœ€è¦ä¿ç•™çš„æ•°æ®ï¼ˆæ—¶é—´æˆ³ >= cutoff_timeï¼‰
                    kept_results = []
                    for result in results:
                        stored_at = result.get("_stored_at", 0)
                        if stored_at >= cutoff_time:
                            kept_results.append(result)
                            product_kept += 1
                        else:
                            product_removed += 1
                    
                    # å¦‚æœè¯¥ä¼šè¯è¿˜æœ‰æ•°æ®ï¼Œæ›´æ–°ï¼›å¦åˆ™æ ‡è®°ä¸ºåˆ é™¤
                    if kept_results:
                        business_results[session_id] = kept_results
                    else:
                        sessions_to_remove.append(session_id)
                
                # åˆ é™¤ç©ºçš„ä¼šè¯
                for session_id in sessions_to_remove:
                    del business_results[session_id]
                
                # å¦‚æœè¯¥ä¸šåŠ¡ä¸‹æ²¡æœ‰ä¼šè¯äº†ï¼Œæ ‡è®°ä¸ºåˆ é™¤
                if not business_results:
                    products_to_remove.append(product_name)
                
                total_removed += product_removed
                total_kept += product_kept
                if product_removed > 0:
                    removed_by_product[product_name] = product_removed
            
            # åˆ é™¤ç©ºçš„ä¸šåŠ¡
            for product_name in products_to_remove:
                del self.test_results[product_name]
            
            return {
                "cutoff_time": cutoff_time,
                "cutoff_date": datetime.fromtimestamp(cutoff_time / 1000).isoformat(),
                "days": days,
                "total_removed": total_removed,
                "total_kept": total_kept,
                "removed_by_product": removed_by_product
            }
    


# ==================== å®šæ—¶ä»»åŠ¡ç›¸å…³ç±» ====================

class TaskConfigLoader:
    """ä»»åŠ¡é…ç½®åŠ è½½å™¨"""
    
    @staticmethod
    def load_tasks_from_jsonl(file_path: Path) -> List[Dict[str, Any]]:
        """
        ä»JSONLæ–‡ä»¶åŠ è½½ä»»åŠ¡é…ç½®
        
        Args:
            file_path: JSONLæ–‡ä»¶è·¯å¾„
            
        Returns:
            ä»»åŠ¡é…ç½®åˆ—è¡¨
        """
        tasks = []
        if not file_path.exists():
            return tasks
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        task_config = json.loads(line)
                        tasks.append(task_config)
                    except json.JSONDecodeError as e:
                        print(f"âš ï¸  è­¦å‘Š: ä»»åŠ¡é…ç½®æ–‡ä»¶ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}")
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: åŠ è½½ä»»åŠ¡é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        return tasks
    
    @staticmethod
    def validate_task_config(task_config: Dict[str, Any]) -> Tuple[bool, str]:
        """
        æ ¡éªŒä»»åŠ¡é…ç½®
        
        Args:
            task_config: ä»»åŠ¡é…ç½®å­—å…¸
            
        Returns:
            (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯ä¿¡æ¯)
        """
        required_fields = ["business", "environment", "start_delay_minutes"]
        
        for field in required_fields:
            if field not in task_config:
                return False, f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}"
        
        # æ ¡éªŒä¸šåŠ¡é…ç½®æ˜¯å¦å·²åˆå§‹åŒ–
        try:
            from .sku_query_framework import SkuQueryFactory
            configs = SkuQueryFactory._get_business_configs()
            business = task_config.get("business")
            if business not in configs:
                return False, f"ä¸šåŠ¡ '{business}' æœªåœ¨é…ç½®ä¸­åˆå§‹åŒ–ï¼Œå¯ç”¨ä¸šåŠ¡: {list(configs.keys())}"
        except Exception as e:
            return False, f"æ ¡éªŒä¸šåŠ¡é…ç½®å¤±è´¥: {e}"
        
        return True, ""
    
    @staticmethod
    def load_expected_values_from_jsonl(file_path: Path) -> Tuple[List[Dict[str, Any]], Optional[str]]:
        """
        ä»JSONLæ–‡ä»¶åŠ è½½é¢„æœŸå€¼ï¼ˆæ¯è¡Œä¸€ä¸ªç”¨ä¾‹çš„é¢„æœŸå€¼ï¼‰
        
        Args:
            file_path: JSONLæ–‡ä»¶è·¯å¾„
            
        Returns:
            (é¢„æœŸå€¼åˆ—è¡¨, é”™è¯¯ä¿¡æ¯)ï¼Œå¦‚æœæˆåŠŸåˆ™é”™è¯¯ä¿¡æ¯ä¸ºNone
        """
        expected_values_list = []
        if not file_path.exists():
            return [], "é¢„æœŸå€¼æ–‡ä»¶ä¸å­˜åœ¨"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        expected_values = json.loads(line)
                        if not isinstance(expected_values, dict):
                            return [], f"ç¬¬ {line_num} è¡Œä¸æ˜¯å­—å…¸æ ¼å¼"
                        
                        # æ ¡éªŒtoleranceå­—æ®µï¼ˆå¯é€‰ï¼‰
                        # tolerance å­—æ®µæ˜¯å¯é€‰çš„ï¼Œå¦‚æœä¸æä¾›åˆ™åœ¨ä½¿ç”¨æ—¶é»˜è®¤ä¸º0
                        # å¦‚æœæä¾›äº†toleranceï¼Œå¿…é¡»æ˜¯å­—å…¸ç±»å‹ï¼ˆå¯ä»¥ä¸ºç©ºå­—å…¸ï¼‰
                        if "tolerance" in expected_values:
                            tolerance = expected_values.get("tolerance")
                            if not isinstance(tolerance, dict):
                                return [], f"ç¬¬ {line_num} è¡Œçš„toleranceå¿…é¡»æ˜¯å­—å…¸ç±»å‹"
                        
                        expected_values_list.append(expected_values)
                    except json.JSONDecodeError as e:
                        return [], f"ç¬¬ {line_num} è¡ŒJSONè§£æå¤±è´¥: {e}"
        except Exception as e:
            return [], f"åŠ è½½é¢„æœŸå€¼æ–‡ä»¶å¤±è´¥: {e}"
        
        if len(expected_values_list) == 0:
            return [], "é¢„æœŸå€¼æ–‡ä»¶ä¸ºç©º"
        
        return expected_values_list, None
    
    @staticmethod
    def append_task_to_jsonl(file_path: Path, task_config: Dict[str, Any]) -> bool:
        """
        è¿½åŠ ä»»åŠ¡åˆ°JSONLæ–‡ä»¶
        
        Args:
            file_path: JSONLæ–‡ä»¶è·¯å¾„
            task_config: ä»»åŠ¡é…ç½®å­—å…¸
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            # è¿½åŠ åˆ°æ–‡ä»¶
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(task_config, ensure_ascii=False) + '\n')
            return True
        except Exception as e:
            print(f"âš ï¸  é”™è¯¯: è¿½åŠ ä»»åŠ¡åˆ°é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def remove_task_from_jsonl(file_path: Path, task_id: str) -> bool:
        """
        ä»JSONLæ–‡ä»¶ä¸­åˆ é™¤ä»»åŠ¡
        
        Args:
            file_path: JSONLæ–‡ä»¶è·¯å¾„
            task_id: ä»»åŠ¡ID
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not file_path.exists():
            return False
        
        try:
            # è¯»å–æ‰€æœ‰ä»»åŠ¡
            tasks = []
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        task_config = json.loads(line)
                        if task_config.get("task_id") != task_id:
                            tasks.append(line)
                    except json.JSONDecodeError:
                        continue
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                for task_line in tasks:
                    f.write(task_line + '\n')
            return True
        except Exception as e:
            print(f"âš ï¸  é”™è¯¯: ä»é…ç½®æ–‡ä»¶åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
            return False


class ReportManager:
    """æŠ¥å‘Šç®¡ç†å™¨"""
    
    def __init__(self, base_dir: Path):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç®¡ç†å™¨
        
        Args:
            base_dir: æŠ¥å‘Šå­˜å‚¨åŸºç¡€ç›®å½•
        """
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(parents=True, exist_ok=True)
        self.reports_dir = self.base_dir / "task_reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
    
    def save_report(self, task_id: str, execution_id: str, html_content: str) -> Path:
        """
        ä¿å­˜HTMLæŠ¥å‘Š
        
        Args:
            task_id: ä»»åŠ¡ID
            execution_id: æ‰§è¡ŒID
            html_content: HTMLå†…å®¹
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        task_dir = self.reports_dir / task_id
        task_dir.mkdir(parents=True, exist_ok=True)
        
        report_file = task_dir / f"{execution_id}.html"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return report_file
    
    def get_report_path(self, task_id: str, execution_id: str) -> Optional[Path]:
        """
        è·å–æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        
        Args:
            task_id: ä»»åŠ¡ID
            execution_id: æ‰§è¡ŒID
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        report_file = self.reports_dir / task_id / f"{execution_id}.html"
        if report_file.exists():
            return report_file
        return None
    
    def cleanup_old_reports(self, days: int = 7) -> Dict[str, Any]:
        """
        æ¸…ç†æ—§æŠ¥å‘Š
        
        Args:
            days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤7å¤©
            
        Returns:
            æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        cutoff_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        removed_count = 0
        kept_count = 0
        
        try:
            task_dirs = [d for d in self.reports_dir.iterdir() if d.is_dir()]
            for task_dir in task_dirs:
                
                for report_file in task_dir.iterdir():
                    if not report_file.is_file() or not report_file.suffix == '.html':
                        continue
                    
                    # ä»æ–‡ä»¶åæå–æ—¶é—´æˆ³ï¼ˆexecution_idæ ¼å¼ï¼šexec_{timestamp}ï¼‰
                    file_stem = report_file.stem
                    if file_stem.startswith('exec_'):
                        try:
                            timestamp = int(file_stem.split('_')[1])
                            if timestamp < cutoff_time:
                                report_file.unlink()
                                removed_count += 1
                            else:
                                kept_count += 1
                        except (ValueError, IndexError):
                            # æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œä¿ç•™
                            kept_count += 1
                    else:
                        # æ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®ï¼Œä¿ç•™
                        kept_count += 1
                
                # å¦‚æœä»»åŠ¡ç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
                if task_dir.exists() and not any(task_dir.iterdir()):
                    task_dir.rmdir()
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        
        return {
            "removed_count": removed_count,
            "kept_count": kept_count,
            "cutoff_time": cutoff_time
        }
    
    def list_reports(self, task_id: Optional[str] = None, days: int = 7) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæŠ¥å‘Š
        
        Args:
            task_id: ä»»åŠ¡IDï¼Œå¦‚æœæŒ‡å®šåˆ™åªåˆ—å‡ºè¯¥ä»»åŠ¡çš„æŠ¥å‘Š
            days: åªåˆ—å‡ºæœ€è¿‘Nå¤©çš„æŠ¥å‘Š
            
        Returns:
            æŠ¥å‘Šåˆ—è¡¨
        """
        cutoff_time = int((datetime.now() - timedelta(days=days)).timestamp() * 1000)
        reports = []
        
        try:
            if task_id:
                task_dirs = [self.reports_dir / task_id] if (self.reports_dir / task_id).is_dir() else []
            else:
                task_dirs = [d for d in self.reports_dir.iterdir() if d.is_dir()]
            
            for task_dir in task_dirs:
                
                current_task_id = task_dir.name
                
                for report_file in task_dir.iterdir():
                    if not report_file.is_file() or not report_file.suffix == '.html':
                        continue
                    
                    file_stem = report_file.stem
                    if file_stem.startswith('exec_'):
                        try:
                            timestamp = int(file_stem.split('_')[1])
                            if timestamp >= cutoff_time:
                                reports.append({
                                    "task_id": current_task_id,
                                    "execution_id": file_stem,
                                    "timestamp": timestamp,
                                    "file_path": str(report_file),
                                    "file_name": report_file.name
                                })
                        except (ValueError, IndexError):
                            pass
        except Exception as e:
            print(f"âš ï¸  åˆ—å‡ºæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
        
        # æŒ‰æ—¶é—´æˆ³å€’åºæ’åº
        reports.sort(key=lambda x: x["timestamp"], reverse=True)
        return reports


class EmailNotifier:
    """é‚®ä»¶é€šçŸ¥æœåŠ¡ - é€šè¿‡ Jenkins Job å‘é€é‚®ä»¶"""
    
    # Jenkins é…ç½®ï¼ˆHard codedï¼‰
    JENKINS_URL = "https://jenkins-api.bj2.agoralab.co/job/QAE/job/ACCS/job/ass_email_notification/buildWithParameters?delay=0sec"
    JENKINS_USER = "ouyangrunli@agora.io"
    JENKINS_TOKEN = "119cb0debb083f1a7fd54f1b5c213edc51"
    
    @staticmethod
    def send_email(subject: str, content: str, to_emails: List[str], 
                   cc_emails: Optional[List[str]] = None) -> Tuple[bool, str]:
        """
        é€šè¿‡ Jenkins Job å‘é€é‚®ä»¶é€šçŸ¥
        
        Args:
            subject: é‚®ä»¶ä¸»é¢˜
            content: é‚®ä»¶å†…å®¹ï¼ˆæ”¯æŒHTMLå’ŒMarkdownï¼‰
            to_emails: æ”¶ä»¶äººé‚®ç®±åˆ—è¡¨
            cc_emails: æŠ„é€äººé‚®ç®±åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        if not to_emails:
            return False, "æ”¶ä»¶äººåˆ—è¡¨ä¸ºç©º"
        
        try:
            # ä½¿ç”¨ Hard coded çš„ Jenkins é…ç½®
            jenkins_url = EmailNotifier.JENKINS_URL
            jenkins_user = EmailNotifier.JENKINS_USER
            jenkins_token = EmailNotifier.JENKINS_TOKEN
            
            # å°† Markdown å†…å®¹è½¬æ¢ä¸º HTMLï¼ˆä¿ç•™åŸæœ‰çš„è½¬æ¢é€»è¾‘ï¼‰
            import re
            # è½¬æ¢æ ‡é¢˜
            html_content = re.sub(r'^### (.*)$', r'<h3>\1</h3>', content, flags=re.MULTILINE)
            html_content = re.sub(r'^## (.*)$', r'<h2>\1</h2>', html_content, flags=re.MULTILINE)
            html_content = re.sub(r'^# (.*)$', r'<h1>\1</h1>', html_content, flags=re.MULTILINE)
            # è½¬æ¢åŠ ç²—
            html_content = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', html_content)
            # è½¬æ¢ä»£ç å—
            html_content = re.sub(r'```([^`]+)```', r'<pre><code>\1</code></pre>', html_content, flags=re.DOTALL)
            html_content = re.sub(r'`([^`]+)`', r'<code>\1</code>', html_content)
            # è½¬æ¢é“¾æ¥
            html_content = re.sub(r'\[([^\]]+)\]\(([^\)]+)\)', r'<a href="\2">\1</a>', html_content)
            # è½¬æ¢åˆ—è¡¨
            html_content = re.sub(r'^- (.*)$', r'<li>\1</li>', html_content, flags=re.MULTILINE)
            html_content = re.sub(r'(<li>.*</li>)', r'<ul>\1</ul>', html_content, flags=re.DOTALL)
            # è½¬æ¢æ¢è¡Œ
            html_content = html_content.replace('\n', '<br>\n')
            
            # æ„å»º Jenkins Job å‚æ•°
            params = {
                "email_subject": subject,
                "email_content": html_content,
                "send_email_to_somebody": ", ".join(to_emails),
                "cc_email_to_somebody": ", ".join(cc_emails) if cc_emails else ""
            }
            
            # æ‰“å°æ—¥å¿—
            print(f"ğŸ“§ é€šè¿‡ Jenkins å‘é€é‚®ä»¶é€šçŸ¥åˆ°: {', '.join(to_emails)}")
            if cc_emails:
                print(f"ğŸ“§ æŠ„é€åˆ°: {', '.join(cc_emails)}")
            print(f"ğŸ“ é‚®ä»¶ä¸»é¢˜: {subject}")
            print(f"ğŸ”— Jenkins Job URL: {jenkins_url}")
            
            # è°ƒç”¨ Jenkins API è§¦å‘æ„å»º
            response = requests.post(
                jenkins_url,
                params=params,
                auth=(jenkins_user, jenkins_token),
                timeout=30
            )
            
            if response.status_code in [200, 201]:
                print(f"âœ… é‚®ä»¶å‘é€ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ° Jenkins")
                return True, "é‚®ä»¶å‘é€ä»»åŠ¡å·²æäº¤åˆ° Jenkins"
            else:
                error_msg = f"Jenkins API è¿”å›é”™è¯¯: {response.status_code}"
                if response.text:
                    error_msg += f" - {response.text[:200]}"
                print(f"âš ï¸  {error_msg}")
                return False, error_msg
                
        except requests.RequestException as e:
            error_msg = f"è°ƒç”¨ Jenkins API å¤±è´¥: {str(e)}"
            print(f"âš ï¸  {error_msg}")
            return False, error_msg
        except Exception as e:
            error_msg = f"å‘é€é‚®ä»¶å¤±è´¥: {str(e)}"
            print(f"âš ï¸  {error_msg}")
            return False, error_msg


class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå™¨"""
    
    def __init__(self, report_manager: ReportManager):
        """
        åˆå§‹åŒ–ä»»åŠ¡æ‰§è¡Œå™¨
        
        Args:
            report_manager: æŠ¥å‘Šç®¡ç†å™¨
        """
        self.report_manager = report_manager
        self.email_notifier = EmailNotifier()
    
    def execute_task(self, task_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        æ‰§è¡Œä»»åŠ¡
        
        Args:
            task_config: ä»»åŠ¡é…ç½®
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        execution_id = f"exec_{int(time.time() * 1000)}"
        task_id = task_config.get("task_id")
        if not task_id:
            raise ValueError("task_id ä¸èƒ½ä¸ºç©º")
        
        task_name = task_config.get("task_name", "")
        business = task_config.get("business")
        if not business:
            raise ValueError("business ä¸èƒ½ä¸ºç©º")
        
        environment = task_config.get("environment", "staging")
        
        start_time = int(time.time() * 1000)
        
        try:
            # å¯¼å…¥å¿…è¦çš„æ¨¡å—
            from .sku_query_framework import SkuQueryFactory
            
            # ä»JSONLæ–‡ä»¶åŠ è½½é¢„æœŸå€¼ï¼ˆæ¯è¡Œä¸€ä¸ªç”¨ä¾‹çš„é¢„æœŸå€¼ï¼‰
            expected_values_file = task_config.get("expected_values_file")
            if not expected_values_file:
                raise ValueError("expected_values_file ä¸èƒ½ä¸ºç©º")
            
            expected_values_list, error_msg = TaskConfigLoader.load_expected_values_from_jsonl(Path(expected_values_file))
            if error_msg:
                raise ValueError(f"é¢„æœŸå€¼æ–‡ä»¶æ ¡éªŒå¤±è´¥: {error_msg}")
            if not expected_values_list:
                raise ValueError(f"é¢„æœŸå€¼æ–‡ä»¶ä¸ºç©º: {expected_values_file}")
            
            # ä¸ºæ¯ä¸ªç”¨ä¾‹æ„å»ºbilling_data
            billing_datas = []
            for idx, expected_values in enumerate(expected_values_list):
                try:
                    # ä»é¢„æœŸå€¼ä¸­æå–toleranceï¼ˆå¿…é¡»å­˜åœ¨ï¼Œå·²åœ¨åŠ è½½æ—¶æ ¡éªŒï¼‰
                    tolerance = expected_values.pop("tolerance", {})
                    
                    # æå–çœŸæ­£çš„expectedå­—æ®µï¼ˆJSONLæ–‡ä»¶ä¸­expectedå­—æ®µåŒ…å«çœŸæ­£çš„é¢„æœŸå€¼ï¼‰
                    # å¦‚æœJSONLæ–‡ä»¶ä¸­æ²¡æœ‰expectedå­—æ®µï¼Œåˆ™ä½¿ç”¨æ•´ä¸ªexpected_valuesï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                    expected_dict = expected_values.pop("expected", expected_values)
                    
                    # æå–å…¶ä»–å…ƒæ•°æ®å­—æ®µï¼ˆä¸æ”¾å…¥expectedä¸­ï¼‰
                    case_name = expected_values.pop("case", f"ç”¨ä¾‹ {idx + 1}")
                    # æå–vidã€startTimeã€stopTimeç­‰å­—æ®µç”¨äºæŸ¥è¯¢ï¼ˆè¿™äº›éƒ½æ˜¯å¿…éœ€å­—æ®µï¼‰
                    vid_from_data = expected_values.pop("vid", None)
                    start_time_from_data = expected_values.pop("startTime", None)
                    stop_time_from_data = expected_values.pop("stopTime", None)
                    
                    # æ ¡éªŒå¿…éœ€å­—æ®µ
                    missing_fields = []
                    if vid_from_data is None:
                        missing_fields.append("vid")
                    if start_time_from_data is None:
                        missing_fields.append("startTime")
                    if stop_time_from_data is None:
                        missing_fields.append("stopTime")
                    
                    # å¦‚æœç¼ºå°‘å¿…éœ€å­—æ®µï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ä»»åŠ¡
                    if missing_fields:
                        error_msg = f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"
                        print(f"âš ï¸  ç”¨ä¾‹ '{case_name}' {error_msg}ï¼Œå°†æ ‡è®°ä¸ºå¤±è´¥")
                        # åˆ›å»ºä¸€ä¸ªå¸¦æœ‰é”™è¯¯ä¿¡æ¯çš„billing_data
                        billing_data = {
                            "vid": vid_from_data or 0,
                            "startTime": start_time_from_data or 0,
                            "stopTime": stop_time_from_data or 0,
                            "case": case_name,
                            "expected": expected_dict,
                            "actual": {},
                            "tolerance": tolerance,
                            "error": error_msg,  # æ ‡è®°é”™è¯¯ä¿¡æ¯
                            "_skip_query": True  # æ ‡è®°è·³è¿‡æŸ¥è¯¢
                        }
                        billing_data.update(expected_values)
                        billing_datas.append(billing_data)
                        continue
                    
                    use_vid = vid_from_data
                    use_start_time = start_time_from_data
                    use_end_time = stop_time_from_data
                    
                    billing_data = {
                        "vid": use_vid,
                        "startTime": use_start_time,
                        "stopTime": use_end_time,
                        "case": case_name,
                        "expected": expected_dict,
                        "actual": {},
                        "tolerance": tolerance
                    }
                    # å°†å…¶ä»–å…ƒæ•°æ®å­—æ®µä¹Ÿä¿å­˜åˆ°billing_dataä¸­ï¼ˆå¦‚appIdã€cnameã€sqlç­‰ï¼‰
                    billing_data.update(expected_values)
                    billing_datas.append(billing_data)
                    
                except Exception as e:
                    # æ•è·å…¶ä»–å¯èƒ½çš„å¼‚å¸¸
                    case_name = expected_values.get("case", f"ç”¨ä¾‹ {idx + 1}")
                    error_msg = f"å¤„ç†ç”¨ä¾‹æ•°æ®æ—¶å‡ºé”™: {str(e)}"
                    print(f"âš ï¸  ç”¨ä¾‹ '{case_name}' {error_msg}ï¼Œå°†æ ‡è®°ä¸ºå¤±è´¥")
                    billing_data = {
                        "vid": 0,
                        "startTime": 0,
                        "stopTime": 0,
                        "case": case_name,
                        "expected": {},
                        "actual": {},
                        "tolerance": {},
                        "error": error_msg,
                        "_skip_query": True
                    }
                    billing_datas.append(billing_data)
                    continue
            
            # æŸ¥è¯¢æ•°æ®
            from .html_report_generator import load_report_config_from_business, HTMLReportGenerator
            from .sku_query_framework import QueryLogger
            
            # åˆ›å»ºæŸ¥è¯¢æ—¥å¿—è®°å½•å™¨
            query_logger = QueryLogger()
            
            client = SkuQueryFactory.get_client(business, environment=environment, query_logger=query_logger)
            
            # æŸ¥è¯¢Detailæ•°æ®ï¼ˆå¦‚æœæœ‰detailå­—æ®µï¼‰
            detail_fields_to_aggregate = []
            try:
                report_config = load_report_config_from_business(business)
                detail_fields_to_aggregate = report_config.get("detail_fields", [])
            except Exception as e:
                print(f"âš ï¸  ä»é…ç½®æ–‡ä»¶åŠ è½½æŠ¥å‘Šé…ç½®å¤±è´¥: {e}ï¼Œå°†ä¸å¤„ç† detail å­—æ®µ")
            
            # ä¸ºæ¯ä¸ªç”¨ä¾‹æŸ¥è¯¢æ•°æ®ï¼ˆå› ä¸ºæ¯ä¸ªç”¨ä¾‹å¯èƒ½æœ‰ä¸åŒçš„vidå’Œæ—¶é—´èŒƒå›´ï¼‰
            for billing_data in billing_datas:
                # è·³è¿‡æ ‡è®°ä¸ºéœ€è¦è·³è¿‡æŸ¥è¯¢çš„ç”¨ä¾‹ï¼ˆæœ‰é”™è¯¯çš„ç”¨ä¾‹ï¼‰
                if billing_data.get("_skip_query"):
                    case_name = billing_data.get("case", "æœªçŸ¥ç”¨ä¾‹")
                    print(f"âš ï¸  è·³è¿‡æŸ¥è¯¢ç”¨ä¾‹ '{case_name}'ï¼ˆæ•°æ®é”™è¯¯ï¼‰")
                    continue
                
                case_vid = billing_data.get("vid")
                case_start_time = billing_data.get("startTime")
                case_end_time = billing_data.get("stopTime")
                
                # å¦‚æœç¼ºå°‘å¿…è¦å‚æ•°ï¼Œè·³è¿‡
                if case_vid is None or case_start_time is None or case_end_time is None:
                    case_name = billing_data.get("case", "æœªçŸ¥ç”¨ä¾‹")
                    print(f"âš ï¸  è­¦å‘Š: ç”¨ä¾‹ '{case_name}' ç¼ºå°‘å¿…è¦å‚æ•° (vid, startTime, stopTime)ï¼Œè·³è¿‡æŸ¥è¯¢")
                    continue
                
                # æŸ¥è¯¢SKUæ•°æ®ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼Œé˜²æ­¢å•ä¸ªç”¨ä¾‹å¤±è´¥å½±å“å…¶ä»–ç”¨ä¾‹ï¼‰
                case_name = billing_data.get("case", "æœªçŸ¥ç”¨ä¾‹")
                try:
                    aggregated_results, hourly_details = client.query_sku_across_hours(
                        vid=case_vid,
                        start_time=case_start_time,
                        end_time=case_end_time,
                        sku_ids=SkuQueryFactory.get_sku_ids(business),
                    )
                    
                    # æŸ¥è¯¢Detailæ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    detail_aggregated = {}
                    if detail_fields_to_aggregate:
                        detail_aggregated = client.aggregate_detail_fields_across_hours(
                            vid=case_vid,
                            start_time=case_start_time,
                            end_time=case_end_time,
                            detail_fields=detail_fields_to_aggregate
                        )
                    
                    # å¡«å……å®é™…å€¼
                    actual_dict = billing_data.setdefault("actual", {})
                    actual_dict.update(aggregated_results)
                    actual_dict.update(detail_aggregated)
                    
                    # ç¡®ä¿æ‰€æœ‰expectedå­—æ®µéƒ½åœ¨actualä¸­å­˜åœ¨ï¼ˆå³ä½¿å€¼ä¸ºNoneï¼‰
                    # è¿™æ ·æŠ¥å‘Šä¸­å°±ä¼šæ˜¾ç¤ºæ‰€æœ‰å­—æ®µï¼Œè€Œä¸æ˜¯åªæ˜¾ç¤ºæœ‰æ•°æ®çš„å­—æ®µ
                    expected_dict = billing_data.get("expected", {})
                    for key in expected_dict.keys():
                        if key not in actual_dict:
                            actual_dict[key] = None
                    
                    print(f"âœ…  ç”¨ä¾‹ '{case_name}' æŸ¥è¯¢æˆåŠŸ")
                    
                except Exception as e:
                    # æŸ¥è¯¢å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–ç”¨ä¾‹
                    error_msg = f"æŸ¥è¯¢æ•°æ®å¤±è´¥: {str(e)}"
                    print(f"âŒ  ç”¨ä¾‹ '{case_name}' {error_msg}")
                    billing_data["error"] = error_msg
                    # actual ä¿æŒä¸ºç©ºå­—å…¸ï¼Œè¡¨ç¤ºæŸ¥è¯¢å¤±è´¥
                    continue
            
            # ç”ŸæˆHTMLæŠ¥å‘Š
            try:
                report_config = load_report_config_from_business(business)
                comparison_config = report_config.get("comparison_config")
                custom_columns = report_config.get("custom_columns")
            except Exception as e:
                print(f"âš ï¸  ä»é…ç½®æ–‡ä»¶åŠ è½½æŠ¥å‘Šé…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                comparison_config = None
                custom_columns = None
            
            html_generator = HTMLReportGenerator(
                comparison_config=comparison_config,
                custom_columns=custom_columns,
                output_dir=str(self.report_manager.base_dir)
            )
            
            # ç”ŸæˆæŠ¥å‘Šå†…å®¹
            html_content = html_generator._build_table_html(billing_datas)
            
            # ä¿å­˜æŠ¥å‘Š
            report_path = self.report_manager.save_report(task_id, execution_id, html_content)
            
            # å¯¼å‡ºæŸ¥è¯¢æ•°æ®ä¸ºjsonlæ–‡ä»¶
            jsonl_file_path = self._export_billing_data_to_jsonl(task_id, execution_id, billing_datas)
            
            # ä¿å­˜æŸ¥è¯¢æ—¥å¿—æ–‡ä»¶
            log_file_path = self._save_query_logs(task_id, execution_id, query_logger)
            
            # è®¡ç®—æ‘˜è¦ï¼ˆæ‰€æœ‰ç”¨ä¾‹çš„æ±‡æ€»ï¼‰
            summary = self._calculate_summary_all_cases(billing_datas, html_generator)
            
            # å‘é€é‚®ä»¶é€šçŸ¥ - ä»ä¸šåŠ¡é…ç½®ä¸­è¯»å–æ”¶ä»¶äººåˆ—è¡¨
            # è·å–ä¸šåŠ¡é…ç½®
            from .sku_query_framework import SkuQueryFactory
            configs = SkuQueryFactory._get_business_configs()
            business_config = configs.get(business, {})
            
            # ä»ä¸šåŠ¡é…ç½®ä¸­è·å– email_config
            email_config = business_config.get("email_config", {})
            email_list = email_config.get("recipients", [])
            cc_list = email_config.get("cc", [])
            
            # å¦‚æœä¸šåŠ¡é…ç½®ä¸­æ²¡æœ‰é…ç½®æ”¶ä»¶äººï¼Œå°è¯•ä» task_config ä¸­è·å–ï¼ˆå…¼å®¹æ—§æ–¹å¼ï¼‰
            if not email_list:
                email_list = task_config.get("email_list", [])
            
            if email_list:
                notification_content = self._build_notification_content(
                    task_config.get("task_name", ""), task_id, execution_id, summary, 
                    report_path, task_config.get("_base_url", ""),
                    query_logs=query_logger.get_logs() if query_logger else None,
                    jsonl_file_path=jsonl_file_path,
                    log_file_path=log_file_path
                )
                subject = f"ã€{task_config.get('task_name', 'å®šæ—¶ä»»åŠ¡')}ã€‘æ‰§è¡ŒæŠ¥å‘Š"
                success, error_msg = self.email_notifier.send_email(
                    subject, notification_content, email_list, cc_list
                )
                if not success:
                    print(f"âš ï¸  é‚®ä»¶é€šçŸ¥å‘é€å¤±è´¥: {error_msg}")
                else:
                    print(f"âœ… é‚®ä»¶é€šçŸ¥å·²å‘é€åˆ°: {', '.join(email_list)}")
                    if cc_list:
                        print(f"ğŸ“§ æŠ„é€åˆ°: {', '.join(cc_list)}")
            else:
                print(f"âš ï¸  æœªé…ç½®æ”¶ä»¶äººï¼Œè·³è¿‡é‚®ä»¶é€šçŸ¥")
            
            return {
                "execution_id": execution_id,
                "status": "success",
                "timestamp": start_time,
                "report_path": str(report_path),
                "jsonl_file_path": str(jsonl_file_path) if jsonl_file_path else None,
                "log_file_path": str(log_file_path) if log_file_path else None,
                "summary": summary,
                "error": None
            }
            
        except Exception as e:
            error_msg = str(e)
            print(f"âš ï¸  ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {error_msg}")
            
            # å‘é€é”™è¯¯é‚®ä»¶é€šçŸ¥ - ä»ä¸šåŠ¡é…ç½®ä¸­è¯»å–æ”¶ä»¶äººåˆ—è¡¨
            try:
                from .sku_query_framework import SkuQueryFactory
                configs = SkuQueryFactory._get_business_configs()
                business_config = configs.get(business, {})
                
                # ä»ä¸šåŠ¡é…ç½®ä¸­è·å– email_config
                email_config = business_config.get("email_config", {})
                email_list = email_config.get("recipients", [])
                cc_list = email_config.get("cc", [])
                
                # å¦‚æœä¸šåŠ¡é…ç½®ä¸­æ²¡æœ‰é…ç½®æ”¶ä»¶äººï¼Œå°è¯•ä» task_config ä¸­è·å–ï¼ˆå…¼å®¹æ—§æ–¹å¼ï¼‰
                if not email_list:
                    email_list = task_config.get("email_list", [])
                
                if email_list:
                    error_content = f"""## âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥

**ä»»åŠ¡åç§°**: {task_config.get('task_name', '')}
**ä»»åŠ¡ID**: {task_id}
**æ‰§è¡Œæ—¶é—´**: {datetime.fromtimestamp(start_time / 1000).strftime('%Y-%m-%d %H:%M:%S')}

**é”™è¯¯ä¿¡æ¯**: {error_msg}
"""
                    subject = f"ã€{task_config.get('task_name', 'å®šæ—¶ä»»åŠ¡')}ã€‘æ‰§è¡Œå¤±è´¥"
                    self.email_notifier.send_email(
                        subject, error_content, email_list, cc_list
                    )
            except Exception as email_error:
                print(f"âš ï¸  å‘é€å¤±è´¥é‚®ä»¶é€šçŸ¥æ—¶å‡ºé”™: {email_error}")
            
            return {
                "execution_id": execution_id,
                "status": "failed",
                "timestamp": start_time,
                "report_path": None,
                "summary": None,
                "error": error_msg
            }
    
    def _calculate_summary_all_cases(self, billing_datas: List[Dict[str, Any]], 
                                     html_generator: Any) -> Dict[str, Any]:
        """
        è®¡ç®—æ‰€æœ‰ç”¨ä¾‹çš„æ•°æ®æ‘˜è¦
        
        Args:
            billing_datas: è®¡è´¹æ•°æ®åˆ—è¡¨
            html_generator: HTMLæŠ¥å‘Šç”Ÿæˆå™¨
            
        Returns:
            æ‘˜è¦ä¿¡æ¯
        """
        total_cases = len(billing_datas)
        passed_cases = 0
        failed_cases = 0
        
        for data in billing_datas:
            if html_generator._has_differences(data):
                failed_cases += 1
            else:
                passed_cases += 1
        
        pass_rate = (passed_cases / total_cases * 100) if total_cases > 0 else 0
        
        return {
            "total_cases": total_cases,
            "passed_cases": passed_cases,
            "failed_cases": failed_cases,
            "pass_rate": round(pass_rate, 1)
        }
    
    def _export_billing_data_to_jsonl(self, task_id: str, execution_id: str, 
                                     billing_datas: List[Dict[str, Any]]) -> Optional[Path]:
        """
        å°†æŸ¥è¯¢æ•°æ®å¯¼å‡ºä¸ºjsonlæ–‡ä»¶
        
        Args:
            task_id: ä»»åŠ¡ID
            execution_id: æ‰§è¡ŒID
            billing_datas: è®¡è´¹æ•°æ®åˆ—è¡¨
            
        Returns:
            jsonlæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # åœ¨æŠ¥å‘Šç›®å½•ä¸‹åˆ›å»ºjsonlæ–‡ä»¶ï¼ˆä½¿ç”¨reports_dirï¼Œä¸APIæŸ¥æ‰¾è·¯å¾„ä¸€è‡´ï¼‰
            jsonl_dir = self.report_manager.reports_dir / task_id
            jsonl_dir.mkdir(parents=True, exist_ok=True)
            jsonl_file = jsonl_dir / f"{execution_id}_data.jsonl"
            
            with open(jsonl_file, 'w', encoding='utf-8') as f:
                for data in billing_datas:
                    # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                    json.dump(data, f, ensure_ascii=False)
                    f.write('\n')
            
            print(f"âœ… æŸ¥è¯¢æ•°æ®å·²å¯¼å‡ºåˆ°: {jsonl_file}")
            return jsonl_file
        except Exception as e:
            print(f"âš ï¸  å¯¼å‡ºjsonlæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _save_query_logs(self, task_id: str, execution_id: str, 
                        query_logger: Any) -> Optional[Path]:
        """
        ä¿å­˜æŸ¥è¯¢æ—¥å¿—æ–‡ä»¶
        
        Args:
            task_id: ä»»åŠ¡ID
            execution_id: æ‰§è¡ŒID
            query_logger: æŸ¥è¯¢æ—¥å¿—è®°å½•å™¨
            
        Returns:
            æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # åœ¨æŠ¥å‘Šç›®å½•ä¸‹åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨reports_dirï¼Œä¸APIæŸ¥æ‰¾è·¯å¾„ä¸€è‡´ï¼‰
            log_dir = self.report_manager.reports_dir / task_id
            log_dir.mkdir(parents=True, exist_ok=True)
            log_file = log_dir / f"{execution_id}_query_logs.log"
            
            # ä¿å­˜ä¸ºå¯è¯»çš„æ—¥å¿—æ ¼å¼
            with open(log_file, 'w', encoding='utf-8') as f:
                for log in query_logger.get_logs():
                    timestamp = log.get("timestamp", "N/A")
                    query_type = log.get("query_type", "Unknown")
                    status = log.get("response_status", "N/A")
                    duration = log.get("duration_ms", 0)
                    error = log.get("error")
                    curl_cmd = log.get("curl_command", "")
                    response_text = log.get("response_text", "")
                    
                    # å†™å…¥æ—¶é—´æˆ³å’ŒæŸ¥è¯¢ç±»å‹
                    f.write(f"[{timestamp}] {query_type} Query\n")
                    f.write(f"  Status: {status}\n")
                    f.write(f"  Duration: {duration:.2f}ms\n")
                    
                    if error:
                        f.write(f"  Error: {error}\n")
                    else:
                        summary = log.get("response_summary", {})
                        if isinstance(summary, dict) and "data_count" in summary:
                            count = summary.get("data_count", 0)
                            f.write(f"  Data Count: {count}\n")
                    
                    # å†™å…¥curlå‘½ä»¤ï¼ˆå•è¡Œï¼‰
                    f.write(f"  Curl Command: {curl_cmd}\n")
                    
                    # å†™å…¥curlè¿”å›ç»“æœ
                    if response_text:
                        f.write(f"  Curl Response: {response_text}\n")
                    elif error:
                        f.write(f"  Curl Response: (Error occurred)\n")
                    else:
                        f.write(f"  Curl Response: (No response)\n")
                    
                    f.write("\n")
            
            print(f"âœ… æŸ¥è¯¢æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
            return log_file
        except Exception as e:
            print(f"âš ï¸  ä¿å­˜æŸ¥è¯¢æ—¥å¿—å¤±è´¥: {e}")
            return None
    
    def _build_notification_content(self, task_name: str, task_id: str, 
                                   execution_id: str, summary: Dict[str, Any],
                                   report_path: Path, base_url: str = "",
                                   query_logs: Optional[List[Dict[str, Any]]] = None,
                                   jsonl_file_path: Optional[Path] = None,
                                   log_file_path: Optional[Path] = None) -> str:
        """
        æ„å»ºé€šçŸ¥å†…å®¹ï¼ˆé‚®ä»¶é€šçŸ¥ï¼‰- ç´§å‡‘ç‰ˆæœ¬
        
        Args:
            task_name: ä»»åŠ¡åç§°
            task_id: ä»»åŠ¡ID
            execution_id: æ‰§è¡ŒID
            summary: æ‘˜è¦ä¿¡æ¯
            report_path: æŠ¥å‘Šè·¯å¾„
            base_url: æœåŠ¡åŸºç¡€URLï¼Œç”¨äºç”Ÿæˆä¸‹è½½é“¾æ¥
            query_logs: æŸ¥è¯¢æ—¥å¿—åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            jsonl_file_path: jsonlæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            log_file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Markdownæ ¼å¼çš„é€šçŸ¥å†…å®¹
        """
        execution_time = datetime.fromtimestamp(int(time.time())).strftime('%Y-%m-%d %H:%M:%S')
        
        status_emoji = "âœ…" if summary["failed_cases"] == 0 else "âš ï¸"
        
        # ç”Ÿæˆä¸‹è½½æ–¹å¼ï¼ˆURLæˆ–curlå‘½ä»¤ï¼‰
        if base_url:
            download_url = f"{base_url.rstrip('/')}/api/report/{execution_id}"
            download_info = f"**ä¸‹è½½é“¾æ¥**: {download_url}"
        else:
            download_info = f"**æ‰§è¡ŒID**: `{execution_id}`"
        
        # ç´§å‡‘çš„é‚®ä»¶å†…å®¹ï¼ˆå‡å°‘ç©ºè¡Œå’Œé—´è·ï¼‰
        content = f"""## {status_emoji} {task_name} æ‰§è¡ŒæŠ¥å‘Š
**æ‰§è¡Œæ—¶é—´**: {execution_time} | **ä»»åŠ¡ID**: {task_id}
**æ•°æ®æ‘˜è¦**: æ€»ç”¨ä¾‹: {summary['total_cases']} | é€šè¿‡: {summary['passed_cases']} | å¤±è´¥: {summary['failed_cases']} | é€šè¿‡ç‡: {summary['pass_rate']}%
**æŠ¥å‘Šä¸‹è½½**: {download_info}
"""
        
        # æ·»åŠ æ–‡ä»¶ä¸‹è½½é“¾æ¥
        if base_url:
            if jsonl_file_path and jsonl_file_path.exists():
                data_download_url = f"{base_url.rstrip('/')}/api/report/{execution_id}/data"
                content += f"**æ•°æ®æ–‡ä»¶**: [ä¸‹è½½ {jsonl_file_path.name}]({data_download_url})\n"
            
            if log_file_path and log_file_path.exists():
                log_download_url = f"{base_url.rstrip('/')}/api/report/{execution_id}/logs"
                content += f"**æ—¥å¿—æ–‡ä»¶**: [ä¸‹è½½ {log_file_path.name}]({log_download_url})\n"
        else:
            # å¦‚æœæ²¡æœ‰base_urlï¼Œåªæ˜¾ç¤ºæ–‡ä»¶å
            if jsonl_file_path and jsonl_file_path.exists():
                content += f"**æ•°æ®æ–‡ä»¶**: `{jsonl_file_path.name}`\n"
            if log_file_path and log_file_path.exists():
                content += f"**æ—¥å¿—æ–‡ä»¶**: `{log_file_path.name}`\n"
        
        return content


class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self, task_executor: TaskExecutor, report_manager: ReportManager):
        """
        åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨
        
        Args:
            task_executor: ä»»åŠ¡æ‰§è¡Œå™¨
            report_manager: æŠ¥å‘Šç®¡ç†å™¨
        """
        self.task_executor = task_executor
        self.report_manager = report_manager
        self.tasks: Dict[str, Dict[str, Any]] = {}  # {task_id: {config, timer, ...}}
        self.execution_history: Dict[str, List[Dict[str, Any]]] = {}  # {task_id: [execution_results]}
        self.lock = threading.Lock()
    
    def add_task(self, task_config: Dict[str, Any]) -> Tuple[bool, str]:
        """
        æ·»åŠ ä»»åŠ¡
        
        Args:
            task_config: ä»»åŠ¡é…ç½®
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        task_id = task_config.get("task_id")
        if not task_id:
            return False, "task_id ä¸èƒ½ä¸ºç©º"
        
        # æ ¡éªŒé…ç½®
        is_valid, error_msg = TaskConfigLoader.validate_task_config(task_config)
        if not is_valid:
            return False, error_msg
        
        with self.lock:
            if task_id in self.tasks:
                return False, f"ä»»åŠ¡ {task_id} å·²å­˜åœ¨"
            
            # è®¡ç®—é¦–æ¬¡æ‰§è¡Œæ—¶é—´
            start_delay_minutes = task_config.get("start_delay_minutes", 30)
            
            # åˆ›å»ºä¸€æ¬¡æ€§æ‰§è¡Œå‡½æ•°
            def execute_once():
                # æ‰§è¡Œä»»åŠ¡
                result = self.task_executor.execute_task(task_config)
                
                # è®°å½•æ‰§è¡Œå†å²
                self._add_execution_history(task_id, result)
                
                # æ¸…ç†æ—§å†å²ï¼ˆä¿ç•™7å¤©ï¼‰
                self._cleanup_old_history()
                
                # æ¸…ç†æ—§æŠ¥å‘Šï¼ˆä¿ç•™7å¤©ï¼‰
                self.report_manager.cleanup_old_reports(days=7)
                
                # ä»»åŠ¡æ‰§è¡Œå®Œæˆåï¼Œä»ä»»åŠ¡åˆ—è¡¨ä¸­ç§»é™¤ï¼ˆä½†ä¿ç•™åœ¨å†å²ä¸­ï¼‰
                with self.lock:
                    if task_id in self.tasks:
                        del self.tasks[task_id]
            
            # å¯åŠ¨ä¸€æ¬¡æ€§æ‰§è¡Œå®šæ—¶å™¨
            timer = threading.Timer(start_delay_minutes * 60, execute_once)
            timer.daemon = True
            
            self.tasks[task_id] = {
                "config": task_config,
                "timer": timer,
                "last_execution": None,
                "execution_count": 0
            }
            
            timer.start()
            
            return True, f"ä»»åŠ¡ {task_id} å·²æ·»åŠ ï¼Œå°†åœ¨ {start_delay_minutes} åˆ†é’Ÿåæ‰§è¡Œä¸€æ¬¡"
    
    def remove_task(self, task_id: str) -> Tuple[bool, str]:
        """
        ç§»é™¤ä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)
        """
        with self.lock:
            if task_id not in self.tasks:
                return False, f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"
            
            # åœæ­¢å®šæ—¶å™¨
            timer = self.tasks[task_id].get("timer")
            if timer:
                timer.cancel()
            
            # åˆ é™¤ä»»åŠ¡
            del self.tasks[task_id]
            
            return True, f"ä»»åŠ¡ {task_id} å·²ç§»é™¤"
    
    def run_task_manually(self, task_id: str) -> Tuple[bool, Dict[str, Any]]:
        """
        æ‰‹åŠ¨æ‰§è¡Œä»»åŠ¡
        
        Args:
            task_id: ä»»åŠ¡ID
            
        Returns:
            (æ˜¯å¦æˆåŠŸ, æ‰§è¡Œç»“æœ)
        """
        with self.lock:
            if task_id not in self.tasks:
                return False, {"error": f"ä»»åŠ¡ {task_id} ä¸å­˜åœ¨"}
            
            task_config = self.tasks[task_id]["config"]
        
        # æ‰§è¡Œä»»åŠ¡
        result = self.task_executor.execute_task(task_config)
        
        # è®°å½•æ‰§è¡Œå†å²
        self._add_execution_history(task_id, result)
        
        return True, result
    
    def _add_execution_history(self, task_id: str, result: Dict[str, Any]):
        """æ·»åŠ æ‰§è¡Œå†å²"""
        with self.lock:
            if task_id not in self.execution_history:
                self.execution_history[task_id] = []
            
            self.execution_history[task_id].append(result)
            self.tasks[task_id]["last_execution"] = result.get("timestamp")
            self.tasks[task_id]["execution_count"] += 1
    
    def _cleanup_old_history(self):
        """æ¸…ç†æ—§å†å²ï¼ˆä¿ç•™7å¤©ï¼‰"""
        cutoff_time = int((datetime.now() - timedelta(days=7)).timestamp() * 1000)
        
        with self.lock:
            for task_id in list(self.execution_history.keys()):
                history = self.execution_history[task_id]
                # è¿‡æ»¤å‡º7å¤©å†…çš„è®°å½•
                self.execution_history[task_id] = [
                    h for h in history 
                    if h.get("timestamp", 0) >= cutoff_time
                ]
                
                # å¦‚æœå†å²ä¸ºç©ºï¼Œåˆ é™¤key
                if not self.execution_history[task_id]:
                    del self.execution_history[task_id]
    
    def get_task_list(self) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡åˆ—è¡¨"""
        with self.lock:
            result = []
            for task_id, task_info in self.tasks.items():
                result.append({
                    "task_id": task_id,
                    "task_name": task_info["config"].get("task_name"),
                    "business": task_info["config"].get("business"),
                    "environment": task_info["config"].get("environment"),
                    "interval_minutes": task_info["config"].get("interval_minutes"),
                    "last_execution": task_info.get("last_execution"),
                    "execution_count": task_info.get("execution_count", 0)
                })
            return result
    
    def get_task_history(self, task_id: str) -> List[Dict[str, Any]]:
        """è·å–ä»»åŠ¡æ‰§è¡Œå†å²"""
        with self.lock:
            return self.execution_history.get(task_id, [])


# Flaskåº”ç”¨
app = Flask(__name__)

# å…¨å±€AppIDç®¡ç†å™¨å®ä¾‹
appid_manager = None

# å…¨å±€è®¤è¯Token
AUTH_TOKEN = "npYXxclHVCN2wvRWJeW57fTsCXz0r2GnFvxdS5ve5eJxrqFYTCQw03uFKwC-T7n0"

# å®šæ—¶æ¸…ç†ä»»åŠ¡
cleanup_thread = None
cleanup_running = False

# å®šæ—¶ä»»åŠ¡ç›¸å…³
task_scheduler = None
task_executor = None
report_manager = None


def generate_auth_token(length: int = 64) -> str:
    """
    ç”Ÿæˆå®‰å…¨çš„è®¤è¯token
    
    Args:
        length: tokené•¿åº¦ï¼ˆé»˜è®¤64å­—ç¬¦ï¼Œæ¨è32-128ï¼‰
        
    Returns:
        éšæœºç”Ÿæˆçš„tokenå­—ç¬¦ä¸²
    """
    # ä½¿ç”¨å¤§å°å†™å­—æ¯ã€æ•°å­—å’Œéƒ¨åˆ†ç‰¹æ®Šå­—ç¬¦
    alphabet = string.ascii_letters + string.digits + "-_"
    token = ''.join(secrets.choice(alphabet) for _ in range(length))
    return token


def cleanup_old_test_results():
    """æ¸…ç†2å‘¨å‰çš„æµ‹è¯•ç»“æœæ•°æ®"""
    global appid_manager
    if appid_manager is None:
        return
    
    try:
        result = appid_manager.clear_old_test_results(days=14)
        if result["total_removed"] > 0:
            print(f"[Cleanup] æ¸…ç†äº† {result['total_removed']} æ¡2å‘¨å‰çš„æµ‹è¯•æ•°æ®ï¼Œä¿ç•™äº† {result['total_kept']} æ¡")
            if result["removed_by_product"]:
                for product, count in result["removed_by_product"].items():
                    print(f"  - {product}: {count} æ¡")
    except Exception as e:
        print(f"[Cleanup Error] æ¸…ç†æµ‹è¯•æ•°æ®æ—¶å‡ºé”™: {str(e)}")


def cleanup_task_worker():
    """å®šæ—¶æ¸…ç†ä»»åŠ¡çš„å·¥ä½œçº¿ç¨‹"""
    global cleanup_running
    while cleanup_running:
        try:
            # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œæ¸…ç†ï¼ˆé¿å…å½±å“æ­£å¸¸ä½¿ç”¨ï¼‰
            # è¿™é‡Œç®€åŒ–ä¸ºæ¯24å°æ—¶æ‰§è¡Œä¸€æ¬¡
            time.sleep(24 * 3600)  # 24å°æ—¶
            if cleanup_running:
                cleanup_old_test_results()
        except Exception as e:
            print(f"[Cleanup Task Error] {str(e)}")
            # å‡ºé”™åç­‰å¾…1å°æ—¶å†é‡è¯•
            time.sleep(3600)


def start_cleanup_task():
    """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡"""
    global cleanup_thread, cleanup_running
    
    if cleanup_thread is not None and cleanup_thread.is_alive():
        return  # ä»»åŠ¡å·²åœ¨è¿è¡Œ
    
    cleanup_running = True
    cleanup_thread = threading.Thread(target=cleanup_task_worker, daemon=True)
    cleanup_thread.start()
    print("âœ“ å®šæ—¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ï¼ˆæ¯24å°æ—¶æ¸…ç†ä¸€æ¬¡2å‘¨å‰çš„æµ‹è¯•æ•°æ®ï¼‰")


def stop_cleanup_task():
    """åœæ­¢å®šæ—¶æ¸…ç†ä»»åŠ¡"""
    global cleanup_running, cleanup_thread
    
    cleanup_running = False
    if cleanup_thread is not None:
        cleanup_thread.join(timeout=5)
    print("å®šæ—¶æ¸…ç†ä»»åŠ¡å·²åœæ­¢")


def init_appid_manager():
    """åˆå§‹åŒ–AppIDç®¡ç†å™¨"""
    global appid_manager
    
    appid_manager = AppIdManager()
    print("AppID Manager initialized (empty)")
    
    # å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡
    start_cleanup_task()


def init_task_scheduler():
    """åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨"""
    global task_scheduler, task_executor, report_manager
    
    try:
        # å°è¯•ç›¸å¯¹å¯¼å…¥ï¼ˆä½œä¸ºåŒ…çš„ä¸€éƒ¨åˆ†ï¼‰
        try:
            from .config_init import get_config_dir, get_config_locations
        except ImportError:
            # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œå°è¯•ç»å¯¹å¯¼å…¥ï¼ˆç›´æ¥è¿è¡Œæˆ–ä½œä¸ºæ¨¡å—è¿è¡Œï¼‰
            from sku_template.config_init import get_config_dir, get_config_locations
        
        # æ‰“å°é…ç½®æŸ¥æ‰¾ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        locations = get_config_locations()
        print(f"ğŸ” é…ç½®ç›®å½•æŸ¥æ‰¾è·¯å¾„: {[str(loc) for loc in locations]}")
        
        config_dir = get_config_dir()
        
        if config_dir is None:
            print("âš ï¸  æœªæ‰¾åˆ°é…ç½®ç›®å½•ï¼Œä»»åŠ¡è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
            print("   æç¤º: é…ç½®ç›®å½•å¿…é¡»åŒ…å« common.json æ–‡ä»¶")
            print("   æ£€æŸ¥çš„è·¯å¾„:")
            for loc in locations:
                common_file = loc / "common.json"
                exists = "âœ“" if common_file.exists() else "âœ—"
                print(f"     {exists} {loc}/common.json")
            return
        
        print(f"âœ“ ä½¿ç”¨é…ç½®ç›®å½•: {config_dir}")
        
        # ç¡®å®šæŠ¥å‘Šç›®å½•ï¼ˆä½¿ç”¨æ•°æ®ç›®å½•ï¼‰
        data_dir = os.environ.get('SKU_DATA_DIR')
        if data_dir:
            reports_base_dir = Path(data_dir) / "reports"
        else:
            # å¦‚æœæ²¡æœ‰è®¾ç½®æ•°æ®ç›®å½•ï¼Œä½¿ç”¨é…ç½®ç›®å½•çš„çˆ¶ç›®å½•ä¸‹çš„ data/reports
            reports_base_dir = config_dir.parent / "data" / "reports"
        
        reports_base_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ“ æŠ¥å‘Šç›®å½•: {reports_base_dir}")
        
        # åˆå§‹åŒ–æŠ¥å‘Šç®¡ç†å™¨
        report_manager = ReportManager(reports_base_dir)
        
        # åˆå§‹åŒ–ä»»åŠ¡æ‰§è¡Œå™¨
        task_executor = TaskExecutor(report_manager)
        
        # åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨
        task_scheduler = TaskScheduler(task_executor, report_manager)
        
        # åŠ è½½ä»»åŠ¡é…ç½®
        tasks_file = config_dir / "tasks.jsonl"
        if tasks_file.exists():
            tasks = TaskConfigLoader.load_tasks_from_jsonl(tasks_file)
            loaded_count = 0
            failed_count = 0
            
            for task_config in tasks:
                is_valid, error_msg = TaskConfigLoader.validate_task_config(task_config)
                if is_valid:
                    success, message = task_scheduler.add_task(task_config)
                    if success:
                        loaded_count += 1
                        print(f"âœ“ ä»»åŠ¡å·²åŠ è½½: {task_config.get('task_id')} - {task_config.get('task_name')}")
                    else:
                        failed_count += 1
                        print(f"âš ï¸  ä»»åŠ¡åŠ è½½å¤±è´¥: {task_config.get('task_id')} - {message}")
                else:
                    failed_count += 1
                    print(f"âš ï¸  ä»»åŠ¡é…ç½®æ— æ•ˆ: {task_config.get('task_id', 'unknown')} - {error_msg}")
            
            print(f"âœ“ ä»»åŠ¡è°ƒåº¦å™¨å·²åˆå§‹åŒ–: æˆåŠŸåŠ è½½ {loaded_count} ä¸ªä»»åŠ¡ï¼Œå¤±è´¥ {failed_count} ä¸ª")
        else:
            print("âœ“ ä»»åŠ¡è°ƒåº¦å™¨å·²åˆå§‹åŒ–ï¼ˆæ— ä»»åŠ¡é…ç½®ï¼‰")
    except Exception as e:
        print(f"âš ï¸  åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def verify_auth():
    """
    éªŒè¯è¯·æ±‚çš„è®¤è¯ä¿¡æ¯
    æ”¯æŒä¸¤ç§æ–¹å¼ï¼š
    1. Authorization: Bearer <token>
    2. X-API-Key: <token>
    
    Returns:
        None if auth valid, Response object if auth invalid
    """
    if AUTH_TOKEN is None:
        # å¦‚æœæ²¡æœ‰é…ç½®tokenï¼Œä¸éœ€è¦è®¤è¯
        return None
    
    # ä»è¯·æ±‚å¤´è·å–token
    auth_header = request.headers.get('Authorization', '')
    api_key = request.headers.get('X-API-Key', '')
    
    token = None
    
    # å°è¯•ä» Authorization header è·å– Bearer token
    if auth_header.startswith('Bearer '):
        token = auth_header[7:]  # å»æ‰ 'Bearer ' å‰ç¼€
    
    # æˆ–è€…ä» X-API-Key header è·å–
    if not token and api_key:
        token = api_key
    
    # éªŒè¯token
    if not token:
        return jsonify({
            "error": "unauthorized",
            "message": "Authentication required. Please provide token via 'Authorization: Bearer <token>' or 'X-API-Key: <token>' header"
        }), 401
    
    if token != AUTH_TOKEN:
        return jsonify({
            "error": "unauthorized",
            "message": "Invalid authentication token"
        }), 401
    
    return None


@app.before_request
def check_auth():
    """è¯·æ±‚å‰æ£€æŸ¥è®¤è¯ï¼ˆhealthæ¥å£é™¤å¤–ï¼‰"""
    # healthæ¥å£ä¸éœ€è¦è®¤è¯
    if request.path == '/health':
        return None
    
    # å…¶ä»–æ‰€æœ‰æ¥å£éƒ½éœ€è¦è®¤è¯
    return verify_auth()


@app.route('/api/appid/acquire', methods=['POST'])
def acquire_appid():
    """è·å–å¯ç”¨çš„AppID"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable", "message": "AppID Manager not initialized"}), 500
    
    try:
        data = request.get_json() or {}
        product_name = data.get('productName')
        force_acquire = data.get('forceAcquire', False)  # é»˜è®¤ä¸ºFalseï¼Œä¿æŒå‘åå…¼å®¹
        
        if not product_name:
            return jsonify({"error": "missing_product_name", "message": "productName is required"}), 400
        
        success, result = appid_manager.acquire_appid(product_name, force_acquire=force_acquire)
        if success:
            return jsonify(result), 200
        else:
            return jsonify(result), 202  # Accepted but waiting
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/appid/release', methods=['POST'])
def release_appid():
    """é‡Šæ”¾AppID"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable", "message": "AppID Manager not initialized"}), 500
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "missing_data", "message": "Request body is required"}), 400
        
        appid = data.get('appid')
        product_name = data.get('productName')
        
        if not appid:
            return jsonify({"error": "missing_appid", "message": "appid is required"}), 400
        
        if not product_name:
            return jsonify({"error": "missing_product_name", "message": "productName is required"}), 400
        
        success, result = appid_manager.release_appid(appid, product_name)
        
        if success:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/appid/status', methods=['GET'])
def get_status():
    """è·å–AppIDçŠ¶æ€ç»Ÿè®¡"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable", "message": "AppID Manager not initialized"}), 500
    
    try:
        product_name = request.args.get('productName')
        status = appid_manager.get_status(product_name)
        return jsonify(status), 200
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/appid/init', methods=['POST'])
def init_product():
    """åˆå§‹åŒ–æˆ–é‡ç½®äº§å“AppIDé…ç½®"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable", "message": "AppID Manager not initialized"}), 500
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "missing_data", "message": "Request body is required"}), 400
        
        product_name = data.get('productName')
        appids = data.get('appids')
        
        if not product_name:
            return jsonify({"error": "missing_product_name", "message": "productName is required"}), 400
        
        if not appids:
            return jsonify({"error": "missing_appids", "message": "appids is required"}), 400
        
        success, result = appid_manager.init_product(product_name, appids)
        if success:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/test/result', methods=['POST'])
def store_test_result():
    """å­˜å‚¨æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable"}), 500
    
    data = request.get_json() or {}
    product_name = data.get('product_name') or data.get('productName')
    session_id = data.get('session_id')
    test_data = data.get('test_data')
    
    if not product_name or not session_id or test_data is None:
        return jsonify({"error": "missing_required_fields"}), 400
    
    appid_manager.store_test_result(product_name, session_id, test_data)
    return jsonify({"success": True}), 200


@app.route('/api/test/results', methods=['GET'])
def get_test_results():
    """è·å–æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable"}), 500
    
    product_name = request.args.get('product_name') or request.args.get('productName')
    session_id = request.args.get('session_id')
    results = appid_manager.get_test_results(product_name, session_id)
    return jsonify(results), 200


@app.route('/api/test/results/clear', methods=['POST'])
def clear_test_results():
    """æ¸…é™¤æµ‹è¯•ç”¨ä¾‹æ‰§è¡Œæ•°æ®"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable"}), 500
    
    data = request.get_json() or {}
    product_name = data.get('product_name') or data.get('productName')
    session_id = data.get('session_id')
    
    appid_manager.clear_test_results(product_name, session_id)
    return jsonify({"success": True}), 200


@app.route('/api/test/results/cleanup', methods=['POST'])
def cleanup_old_results():
    """æ‰‹åŠ¨è§¦å‘æ¸…ç†2å‘¨å‰çš„æµ‹è¯•æ•°æ®"""
    if appid_manager is None:
        return jsonify({"error": "service_unavailable"}), 500
    
    try:
        data = request.get_json() or {}
        days = data.get('days', 14)  # é»˜è®¤14å¤©ï¼ˆ2å‘¨ï¼‰
        
        result = appid_manager.clear_old_test_results(days=days)
        return jsonify({
            "success": True,
            "result": result
        }), 200
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({"status": "healthy", "timestamp": int(time.time() * 1000)}), 200


# ==================== å®šæ—¶ä»»åŠ¡APIæ¥å£ ====================

@app.route('/api/task/init', methods=['POST'])
def init_task_scheduler_api():
    """
    é€šè¿‡APIåˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨ï¼ˆç±»ä¼¼ /api/appid/initï¼‰
    
    è¿™æ˜¯ä¸€ä¸ªå…¨æ–°çš„åŠŸèƒ½ï¼Œé€šè¿‡APIåŠ¨æ€åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨ï¼Œæ”¯æŒä¸Šä¼ é…ç½®æ–‡ä»¶ã€‚
    
    æ¥æ”¶å‚æ•°ï¼ˆmultipart/form-dataï¼‰ï¼š
    - business_name: ä¸šåŠ¡åç§°ï¼ˆå¿…å¡«ï¼‰
    - business_config_file: ä¸šåŠ¡é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸Šä¼ åˆ™ä¿å­˜åˆ°é…ç½®ç›®å½•ï¼‰
    - common_config_file: common.json é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸Šä¼ åˆ™ä¿å­˜åˆ°é…ç½®ç›®å½•ï¼‰
    - data_dir: æ•°æ®ç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„ dataï¼‰
    
    è¯´æ˜ï¼š
    - æœåŠ¡å™¨ä¸Šä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ `sku-config` ä½œä¸ºé…ç½®ç›®å½•
    - å¦‚æœä¸Šä¼ äº†é…ç½®æ–‡ä»¶ï¼Œä¿å­˜åˆ°é…ç½®ç›®å½•
    - å¦‚æœé…ç½®æ–‡ä»¶å·²å­˜åœ¨äºé…ç½®ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨
    - å¦‚æœæ—¢æ²¡æœ‰ä¸Šä¼ æ–‡ä»¶ä¹Ÿæ²¡æœ‰å·²å­˜åœ¨çš„æ–‡ä»¶ï¼Œè¿”å›é”™è¯¯
    - åªæ¸…é™¤æŒ‡å®šä¸šåŠ¡çš„ç¼“å­˜ï¼Œä¸å½±å“å…¶ä»–ä¸šåŠ¡
    - åˆå§‹åŒ–æˆåŠŸåï¼Œä»»åŠ¡è°ƒåº¦å™¨å°±å¯ä»¥ä½¿ç”¨äº†
    """
    global task_scheduler, task_executor, report_manager
    
    try:
        # è·å–å‚æ•°
        business_name = request.form.get('business_name')
        data_dir_path = request.form.get('data_dir')
        
        # è·å–ä¸Šä¼ çš„æ–‡ä»¶
        business_config_file = request.files.get('business_config_file')
        common_config_file = request.files.get('common_config_file')
        
        # æ ¡éªŒå¿…éœ€å‚æ•°
        if not business_name:
            return jsonify({"error": "missing_parameter", "message": "business_name å‚æ•°æ˜¯å¿…å¡«çš„"}), 400
        
        # æœåŠ¡å™¨ä¸Šä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„ sku-config ä½œä¸ºé…ç½®ç›®å½•
        config_path = Path.cwd() / "sku-config"
        config_path.mkdir(parents=True, exist_ok=True)
        
        # å¤„ç† common.json æ–‡ä»¶
        common_config_path = config_path / "common.json"
        if common_config_file and common_config_file.filename:
            # å¦‚æœä¸Šä¼ äº† common.jsonï¼Œä¿å­˜å®ƒ
            file_content = common_config_file.read().decode('utf-8')
            try:
                # éªŒè¯JSONæ ¼å¼
                json.loads(file_content)
                with open(common_config_path, 'w', encoding='utf-8') as f:
                    f.write(file_content)
            except json.JSONDecodeError as e:
                return jsonify({"error": "invalid_json", "message": f"common.json æ ¼å¼é”™è¯¯: {e}"}), 400
        elif not common_config_path.exists():
            # å¦‚æœä¸å­˜åœ¨ä¸”æ²¡æœ‰ä¸Šä¼ ï¼Œåˆ›å»ºç©ºçš„ common.json
            with open(common_config_path, 'w', encoding='utf-8') as f:
                json.dump({}, f, indent=2)
        
        # å¤„ç†ä¸šåŠ¡é…ç½®æ–‡ä»¶
        businesses_dir = config_path / "businesses"
        businesses_dir.mkdir(parents=True, exist_ok=True)
        business_config_path = businesses_dir / f"{business_name}.json"
        
        if business_config_file and business_config_file.filename:
            # å¦‚æœä¸Šä¼ äº†ä¸šåŠ¡é…ç½®æ–‡ä»¶ï¼Œä¿å­˜å®ƒ
            file_content = business_config_file.read().decode('utf-8')
            try:
                # éªŒè¯JSONæ ¼å¼
                business_config = json.loads(file_content)
                with open(business_config_path, 'w', encoding='utf-8') as f:
                    json.dump(business_config, f, indent=2, ensure_ascii=False)
            except json.JSONDecodeError as e:
                return jsonify({"error": "invalid_json", "message": f"ä¸šåŠ¡é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}"}), 400
        elif not business_config_path.exists():
            # å¦‚æœæ²¡æœ‰ä¸Šä¼ ä¸”æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é”™è¯¯
            return jsonify({
                "error": "business_config_not_found",
                "message": f"ä¸šåŠ¡é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {business_config_path}",
                "hint": f"è¯·ç¡®ä¿é…ç½®æ–‡ä»¶å­˜åœ¨äº: {business_config_path}ï¼Œæˆ–è€…ä¸Šä¼  business_config_file å‚æ•°"
            }), 400
        
        # è®¾ç½®é…ç½®ç›®å½•
        try:
            from .config_init import set_config_dir
        except ImportError:
            from sku_template.config_init import set_config_dir
        set_config_dir(config_path)
        
        # å¯¼å…¥ SkuQueryFactoryï¼ˆç”¨äºåŠ è½½å’Œæ¸…é™¤ä¸šåŠ¡é…ç½®ï¼‰
        from .sku_query_framework import SkuQueryFactory
        
        # éªŒè¯ä¸šåŠ¡é…ç½®æ–‡ä»¶æ ¼å¼ï¼ˆå†æ¬¡éªŒè¯ï¼Œç¡®ä¿æ–‡ä»¶æœ‰æ•ˆï¼‰
        try:
            with open(business_config_path, 'r', encoding='utf-8') as f:
                json.load(f)  # éªŒè¯JSONæ ¼å¼
        except json.JSONDecodeError as e:
            return jsonify({"error": "invalid_json", "message": f"ä¸šåŠ¡é…ç½®æ–‡ä»¶JSONæ ¼å¼é”™è¯¯: {e}"}), 400
        
        # åªæ¸…é™¤è¯¥ä¸šåŠ¡çš„ç¼“å­˜ï¼Œä¸å½±å“å…¶ä»–ä¸šåŠ¡
        if business_name in SkuQueryFactory._BUSINESS_CONFIGS:
            del SkuQueryFactory._BUSINESS_CONFIGS[business_name]
        
        # éªŒè¯ä¸šåŠ¡é…ç½®æ˜¯å¦å¯ä»¥åŠ è½½
        try:
            configs = SkuQueryFactory._get_business_configs()
            if business_name not in configs:
                return jsonify({
                    "error": "business_config_load_failed",
                    "message": f"ä¸šåŠ¡é…ç½®åŠ è½½å¤±è´¥: {business_name}",
                    "hint": "è¯·æ£€æŸ¥ä¸šåŠ¡é…ç½®æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®"
                }), 400
        except Exception as e:
            return jsonify({
                "error": "business_config_load_failed",
                "message": f"ä¸šåŠ¡é…ç½®åŠ è½½å¤±è´¥: {str(e)}"
            }), 400
        
        # è®¾ç½®æ•°æ®ç›®å½•
        if data_dir_path:
            data_path = Path(data_dir_path)
            data_path.mkdir(parents=True, exist_ok=True)
            os.environ['SKU_DATA_DIR'] = str(data_path)
        else:
            # é»˜è®¤æ•°æ®ç›®å½•ï¼šå½“å‰å·¥ä½œç›®å½•ä¸‹çš„ data
            data_path = Path.cwd() / "data"
            data_path.mkdir(parents=True, exist_ok=True)
            os.environ['SKU_DATA_DIR'] = str(data_path)
        
        # ç¡®å®šæŠ¥å‘Šç›®å½•
        reports_base_dir = Path(os.environ.get('SKU_DATA_DIR')) / "reports"
        reports_base_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æŠ¥å‘Šç®¡ç†å™¨
        report_manager = ReportManager(reports_base_dir)
        
        # åˆå§‹åŒ–ä»»åŠ¡æ‰§è¡Œå™¨
        task_executor = TaskExecutor(report_manager)
        
        # åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨
        task_scheduler = TaskScheduler(task_executor, report_manager)
        
        result = {
            "success": True,
            "message": "ä»»åŠ¡è°ƒåº¦å™¨åˆå§‹åŒ–æˆåŠŸ",
            "config_dir": str(config_path),
            "data_dir": str(data_path),
            "reports_dir": str(reports_base_dir),
            "business_name": business_name,
            "business_config_file": str(business_config_path)
        }
        
        # å¦‚æœä¸Šä¼ äº†æ–‡ä»¶ï¼Œæ·»åŠ åˆ°å“åº”ä¸­
        if business_config_file and business_config_file.filename:
            result["business_config_uploaded"] = True
        if common_config_file and common_config_file.filename:
            result["common_config_uploaded"] = True
        
        return jsonify(result), 200
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/task/add', methods=['POST'])
def add_task():
    """æ·»åŠ ä¸€æ¬¡æ€§ä»»åŠ¡
    
    æ¥æ”¶å‚æ•°ï¼š
    - business: ä¸šåŠ¡åç§°ï¼ˆå¿…å¡«ï¼‰
    - environment: ç¯å¢ƒï¼ˆå¿…å¡«ï¼Œstaging/prodï¼‰
    - start_delay_minutes: æ‰§è¡Œå»¶è¿Ÿï¼ˆåˆ†é’Ÿï¼Œå¿…å¡«ï¼‰ï¼Œä»»åŠ¡å°†åœ¨å»¶è¿Ÿåæ‰§è¡Œä¸€æ¬¡
    - expected_values_file: ä¸Šä¼ çš„JSONLæ–‡ä»¶ï¼ˆå¿…å¡«ï¼‰ï¼ŒåŒ…å«ç”¨ä¾‹çš„é¢„æœŸå€¼
    
    è¯´æ˜ï¼š
    - ä»»åŠ¡æ˜¯ä¸€æ¬¡æ€§çš„ï¼Œæ‰§è¡Œå®Œæˆåè‡ªåŠ¨ç»“æŸï¼Œä¸ä¼šé‡å¤æ‰§è¡Œ
    - æŸ¥è¯¢æ—¶é—´èŒƒå›´å›ºå®šä¸ºè¿‡å»24å°æ—¶
    - é‚®ä»¶æ”¶ä»¶äººé…ç½®åœ¨ä¸šåŠ¡é…ç½®æ–‡ä»¶çš„ email_config ä¸­ï¼ˆrecipients å’Œ cc å­—æ®µï¼‰
    - Jenkins é‚®ä»¶å‘é€å‡­è¯å·²åœ¨ä»£ç ä¸­é…ç½®
    """
    global task_scheduler
    
    if task_scheduler is None:
        return jsonify({"error": "service_unavailable", "message": "Task scheduler not initialized"}), 500
    
    try:
        # è·å–å‚æ•°
        business = request.form.get('business')
        environment = request.form.get('environment')
        start_delay_minutes = request.form.get('start_delay_minutes')
        
        # è·å–ä¸Šä¼ çš„æ–‡ä»¶
        if 'expected_values_file' not in request.files:
            return jsonify({"error": "missing_file", "message": "expected_values_file is required"}), 400
        
        file = request.files['expected_values_file']
        if file.filename == '':
            return jsonify({"error": "missing_file", "message": "expected_values_file is required"}), 400
        
        # æ ¡éªŒå¿…éœ€å‚æ•°
        if not business:
            return jsonify({"error": "missing_parameter", "message": "business is required"}), 400
        if not environment:
            return jsonify({"error": "missing_parameter", "message": "environment is required"}), 400
        if not start_delay_minutes:
            return jsonify({"error": "missing_parameter", "message": "start_delay_minutes is required"}), 400
        
        # è§£æå‚æ•°
        try:
            start_delay_minutes = int(start_delay_minutes)
        except (ValueError, json.JSONDecodeError) as e:
            return jsonify({"error": "invalid_parameter", "message": f"å‚æ•°æ ¼å¼é”™è¯¯: {e}"}), 400
        
        # è¯»å–ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹
        file_content = file.read().decode('utf-8')
        
        # å…ˆæ ¡éªŒæ–‡ä»¶å†…å®¹ï¼ˆä¸´æ—¶ä¿å­˜åˆ°å†…å­˜ä¸­æ ¡éªŒï¼‰
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.jsonl', delete=False, encoding='utf-8') as tmp_file:
            tmp_file.write(file_content)
            tmp_file_path = Path(tmp_file.name)
        
        try:
            # åŠ è½½å¹¶æ ¡éªŒé¢„æœŸå€¼
            expected_values_list, error_msg = TaskConfigLoader.load_expected_values_from_jsonl(tmp_file_path)
            if error_msg:
                return jsonify({"error": "invalid_expected_values", "message": error_msg}), 400
        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            tmp_file_path.unlink()
        
        # è·å–é…ç½®ç›®å½•ï¼ˆç”¨äºéªŒè¯ä¸šåŠ¡é…ç½®ï¼‰
        try:
            from .config_init import get_config_dir
        except ImportError:
            from sku_template.config_init import get_config_dir
        config_dir = get_config_dir()
        if not config_dir:
            return jsonify({"error": "config_not_found", "message": "é…ç½®ç›®å½•æœªæ‰¾åˆ°"}), 500
        
        # è·å–æ•°æ®ç›®å½•ï¼ˆç”¨äºä¿å­˜é¢„æœŸå€¼æ–‡ä»¶å’ŒæŠ¥å‘Šï¼‰
        data_dir = os.environ.get('SKU_DATA_DIR')
        if not data_dir:
            # å¦‚æœæ²¡æœ‰è®¾ç½®æ•°æ®ç›®å½•ï¼Œä½¿ç”¨é…ç½®ç›®å½•çš„çˆ¶ç›®å½•ä¸‹çš„ data ç›®å½•
            data_dir = str(config_dir.parent / "data")
        data_dir_path = Path(data_dir)
        data_dir_path.mkdir(parents=True, exist_ok=True)
        
        # ç”Ÿæˆtask_idï¼ˆbusiness_UUIDæ ¼å¼ï¼‰
        task_id = f"{business}_{uuid.uuid4().hex[:8]}"
        
        # ä¿å­˜é¢„æœŸå€¼æ–‡ä»¶åˆ°æ•°æ®ç›®å½•
        expected_values_dir = data_dir_path / "task_expected_values"
        expected_values_dir.mkdir(parents=True, exist_ok=True)
        expected_values_file = expected_values_dir / f"{task_id}.jsonl"
        with open(expected_values_file, 'w', encoding='utf-8') as f:
            f.write(file_content)
        
        # éªŒè¯ä¸šåŠ¡é…ç½®æ˜¯å¦å­˜åœ¨
        from .sku_query_framework import SkuQueryFactory
        configs = SkuQueryFactory._get_business_configs()
        if business not in configs:
            return jsonify({"error": "business_not_found", "message": f"ä¸šåŠ¡ '{business}' æœªåœ¨é…ç½®ä¸­åˆå§‹åŒ–"}), 400
        
        # æ„å»ºä»»åŠ¡é…ç½®ï¼ˆä¸€æ¬¡æ€§ä»»åŠ¡ï¼‰
        # é‚®ä»¶æ”¶ä»¶äººå°†ä»ä¸šåŠ¡é…ç½®çš„ email_config ä¸­è¯»å–
        task_config = {
            "task_id": task_id,
            "task_name": f"{business}ç›‘æ§ä»»åŠ¡",
            "business": business,
            "environment": environment,
            "start_delay_minutes": start_delay_minutes,
            "expected_values_file": str(expected_values_file),
            "_base_url": request.host_url.rstrip('/')  # ä¿å­˜base_urlç”¨äºç”Ÿæˆä¸‹è½½é“¾æ¥
        }
        
        # æ ¡éªŒé…ç½®
        is_valid, error_msg = TaskConfigLoader.validate_task_config(task_config)
        if not is_valid:
            return jsonify({"error": "invalid_config", "message": error_msg}), 400
        
        # æ·»åŠ åˆ°è°ƒåº¦å™¨
        success, message = task_scheduler.add_task(task_config)
        if success:
            return jsonify({
                "success": True,
                "task_id": task_id,
                "message": message
            }), 200
        else:
            return jsonify({"error": "add_failed", "message": message}), 400
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/task/list', methods=['GET'])
def list_tasks():
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    global task_scheduler
    
    if task_scheduler is None:
        return jsonify({"error": "service_unavailable", "message": "Task scheduler not initialized"}), 500
    
    try:
        tasks = task_scheduler.get_task_list()
        return jsonify({"tasks": tasks}), 200
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/task/<task_id>', methods=['DELETE'])
def remove_task(task_id):
    """åˆ é™¤ä»»åŠ¡"""
    global task_scheduler
    
    if task_scheduler is None:
        return jsonify({"error": "service_unavailable", "message": "Task scheduler not initialized"}), 500
    
    try:
        success, message = task_scheduler.remove_task(task_id)
        if success:
            # ä»é…ç½®æ–‡ä»¶åˆ é™¤
            try:
                from .config_init import get_config_dir
            except ImportError:
                from sku_template.config_init import get_config_dir
            config_dir = get_config_dir()
            if config_dir:
                tasks_file = config_dir / "tasks.jsonl"
                TaskConfigLoader.remove_task_from_jsonl(tasks_file, task_id)
            
            return jsonify({"success": True, "message": message}), 200
        else:
            return jsonify({"error": "remove_failed", "message": message}), 400
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/task/<task_id>/run', methods=['POST'])
def run_task(task_id):
    """æ‰‹åŠ¨è§¦å‘æ‰§è¡Œä»»åŠ¡"""
    global task_scheduler
    
    if task_scheduler is None:
        return jsonify({"error": "service_unavailable", "message": "Task scheduler not initialized"}), 500
    
    try:
        success, result = task_scheduler.run_task_manually(task_id)
        if success:
            return jsonify(result), 200
        else:
            return jsonify(result), 400
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/task/<task_id>/history', methods=['GET'])
def get_task_history(task_id):
    """è·å–ä»»åŠ¡æ‰§è¡Œå†å²"""
    global task_scheduler
    
    if task_scheduler is None:
        return jsonify({"error": "service_unavailable", "message": "Task scheduler not initialized"}), 500
    
    try:
        history = task_scheduler.get_task_history(task_id)
        return jsonify({"task_id": task_id, "history": history}), 200
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/report/<execution_id>', methods=['GET'])
def download_report(execution_id):
    """ä¸‹è½½HTMLæŠ¥å‘Š"""
    global report_manager
    
    if report_manager is None:
        return jsonify({"error": "service_unavailable", "message": "Report manager not initialized"}), 500
    
    try:
        # ä»execution_idæå–task_idï¼ˆæ ¼å¼ï¼šexec_{timestamp}ï¼‰
        # éœ€è¦éå†æ‰€æœ‰ä»»åŠ¡ç›®å½•æŸ¥æ‰¾
        reports = report_manager.list_reports(days=7)
        
        for report in reports:
            if report["execution_id"] == execution_id:
                report_path = Path(report["file_path"])
                if report_path.exists():
                    return send_file(str(report_path), mimetype='text/html', 
                                   as_attachment=True, download_name=report["file_name"])
        
        return jsonify({"error": "not_found", "message": f"æŠ¥å‘Š {execution_id} ä¸å­˜åœ¨"}), 404
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/report/<execution_id>/data', methods=['GET'])
def download_report_data(execution_id):
    """ä¸‹è½½æ•°æ®æ–‡ä»¶ï¼ˆjsonlï¼‰"""
    global report_manager
    
    if report_manager is None:
        return jsonify({"error": "service_unavailable", "message": "Report manager not initialized"}), 500
    
    try:
        # ä»execution_idæå–task_idï¼ˆæ ¼å¼ï¼šexec_{timestamp}ï¼‰
        # éœ€è¦éå†æ‰€æœ‰ä»»åŠ¡ç›®å½•æŸ¥æ‰¾
        reports = report_manager.list_reports(days=7)
        
        for report in reports:
            if report["execution_id"] == execution_id:
                task_id = report["task_id"]
                # æŸ¥æ‰¾jsonlæ–‡ä»¶
                data_file = report_manager.reports_dir / task_id / f"{execution_id}_data.jsonl"
                if data_file.exists():
                    return send_file(str(data_file), mimetype='application/jsonl', 
                                   as_attachment=True, download_name=f"{execution_id}_data.jsonl")
        
        return jsonify({"error": "not_found", "message": f"æ•°æ®æ–‡ä»¶ {execution_id}_data.jsonl ä¸å­˜åœ¨"}), 404
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/report/<execution_id>/logs', methods=['GET'])
def download_report_logs(execution_id):
    """ä¸‹è½½æ—¥å¿—æ–‡ä»¶ï¼ˆlogï¼‰"""
    global report_manager
    
    if report_manager is None:
        return jsonify({"error": "service_unavailable", "message": "Report manager not initialized"}), 500
    
    try:
        # ä»execution_idæå–task_idï¼ˆæ ¼å¼ï¼šexec_{timestamp}ï¼‰
        # éœ€è¦éå†æ‰€æœ‰ä»»åŠ¡ç›®å½•æŸ¥æ‰¾
        reports = report_manager.list_reports(days=7)
        
        for report in reports:
            if report["execution_id"] == execution_id:
                task_id = report["task_id"]
                # æŸ¥æ‰¾logæ–‡ä»¶
                log_file = report_manager.reports_dir / task_id / f"{execution_id}_query_logs.log"
                if log_file.exists():
                    return send_file(str(log_file), mimetype='text/plain', 
                                   as_attachment=True, download_name=f"{execution_id}_query_logs.log")
        
        return jsonify({"error": "not_found", "message": f"æ—¥å¿—æ–‡ä»¶ {execution_id}_query_logs.log ä¸å­˜åœ¨"}), 404
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


@app.route('/api/report/list', methods=['GET'])
def list_reports():
    """è·å–æŠ¥å‘Šåˆ—è¡¨"""
    global report_manager
    
    if report_manager is None:
        return jsonify({"error": "service_unavailable", "message": "Report manager not initialized"}), 500
    
    try:
        task_id = request.args.get('task_id')
        days = int(request.args.get('days', 7))
        
        reports = report_manager.list_reports(task_id=task_id, days=days)
        return jsonify({"reports": reports}), 200
    except Exception as e:
        return jsonify({"error": "internal_error", "message": str(e)}), 500


def main():
    """ä¸»å‡½æ•°"""
    global AUTH_TOKEN
    
    parser = argparse.ArgumentParser(description='AppID Manager Service')
    parser.add_argument('--host', default='0.0.0.0', help='Host to bind to (default: 0.0.0.0 for external access, use 127.0.0.1 for localhost only)')
    parser.add_argument('--port', type=int, default=8888, help='Port to bind to')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    parser.add_argument('--auth-token', default=None, 
                       help='Authentication token (or set APPID_AUTH_TOKEN env var). If not set, authentication is disabled.')
    parser.add_argument('--generate-token', action='store_true',
                       help='Generate a secure authentication token and exit')
    parser.add_argument('--token-length', type=int, default=64,
                       help='Token length when using --generate-token (default: 64, recommended: 32-128)')
    parser.add_argument('--config-dir', default=None, type=str,
                       help='Configuration directory path (or set SKU_CONFIG_DIR env var). Priority: command line > env var > system defaults')
    parser.add_argument('--data-dir', default=None, type=str,
                       help='Data directory path for storing uploaded task files, reports, and logs (or set SKU_DATA_DIR env var). Default: <config_dir>/../data or ./data. Optional if default location is acceptable.')
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯ç”Ÿæˆtokenï¼Œç”Ÿæˆåé€€å‡º
    if args.generate_token:
        token = generate_auth_token(args.token_length)
        print("\n" + "="*70)
        print("Generated Authentication Token:")
        print("="*70)
        print(token)
        print("="*70)
        print("\nUsage examples:")
        print(f"  # Start service with this token:")
        print(f"  python3.11 appid_manager_service.py --auth-token \"{token}\"")
        print(f"\n  # Or set environment variable:")
        print(f"  export APPID_AUTH_TOKEN=\"{token}\"")
        print(f"  python3.11 appid_manager_service.py")
        print("\n" + "="*70)
        return
    
    # è®¾ç½®è®¤è¯tokenï¼ˆä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼Œå…¶æ¬¡ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
    AUTH_TOKEN = args.auth_token or os.environ.get('APPID_AUTH_TOKEN')
    
    # è®¾ç½®é…ç½®ç›®å½•ï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > è‡ªåŠ¨æŸ¥æ‰¾ï¼‰
    if args.config_dir:
        config_dir_path = Path(args.config_dir)
        if not config_dir_path.exists():
            print(f"âš ï¸  è­¦å‘Š: æŒ‡å®šçš„é…ç½®ç›®å½•ä¸å­˜åœ¨: {config_dir_path}")
            print(f"   å°†ä½¿ç”¨è‡ªåŠ¨æŸ¥æ‰¾çš„é…ç½®ç›®å½•")
        else:
            try:
                from .config_init import set_config_dir
            except ImportError:
                from sku_template.config_init import set_config_dir
            set_config_dir(config_dir_path)
            print(f"âœ“ ä½¿ç”¨æŒ‡å®šçš„é…ç½®ç›®å½•: {config_dir_path}")
    elif os.environ.get('SKU_CONFIG_DIR'):
        config_dir_path = Path(os.environ.get('SKU_CONFIG_DIR'))
        if config_dir_path.exists():
            try:
                from .config_init import set_config_dir
            except ImportError:
                from sku_template.config_init import set_config_dir
            set_config_dir(config_dir_path)
            print(f"âœ“ ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®ç›®å½•: {config_dir_path}")
    
    # è®¾ç½®æ•°æ®ç›®å½•ï¼ˆä¼˜å…ˆçº§ï¼šå‘½ä»¤è¡Œå‚æ•° > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼ï¼‰
    # æ•°æ®ç›®å½•ç”¨äºä¿å­˜ï¼š
    # 1. ä¸Šä¼ çš„é¢„æœŸå€¼æ–‡ä»¶ï¼ˆé€šè¿‡ /api/task/add ä¸Šä¼ ï¼Œéœ€è¦æŒä¹…åŒ–å› ä¸ºä»»åŠ¡å¯èƒ½å»¶è¿Ÿæ‰§è¡Œï¼‰
    # 2. ä»»åŠ¡æ‰§è¡Œåç”Ÿæˆçš„HTMLæŠ¥å‘Š
    # 3. æŸ¥è¯¢æ—¥å¿—æ–‡ä»¶
    # æ³¨æ„ï¼šå³ä½¿ä¸æŒ‡å®š --data-dirï¼Œç³»ç»Ÿä¹Ÿä¼šä½¿ç”¨é»˜è®¤ä½ç½®è‡ªåŠ¨åˆ›å»ºæ•°æ®ç›®å½•
    if args.data_dir:
        data_dir_path = Path(args.data_dir)
        data_dir_path.mkdir(parents=True, exist_ok=True)
        os.environ['SKU_DATA_DIR'] = str(data_dir_path)
        print(f"âœ“ ä½¿ç”¨æŒ‡å®šçš„æ•°æ®ç›®å½•: {data_dir_path}")
    elif os.environ.get('SKU_DATA_DIR'):
        data_dir_path = Path(os.environ.get('SKU_DATA_DIR'))
        data_dir_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ“ ä½¿ç”¨ç¯å¢ƒå˜é‡æ•°æ®ç›®å½•: {data_dir_path}")
    else:
        # é»˜è®¤æ•°æ®ç›®å½•ï¼šé…ç½®ç›®å½•çš„çˆ¶ç›®å½•ä¸‹çš„ data ç›®å½•ï¼Œæˆ–å½“å‰ç›®å½•ä¸‹çš„ data
        # ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºï¼Œç”¨æˆ·æ— éœ€æ‰‹åŠ¨æŒ‡å®šï¼ˆé™¤ééœ€è¦è‡ªå®šä¹‰ä½ç½®ï¼‰
        try:
            from .config_init import get_config_dir
            config_dir = get_config_dir()
            if config_dir:
                data_dir_path = config_dir.parent / "data"
            else:
                data_dir_path = Path.cwd() / "data"
            data_dir_path.mkdir(parents=True, exist_ok=True)
            os.environ['SKU_DATA_DIR'] = str(data_dir_path)
            print(f"âœ“ ä½¿ç”¨é»˜è®¤æ•°æ®ç›®å½•: {data_dir_path} (ä¸Šä¼ çš„æ–‡ä»¶å’ŒæŠ¥å‘Šå°†ä¿å­˜åœ¨æ­¤ç›®å½•)")
        except Exception as e:
            print(f"âš ï¸  è®¾ç½®æ•°æ®ç›®å½•å¤±è´¥: {e}")
    
    # åˆå§‹åŒ–AppIDç®¡ç†å™¨
    init_appid_manager()
    
    # åˆå§‹åŒ–ä»»åŠ¡è°ƒåº¦å™¨
    init_task_scheduler()
    
    print(f"Starting AppID Manager Service on {args.host}:{args.port}")
    
    if AUTH_TOKEN:
        print(f"âœ“ Authentication enabled (token configured)")
        print("  All API requests require authentication via:")
        print("    - Authorization: Bearer <token>")
        print("    - or X-API-Key: <token>")
    else:
        print("âš  Authentication disabled (no token configured)")
        print("  WARNING: Service is accessible without authentication!")
    
    print("\nAvailable endpoints:")
    print("  ã€AppIDç®¡ç†æ¥å£ã€‘")
    print("  POST /api/appid/acquire - Get available appid (requires auth)")
    print("  POST /api/appid/release - Release appid (requires auth)")
    print("  GET  /api/appid/status  - Get status (requires auth)")
    print("  POST /api/appid/init    - Initialize product (requires auth)")
    print("  ã€æµ‹è¯•ç»“æœå­˜å‚¨æ¥å£ã€‘")
    print("  POST /api/test/result   - Store test result (requires auth)")
    print("  GET  /api/test/results   - Get test results (JSON, requires auth)")
    print("  POST /api/test/results/clear - Clear test results (requires auth)")
    print("  ã€å®šæ—¶ä»»åŠ¡æ¥å£ã€‘")
    print("  POST /api/task/add - Add task (requires auth)")
    print("  GET  /api/task/list - List all tasks (requires auth)")
    print("  DELETE /api/task/<task_id> - Remove task (requires auth)")
    print("  POST /api/task/<task_id>/run - Manually run task (requires auth)")
    print("  GET  /api/task/<task_id>/history - Get task execution history (requires auth)")
    print("  GET  /api/report/<execution_id> - Download report (requires auth)")
    print("  GET  /api/report/list - List reports (requires auth)")
    print("  ã€é€šç”¨æ¥å£ã€‘")
    print("  GET  /health            - Health check (no auth required)")
    
    app.run(host=args.host, port=args.port, debug=args.debug)


if __name__ == '__main__':
    main()
