<div align="center">
  <img src="assets/logo.svg" alt="QWED Logo - AI Verification Engine" width="80" height="80">
  <h1>QWED Protocol</h1>
  <h3>Model Agnostic Verification Layer for AI</h3>
  
  > **QWED Verification** - Production-grade deterministic verification layer for Large Language Models. Works with **ANY LLM** - OpenAI, Anthropic, Gemini, Llama (via Ollama), or any local model. Detect and prevent AI hallucinations through 8 specialized verification engines. **Your LLM, Your Choice, Our Verification.**
  
  <p>
    <b>Don't fix the liar. Verify the lie.</b><br>
    <i>QWED does not reduce hallucinations. It makes them irrelevant.</i>
  </p>

  <p>
    <b>If an AI output cannot be proven, QWED will not allow it into production.</b>
  </p>

  <p>
    <b>üåê Model Agnostic:</b> Local ($0) ‚Ä¢ Budget ($5/mo) ‚Ä¢ Premium ($100/mo) - You choose!
  </p>

  [![CI](https://github.com/QWED-AI/qwed-verification/actions/workflows/ci.yml/badge.svg)](https://github.com/QWED-AI/qwed-verification/actions/workflows/ci.yml)
  [![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)](LICENSE)
  [![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/)
  [![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](Dockerfile)
  [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18110785.svg)](https://doi.org/10.5281/zenodo.18110785)
  [![status](https://joss.theoj.org/papers/385abbd3a6733fc907f1780eb5b6c927/status.svg)](https://joss.theoj.org/papers/385abbd3a6733fc907f1780eb5b6c927)
  [![PyPI version](https://img.shields.io/pypi/v/qwed.svg)](https://pypi.org/project/qwed/)
  [![Contributors](https://img.shields.io/github/contributors/QWED-AI/qwed-verification)](https://github.com/QWED-AI/qwed-verification/graphs/contributors)
  
  [![GitHub stars](https://img.shields.io/github/stars/QWED-AI/qwed-verification?style=social)](https://github.com/QWED-AI/qwed-verification)
  [![GitHub forks](https://img.shields.io/github/forks/QWED-AI/qwed-verification?style=social)](https://github.com/QWED-AI/qwed-verification/fork)
  [![GitHub watchers](https://img.shields.io/github/watchers/QWED-AI/qwed-verification?style=social)](https://github.com/QWED-AI/qwed-verification)

  <br>

  **üíñ Support QWED Development:**
  
  <a href="https://github.com/sponsors/rahuldass19"><img src="https://img.shields.io/github/sponsors/rahuldass19?style=for-the-badge&logo=githubsponsors&label=Sponsor&color=EA4AAA" alt="Sponsor on GitHub"></a>

  <br>
  
  [![Twitter](https://img.shields.io/badge/Twitter-@rahuldass29-1DA1F2?style=flat&logo=twitter&logoColor=white)](https://x.com/rahuldass29)
  [![LinkedIn](https://img.shields.io/badge/LinkedIn-Rahul%20Dass-0077B5?style=flat&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/rahul-dass-23b370b0/)
  [![Blog](https://img.shields.io/badge/Blog-Unreadable%20Code%20Benchmark-FF5722?style=flat&logo=docusaurus&logoColor=white)](https://docs.qwedai.com/blog/unreadable-code-agi-benchmark)

  <br>
  <a href="#-quick-start-install--verify-in-30-seconds">Quick Start</a> ¬∑ 
  <a href="#-new-in-v210-client-side-verification">üÜï QWEDLocal</a> ¬∑
  <a href="#-the-llm-hallucination-problem-why-ai-cant-be-trusted">The Problem</a> ¬∑ 
  <a href="#-the-8-verification-engines-how-qwed-validates-llm-outputs">The 8 Engines</a> ¬∑
  <a href="docs/INTEGRATION.md">üîå Integration</a> ¬∑
  <a href="docs/QWED_LOCAL.md">‚ö° QWEDLocal</a> ¬∑
  <a href="docs/CLI.md">üñ•Ô∏è CLI</a> ¬∑
  <a href="docs/OLLAMA_INTEGRATION.md">üÜì Ollama (FREE!)</a> ¬∑
  <a href="https://docs.qwedai.com">üìñ Full Documentation</a>
</div>

---

> **‚ö†Ô∏è What QWED Is (and Isn't)**
> 
> **QWED is:** An open-source engineering tool that combines existing verification libraries (SymPy, Z3, SQLGlot, AST) into a unified API for LLM output validation.
> 
> **QWED is NOT:** Novel research. We don't claim algorithmic innovation. We claim practical integration for production use cases.
> 
> **Works when:** Developer provides ground truth (expected values, schemas, contracts) and LLM generates structured output.
> 
> **Doesn't work when:** Specs come from natural language, outputs are freeform text, or verification domain is unsupported.

---

## üöÄ Quick Start: Install & Verify in 30 Seconds

```bash
# Install from PyPI (Recommended)
pip install qwed

# Or install from source
git clone https://github.com/QWED-AI/qwed-verification.git
cd qwed-verification
pip install -e .
```

```python
from qwed_sdk import QWEDClient

client = QWEDClient(api_key="your_key")

# The LLM says: "Derivative of x^2 is 3x" (Hallucination!)
response = client.verify_math(
    query="What is the derivative of x^2?",
    llm_output="3x" 
)

print(response)
# -> ‚ùå CORRECTED: The derivative is 2x. (Verified by SymPy)
```

### üÜï **NEW:** Client-Side Verification (v2.1.0)

No backend server? No problem! Use **QWEDLocal**:

```python
from qwed_sdk import QWEDLocal

# FREE with Ollama (local LLMs)
client = QWEDLocal(
    base_url="http://localhost:11434/v1",
    model="llama3"
)

# Or use OpenAI
client = QWEDLocal(
    provider="openai",
    api_key="sk-...",
    model="gpt-4o-mini"
)

result = client.verify_math("What is 2+2?")
print(result.verified)  # True
print(result.value)  # 4
```

**Features:**
- ‚úÖ Works with **ANY LLM** (Ollama, OpenAI, Anthropic, Gemini)
- ‚úÖ **$0 cost** with local models
- ‚úÖ **Smart caching** (50-80% cost savings)
- ‚úÖ **100% private** (data never leaves your machine)

### üîí **NEW in v2.2.0:** PII Masking (Enterprise Privacy)

Automatically mask sensitive data before sending to LLMs:

```python
from qwed_sdk import QWEDLocal

# Enable PII masking (requires pip install 'qwed[pii]')
client = QWEDLocal(
    provider="openai",
    api_key="sk-...",
    mask_pii=True  # üîí Privacy protection
)

result = client.verify("My email is john@example.com")
# LLM sees: "My email is <EMAIL_ADDRESS>"

# Check what was masked
print(result.evidence['pii_masked'])
# {'pii_detected': 1, 'types': ['EMAIL_ADDRESS']}
```

**Compliance:**
- üè• **HIPAA** (Healthcare)
- üè¶ **PCI-DSS** (Finance)
- üá™üá∫ **GDPR** (EU Privacy)

**CLI:**
```bash
qwed verify "Email: user@example.com" --mask-pii
qwed pii "My SSN is 123-45-6789"  # Test detection
```

üìñ **[PII Masking Guide ‚Üí](docs/PII_MASKING.md)** | **[QWEDLocal Guide ‚Üí](docs/QWED_LOCAL.md)** | **[CLI Reference ‚Üí](docs/CLI.md)**

---

## üö® The LLM Hallucination Problem: Why AI Can't Be Trusted

Everyone is trying to fix AI hallucinations by **Fine-Tuning** (teaching it more data).

This is like forcing a student to memorize 1,000,000 math problems.

**What happens when they see the 1,000,001st problem? They guess.**

---

## üìä The Proof: Why Enterprise AI Needs QWED Verification

We benchmarked **Claude Opus 4.5** (one of the world's best LLMs) on 215 critical tasks.

![QWED Benchmark Results - LLM Accuracy Testing](assets/benchmark_chart.png)

| Finding | Implication |
|---------|-------------|
| **Finance:** 73% accuracy | Banks can't use raw LLM for calculations |
| **Adversarial:** 85% accuracy | LLMs fall for authority bias tricks |
| **QWED:** 100% error detection | All 22 errors caught before production |

> **QWED doesn't compete with LLMs. We ENABLE them for production use.**

üìÑ [Full Benchmark Report ‚Üí](BENCHMARKS.md)

---

## üéØ Use Cases & Applications

QWED is designed for industries where AI errors have real consequences:

| Industry | Use Case | Risk Without QWED |
|----------|----------|-------------------|
| üè¶ **Financial Services** | Transaction validation, fraud detection | $12,889 error per miscalculation |
| üè• **Healthcare AI** | Drug interaction checking, diagnosis verification | Patient safety risks |
| ‚öñÔ∏è **Legal Tech** | Contract analysis, compliance checking | Regulatory violations |
| üìö **Educational AI** | AI tutoring, assessment systems | Misinformation to students |
| üè≠ **Manufacturing** | Process control, quality assurance | Production defects |

---

## ‚úÖ The Solution: Verification Layer

**QWED** is the first open-source **Neurosymbolic AI Verification Layer**.

We combine:
- **Neural Networks** (LLMs) for natural language understanding
- **Symbolic Reasoning** (SymPy, Z3, AST) for deterministic verification

### The Core Philosophy: "The Untrusted Translator"

QWED operates on a strict principle: **Don't trust the LLM to compute or judge; trust it only to translate.**

**Example Flow:**
```
User Query: "If all A are B, and x is A, is x B?"

‚Üì (LLM translates)

Z3 DSL: Implies(A(x), B(x))

‚Üì (Z3 proves)

Result: TRUE (Proven by formal logic)
```

The LLM is an **Untrusted Translator**. The Symbolic Engine is the **Trusted Verifier**.

---

## üí° How QWED Compares

### The "Judge" Problem

Most AI safety tools use **"LLM-as-a-Judge"** (asking GPT-4 to grade GPT-3.5). This is fundamentally unsafe:

- **Recursive Hallucination:** If the judge has the same bias as the generator, errors go undetected
- **Probabilistic Evaluation:** LLMs give probability, not proof
- **Subjectivity:** Different judges = different answers

**QWED introduces "Solver-as-a-Judge"**: Replace neural network opinions with compiler execution and mathematical proof.

### Comparison Table

| Feature | **QWED Protocol** | NeMo Guardrails | LangChain Evaluators |
|---------|-------------------|-----------------|----------------------|
| **The "Judge"** | Deterministic Solver (Z3/SymPy) | Semantic Matcher | Another LLM (GPT-4) |
| **Mechanism** | Translation to DSL | Vector Similarity | Prompt Engineering |
| **Verification Type** | Mathematical Proof | Policy Adherence | Consensus/Opinion |
| **Primary Goal** | Correctness (Truth) | Safety (Appropriateness) | Quality Score |
| **False Positives** | Near Zero (Logic-based) | Medium (Semantic drift) | High (Subjectivity) |
| **Works Offline** | ‚úÖ Yes (QWEDLocal) | ‚ùå No | ‚ùå No |
| **Privacy** | ‚úÖ 100% Local | ‚ùå Cloud-based | ‚ùå Cloud-based |

**QWED's Advantage:** When you need **proof**, not opinion.

---

## üî¨ The Verification Engines

QWED routes queries to specialized engines that act as DSL interpreters:


```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Query  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ LLM (The Guesser)‚îÇ
‚îÇ GPT-4 / Claude   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ Unverified Output
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  QWED Protocol     ‚îÇ
‚îÇ  (Verification)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚ñº        ‚ñº
‚ùå Reject  ‚úÖ Verified
            ‚îÇ
            ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ Your Application‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## QWED üÜö Traditional AI Safety Approaches

| Approach | Accuracy | Deterministic | Explainable | Best For |
|----------|----------|---------------|-------------|----------|
| **QWED Verification** | ‚úÖ 99%+ | ‚úÖ Yes | ‚úÖ Full trace | Production AI |
| Fine-tuning / RLHF | ‚ö†Ô∏è ~85% | ‚ùå No | ‚ùå Black box | General improvement |
| RAG (Retrieval) | ‚ö†Ô∏è ~80% | ‚ùå No | ‚ö†Ô∏è Limited | Knowledge grounding |
| Prompt Engineering | ‚ö†Ô∏è ~70% | ‚ùå No | ‚ö†Ô∏è Limited | Quick fixes |
| Guardrails | ‚ö†Ô∏è Variable | ‚ùå No | ‚ö†Ô∏è Reactive | Content filtering |

> **QWED doesn't replace these - it complements them with mathematical certainty.**

---

## üîß The 8 Verification Engines: How QWED Validates LLM Outputs

We don't use another LLM to check your LLM. **That's circular logic.**

We use **Hard Engineering**:

| Engine | Tech Stack | What it Solves |
|--------|------------|----------------|
| **üßÆ Math Verifier** | `SymPy` + `NumPy` | Calculus, Linear Algebra, Finance. No more `$1 + $1 = $3`. |
| **‚öñÔ∏è Logic Verifier** | `Z3 Prover` | Formal Verification. Checks for logical contradictions. |
| **üõ°Ô∏è Code Security** | `AST` + `Semgrep` | Catches `eval()`, secrets, vulnerabilities before code runs. |
| **üìä Stats Engine** | `Pandas` + `Wasm` | Sandboxed execution for trusted data analysis. |
| **üóÑÔ∏è SQL Validator** | `SQLGlot` | Prevents Injection & validates schema. |
| **üîç Fact Checker** | `TF-IDF` + `NLI` | Checks grounding against source docs. |
| **üëÅÔ∏è Image Verifier** | `OpenCV` + `Metadata` | Verifies image dimensions, format, pixel data. |
| **ü§ù Consensus Engine** | `Multi-Provider` | Cross-checks GPT-4 vs Claude vs Gemini. |

---

## üß† The QWED Philosophy: Verification Over Correction

| ‚ùå Wrong Approach | ‚úÖ QWED Approach |
|-------------------|------------------|
| "Let's fine-tune the model to be more accurate" | "Let's verify the output with math" |
| "Trust the AI's confidence score" | "Trust the symbolic proof" |
| "Add more training data" | "Add a verification layer" |
| "Hope it doesn't hallucinate" | "Catch hallucinations deterministically" |

**QWED = Query with Evidence and Determinism**

> **Probabilistic systems should not be trusted with deterministic tasks.**
> **If it can't be verified, it doesn't ship.**

---

## üîå LLM Framework Integrations

Already using an Agent framework? QWED drops right in.

### ü¶ú LangChain (Native Integration)

**Install:** `pip install 'qwed[langchain]'`

```python
from qwed_sdk.integrations.langchain import QWEDTool
from langchain.agents import initialize_agent
from langchain_openai import ChatOpenAI

# Initialize QWED verification tool
tool = QWEDTool(provider="openai", model="gpt-4o-mini")

# Add to your agent
llm = ChatOpenAI()
agent = initialize_agent(tools=[tool], llm=llm)

# Agent automatically uses QWED for verification
agent.run("Verify: what is the derivative of x^2?")
```

### ü§ñ CrewAI

```python
from qwed_sdk.crewai import QWEDVerifiedAgent

agent = QWEDVerifiedAgent(role="Analyst", allow_dangerous_code=False)
```

---

## üåç Multi-Language SDK Support

| Language | Package | Status |
|----------|---------|--------|
| üêç Python | `qwed` | ‚úÖ Available on PyPI |
| üü¶ TypeScript | `@qwed-ai/sdk` | ‚úÖ Available on npm |
| üêπ Go | `qwed-go` | üü° Coming Soon |
| ü¶Ä Rust | `qwed` | üü° Coming Soon |

git clone https://github.com/QWED-AI/qwed-verification.git
cd qwed-verification
pip install -r requirements.txt
```

---

## üéØ Real Example: The $12,889 Bug

**User asks AI:** "Calculate compound interest: $100K at 5% for 10 years"

**GPT-4 responds:** "$150,000"  
*(Used simple interest by mistake)*

**With QWED:**
```python
response = client.verify_math(
    query="Compound interest: $100K, 5%, 10 years",
    llm_output="$150,000"
)
# -> ‚ùå INCORRECT: Expected $162,889.46
#    Error: Used simple interest formula instead of compound
```

**Cost of not verifying:** $12,889 error per transaction üí∏

---

## ‚ùì Frequently Asked Questions

### Q: How does QWED differ from RAG (Retrieval Augmented Generation)?
**A:** RAG improves the *input* to the LLM by grounding it in documents. QWED verifies the *output* deterministically. RAG adds knowledge; QWED adds certainty.

### Q: Can QWED work with any LLM?
**A:** Yes! QWED is model-agnostic and works with GPT-4, Claude, Gemini, Llama, Mistral, and any other LLM. We verify outputs, not models.

### Q: Does QWED replace fine-tuning?
**A:** No. Fine-tuning makes models better at tasks. QWED verifies they got it right. Use both.

### Q: Is QWED open source?
**A:** Yes! Apache 2.0 license. Enterprise features (audit logs, multi-tenancy) are in a separate repo.

### Q: What's the latency overhead?
**A:** Typically <100ms for most verifications. Math and logic proofs are instant. Consensus checks take longer (multiple API calls).

---

## üìö Documentation & Resources

| Resource | Description |
|----------|-------------|
| [üìñ Full Documentation](https://docs.qwedai.com) | Complete API reference and guides |
| [üîß API Reference](https://docs.qwedai.com/docs/api/overview) | Endpoints and schemas |
| [üìä Benchmarks](https://docs.qwedai.com/blog/unreadable-code-agi-benchmark) | LLM accuracy testing results |
| [ü§ù Contributing Guide](./CONTRIBUTING.md) | How to contribute to QWED |
| [üèóÔ∏è Architecture](./docs/ARCHITECTURE.md) | System design and engine internals |
| [üîí Security Policy](./SECURITY.md) | Reporting vulnerabilities |

---

## üè¢ Enterprise Features

Need **observability**, **multi-tenancy**, **audit logs**, or **compliance exports**?

üìß Contact: **rahul@qwedai.com**

---

## üìÑ License

Apache 2.0 - See [LICENSE](LICENSE)

---

## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=QWED-AI/qwed-verification&type=Date)](https://star-history.com/#QWED-AI/qwed-verification&Date)

<details>
<summary>If chart doesn't load, click here for alternatives</summary>

**Current Stars:** [![GitHub stars](https://img.shields.io/github/stars/QWED-AI/qwed-verification?style=social)](https://github.com/QWED-AI/qwed-verification/stargazers)

**View trend:** [Star History Page](https://star-history.com/#QWED-AI/qwed-verification&Date)

</details>

---

## üë• Contributors

<a href="https://github.com/QWED-AI/qwed-verification/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=QWED-AI/qwed-verification" alt="QWED Contributors" />
</a>

---

## üìÑ Citation

If you use QWED in your research or project, please cite our archived paper:

```bibtex
@software{dass2025qwed,
  author = {Dass, Rahul},
  title = {QWED Protocol: Deterministic Verification for Large Language Models},
  year = {2025},
  publisher = {Zenodo},
  version = {v1.0.0},
  doi = {10.5281/zenodo.18110785},
  url = {https://doi.org/10.5281/zenodo.18110785}
}
```

**Plain text:**
> Dass, R. (2025). QWED Protocol: Deterministic Verification for Large Language Models (Version v1.1.0). Zenodo. https://doi.org/10.5281/zenodo.18110785

---

## ‚úÖ Using QWED in Your Project?

Add this badge to your README to show you're using verified AI:

```markdown
[![Verified by QWED](https://img.shields.io/badge/Verified_by-QWED-00C853?style=flat&logo=checkmarx)](https://github.com/QWED-AI/qwed-verification)
```

**Preview:**  
[![Verified by QWED](https://img.shields.io/badge/Verified_by-QWED-00C853?style=flat&logo=checkmarx)](https://github.com/QWED-AI/qwed-verification)

This badge tells users that your LLM outputs are deterministically verified, not just "hallucination-prone guesses."

---

<div align="center">
  
  ### ‚≠ê Star us if you believe AI needs verification
  
  <a href="https://github.com/QWED-AI/qwed-verification">
    <img src="https://img.shields.io/github/stars/QWED-AI/qwed-verification?style=social" alt="GitHub Stars">
  </a>
  
  <br><br>
  
  <h3>Ready to trust your AI?</h3>
  <p><i>"Safe AI is the only AI that scales."</i></p>
  <br>
  <a href="CONTRIBUTING.md">Contribute</a> ¬∑ 
  <a href="docs/ARCHITECTURE.md">Architecture</a> ¬∑ 
  <a href="SECURITY.md">Security</a> ¬∑ 
  <a href="https://docs.qwedai.com">Documentation</a>
</div>
