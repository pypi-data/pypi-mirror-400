# üõ†Ô∏è Unihra Python SDK

<div align="center">

[![PyPI version](https://img.shields.io/pypi/v/unihra.svg?style=flat-square&color=blue)](https://pypi.org/project/unihra/)
[![Python Versions](https://img.shields.io/pypi/pyversions/unihra.svg?style=flat-square)](https://pypi.org/project/unihra/)
[![License](https://img.shields.io/badge/License-MIT-green.svg?style=flat-square)](https://github.com/Unihra/unihra_sdk/blob/main/LICENSE)

**Enterprise-grade SEO & Semantic Analysis SDK.**<br>
*Compare content, find semantic gaps, and generate structure recommendations using Vector AI & Zone Analysis.*

[üá¨üáß English](#-english-documentation) | [üá∑üá∫ –†—É—Å—Å–∫–∏–π](#-russian-documentation)

---

### üöÄ Ecosystem & Resources

| **Web UI** | **API Docs** | **Get API Key** | **News Channel** |
| :---: | :---: | :---: | :---: |
| üñ•Ô∏è [**unihra.ru**](https://unihra.ru) | üìö [**unihra.ru/docs**](https://unihra.ru/docs) | üîë [**@UniHRA_bot**](https://t.me/UniHRA_bot) | üì¢ [**@mncosine**](https://t.me/mncosine) |
| *Visual Sandbox* | *REST API Spec* | *Get Free Key Here* | *Updates & Tips* |

</div>

---

## üá¨üáß English Documentation

### ‚ú® Key Features

*   **üß† Semantic Context Analysis**: Goes beyond simple keyword frequency. It analyzes HTML zones (`H1`, `Title`, `Strong`) and the distance of terms to your target query to provide "Add to Title/H1" recommendations.
*   **üèóÔ∏è Page Structure Analysis**: Automatically extracts and compares H1-H6 headers, Meta Tags, and Technical uniqueness metrics for **all** analyzed pages (Own + Competitors).
*   **‚ö°Ô∏è SSE Streaming Abstraction**: Automatically handles server-sent events, queue polling, and connection stability.
*   **üêº Pandas & Excel Ready**: Export multi-sheet reports (`.xlsx`) with conditional formatting in one line of code.
*   **üõ°Ô∏è Smart Retries**: Built-in exponential backoff strategy for network resilience.
*   **ü™ê Jupyter Native**: Interactive HTML progress bars for Notebook environments.

### üì¶ Installation

```bash
pip install unihra
```
*Optional: Install dependencies for Excel export and progress bars:*
```bash
pip install pandas openpyxl tqdm
```

### ‚ö°Ô∏è Quick Start

#### 1. Full Analysis with Context
To enable Zone Analysis and Gap detection, you must provide `queries` (the main keywords you want to rank for).

```python
from unihra import UnihraClient

# Initialize client
client = UnihraClient(api_key="YOUR_API_KEY", max_retries=3)

# Run Analysis
result = client.analyze(
    own_page="https://example.com/my-product",
    competitors=[
        "https://competitor.com/top-product", 
        "https://market-leader.com/item"
    ],
    queries=["buy widget", "best widgets 2025"], # <--- Required for Structure Recommendations
    lang="en",
    verbose=True # Shows interactive progress bar
)

# Access the data
gaps = result.get('semantic_context_analysis', [])
structures = result.get('page_structure', [])

print(f"Found {len(gaps)} semantic gaps.")

# Print titles of all analyzed pages
for page in structures:
    print(f"URL: {page['url']}")
    print(f"Title: {page['meta_tags']['title']}\n")
```

#### 2. Export to Excel
Generate a professional SEO report with multiple sheets: *Page Structure*, *Semantic Gaps*, *Word Analysis*, *N-Grams*, and *Vectors*.

```python
client.save_report(result, "seo_report.xlsx")
```

### üìä Data Model & Internals

The SDK returns a Python dictionary mirroring the API response. Here is a breakdown of each logic block:

<details>
<summary><b>1. Page Structure (New!)</b></summary>

Returns a **List** of objects (for your page and all competitors). Each object contains:

*   `url`: Page URL.
*   `meta_tags`: Dictionary with `title`, `description`, etc.
*   `content`: Dictionary with `h1_heading`, `heading_structure_raw` (all headers).
*   `metrics`: Dictionary with `char_count_no_spaces`, `uniqueness_percentage`.

</details>

<details>
<summary><b>2. Semantic Context Analysis (Zone Analysis)</b></summary>

**This is the most critical part of the analysis.** It calculates a weighted score based on *where* a word appears (Title > H1 > H2 > Text) and *how close* it is to the target query.

*   `lemma`: The base form of the word.
*   `competitor_avg_score`: The weighted score of this word across top competitors.
*   `own_score`: Your weighted score. If `0.0`, the word is missing or used in a very weak zone (e.g., footer).
*   `gap`: The difference between competitors and you. Higher gap = higher priority.
*   `coverage_percent`: Percentage of competitors that use this word in a significant context.
*   `context_snippet`: A 3-word phrase (trigram) showing how competitors use this word.
*   `recommendation`: Actionable advice based on the gap (e.g., *"Add to Title/H1"*, *"Add to H2/H3"*, *"Mention in Body"*).

```json
{
  "lemma": "battery",
  "competitor_avg_score": 10.5,
  "own_score": 0.0,
  "gap": 10.5,
  "coverage_percent": 80.0,
  "context_snippet": "long lasting battery life",
  "recommendation": "Add to Title/H1" 
}
```
</details>

<details>
<summary><b>3. Block Comparison (Lexical Analysis)</b></summary>

Classical TF-IDF comparison. Useful for finding over-optimization (spam) or general content relevancy.

*   `frequency`: Weighted frequency (TF).
*   `frequency_own_page`: How many times it appears on your page.
*   `pct_target_comp_avg`: Average density (%) on competitor pages.
*   `action_needed`: Simple recommendation (`add`, `increase`, `decrease`, `ok`).

```json
{
  "word": "price",
  "frequency": 12.5,
  "pct_target_comp_avg": 2.5,
  "action_needed": "increase",
  "present_on_own_page": true
}
```
</details>

<details>
<summary><b>4. N-grams Analysis (Phrases)</b></summary>

Analyzes stable word combinations (Bigrams and Trigrams).

*   `ngram`: The phrase (e.g., "fast delivery").
*   `pages_count`: On how many competitor sites this exact phrase appears.

</details>

<details>
<summary><b>5. DrMaxs (Vector AI)</b></summary>

Uses Neural Network Embeddings to find **Latent Semantic Indexing (LSI)** words. These are words that are semantically close to your topic but might not be direct synonyms.

*   `by_frequency`: Most frequent semantically related words.
*   `by_tfidf`: Most unique/important semantically related words.
*   `similarity_score`: Cosine similarity to the topic vector (0.0 to 1.0).

```json
{
  "word": "logistics",
  "similarity_score": 0.89,
  "present_on_own_page": false
}
```
</details>

### üíª CLI Usage

You can use the SDK directly from your terminal.

```bash
# Run analysis and save to Excel
python -m unihra \
  --key "YOUR_KEY" \
  --own "https://mysite.com" \
  --comp "https://comp1.com" \
  --comp "https://comp2.com" \
  --query "main keyword" \
  --save report.xlsx \
  --verbose
```

---

## üá∑üá∫ Russian Documentation

### ‚ú® –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

*   **üß† –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞**: –ê–ª–≥–æ—Ä–∏—Ç–º –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–µ –ø—Ä–æ—Å—Ç–æ —á–∞—Å—Ç–æ—Ç—É —Å–ª–æ–≤, –∞ –∏—Ö –≤–µ—Å –≤ –∑–æ–Ω–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞ (`H1`, `Title`, `Strong`) –∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –∫–ª—é—á–µ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.
*   **üèóÔ∏è –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Å—Ç—Ä–∞–Ω–∏—Ü—ã**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ H1-H6, Meta-—Ç–µ–≥–∏ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ **–≤—Å–µ–º** –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º—ã–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º.
*   **‚ö°Ô∏è –ü–æ–ª–Ω–∞—è –∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è API**: –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –±–µ—Ä–µ—Ç –Ω–∞ —Å–µ–±—è —Ä–∞–±–æ—Ç—É —Å –æ—á–µ—Ä–µ–¥—è–º–∏, SSE-—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º –∏ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫.
*   **üêº –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Pandas**: –≠–∫—Å–ø–æ—Ä—Ç —Å–ª–æ–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ DataFrame –∏–ª–∏ –∫—Ä–∞—Å–∏–≤—ã–π Excel –æ—Ç—á–µ—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π.
*   **üõ°Ô∏è Smart Retries**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –ª–∏–º–∏—Ç–æ–≤ (`429`) –∏ —Ä–∞–∑—Ä—ã–≤–æ–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è.
*   **ü™ê Jupyter Support**: –ö—Ä–∞—Å–∏–≤—ã–µ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä—ã –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ –≤ –Ω–æ—É—Ç–±—É–∫–∞—Ö.

### üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞

```bash
pip install unihra
```

### ‚ö°Ô∏è –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

#### 1. –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞
–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ (H1-H6) –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä `queries` (—Ü–µ–ª–µ–≤—ã–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã, –ø–æ–¥ –∫–æ—Ç–æ—Ä—ã–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞).

```python
from unihra import UnihraClient

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
client = UnihraClient(api_key="–í–ê–®_–ö–õ–Æ–ß")

# –ó–∞–ø—É—Å–∫ (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º)
result = client.analyze(
    own_page="https://example.com/catalog/tovar",
    competitors=[
        "https://competitor.ru/item/1", 
        "https://market.ru/product/2"
    ],
    queries=["–∫—É–ø–∏—Ç—å —Ç–æ–≤–∞—Ä", "–ª—É—á—à–∏–π —Ç–æ–≤–∞—Ä 2025"], # <--- –í–∞–∂–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–æ–Ω
    lang="ru",
    verbose=True # –í–∫–ª—é—á–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä
)

print("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")

# –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä—É–∫—Ç—É—Ä (–°–≤–æ—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ + –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã)
structures = result.get('page_structure', [])

if structures:
    my_page = structures[0]
    print(f"–ú–æ–π H1: {my_page['content']['h1_heading']}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å: {my_page['metrics']['uniqueness_percentage']}%")
```

#### 2. –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á–µ—Ç–∞
–°–æ–∑–¥–∞–µ—Ç `.xlsx` —Ñ–∞–π–ª —Å –≤–∫–ª–∞–¥–∫–∞–º–∏: *Page Structure*, *Semantic Gaps*, *Word Analysis*, *N-Grams*, *Vectors*.

```python
client.save_report(result, "seo_audit.xlsx")
```

### üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –í–Ω—É—Ç—Ä—è–Ω–∫–∞

–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ 5 –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤.

<details>
<summary><b>1. Page Structure (–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã)</b></summary>

–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç **—Å–ø–∏—Å–æ–∫** –æ–±—ä–µ–∫—Ç–æ–≤. –ö–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç:

*   `url`: –°—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É.
*   `content`: –ó–∞–≥–æ–ª–æ–≤–∫–∏ H1-H6 (`h1_heading`, `heading_structure_raw`).
*   `meta_tags`: –ú–µ—Ç–∞-—Ç–µ–≥–∏ (`title`, `description`).
*   `metrics`: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏ (`uniqueness_percentage`, `char_count_no_spaces`).

</details>

<details>
<summary><b>2. Semantic Context Analysis (–ó–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –†–∞–∑—Ä—ã–≤—ã)</b></summary>

**–°–∞–º—ã–π –≤–∞–∂–Ω—ã–π –±–ª–æ–∫.** –ê–ª–≥–æ—Ä–∏—Ç–º –≤–∑–≤–µ—à–∏–≤–∞–µ—Ç —Å–ª–æ–≤–∞. –°–ª–æ–≤–æ –≤ `Title` –ø–æ–ª—É—á–∞–µ—Ç –±–æ–ª—å—à–µ –±–∞–ª–ª–æ–≤, —á–µ–º —Å–ª–æ–≤–æ –≤ —Ñ—É—Ç–µ—Ä–µ. –¢–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ —Å–ª–æ–≤–∞ –¥–æ –≤–∞—à–µ–≥–æ `query`.

*   `lemma`: –õ–µ–º–º–∞ —Å–ª–æ–≤–∞.
*   `competitor_avg_score`: –°—Ä–µ–¥–Ω–∏–π –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π –±–∞–ª–ª –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.
*   `own_score`: –í–∞—à –±–∞–ª–ª. –ï—Å–ª–∏ `0.0`, –∑–Ω–∞—á–∏—Ç —Å–ª–æ–≤–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –≤–∞–∂–Ω—ã—Ö –∑–æ–Ω–∞—Ö.
*   `gap`: –í–µ–ª–∏—á–∏–Ω–∞ –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏—è. –ß–µ–º –±–æ–ª—å—à–µ, —Ç–µ–º –≤–∞–∂–Ω–µ–µ —Å–ª–æ–≤–æ.
*   `coverage_percent`: –ü—Ä–æ—Ü–µ–Ω—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö —ç—Ç–æ —Å–ª–æ–≤–æ –µ—Å—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
*   `context_snippet`: –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (—Ç—Ä–∏–≥—Ä–∞–º–º–∞) –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.
*   `recommendation`: –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –¢–ó (–Ω–∞–ø—Ä–∏–º–µ—Ä, *"–î–æ–±–∞–≤–∏—Ç—å –≤ Title/H1"*, *"–î–æ–±–∞–≤–∏—Ç—å –≤ H2/H3"* –∏–ª–∏ *"–í–ø–∏—Å–∞—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç"*).

```json
{
  "lemma": "–∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä",
  "competitor_avg_score": 10.5,
  "own_score": 0.0,
  "gap": 10.5,
  "coverage_percent": 80.0,
  "context_snippet": "–∫—É–ø–∏—Ç—å –º–æ—â–Ω—ã–π –∞–∫–∫—É–º—É–ª—è—Ç–æ—Ä",
  "recommendation": "–î–æ–±–∞–≤–∏—Ç—å –≤ Title/H1" 
}
```
</details>

<details>
<summary><b>3. Block Comparison (–õ–µ–∫—Å–∏–∫–∞)</b></summary>

–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ TF-IDF –∏ "–º–µ—à–∫–∞ —Å–ª–æ–≤". –ü–æ–º–æ–≥–∞–µ—Ç –Ω–∞–π—Ç–∏ –ø–µ—Ä–µ—Å–ø–∞–º –∏–ª–∏ –Ω–µ–¥–æ—Å–ø–∞–º –æ–±—â–µ–π –ª–µ–∫—Å–∏–∫–∏.

*   `action_needed`: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è (`–î–æ–±–∞–≤–∏—Ç—å`, `–£–º–µ–Ω—å—à–∏—Ç—å`, `–û–∫`).
*   `pct_target_comp_avg`: –°—Ä–µ–¥–Ω—è—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å (%) —É –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤.
*   `frequency_own_page`: –ê–±—Å–æ–ª—é—Ç–Ω–æ–µ —á–∏—Å–ª–æ –≤—Ö–æ–∂–¥–µ–Ω–∏–π —É –≤–∞—Å.

</details>

<details>
<summary><b>4. N-grams Analysis (–§—Ä–∞–∑—ã)</b></summary>

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É—Å—Ç–æ–π—á–∏–≤—ã–µ —Å–ª–æ–≤–æ—Å–æ—á–µ—Ç–∞–Ω–∏—è.

*   `ngram`: –§—Ä–∞–∑–∞ (–±–∏–≥—Ä–∞–º–º–∞ –∏–ª–∏ —Ç—Ä–∏–≥—Ä–∞–º–º–∞).
*   `pages_count`: –ù–∞ —Å–∫–æ–ª—å–∫–∏—Ö —Å–∞–π—Ç–∞—Ö –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ —ç—Ç–∞ —Ñ—Ä–∞–∑–∞ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ç–æ—á—å-–≤-—Ç–æ—á—å.

</details>

<details>
<summary><b>5. DrMaxs (–í–µ–∫—Ç–æ—Ä–Ω—ã–π AI)</b></summary>

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ **LSI (Latent Semantic Indexing)**. –ù–∞—Ö–æ–¥–∏—Ç —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã–µ **–ø–æ —Å–º—ã—Å–ª—É** –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏—Ö –ø—Ä—è–º–æ, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –∏—Ö —Å–∏–Ω–æ–Ω–∏–º—ã.

*   `by_frequency`: –°–∞–º—ã–µ —á–∞—Å—Ç–æ—Ç–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞.
*   `by_tfidf`: –°–∞–º—ã–µ "–≤–∞–∂–Ω—ã–µ" –≤–µ–∫—Ç–æ—Ä–∞.
*   `similarity_score`: –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –±–ª–∏–∑–æ—Å—Ç—å –∫ —Ç–µ–º–∞—Ç–∏–∫–µ (0.0 - 1.0).

</details>

### üíª –†–∞–±–æ—Ç–∞ —á–µ—Ä–µ–∑ CLI

```bash
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
python -m unihra \
  --key "–í–ê–®_–ö–õ–Æ–ß" \
  --own "https://site.ru/page" \
  --comp "https://comp1.ru/p1" \
  --comp "https://comp2.ru/p2" \
  --query "–∑–∞–ø—Ä–æ—Å 1" \
  --save audit.xlsx \
  --verbose
```

---

<div align="center">
    <p>Developed with ‚ù§Ô∏è by <b>Unihra Team</b></p>
    <p>
        <a href="https://t.me/mncosine">Telegram News</a> ‚Ä¢ 
        <a href="https://unihra.ru">Web Service</a> ‚Ä¢ 
        <a href="https://t.me/UniHRA_bot">Get API Key Bot</a>
    </p>
</div>