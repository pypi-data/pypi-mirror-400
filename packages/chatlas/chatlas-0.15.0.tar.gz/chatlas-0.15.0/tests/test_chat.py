import re
import tempfile

import pytest
from chatlas import (
    AssistantTurn,
    ChatOpenAI,
    ContentToolRequest,
    ContentToolResult,
    ToolRejectError,
    Turn,
    UserTurn,
)
from chatlas._chat import ToolFailureWarning
from pydantic import BaseModel


@pytest.mark.vcr
def test_simple_batch_chat():
    chat = ChatOpenAI()
    response = chat.chat("What's 1 + 1. Just give me the answer, no punctuation")
    assert str(response) == "2"


@pytest.mark.vcr
@pytest.mark.asyncio
async def test_simple_async_batch_chat():
    chat = ChatOpenAI()
    response = await chat.chat_async(
        "What's 1 + 1. Just give me the answer, no punctuation",
    )
    assert "2" == await response.get_content()


@pytest.mark.vcr
def test_simple_streaming_chat():
    chat = ChatOpenAI()
    res = chat.stream(
        """
        What are the canonical colors of the ROYGBIV rainbow?
        Put each colour on its own line. Don't use punctuation.
    """
    )
    chunks = [chunk for chunk in res]
    assert len(chunks) > 2
    result = "".join(chunks)
    res = re.sub(r"\s+", "", result).lower()
    assert res == "redorangeyellowgreenblueindigoviolet"
    turn = chat.get_last_turn()
    assert turn is not None
    res = re.sub(r"\s+", "", turn.text).lower()
    assert res == "redorangeyellowgreenblueindigoviolet"


@pytest.mark.vcr
@pytest.mark.asyncio
async def test_simple_streaming_chat_async():
    chat = ChatOpenAI()
    res = await chat.stream_async(
        """
        What are the canonical colors of the ROYGBIV rainbow?
        Put each colour on its own line. Don't use punctuation.
    """
    )
    chunks = [chunk async for chunk in res]
    assert len(chunks) > 2
    result = "".join(chunks)
    rainbow_re = "^red *\norange *\nyellow *\ngreen *\nblue *\nindigo *\nviolet *\n?$"
    assert re.match(rainbow_re, result.lower())
    turn = chat.get_last_turn()
    assert turn is not None
    assert re.match(rainbow_re, turn.text.lower())


def test_basic_repr(snapshot):
    chat = ChatOpenAI(
        system_prompt="You're a helpful assistant that returns very minimal output",
    )
    chat.set_turns(
        [
            UserTurn("What's 1 + 1? What's 1 + 2?"),
            AssistantTurn("2  3", tokens=(15, 5, 5), cost=0.001),
        ]
    )
    assert snapshot == repr(chat)


def test_basic_str(snapshot):
    chat = ChatOpenAI(
        system_prompt="You're a helpful assistant that returns very minimal output",
    )
    chat.set_turns(
        [
            UserTurn("What's 1 + 1? What's 1 + 2?"),
            AssistantTurn("2  3", tokens=(15, 5, 0), cost=0.001),
        ]
    )
    assert snapshot == str(chat)


def test_basic_export(snapshot):
    chat = ChatOpenAI(
        system_prompt="You're a helpful assistant that returns very minimal output",
    )
    chat.set_turns(
        [
            UserTurn("What's 1 + 1? What's 1 + 2?"),
            AssistantTurn("2  3", tokens=(15, 5, 0)),
        ]
    )
    with tempfile.TemporaryDirectory() as tmpdir:
        tmpfile = tmpdir + "/chat.html"
        chat.export(tmpfile, title="My Chat")
        with open(tmpfile, "r") as f:
            assert snapshot == f.read()


@pytest.mark.vcr
def test_chat_structured():
    chat = ChatOpenAI()

    class Person(BaseModel):
        name: str
        age: int

    data = chat.chat_structured("John, age 15, won first prize", data_model=Person)
    assert data == Person(name="John", age=15)


@pytest.mark.vcr
@pytest.mark.asyncio
async def test_chat_structured_async():
    chat = ChatOpenAI()

    class Person(BaseModel):
        name: str
        age: int

    data = await chat.chat_structured_async(
        "John, age 15, won first prize", data_model=Person
    )
    assert data == Person(name="John", age=15)


@pytest.mark.vcr
def test_last_turn_retrieval():
    chat = ChatOpenAI()
    assert chat.get_last_turn(role="user") is None
    assert chat.get_last_turn(role="assistant") is None

    chat.chat("Hi")
    user_turn = chat.get_last_turn(role="user")
    assert user_turn is not None and user_turn.role == "user"
    turn = chat.get_last_turn(role="assistant")
    assert turn is not None and turn.role == "assistant"


def test_system_prompt_retrieval():
    chat1 = ChatOpenAI()
    assert chat1.system_prompt is None
    assert chat1.get_last_turn(role="system") is None

    chat2 = ChatOpenAI(system_prompt="You are from New Zealand")
    assert chat2.system_prompt == "You are from New Zealand"
    turn = chat2.get_last_turn(role="system")
    assert turn is not None and turn.text == "You are from New Zealand"


def test_modify_system_prompt():
    chat = ChatOpenAI()
    chat.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello"),
        ]
    )

    # NULL -> NULL
    chat.system_prompt = None
    assert chat.system_prompt is None

    # NULL -> string
    chat.system_prompt = "x"
    assert chat.system_prompt == "x"

    # string -> string
    chat.system_prompt = "y"
    assert chat.system_prompt == "y"

    # string -> NULL
    chat.system_prompt = None
    assert chat.system_prompt is None


@pytest.mark.vcr
def test_json_serialize():
    chat = ChatOpenAI()
    chat.chat("Tell me a short joke", echo="none")
    turns = chat.get_turns()
    turns_json = [x.model_dump_json() for x in turns]
    turns_restored = [Turn.model_validate_json(x) for x in turns_json]

    assert len(turns) == 2
    # Verify correct types were restored
    assert type(turns_restored[0]) == type(turns[0])
    assert type(turns_restored[1]) == type(turns[1])

    # Completion objects, at least of right now, aren't included in the JSON
    # Need to create new turn without completion for comparison
    turns_for_comparison = [turns[0]]
    if isinstance(turns[1], AssistantTurn):
        turns_for_comparison.append(
            AssistantTurn(
                turns[1].contents,
                tokens=turns[1].tokens,
                finish_reason=turns[1].finish_reason,
                completion=None,
                cost=turns[1].cost,
            )
        )
    else:
        turns_for_comparison.append(turns[1])
    assert turns_for_comparison == turns_restored


# Chat can be deepcopied/forked
@pytest.mark.vcr
def test_deepcopy_chat():
    import copy

    chat = ChatOpenAI()
    chat.chat("Hi", echo="none")
    chat_fork = copy.deepcopy(chat)

    assert len(chat.get_turns()) == 2
    assert len(chat_fork.get_turns()) == 2

    chat_fork.chat("Bye", echo="none")

    assert len(chat.get_turns()) == 2
    assert len(chat_fork.get_turns()) == 4


@pytest.mark.vcr
def test_chat_callbacks():
    chat = ChatOpenAI()

    def test_tool(user: str) -> str:
        "Find out a user's favorite color"
        return "red"

    chat.register_tool(test_tool)

    last_request = None
    cb_count_request = 0
    cb_count_result = 0

    def on_tool_request(request: ContentToolRequest):
        nonlocal cb_count_request, last_request
        cb_count_request += 1
        assert isinstance(request, ContentToolRequest)
        assert request.name == "test_tool"
        last_request = request

    def on_tool_result(result: ContentToolResult):
        nonlocal cb_count_result, last_request
        cb_count_result += 1
        assert isinstance(result, ContentToolResult)
        assert result.request == last_request

    chat.on_tool_request(on_tool_request)
    chat.on_tool_result(on_tool_result)
    chat.chat("What are Joe and Hadley's favorite colors?")

    assert cb_count_request == 2
    assert cb_count_result == 2


@pytest.mark.vcr
@pytest.mark.filterwarnings("ignore", category=ToolFailureWarning)
def test_chat_tool_request_reject():
    chat = ChatOpenAI()

    def test_tool(user: str) -> str:
        "Find out a user's favorite color"
        return "red"

    chat.register_tool(test_tool)

    def on_tool_request(request: ContentToolRequest):
        if request.arguments["user"] == "Joe":
            raise ToolRejectError("Joe denied the request.")

    chat.on_tool_request(on_tool_request)

    response = chat.chat(
        "What are Joe and Hadley's favorite colors? ",
        "Write 'Joe ____ Hadley ____'. Use 'unknown' if you don't know. ",
        "Don't ever include punctuation in your answers.",
    )

    assert str(response).lower() == "joe unknown hadley red"


@pytest.mark.vcr
@pytest.mark.filterwarnings("ignore", category=ToolFailureWarning)
def test_chat_tool_request_reject2(capsys):
    chat = ChatOpenAI()

    def test_tool(user: str) -> str:
        "Find out a user's favorite color"
        if "joe" in user.lower():
            raise ToolRejectError("Joe denied the request.")
        return "red"

    chat.register_tool(test_tool)

    response = chat.chat(
        "What are Joe and Hadley's favorite colors? ",
        "Write 'Joe ____ Hadley ____'. Use 'unknown' if you don't know. ",
        "Don't ever include punctuation in your answers.",
    )

    assert str(response).lower() == "joe unknown hadley red"
    assert "Joe denied the request." in capsys.readouterr().out


def test_get_cost():
    chat = ChatOpenAI(api_key="fake_key")
    chat.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello", tokens=(2, 10, 2)),
            UserTurn("Hi"),
            AssistantTurn("Hello", tokens=(14, 10, 2)),
        ]
    )

    with pytest.raises(
        ValueError,
        match=re.escape(
            "Expected `include` to be one of 'all' or 'last', not 'bad_option'"
        ),
    ):
        chat.get_cost(include="bad_option")  # type: ignore

    # Checking that these have the right form vs. the actual calculation because the price may change
    cost = chat.get_cost(include="all")
    assert isinstance(cost, float)
    assert cost > 0

    last = chat.get_cost(include="last")
    assert isinstance(last, float)
    assert last > 0

    assert cost > last

    # User-specified cost values
    byoc = (2.0, 3.0, 0.1)

    expected_cost = (
        (10 * byoc[1] / 1e6) + (2 * byoc[0] / 1e6) + (2 * byoc[2] / 1e6)
    ) + ((10 * byoc[1] / 1e6) + (14 * byoc[0] / 1e6) + (2 * byoc[2] / 1e6))
    cost2 = chat.get_cost(include="all", token_price=byoc)
    assert cost2 == expected_cost

    # get_cost(include="last") returns the full cost of the last assistant turn
    # Last turn has tokens=(14, 10, 2) -> input=14, output=10, cached=2
    last_expected_cost = (
        (14 * byoc[0] / 1e6) + (10 * byoc[1] / 1e6) + (2 * byoc[2] / 1e6)
    )
    last2 = chat.get_cost(include="last", token_price=byoc)
    assert last2 == last_expected_cost

    chat2 = ChatOpenAI(api_key="fake_key", model="BADBAD")
    chat2.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello", tokens=(2, 10, 0)),
            UserTurn("Hi"),
            AssistantTurn("Hello", tokens=(14, 10, 0)),
        ]
    )
    with pytest.raises(
        KeyError,
        match="We could not locate pricing information for model 'BADBAD' from provider 'OpenAI'. If you know the pricing for this model, specify it in `token_price`.",
    ):
        chat2.get_cost(include="all")


# -----------------------------------------------------------------------------
# Tests for repr formatting
# -----------------------------------------------------------------------------


def test_turn_repr_user():
    """Test that UserTurn repr shows content without header."""
    turn = UserTurn("Hello, world!")
    assert repr(turn) == "Hello, world!"


def test_turn_repr_system():
    """Test that SystemTurn repr shows content without header."""
    from chatlas import SystemTurn

    turn = SystemTurn("You are a helpful assistant.")
    assert repr(turn) == "You are a helpful assistant."


def test_turn_repr_assistant_with_tokens():
    """Test that AssistantTurn repr shows content without header/token info."""
    turn = AssistantTurn("The answer is 42.", tokens=(100, 50, 20), cost=0.0025)
    assert repr(turn) == "The answer is 42."


def test_turn_repr_assistant_without_tokens():
    """Test that AssistantTurn repr works without token info."""
    turn = AssistantTurn("Hello!")
    assert repr(turn) == "Hello!"


def test_turn_repr_assistant_no_cached_tokens():
    """Test that AssistantTurn repr shows content without token info."""
    turn = AssistantTurn("Test", tokens=(100, 50, 0), cost=0.001)
    assert repr(turn) == "Test"


def test_chat_repr_header_format():
    """Test Chat repr header shows correct format."""
    chat = ChatOpenAI(api_key="fake_key", system_prompt="Be helpful")
    chat.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello!", tokens=(10, 20, 5), cost=0.001),
        ]
    )
    result = repr(chat)

    first_line = result.split("\n")[0]
    assert first_line.startswith("<Chat")
    assert "OpenAI" in first_line
    assert "turns=3" in first_line
    assert "input=10+5" in first_line
    assert "output=20" in first_line
    assert "cost=" in first_line


def test_chat_repr_no_tokens():
    """Test Chat repr when no token info is available."""
    chat = ChatOpenAI(api_key="fake_key")
    chat.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello!"),
        ]
    )
    result = repr(chat)

    first_line = result.split("\n")[0]
    assert "turns=2" in first_line
    assert "input=" not in first_line


def test_turn_repr_with_tool_request():
    """Test repr formatting for turns with tool requests."""
    from chatlas import ContentToolRequest

    turn = AssistantTurn(
        [
            ContentToolRequest(id="123", name="get_weather", arguments={"city": "NYC"}),
        ],
        tokens=(50, 30, 0),
    )
    result = repr(turn)

    assert "## Assistant" not in result
    assert "ðŸ”§ tool request (123)" in result
    assert 'get_weather(city="NYC")' in result


def test_turn_repr_with_tool_result():
    """Test repr formatting for turns with tool results."""
    request = ContentToolRequest(
        id="123", name="get_weather", arguments={"city": "NYC"}
    )
    turn = UserTurn(
        [
            ContentToolResult(value="72Â°F and sunny", request=request),
        ]
    )
    result = repr(turn)

    assert "## User" not in result
    assert "âœ… tool result (123)" in result
    assert "72Â°F and sunny" in result


def test_str_unchanged():
    """Verify that __str__ still uses the original emoji-based format."""
    chat = ChatOpenAI(api_key="fake_key")
    chat.set_turns(
        [
            UserTurn("Hi"),
            AssistantTurn("Hello!"),
        ]
    )
    result = str(chat)

    assert "ðŸ‘¤" in result or "User" in result
    assert "ðŸ¤–" in result or "Assistant" in result
