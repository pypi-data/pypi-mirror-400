orchestrator:
  id: orka-ui
  strategy: parallel
  queue: orka:generated
  memory_preset: "working"  # Use working memory for active processing
  agents:
    - fork_2
    - join_1
    - openai-binary_6
    - router_7
    - answer-final
agents:
  - id: fork_2
    type: fork
    targets:
      - [duckduckgo_4]  # Fixed: Each branch must be wrapped in a list
      - [openai-classification_5]
  - id: duckduckgo_4
    type: duckduckgo
    queue: orka:duckduckgo_4
    prompt: |
      {{ get_input() }}
  - id: openai-classification_5
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.2
    queue: orka:openai-classification_5
    prompt: |-
      Classify the sentence into one of the categories.
      SENTENCE: {{ get_input() }}
      
      Choose exactly one from: tech, nature, people, others.
      Answer with only the category name.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: join_1
    type: join
    group: fork_2
  - id: openai-binary_6
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.1
    queue: orka:openai-binary_6
    prompt: |-
      Do the sentence or the extra data relate to a person?
      SENTENCE: {{ get_input() }}
      EXTRA DATA: {{ joined_results() }}
      
      Answer with exactly 'true' or 'false' only.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: router_7
    type: router
    params:
      decision_key: openai-binary_6
      routing_map:
        "true":
          - openai-answer_10
          - duckduckgo_8
          - openai-answer_9
        "false":
          - openai-answer_11
  - id: openai-answer_10
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.2
    queue: orka:openai-answer_10
    prompt: |-
      Return me ONLY name and surname of the person pointed in this sentence or extra data.

      SENTENCE: {{ get_input() }}
      EXTRA DATA: {{ joined_results() }}
      
      Provide just the name, nothing else.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: duckduckgo_8
    type: duckduckgo
    queue: orka:duckduckgo_8
    prompt: '{{ get_agent_response("openai-answer_10") }}'
  - id: openai-answer_9
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.7
    queue: orka:openai-answer_9
    prompt: |-
      Based on the sentence, return a compelling answer or a deeper overview, also using the extra data.

      SENTENCE: {{ get_input() }}
      EXTRA DATA: {{ joined_results() }}
      
      Provide a comprehensive and engaging response.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: openai-answer_11
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.7
    queue: orka:openai-answer_11
    prompt: |-
      Based on the sentence, return a compelling answer or a deeper overview, also using the extra data.

      SENTENCE: {{ get_input() }}
      EXTRA DATA: {{ joined_results() }}
      
      Provide a detailed and informative response.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
  - id: answer-final
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.6
    queue: orka:answer-final
    prompt: |-
      Based on the sentence, return a compelling answer or a deeper overview, also using the extra data.

      SENTENCE: {{ get_input() }}
      EXTRA DATA: {{ joined_results() }}
      
      Provide the final, polished response.
    params:
      structured_output:
        enabled: true
        mode: prompt
        schema:
          required: [response]
          optional:
            confidence: number
