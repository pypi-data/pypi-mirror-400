defaults:
  - default
  - _self_

nvbenjo:
  models:
      bert:
        type_or_path: huggingface:google-bert/bert-base-cased
        kwargs: {}
        shape: [{"name": "input_ids", "shape": [B, 200], "type": "long", min_max: [0, 200]}]
        num_warmup_batches: &num-warmup-batches 1
        num_batches: &num-batches 10
        batch_sizes: &batch-sizes [1, 8, 16]
        devices: &devices ["cuda:0"]
        runtime_options:
          FP16:
            precision: FP16
          FP32:
            precision: FP32
          AMP_FP16:
            precision: AMP_FP16
        custom_batchmetrics:
          # `tokens_per_batch / time_total_batch_normalized` to get tokens per second
          tokens_per_second: 200.0

      gpt2:
        type_or_path: huggingface:openai-community/gpt2
        kwargs: {}
        shape: [{"name": "input_ids", "shape": [B, 90], "type": "long", min_max: [0, 200]}]
        num_warmup_batches: *num-warmup-batches
        num_batches: *num-batches
        batch_sizes: *batch-sizes
        devices: *devices
        runtime_options:
          BFLOAT16:
            compile: false
            precision: BFLOAT16
          FP32:
            compile: false
            precision: FP32
        custom_batchmetrics:
          # `tokens_per_batch / time_total_batch_normalized` to get tokens per second
          tokens_per_second: 90.0

      ast-audioset:
        type_or_path: huggingface:MIT/ast-finetuned-audioset-10-10-0.4593
        kwargs: {}
        shape: [{"name": "input_values", "shape": [B, 1024, 128], "type": "float", "min_max": [0, 1]}]
        num_warmup_batches: *num-warmup-batches
        num_batches: *num-batches
        batch_sizes: *batch-sizes
        devices: *devices
        runtime_options:
          FP32:
            precision: FP32
          AMP_FP16:
            precision: AMP_FP16
          AMP_BFLOAT16:
            precision: AMP_BFLOAT16
        custom_batchmetrics:
          # `audio_duration / time_total_batch_normalized` to get real time factor
          real_time_factor: 10.24

      openai/whisper-small:
        type_or_path: huggingface:openai/whisper-small
        kwargs: {}
        shape: [
            {"name": "input_features", "shape": [B, 80, 3000], "min_max": [0, 1]},
            {"name": "decoder_input_ids", "shape": [B, 6], "value": 50258, "type": "long"},
            {"name": "attention_mask", "shape": [B, 6], "value": 1, "type": "long"},
          ]
        num_warmup_batches: *num-warmup-batches
        num_batches: *num-batches
        batch_sizes: *batch-sizes
        devices: *devices
        runtime_options:
          FP16:
            precision: FP16
          FP32:
            precision: FP32
        custom_batchmetrics:
          # `audio_duration / time_total_batch_normalized` to get real time factor
          real_time_factor: 30.0

      google/t5:
        type_or_path: huggingface:google/t5-v1_1-small
        kwargs: {}
        shape: [
            {"name": "input_ids", "shape": [B, 512], "type": "long", "min_max": [0, 32128]},
            {"name": "attention_mask", "shape": [B, 512], "type": "long", "value": 1},
            {"name": "decoder_input_ids", "shape": [B, 8], "type": "long", "value": 0},
          ]
        num_warmup_batches: *num-warmup-batches
        num_batches: *num-batches
        batch_sizes: *batch-sizes
        devices: *devices
        runtime_options:
          FP16:
            precision: FP16
          FP32:
            precision: FP32
        custom_batchmetrics:
          # `tokens_per_batch / time_total_batch_normalized` to get tokens per second
          tokens_per_second: 512.0

      mobilevit:
        type_or_path: huggingface:apple/mobilevit-small
        kwargs: {}
        shape: [{"name": "pixel_values", "shape": [B, 3, 224, 224], "type": "float", "min_max": [0, 1]}]
        num_warmup_batches: *num-warmup-batches
        num_batches: *num-batches
        batch_sizes: *batch-sizes
        devices: *devices
        runtime_options:
          FP32:
            precision: FP32
          AMP_FP16:
            precision: AMP_FP16
          AMP_BFLOAT16:
            precision: AMP_BFLOAT16
        custom_batchmetrics:
          # `images_per_batch / time_total_batch_normalized` to get images per second
          fps: 1
