# Unreadable AGI Code Benchmark

> **Thesis:** As AI systems become more capable, they will generate code optimized for machines‚Äînot humans. When code becomes unreadable, traditional code review fails. Verification becomes essential.

## What We Tested

We asked LLMs to generate "machine-optimized" code for 11 algorithmic challenges:

| Domain | Test | What It Does |
|--------|------|--------------|
| Math | Prime Sieve | Generate primes up to 1000 |
| Math | Matrix Multiplication | Multiply two 3√ó3 matrices |
| Math | Fibonacci Matrix | First 20 Fibonacci via matrix exponentiation |
| AI | Backpropagation | One training step of a perceptron |
| AI | DFS Maze Solver | Find path in a 4√ó4 maze |
| AI | Bitonic Sort | Sort 16 integers without `sort()` |
| Security | RSA Encryption | Encrypt/decrypt with p=61, q=53 |
| Finance | Black-Scholes | Option pricing calculation |
| Simulation | Game of Life | One generation on 5√ó5 grid |
| Simulation | Sudoku Validator | Validate a 9√ó9 solved board |
| Math | Fibonacci One-liner | First 100 Fibonacci in one line |

## Raw Results

| Model | Code Executed | QWED Verified |
|-------|---------------|---------------|
| GPT-4o | 5/11 (45%) | 3/11 (27%) |
| Claude Sonnet 4.5 | 10/11 (91%) | 7/11 (64%) |
| Claude Opus 4.5 | 10/11 (91%) | 9/11 (82%) |

### What Passed QWED Verification (Opus 4.5)

| Test | Status | Verification Method |
|------|--------|---------------------|
| Prime Sieve | ‚úÖ | Output contains expected primes |
| Matrix Mult | ‚úÖ | SymPy symbolic verification |
| Fibonacci | ‚úÖ | Sequence comparison |
| Backprop | ‚úÖ | Gradient check (basic) |
| DFS Maze | ‚úÖ | Path existence check |
| Bitonic Sort | ‚úÖ | Sorted order check |
| RSA | ‚úÖ | Decrypt(Encrypt(m)) == m |
| Game of Life | ‚úÖ | Valid grid structure |
| Sudoku | ‚úÖ | Constraint satisfaction |

### What Failed

| Test | Why It Failed |
|------|---------------|
| Black-Scholes | Wrong numerical output (6.09 vs expected 9-11) |
| Fibonacci 100 | Lambda returned function, not values |

---

## What We Learned

### 1. LLMs Can Generate Working "Unreadable" Code

Example from Claude Opus 4.5 (RSA):
```python
print((lambda p,q,m:(lambda n,phi:(lambda e,d:(pow(m,e,n),pow(pow(m,e,n),d,n)))(65537,pow(65537,-1,phi)))(p*q,(p-1)*(q-1)))(61,53,42))
# Output: (2557, 42) ‚Üê Correctly encrypts and decrypts!
```

A human reviewing this would struggle. But QWED verified: `decrypt(encrypt(42)) == 42` ‚úÖ

### 2. QWED Catches Real Errors

When Black-Scholes returned `6.09` instead of the expected `~10.45`, QWED flagged it as **FAILED**. The code looked correct, but the output was wrong. Traditional review might have missed this.

### 3. Code Quality ‚â† Code Correctness

Some tests generated "readable" code that failed execution. Others generated dense one-liners that executed perfectly. **Readability is orthogonal to correctness.**

---

## QWED Limitations (Honest Assessment)

### What QWED Does Well
- ‚úÖ Output comparison (expected vs actual)
- ‚úÖ Symbolic math verification (SymPy)
- ‚úÖ Property-based testing (is it sorted? does path exist?)
- ‚úÖ Reversibility checks (encrypt/decrypt)

### What QWED Does NOT Do

| Limitation | Example |
|------------|---------|
| **Does not verify algorithm correctness** | A function could use O(n¬≥) when O(n log n) is expected‚ÄîQWED won't catch this |
| **Does not verify efficiency** | Two implementations with same output but 100x speed difference look identical |
| **Does not verify logic** | If the formula is wrong but output matches by chance, QWED passes it |
| **No symbolic execution** | Cannot trace through code paths |
| **Limited domain coverage** | Only supports: Math, Logic, Code, SQL, Stats, Fact, Image, Reasoning |

### Concrete Example of Limitation

This code returns the "right answer" but is completely wrong:
```python
def fibonacci(n):
    return [0, 1, 1, 2, 3, 5, 8, 13, 21, 34][n]  # Just a lookup table
```

QWED would verify `fibonacci(5) == 5` ‚úÖ ‚Äî but it's not a real Fibonacci implementation.

---

## Where Community Can Contribute

### High Impact Areas

| Area | What's Needed | Difficulty |
|------|---------------|------------|
| **Symbolic Execution** | Trace code paths, verify loop invariants | üî¥ Hard |
| **Algorithm Verification** | Check complexity, verify implementation matches spec | üî¥ Hard |
| **More Domains** | Embedded systems, reactive programming, GPU kernels | üü° Medium |
| **Better Property Tests** | Stronger assertions than just "output matches" | üü° Medium |
| **Prompt Engineering** | Better prompts for constraint extraction | üü¢ Easy |

### Specific Open Issues

1. **Backprop Verification** ‚Äî Currently we just check execution. Need actual gradient verification against hand-calculated values.

2. **Numerical Precision** ‚Äî Black-Scholes failed because our expected range was wrong. Need proper numerical tolerance handling.

3. **Generator Detection** ‚Äî Sudoku test sometimes returns `<generator object>` instead of actual value. Need smarter output parsing.

4. **Syntax Error Handling** ‚Äî When code has mismatched parentheses, we just say "failed". Could provide better error analysis.

---

## The Bigger Picture

### Why This Matters for AGI

As AI systems approach AGI-level capabilities:

1. **Code will be optimized for machines, not humans**
   - Compilers already do this (try reading LLVM IR)
   - AI will extend this to source code itself

2. **Code review becomes impossible**
   - A 10,000 line machine-optimized function cannot be reviewed
   - But its output can still be verified

3. **Verification becomes the only trust mechanism**
   - You don't need to understand HOW it works
   - You need to verify THAT it produces correct outputs

### QWED's Role

QWED is an early attempt at this verification layer. It's not complete. It's not perfect. But it demonstrates the concept:

> **Trust through verification, not understanding.**

---

## How to Reproduce These Results

```bash
# Clone the repo
git clone https://github.com/QWED-AI/qwed-verification.git
cd qwed-verification

# Install dependencies
pip install -r requirements.txt

# Set your API keys
export AZURE_OPENAI_API_KEY="your-key"
export AZURE_ANTHROPIC_API_KEY="your-key"

# Run the benchmark
python benchmarks/unreadable_code_challenge.py --models claude-opus-4.5
```

---

## Conclusion

This benchmark doesn't prove QWED is "production ready". It proves a concept:

1. ‚úÖ LLMs can generate code humans can't easily read
2. ‚úÖ QWED can verify correctness of that code
3. ‚ö†Ô∏è QWED has significant limitations
4. üîß Community contributions can address these gaps

**We're not bragging. We're showing what works, what doesn't, and where help is needed.**

---

*Benchmark conducted: December 24, 2024*  
*Models: GPT-4o, Claude Sonnet 4.5, Claude Opus 4.5*  
*Framework: QWED 2.0*
