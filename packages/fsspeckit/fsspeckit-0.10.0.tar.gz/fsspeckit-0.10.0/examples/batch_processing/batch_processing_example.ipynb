{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Batch Processing with fsspec-utils\n",
                "\n",
                "This example demonstrates how to perform batch processing operations with \n",
                "different file formats using fsspec-utils.\n",
                "\n",
                "The example shows:\n",
                "1. Creating sample data files in different formats (Parquet, CSV, JSON)\n",
                "2. Reading files in batches using the `batch_size` parameter\n",
                "3. Processing batches of data efficiently\n",
                "4. Demonstrating the differences between batch processing for different file formats"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import tempfile\n",
                "import shutil\n",
                "import os\n",
                "from pathlib import Path\n",
                "import polars as pl\n",
                "import pyarrow as pa\n",
                "import pyarrow.parquet as pq\n",
                "\n",
                "# Import fsspec-utils\n",
                "from fsspeckit import filesystem"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_sample_data(temp_dir):\n",
                "    \"\"\"Create sample Parquet, CSV, and JSON files for demonstration.\"\"\"\n",
                "    print(f\"Creating sample data in {temp_dir}\")\n",
                "\n",
                "    # Create sample data\n",
                "    sample_data = [\n",
                "        {\"id\": 1, \"name\": \"Alice\", \"age\": 25, \"city\": \"New York\"},\n",
                "        {\"id\": 2, \"name\": \"Bob\", \"age\": 30, \"city\": \"London\"},\n",
                "        {\"id\": 3, \"name\": \"Charlie\", \"age\": 35, \"city\": \"Paris\"},\n",
                "        {\"id\": 4, \"name\": \"Diana\", \"age\": 28, \"city\": \"Tokyo\"},\n",
                "        {\"id\": 5, \"name\": \"Eve\", \"age\": 32, \"city\": \"Berlin\"},\n",
                "        {\"id\": 6, \"name\": \"Frank\", \"age\": 27, \"city\": \"Sydney\"},\n",
                "        {\"id\": 7, \"name\": \"Grace\", \"age\": 29, \"city\": \"Toronto\"},\n",
                "        {\"id\": 8, \"name\": \"Henry\", \"age\": 31, \"city\": \"Moscow\"},\n",
                "    ]\n",
                "\n",
                "    # Create Parquet files\n",
                "    for i in range(3):\n",
                "        file_path = os.path.join(temp_dir, f\"data_{i + 1}.parquet\")\n",
                "        df = pl.DataFrame(sample_data[i * 2 : (i + 1) * 2])\n",
                "        df.write_parquet(file_path)\n",
                "        print(f\"Created Parquet file: {file_path}\")\n",
                "\n",
                "    # Create CSV files\n",
                "    for i in range(3):\n",
                "        file_path = os.path.join(temp_dir, f\"data_{i + 1}.csv\")\n",
                "        df = pl.DataFrame(sample_data[i * 2 : (i + 1) * 2])\n",
                "        df.write_csv(file_path)\n",
                "        print(f\"Created CSV file: {file_path}\")\n",
                "\n",
                "    # Create JSON files\n",
                "    for i in range(3):\n",
                "        file_path = os.path.join(temp_dir, f\"data_{i + 1}.json\")\n",
                "        with open(file_path, \"w\") as f:\n",
                "            import json\n",
                "\n",
                "            json.dump(sample_data[i * 2 : (i + 1) * 2], f)\n",
                "        print(f\"Created JSON file: {file_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def demonstrate_parquet_batch_reading(temp_dir):\n",
                "    \"\"\"Demonstrate batch reading of Parquet files.\"\"\"\n",
                "    print(\"\\n=== Parquet Batch Reading ===\")\n",
                "\n",
                "    # Get filesystem\n",
                "    fs = filesystem(\"file\")\n",
                "\n",
                "    # Define the path pattern for Parquet files\n",
                "    parquet_path = os.path.join(temp_dir, \"*.parquet\")\n",
                "\n",
                "    # Example 1: Read Parquet files in batches\n",
                "    print(\"\\n1. Reading Parquet files in batches (batch_size=2):\")\n",
                "    for i, batch in enumerate(fs.read_parquet(parquet_path, batch_size=2)):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Number of rows: {batch.num_rows}\")\n",
                "        print(f\"   - Columns: {batch.column_names}\")\n",
                "        print(f\"   - Data preview: {batch.to_pandas().head(1).to_dict('records')}\")\n",
                "\n",
                "    # Example 2: Read Parquet files with include_file_path=True\n",
                "    print(\"\\n2. Reading Parquet files with include_file_path=True:\")\n",
                "    for i, batch in enumerate(\n",
                "        fs.read_parquet(parquet_path, batch_size=2, include_file_path=True)\n",
                "    ):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Number of rows: {batch.num_rows}\")\n",
                "        print(f\"   - Columns: {batch.column_names}\")\n",
                "        if \"file_path\" in batch.column_names:\n",
                "            file_paths = batch.column(\"file_path\").to_pylist()\n",
                "            print(f\"   - File paths: {set(file_paths)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def demonstrate_csv_batch_reading(temp_dir):\n",
                "    \"\"\"Demonstrate batch reading of CSV files.\"\"\"\n",
                "    print(\"\\n=== CSV Batch Reading ===\")\n",
                "\n",
                "    # Get filesystem\n",
                "    fs = filesystem(\"file\")\n",
                "\n",
                "    # Define the path pattern for CSV files\n",
                "    csv_path = os.path.join(temp_dir, \"*.csv\")\n",
                "\n",
                "    # Example 1: Read CSV files in batches\n",
                "    print(\"\\n1. Reading CSV files in batches (batch_size=2):\")\n",
                "    for i, batch in enumerate(fs.read_csv(csv_path, batch_size=2)):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Shape: {batch.shape}\")\n",
                "        print(f\"   - Columns: {batch.columns}\")\n",
                "        print(f\"   - Data preview: {batch.head(1).to_dicts()}\")\n",
                "\n",
                "    # Example 2: Read CSV files with include_file_path=True\n",
                "    print(\"\\n2. Reading CSV files with include_file_path=True:\")\n",
                "    for i, batch in enumerate(\n",
                "        fs.read_csv(csv_path, batch_size=2, include_file_path=True)\n",
                "    ):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Shape: {batch.shape}\")\n",
                "        print(f\"   - Columns: {batch.columns}\")\n",
                "        if \"file_path\" in batch.columns:\n",
                "            file_paths = batch[\"file_path\"].unique().to_list()\n",
                "            print(f\"   - File paths: {file_paths}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def demonstrate_json_batch_reading(temp_dir):\n",
                "    \"\"\"Demonstrate batch reading of JSON files.\"\"\"\n",
                "    print(\"\\n=== JSON Batch Reading ===\")\n",
                "\n",
                "    # Get filesystem\n",
                "    fs = filesystem(\"file\")\n",
                "\n",
                "    # Define the path pattern for JSON files\n",
                "    json_path = os.path.join(temp_dir, \"*.json\")\n",
                "\n",
                "    # Example 1: Read JSON files in batches\n",
                "    print(\"\\n1. Reading JSON files in batches (batch_size=2):\")\n",
                "    for i, batch in enumerate(fs.read_json(json_path, batch_size=2)):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Shape: {batch.shape}\")\n",
                "        print(f\"   - Columns: {batch.columns}\")\n",
                "        print(f\"   - Data preview: {batch.head(1).to_dicts()}\")\n",
                "\n",
                "    # Example 2: Read JSON files with include_file_path=True\n",
                "    print(\"\\n2. Reading JSON files with include_file_path=True:\")\n",
                "    for i, batch in enumerate(\n",
                "        fs.read_json(json_path, batch_size=2, include_file_path=True)\n",
                "    ):\n",
                "        print(f\"   Batch {i + 1}:\")\n",
                "        print(f\"   - Type: {type(batch)}\")\n",
                "        print(f\"   - Shape: {batch.shape}\")\n",
                "        print(f\"   - Columns: {batch.columns}\")\n",
                "        if \"file_path\" in batch.columns:\n",
                "            file_paths = batch[\"file_path\"].unique().to_list()\n",
                "            print(f\"   - File paths: {file_paths}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a temporary directory\n",
                "temp_dir = tempfile.mkdtemp()\n",
                "print(f\"Created temporary directory: {temp_dir}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create sample data\n",
                "create_sample_data(temp_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Demonstrate batch reading for each format\n",
                "demonstrate_parquet_batch_reading(temp_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "demonstrate_csv_batch_reading(temp_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "demonstrate_json_batch_reading(temp_dir)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clean up temporary directory\n",
                "shutil.rmtree(temp_dir)\n",
                "print(f\"\\nCleaned up temporary directory: {temp_dir}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}