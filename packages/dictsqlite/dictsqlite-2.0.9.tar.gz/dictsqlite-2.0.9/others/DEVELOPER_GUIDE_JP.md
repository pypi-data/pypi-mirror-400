# DictSQLite v4.1 é–‹ç™ºè€…ã‚¬ã‚¤ãƒ‰ï¼ˆæ—¥æœ¬èªï¼‰

## ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ](#ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ)
3. [åŒæœŸAPIè©³ç´°](#åŒæœŸapiè©³ç´°)
4. [éåŒæœŸAPIè©³ç´°](#éåŒæœŸapiè©³ç´°)
5. [æ°¸ç¶šåŒ–ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚¬ã‚¤ãƒ‰](#æ°¸ç¶šåŒ–ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚¬ã‚¤ãƒ‰)
6. [ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–](#ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–)
7. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½)
8. [ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](#ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹)
9. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
10. [å®Ÿè·µä¾‹](#å®Ÿè·µä¾‹)

---

## æ¦‚è¦

DictSQLite v4.1ã¯ã€Pythonã®è¾æ›¸ãƒ©ã‚¤ã‚¯ãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§SQLiteã‚’æ“ä½œã§ãã‚‹é«˜æ€§èƒ½ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚Rustã§å®Ÿè£…ã•ã‚Œã€ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™:

### ä¸»è¦æ©Ÿèƒ½

- âœ… **é«˜é€Ÿ**: å¹³å‡ 1.2M ops/secã€æœ€å¤§ 4.6M ops/sec
- âœ… **3å±¤ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Hot Tier (ãƒ¡ãƒ¢ãƒª) â†’ Warm Tier â†’ Cold Tier (SQLite)
- âœ… **LRUè‡ªå‹•ç®¡ç†**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è‡ªå‹•åˆ¶å¾¡
- âœ… **3ã¤ã®æ°¸ç¶šåŒ–ãƒ¢ãƒ¼ãƒ‰**: Memory / Lazy / WriteThrough
- âœ… **æš—å·åŒ–å¯¾å¿œ**: AES-256-GCM
- âœ… **è¾æ›¸äº’æ›API**: Pythonæ¨™æº–è¾æ›¸ã¨åŒã˜ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- âœ… **éåŒæœŸã‚µãƒãƒ¼ãƒˆ**: AsyncDictSQLite ã§é«˜é€Ÿä¸¦è¡Œå‡¦ç†

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¦‚è¦

| æ“ä½œ | é€Ÿåº¦ (ops/sec) | ç”¨é€” |
|------|----------------|------|
| åŸºæœ¬çš„ãªèª­ã¿æ›¸ã | 1.2M - 2.4M | ä¸€èˆ¬çš„ãªç”¨é€” |
| å‰Šé™¤æ“ä½œ | 4.6M | é«˜é€Ÿã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— |
| ãƒãƒ«ã‚¯æ“ä½œ | 2.3M - 2.5M | å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç† |
| æš—å·åŒ–æ“ä½œ | 600K - 1.7M | ã‚»ã‚­ãƒ¥ã‚¢ãªãƒ‡ãƒ¼ã‚¿ä¿å­˜ |

---

## ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# Rustãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ãƒ“ãƒ«ãƒ‰
cd others/beta-versions/dictsqlite_v4.1
cargo build --release
maturin develop --release
```

### æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªä½¿ã„æ–¹

```python
from dictsqlite_v4 import DictSQLiteV4

# åŸºæœ¬çš„ãªä½¿ã„æ–¹
db = DictSQLiteV4('data.db')

# æ›¸ãè¾¼ã¿
db['key'] = 'value'
db['user:1'] = {'name': 'Alice', 'age': 30}

# èª­ã¿è¾¼ã¿
print(db['key'])  # 'value'
print(db['user:1'])  # {'name': 'Alice', 'age': 30}

# å‰Šé™¤
del db['key']

# ã‚¯ãƒ­ãƒ¼ã‚º
db.close()
```

---

## åŒæœŸAPIè©³ç´°

### åˆæœŸåŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```python
DictSQLiteV4(
    db_path: str,                           # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    hot_capacity: int = 1_000_000,          # Hot Tierã®å®¹é‡
    enable_async: bool = True,              # éåŒæœŸãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹åŒ–
    persist_mode: str = "writethrough",     # æ°¸ç¶šåŒ–ãƒ¢ãƒ¼ãƒ‰
    encryption_password: str = None,        # æš—å·åŒ–ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
    enable_safe_pickle: bool = False,       # Safe Pickleæ¤œè¨¼
    safe_pickle_allowed_modules: list = None  # è¨±å¯ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
)
```

#### ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©³ç´°

**db_path**
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
- å­˜åœ¨ã—ãªã„å ´åˆã¯è‡ªå‹•ä½œæˆ
- ä¾‹: `'data.db'`, `'/tmp/cache.db'`, `':memory:'`

**hot_capacity**
- ãƒ¡ãƒ¢ãƒªä¸Šã«ä¿æŒã™ã‚‹æœ€å¤§ã‚¢ã‚¤ãƒ†ãƒ æ•°
- LRUã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ã®é–¾å€¤
- æ¨å¥¨å€¤:
  - å°è¦æ¨¡: 10,000
  - ä¸­è¦æ¨¡: 100,000
  - å¤§è¦æ¨¡: 1,000,000

**enable_async**
- ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰éåŒæœŸãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹åŒ–
- `True`: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å„ªå…ˆï¼ˆæ¨å¥¨ï¼‰
- `False`: ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§å„ªå…ˆ

**persist_mode**
- `"memory"`: ãƒ¡ãƒ¢ãƒªã®ã¿ï¼ˆæ°¸ç¶šåŒ–ãªã—ã€æœ€é€Ÿï¼‰
- `"lazy"`: é…å»¶æ›¸ãè¾¼ã¿ï¼ˆé«˜é€Ÿã€å®šæœŸçš„ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥å¿…è¦ï¼‰
- `"writethrough"`: å³åº§ã«æ°¸ç¶šåŒ–ï¼ˆå®‰å…¨ã€ã‚„ã‚„ä½é€Ÿï¼‰

**encryption_password**
- AES-256-GCMæš—å·åŒ–ã®ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰
- `None`: æš—å·åŒ–ãªã—
- æ–‡å­—åˆ—: æš—å·åŒ–æœ‰åŠ¹

### åŸºæœ¬æ“ä½œ

#### è¾æ›¸ãƒ©ã‚¤ã‚¯ãªæ“ä½œ

```python
db = DictSQLiteV4('data.db')

# æ›¸ãè¾¼ã¿
db['key1'] = 'value1'
db['key2'] = {'nested': 'data'}
db['key3'] = [1, 2, 3, 4, 5]

# èª­ã¿è¾¼ã¿
value = db['key1']              # 'value1'
value = db.get('key1')          # 'value1'
value = db.get('missing', 42)   # 42 (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤)

# å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if 'key1' in db:
    print('å­˜åœ¨ã—ã¾ã™')

# å‰Šé™¤
del db['key1']

# ã‚µã‚¤ã‚º
count = len(db)

# ã‚­ãƒ¼ä¸€è¦§
keys = db.keys()        # ã™ã¹ã¦ã®ã‚­ãƒ¼
items = db.items()      # (key, value) ã®ãƒšã‚¢
values = db.values()    # ã™ã¹ã¦ã®å€¤
```

#### é«˜åº¦ãªæ“ä½œ

```python
# setdefault: ã‚­ãƒ¼ãŒå­˜åœ¨ã—ãªã‘ã‚Œã°è¨­å®š
value = db.setdefault('counter', 0)  # åˆå›ã¯0ã‚’è¨­å®šã—ã¦è¿”ã™

# pop: å‰Šé™¤ã—ã¦å€¤ã‚’è¿”ã™
value = db.pop('key1', None)  # ã‚­ãƒ¼ã‚’å‰Šé™¤ã—ã¦å€¤ã‚’è¿”ã™

# update: è¤‡æ•°ã®ã‚­ãƒ¼ã‚’ä¸€æ‹¬æ›´æ–°
db.update({
    'key1': 'value1',
    'key2': 'value2',
    'key3': 'value3'
})

# clear: ã™ã¹ã¦ã‚¯ãƒªã‚¢
db.clear()
```

#### ãƒãƒ«ã‚¯æ“ä½œï¼ˆé«˜é€Ÿï¼‰

```python
# bulk_insert: å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’é«˜é€ŸæŒ¿å…¥
data = {f'key_{i}': f'value_{i}' for i in range(10000)}
db.bulk_insert(data)  # 2.3M ops/sec

# ãƒãƒƒãƒèª­ã¿è¾¼ã¿
keys = [f'key_{i}' for i in range(1000)]
for key in keys:
    value = db.get(key)
```

### æ°¸ç¶šåŒ–åˆ¶å¾¡

```python
# Lazyãƒ¢ãƒ¼ãƒ‰ã§ã®æ˜ç¤ºçš„ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
db = DictSQLiteV4('data.db', persist_mode='lazy')
db['key'] = 'value'
db.flush()  # ãƒ‡ã‚£ã‚¹ã‚¯ã«æ›¸ãè¾¼ã¿

# å®‰å…¨ãªã‚¯ãƒ­ãƒ¼ã‚ºï¼ˆè‡ªå‹•ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼‰
db.close()

# ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆæ¨å¥¨ï¼‰
with DictSQLiteV4('data.db') as db:
    db['key'] = 'value'
# è‡ªå‹•çš„ã«flush()ã¨close()ãŒå‘¼ã°ã‚Œã‚‹
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š

```python
import time

db = DictSQLiteV4('benchmark.db', persist_mode='memory')

# æ›¸ãè¾¼ã¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
start = time.perf_counter()
for i in range(10000):
    db[f'key_{i}'] = f'value_{i}'
elapsed = time.perf_counter() - start
ops_per_sec = 10000 / elapsed
print(f'Write: {ops_per_sec:,.0f} ops/sec')

# èª­ã¿è¾¼ã¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
start = time.perf_counter()
for i in range(10000):
    _ = db[f'key_{i}']
elapsed = time.perf_counter() - start
ops_per_sec = 10000 / elapsed
print(f'Read: {ops_per_sec:,.0f} ops/sec')

db.close()
```

---

## éåŒæœŸAPIè©³ç´°

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
import asyncio
from dictsqlite_v4 import AsyncDictSQLite

async def main():
    # åˆæœŸåŒ–
    db = AsyncDictSQLite('async_data.db', persist_mode='lazy')
    
    # éåŒæœŸæ›¸ãè¾¼ã¿
    await db.set_async('key1', 'value1')
    
    # éåŒæœŸèª­ã¿è¾¼ã¿
    value = await db.get_async('key1')
    print(value)  # 'value1'
    
    # ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã¨ã‚¯ãƒ­ãƒ¼ã‚º
    await db.flush()
    await db.close()

# å®Ÿè¡Œ
asyncio.run(main())
```

### ä¸¦è¡Œå‡¦ç†ï¼ˆé«˜æ€§èƒ½ï¼‰

```python
import asyncio
from dictsqlite_v4 import AsyncDictSQLite

async def main():
    db = AsyncDictSQLite('concurrent.db', persist_mode='lazy')
    
    # ä¸¦è¡Œæ›¸ãè¾¼ã¿ï¼ˆé«˜é€Ÿï¼‰
    tasks = [
        db.set_async(f'key_{i}', f'value_{i}')
        for i in range(1000)
    ]
    await asyncio.gather(*tasks)  # ã™ã¹ã¦ä¸¦è¡Œå®Ÿè¡Œ
    
    # ä¸¦è¡Œèª­ã¿è¾¼ã¿ï¼ˆé«˜é€Ÿï¼‰
    tasks = [
        db.get_async(f'key_{i}')
        for i in range(1000)
    ]
    results = await asyncio.gather(*tasks)
    
    await db.flush()
    await db.close()

asyncio.run(main())
```

### ã‚»ãƒãƒ•ã‚©ã«ã‚ˆã‚‹åŒæ™‚å®Ÿè¡Œåˆ¶å¾¡

```python
import asyncio
from dictsqlite_v4 import AsyncDictSQLite

async def main():
    db = AsyncDictSQLite('controlled.db', persist_mode='lazy')
    
    # åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™
    semaphore = asyncio.Semaphore(10)  # æœ€å¤§10ä¸¦è¡Œ
    
    async def limited_write(key, value):
        async with semaphore:
            await db.set_async(key, value)
    
    # å¤§é‡ã®ã‚¿ã‚¹ã‚¯ã‚’åˆ¶å¾¡ã•ã‚ŒãŸä¸¦è¡Œæ•°ã§å®Ÿè¡Œ
    tasks = [
        limited_write(f'key_{i}', f'value_{i}')
        for i in range(10000)
    ]
    await asyncio.gather(*tasks)
    
    await db.flush()
    await db.close()

asyncio.run(main())
```

### ãƒãƒƒãƒå‡¦ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```python
async def batch_process(db, data_chunks):
    """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«å‡¦ç†"""
    
    for chunk in data_chunks:
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ä¸¦è¡Œæ›¸ãè¾¼ã¿
        tasks = [
            db.set_async(key, value)
            for key, value in chunk.items()
        ]
        await asyncio.gather(*tasks)
        
        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆãƒ¡ãƒ¢ãƒªç®¡ç†ï¼‰
        await db.flush()

# ä½¿ç”¨ä¾‹
async def main():
    db = AsyncDictSQLite('batch.db', persist_mode='lazy')
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’1000ã‚¢ã‚¤ãƒ†ãƒ ãšã¤ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
    all_data = {f'key_{i}': f'value_{i}' for i in range(100000)}
    chunk_size = 1000
    chunks = [
        dict(list(all_data.items())[i:i+chunk_size])
        for i in range(0, len(all_data), chunk_size)
    ]
    
    await batch_process(db, chunks)
    await db.close()

asyncio.run(main())
```

---

## æ°¸ç¶šåŒ–ãƒ¢ãƒ¼ãƒ‰é¸æŠã‚¬ã‚¤ãƒ‰

### ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒè¡¨

| ãƒ¢ãƒ¼ãƒ‰ | é€Ÿåº¦ | æ°¸ç¶šæ€§ | ãƒ¡ãƒ¢ãƒª | ç”¨é€” |
|--------|------|--------|--------|------|
| **Memory** | âš¡âš¡âš¡ æœ€é€Ÿ (1.4M ops/sec) | âŒ ãªã— | ğŸ’¾ğŸ’¾ å¤§ | ä¸€æ™‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€ãƒ†ã‚¹ãƒˆ |
| **Lazy** | âš¡âš¡ é«˜é€Ÿ (1.3M ops/sec) | âœ… å®šæœŸçš„ | ğŸ’¾ ä¸­ | é€šå¸¸ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆæ¨å¥¨ï¼‰ |
| **WriteThrough** | âš¡ ä½é€Ÿ (20K ops/sec) | âœ…âœ… å³åº§ | ğŸ’¾ å° | é‡‘èã€ãƒ­ã‚°ã€é‡è¦ãƒ‡ãƒ¼ã‚¿ |

### Memory ãƒ¢ãƒ¼ãƒ‰

**ç‰¹å¾´:**
- ãƒ‡ãƒ¼ã‚¿ã¯ä¸€åˆ‡ãƒ‡ã‚£ã‚¹ã‚¯ã«ä¿å­˜ã•ã‚Œãªã„
- ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†æ™‚ã«ãƒ‡ãƒ¼ã‚¿æ¶ˆå¤±
- æœ€é«˜é€Ÿåº¦: 1,378,988 ops/sec

**æ¨å¥¨ç”¨é€”:**
```python
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥
session_cache = DictSQLiteV4(':memory:', persist_mode='memory')
session_cache[f'user_{user_id}'] = user_data

# ä¸€æ™‚çš„ãªè¨ˆç®—çµæœ
temp_results = DictSQLiteV4('temp.db', persist_mode='memory')
for result in compute_intensive_task():
    temp_results[result.id] = result.data
```

**æ³¨æ„ç‚¹:**
- ãƒ‡ãƒ¼ã‚¿ã¯æ°¸ç¶šåŒ–ã•ã‚Œãªã„
- ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•å¾Œã¯ãƒ‡ãƒ¼ã‚¿ãªã—

### Lazy ãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰

**ç‰¹å¾´:**
- æ›¸ãè¾¼ã¿ã¯ãƒ¡ãƒ¢ãƒªã«ä¿æŒã€å®šæœŸçš„ã«ãƒ‡ã‚£ã‚¹ã‚¯ã¸ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
- é«˜é€Ÿ: 1,316,355 ops/sec
- ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ€§èƒ½ã¨ä¿¡é ¼æ€§

**æ¨å¥¨ç”¨é€”:**
```python
# Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
cache = DictSQLiteV4('app_cache.db', persist_mode='lazy', hot_capacity=100000)
cache[f'api_response_{key}'] = response_data

# å®šæœŸçš„ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
import threading
def periodic_flush():
    while True:
        time.sleep(300)  # 5åˆ†ã”ã¨
        cache.flush()

threading.Thread(target=periodic_flush, daemon=True).start()
```

**ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚¿ã‚¤ãƒŸãƒ³ã‚°:**
```python
# æ‰‹å‹•ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
db.flush()

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†æ™‚
import atexit
atexit.register(db.flush)

# å®šæœŸçš„ãªãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆæ¨å¥¨ï¼‰
import schedule
schedule.every(5).minutes.do(db.flush)
```

### WriteThrough ãƒ¢ãƒ¼ãƒ‰

**ç‰¹å¾´:**
- å„æ›¸ãè¾¼ã¿ã‚’å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã¸æ°¸ç¶šåŒ–
- ãƒ‡ãƒ¼ã‚¿æå¤±ãƒªã‚¹ã‚¯æœ€å°
- ä½é€Ÿ: 20,400 ops/sec

**æ¨å¥¨ç”¨é€”:**
```python
# é‡‘èå–å¼•ãƒ­ã‚°
transaction_log = DictSQLiteV4(
    'transactions.db',
    persist_mode='writethrough'
)
transaction_log[transaction_id] = {
    'amount': 1000.00,
    'timestamp': time.time(),
    'status': 'completed'
}
# å³åº§ã«ãƒ‡ã‚£ã‚¹ã‚¯ã«ä¿å­˜ã•ã‚Œã‚‹

# ç›£æŸ»ãƒ­ã‚°
audit_log = DictSQLiteV4('audit.db', persist_mode='writethrough')
audit_log[f'event_{event_id}'] = audit_event
```

**æœ€é©åŒ–:**
```python
# ãƒãƒ«ã‚¯æ“ä½œã‚’ä½¿ç”¨ï¼ˆWriteThroughã§ã‚‚é«˜é€ŸåŒ–ï¼‰
transactions = {
    f'tx_{i}': {'amount': i * 100, 'status': 'pending'}
    for i in range(1000)
}
transaction_log.bulk_insert(transactions)  # ä¸€æ‹¬æŒ¿å…¥ã¯é«˜é€Ÿ
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. é©åˆ‡ãªhot_capacityè¨­å®š

```python
# ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦èª¿æ•´
small_db = DictSQLiteV4('small.db', hot_capacity=10_000)      # < 10K items
medium_db = DictSQLiteV4('medium.db', hot_capacity=100_000)   # < 100K items
large_db = DictSQLiteV4('large.db', hot_capacity=1_000_000)   # < 1M items
```

**è¨ˆç®—å¼:**
```python
# æ¨å¥¨å®¹é‡ = äºˆæƒ³ãƒ‡ãƒ¼ã‚¿é‡ * 0.2ï¼ˆ20%ã‚’ãƒ›ãƒƒãƒˆã«ä¿æŒï¼‰
estimated_items = 500_000
hot_capacity = int(estimated_items * 0.2)
db = DictSQLiteV4('data.db', hot_capacity=hot_capacity)
```

### 2. ãƒãƒ«ã‚¯æ“ä½œã®æ´»ç”¨

```python
# ğŸŒ é…ã„: ãƒ«ãƒ¼ãƒ—ã§å€‹åˆ¥æŒ¿å…¥
for i in range(10000):
    db[f'key_{i}'] = f'value_{i}'  # 1.2M ops/sec

# âš¡ é«˜é€Ÿ: ãƒãƒ«ã‚¯æŒ¿å…¥
data = {f'key_{i}': f'value_{i}' for i in range(10000)}
db.bulk_insert(data)  # 2.3M ops/secï¼ˆç´„2å€é«˜é€Ÿï¼‰
```

### 3. é©åˆ‡ãªãƒ¢ãƒ¼ãƒ‰é¸æŠ

```python
# èª­ã¿è¾¼ã¿é »åº¦ãŒé«˜ã„å ´åˆ
read_heavy_db = DictSQLiteV4(
    'read_heavy.db',
    persist_mode='lazy',      # é«˜é€Ÿèª­ã¿è¾¼ã¿
    hot_capacity=500_000      # å¤§ãã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
)

# æ›¸ãè¾¼ã¿é »åº¦ãŒé«˜ã„å ´åˆ
write_heavy_db = DictSQLiteV4(
    'write_heavy.db',
    persist_mode='lazy',      # é«˜é€Ÿæ›¸ãè¾¼ã¿
    enable_async=True         # éåŒæœŸãƒ•ãƒ©ãƒƒã‚·ãƒ¥
)

# ãƒ‡ãƒ¼ã‚¿æå¤±ãŒè¨±å®¹ã§ããªã„å ´åˆ
critical_db = DictSQLiteV4(
    'critical.db',
    persist_mode='writethrough'  # å®‰å…¨æ€§å„ªå…ˆ
)
```

### 4. éåŒæœŸå‡¦ç†ã®æ´»ç”¨

```python
import asyncio

async def fast_batch_write():
    db = AsyncDictSQLite('async.db', persist_mode='lazy')
    
    # ä¸¦è¡Œæ›¸ãè¾¼ã¿ï¼ˆé«˜é€Ÿï¼‰
    tasks = [db.set_async(f'key_{i}', f'value_{i}') for i in range(10000)]
    await asyncio.gather(*tasks)
    
    await db.flush()
    await db.close()

# åŒæœŸç‰ˆã‚ˆã‚Šé«˜é€Ÿ
asyncio.run(fast_batch_write())
```

### 5. LRUã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ã®ç†è§£

```python
# LRUã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ãŒç™ºç”Ÿã™ã‚‹å ´åˆ
db = DictSQLiteV4('data.db', hot_capacity=1000)

# 1000ã‚¢ã‚¤ãƒ†ãƒ ã¾ã§ã¯é«˜é€Ÿï¼ˆãƒ¡ãƒ¢ãƒªã‹ã‚‰ï¼‰
for i in range(1000):
    db[f'key_{i}'] = f'value_{i}'  # è¶…é«˜é€Ÿ

# 1001å€‹ç›®ã‹ã‚‰ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ç™ºç”Ÿ
db['key_1000'] = 'value_1000'  # ã‚„ã‚„ä½é€Ÿï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ã‚£ã‚¹ã‚¯ã¸ï¼‰

# èª­ã¿è¾¼ã¿ã¯é€éçš„ï¼ˆè‡ªå‹•çš„ã«ãƒ‡ã‚£ã‚¹ã‚¯ã‹ã‚‰å–å¾—ï¼‰
value = db['key_0']  # ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ã¦ã‚‚å–å¾—å¯èƒ½
```

### 6. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

```python
# Pickleå‡¦ç†ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’é¿ã‘ã‚‹
# âœ… è‰¯ã„: ã‚·ãƒ³ãƒ—ãƒ«ãªå‹
db['key'] = 'string'
db['key'] = 12345
db['key'] = [1, 2, 3]
db['key'] = {'simple': 'dict'}

# âš ï¸ æ³¨æ„: è¤‡é›‘ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯é…ã„
class ComplexObject:
    def __init__(self):
        self.data = [i for i in range(10000)]

db['key'] = ComplexObject()  # PickleåŒ–ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æ©Ÿèƒ½

### AES-256-GCMæš—å·åŒ–

```python
# æš—å·åŒ–ã‚’æœ‰åŠ¹åŒ–
secure_db = DictSQLiteV4(
    'secure.db',
    encryption_password='my_secure_password_123'
)

# é€šå¸¸é€šã‚Šä½¿ç”¨ï¼ˆé€éçš„ã«æš—å·åŒ–ï¼‰
secure_db['secret_key'] = 'confidential_data'
value = secure_db['secret_key']  # è‡ªå‹•çš„ã«å¾©å·åŒ–

secure_db.close()
```

**ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:**
- æš—å·åŒ–æ›¸ãè¾¼ã¿: 600K ops/secï¼ˆæš—å·åŒ–ãªã—ã®ç´„50%ï¼‰
- æš—å·åŒ–èª­ã¿è¾¼ã¿: 1.7M ops/secï¼ˆæš—å·åŒ–ãªã—ã®ç´„72%ï¼‰

**æ¨å¥¨ç”¨é€”:**
```python
# ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æƒ…å ±
auth_db = DictSQLiteV4(
    'auth.db',
    encryption_password=os.environ['DB_PASSWORD'],
    persist_mode='writethrough'  # å®‰å…¨æ€§å„ªå…ˆ
)
auth_db[f'user_{user_id}'] = {
    'password_hash': hash_password(password),
    'salt': salt,
    'mfa_secret': mfa_secret
}

# æ©Ÿå¯†ãƒ­ã‚°
audit_db = DictSQLiteV4(
    'audit.db',
    encryption_password=config['audit_password'],
    persist_mode='writethrough'
)
```

### Safe Pickleæ¤œè¨¼

```python
# Pickleæ¤œè¨¼ã‚’æœ‰åŠ¹åŒ–
safe_db = DictSQLiteV4(
    'safe.db',
    enable_safe_pickle=True,
    safe_pickle_allowed_modules=['datetime', 'decimal', 'myapp.models']
)

# è¨±å¯ã•ã‚ŒãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã¿ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºå¯èƒ½
from datetime import datetime
safe_db['timestamp'] = datetime.now()  # âœ… OK

# ä¸æ­£ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯æ‹’å¦
import pickle
malicious_data = pickle.dumps(eval)  # âš ï¸ å±é™º
# safe_db['bad'] = malicious_data  # âŒ ã‚¨ãƒ©ãƒ¼
```

### ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ç®¡ç†ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

```python
import os
from getpass import getpass

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼ˆæ¨å¥¨ï¼‰
password = os.environ.get('DB_PASSWORD')
if not password:
    password = getpass('Enter database password: ')

db = DictSQLiteV4('secure.db', encryption_password=password)

# ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰æ•°ã‹ã‚‰å‰Šé™¤
password = None
```

---

## ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ä½¿ç”¨

```python
# âœ… æ¨å¥¨: è‡ªå‹•çš„ã«ã‚¯ãƒ­ãƒ¼ã‚º
with DictSQLiteV4('data.db') as db:
    db['key'] = 'value'
# è‡ªå‹•çš„ã«flush()ã¨close()

# âŒ éæ¨å¥¨: æ‰‹å‹•ã‚¯ãƒ­ãƒ¼ã‚º
db = DictSQLiteV4('data.db')
db['key'] = 'value'
db.close()  # å¿˜ã‚Œã‚„ã™ã„
```

### 2. ä¾‹å¤–å‡¦ç†

```python
from dictsqlite_v4 import DictSQLiteV4

try:
    with DictSQLiteV4('data.db') as db:
        value = db['nonexistent_key']
except KeyError:
    print('ã‚­ãƒ¼ãŒå­˜åœ¨ã—ã¾ã›ã‚“')
except Exception as e:
    print(f'ã‚¨ãƒ©ãƒ¼: {e}')
```

### 3. å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†

```python
def process_large_dataset(data_source):
    with DictSQLiteV4('large.db', persist_mode='lazy', hot_capacity=100000) as db:
        batch = {}
        batch_size = 1000
        
        for i, item in enumerate(data_source):
            batch[item.id] = item.data
            
            # 1000ä»¶ã”ã¨ã«ãƒãƒ«ã‚¯æŒ¿å…¥
            if len(batch) >= batch_size:
                db.bulk_insert(batch)
                batch.clear()
                
                # 10000ä»¶ã”ã¨ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
                if i % 10000 == 0:
                    db.flush()
                    print(f'Processed {i} items')
        
        # æ®‹ã‚Šã‚’æŒ¿å…¥
        if batch:
            db.bulk_insert(batch)
        
        db.flush()
```

### 4. ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹å¯¾å¿œ

```python
from multiprocessing import Process
import time

def worker(worker_id, db_path):
    """å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯ç‹¬è‡ªã®DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æŒã¤"""
    db = DictSQLiteV4(db_path, persist_mode='lazy')
    
    for i in range(1000):
        db[f'worker_{worker_id}_item_{i}'] = f'data_{i}'
    
    db.flush()
    db.close()

# è¤‡æ•°ãƒ¯ãƒ¼ã‚«ãƒ¼ã§ä¸¦è¡Œå‡¦ç†
processes = []
for i in range(4):
    p = Process(target=worker, args=(i, f'worker_{i}.db'))
    p.start()
    processes.append(p)

for p in processes:
    p.join()
```

### 5. ãƒ­ã‚°è¨˜éŒ²

```python
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

with DictSQLiteV4('data.db') as db:
    logger.info(f'Database opened with {len(db)} items')
    
    db['new_key'] = 'new_value'
    logger.info('Item added')
    
    db.flush()
    logger.info('Database flushed')
```

### 6. å®šæœŸçš„ãªãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

```python
import schedule
import time

def maintain_database():
    with DictSQLiteV4('data.db') as db:
        # å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
        current_time = time.time()
        expired_keys = [
            key for key in db.keys()
            if key.startswith('cache_') and is_expired(db[key], current_time)
        ]
        
        for key in expired_keys:
            del db[key]
        
        db.flush()
        print(f'Removed {len(expired_keys)} expired items')

# 1æ™‚é–“ã”ã¨ã«ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
schedule.every(1).hour.do(maintain_database)

while True:
    schedule.run_pending()
    time.sleep(60)
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

#### 1. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼

**å•é¡Œ:**
```python
db = DictSQLiteV4('huge.db', hot_capacity=10_000_000)  # å¤§ãã™ãã‚‹
# MemoryError
```

**è§£æ±ºç­–:**
```python
# hot_capacityã‚’æ¸›ã‚‰ã™
db = DictSQLiteV4('huge.db', hot_capacity=500_000)

# ã¾ãŸã¯LRUã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³ã«ä»»ã›ã‚‹
db = DictSQLiteV4('huge.db', hot_capacity=100_000)  # è‡ªå‹•çš„ã«ãƒ‡ã‚£ã‚¹ã‚¯ã¸é€€é¿
```

#### 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒé…ã„

**å•é¡Œ:**
```python
# WriteThroughãƒ¢ãƒ¼ãƒ‰ã§å¤§é‡æ›¸ãè¾¼ã¿
db = DictSQLiteV4('data.db', persist_mode='writethrough')
for i in range(100000):
    db[f'key_{i}'] = f'value_{i}'  # é…ã„: 20K ops/sec
```

**è§£æ±ºç­–:**
```python
# Lazyãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
db = DictSQLiteV4('data.db', persist_mode='lazy')
for i in range(100000):
    db[f'key_{i}'] = f'value_{i}'  # é«˜é€Ÿ: 1.3M ops/sec
db.flush()

# ã¾ãŸã¯ãƒãƒ«ã‚¯æ“ä½œã‚’ä½¿ç”¨
data = {f'key_{i}': f'value_{i}' for i in range(100000)}
db.bulk_insert(data)  # ã•ã‚‰ã«é«˜é€Ÿ: 2.3M ops/sec
```

#### 3. ãƒ‡ãƒ¼ã‚¿æå¤±

**å•é¡Œ:**
```python
db = DictSQLiteV4('data.db', persist_mode='lazy')
db['important'] = 'data'
# ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ â†’ ãƒ‡ãƒ¼ã‚¿æå¤±
```

**è§£æ±ºç­–:**
```python
# é‡è¦ãªãƒ‡ãƒ¼ã‚¿ã¯WriteThroughãƒ¢ãƒ¼ãƒ‰
critical_db = DictSQLiteV4('critical.db', persist_mode='writethrough')
critical_db['important'] = 'data'  # å³åº§ã«ä¿å­˜

# ã¾ãŸã¯Lazyãƒ¢ãƒ¼ãƒ‰ã§å®šæœŸçš„ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
db = DictSQLiteV4('data.db', persist_mode='lazy')
db['important'] = 'data'
db.flush()  # æ˜ç¤ºçš„ã«ãƒ•ãƒ©ãƒƒã‚·ãƒ¥
```

#### 4. æš—å·åŒ–ãŒé…ã„

**å•é¡Œ:**
```python
db = DictSQLiteV4('data.db', encryption_password='pass')
# æš—å·åŒ–ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã§é…ã„
```

**è§£æ±ºç­–:**
```python
# æœ¬å½“ã«æš—å·åŒ–ãŒå¿…è¦ã‹æ¤œè¨
# ä¸è¦ãªã‚‰æš—å·åŒ–ãªã—ã§ä½¿ç”¨
fast_db = DictSQLiteV4('data.db')  # æš—å·åŒ–ãªã—

# ã¾ãŸã¯æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®ã¿æš—å·åŒ–
normal_db = DictSQLiteV4('normal.db')  # é€šå¸¸ãƒ‡ãƒ¼ã‚¿
secure_db = DictSQLiteV4('secure.db', encryption_password='pass')  # æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿
```

#### 5. KeyError

**å•é¡Œ:**
```python
value = db['nonexistent_key']  # KeyError
```

**è§£æ±ºç­–:**
```python
# get()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨
value = db.get('nonexistent_key', 'default_value')

# ã¾ãŸã¯å­˜åœ¨ãƒã‚§ãƒƒã‚¯
if 'key' in db:
    value = db['key']

# ã¾ãŸã¯ä¾‹å¤–å‡¦ç†
try:
    value = db['key']
except KeyError:
    value = 'default_value'
```

---

## å®Ÿè·µä¾‹

### ä¾‹1: Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥

```python
from dictsqlite_v4 import DictSQLiteV4
import time
import hashlib

class APICache:
    def __init__(self, cache_file='api_cache.db', ttl=3600):
        self.db = DictSQLiteV4(
            cache_file,
            persist_mode='lazy',
            hot_capacity=50000
        )
        self.ttl = ttl
    
    def get_cache_key(self, endpoint, params):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        key_str = f"{endpoint}:{str(sorted(params.items()))}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, endpoint, params):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—"""
        key = self.get_cache_key(endpoint, params)
        
        if key in self.db:
            cached = self.db[key]
            if time.time() - cached['timestamp'] < self.ttl:
                return cached['data']
        
        return None
    
    def set(self, endpoint, params, data):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜"""
        key = self.get_cache_key(endpoint, params)
        self.db[key] = {
            'data': data,
            'timestamp': time.time()
        }
    
    def cleanup(self):
        """æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤"""
        current_time = time.time()
        expired = []
        
        for key in self.db.keys():
            cached = self.db[key]
            if current_time - cached['timestamp'] >= self.ttl:
                expired.append(key)
        
        for key in expired:
            del self.db[key]
        
        self.db.flush()
        return len(expired)
    
    def close(self):
        self.db.close()

# ä½¿ç”¨ä¾‹
cache = APICache(ttl=3600)  # 1æ™‚é–“ã®TTL

# APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def fetch_user_data(user_id):
    endpoint = '/api/users'
    params = {'id': user_id}
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ãƒã‚§ãƒƒã‚¯
    cached = cache.get(endpoint, params)
    if cached:
        print('Cache hit!')
        return cached
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹: APIã‚’å‘¼ã³å‡ºã—
    print('Cache miss, fetching from API...')
    data = call_external_api(endpoint, params)
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
    cache.set(endpoint, params, data)
    return data

# å®šæœŸçš„ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
import schedule
schedule.every(1).hour.do(cache.cleanup)
```

### ä¾‹2: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

```python
from dictsqlite_v4 import DictSQLiteV4
import uuid
import time

class SessionManager:
    def __init__(self, session_file='sessions.db', timeout=1800):
        self.db = DictSQLiteV4(
            session_file,
            persist_mode='lazy',
            hot_capacity=10000
        )
        self.timeout = timeout
    
    def create_session(self, user_id, user_data):
        """æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ"""
        session_id = str(uuid.uuid4())
        self.db[session_id] = {
            'user_id': user_id,
            'user_data': user_data,
            'created_at': time.time(),
            'last_accessed': time.time()
        }
        return session_id
    
    def get_session(self, session_id):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
        if session_id not in self.db:
            return None
        
        session = self.db[session_id]
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒã‚§ãƒƒã‚¯
        if time.time() - session['last_accessed'] > self.timeout:
            del self.db[session_id]
            return None
        
        # ã‚¢ã‚¯ã‚»ã‚¹æ™‚åˆ»ã‚’æ›´æ–°
        session['last_accessed'] = time.time()
        self.db[session_id] = session
        
        return session
    
    def update_session(self, session_id, user_data):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°"""
        if session_id in self.db:
            session = self.db[session_id]
            session['user_data'] = user_data
            session['last_accessed'] = time.time()
            self.db[session_id] = session
    
    def delete_session(self, session_id):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤"""
        if session_id in self.db:
            del self.db[session_id]
    
    def cleanup_expired(self):
        """æœŸé™åˆ‡ã‚Œã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤"""
        current_time = time.time()
        expired = []
        
        for session_id in self.db.keys():
            session = self.db[session_id]
            if current_time - session['last_accessed'] > self.timeout:
                expired.append(session_id)
        
        for session_id in expired:
            del self.db[session_id]
        
        self.db.flush()
        return len(expired)
    
    def close(self):
        self.db.flush()
        self.db.close()

# ä½¿ç”¨ä¾‹
sessions = SessionManager(timeout=1800)  # 30åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆ
session_id = sessions.create_session(
    user_id=123,
    user_data={'username': 'alice', 'role': 'admin'}
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—
session = sessions.get_session(session_id)
if session:
    print(f"User: {session['user_data']['username']}")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°
sessions.update_session(session_id, {'username': 'alice', 'role': 'superadmin'})

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆå®šæœŸçš„ã«å®Ÿè¡Œï¼‰
import schedule
schedule.every(10).minutes.do(sessions.cleanup_expired)
```

### ä¾‹3: ã‚¸ãƒ§ãƒ–ã‚­ãƒ¥ãƒ¼

```python
import asyncio
from dictsqlite_v4 import AsyncDictSQLite
import time
import uuid

class AsyncJobQueue:
    def __init__(self, queue_file='jobs.db'):
        self.db = AsyncDictSQLite(queue_file, persist_mode='lazy')
    
    async def enqueue(self, job_type, job_data, priority=5):
        """ã‚¸ãƒ§ãƒ–ã‚’ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ """
        job_id = str(uuid.uuid4())
        await self.db.set_async(job_id, {
            'type': job_type,
            'data': job_data,
            'priority': priority,
            'status': 'pending',
            'created_at': time.time(),
            'attempts': 0
        })
        return job_id
    
    async def dequeue(self):
        """æœ€å„ªå…ˆã‚¸ãƒ§ãƒ–ã‚’å–å¾—"""
        # ã™ã¹ã¦ã®pendingã‚¸ãƒ§ãƒ–ã‚’å–å¾—
        all_jobs = {}
        for key in await self.db.keys_async():
            job = await self.db.get_async(key)
            if job['status'] == 'pending':
                all_jobs[key] = job
        
        if not all_jobs:
            return None, None
        
        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        sorted_jobs = sorted(
            all_jobs.items(),
            key=lambda x: (x[1]['priority'], x[1]['created_at']),
            reverse=True
        )
        
        job_id, job = sorted_jobs[0]
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å‡¦ç†ä¸­ã«æ›´æ–°
        job['status'] = 'processing'
        job['started_at'] = time.time()
        await self.db.set_async(job_id, job)
        
        return job_id, job
    
    async def complete(self, job_id):
        """ã‚¸ãƒ§ãƒ–ã‚’å®Œäº†ã¨ã—ã¦ãƒãƒ¼ã‚¯"""
        job = await self.db.get_async(job_id)
        if job:
            job['status'] = 'completed'
            job['completed_at'] = time.time()
            await self.db.set_async(job_id, job)
        await self.db.flush()
    
    async def fail(self, job_id, error_message, max_retries=3):
        """ã‚¸ãƒ§ãƒ–ã‚’å¤±æ•—ã¨ã—ã¦ãƒãƒ¼ã‚¯"""
        job = await self.db.get_async(job_id)
        if job:
            job['attempts'] += 1
            
            if job['attempts'] >= max_retries:
                job['status'] = 'failed'
                job['error'] = error_message
            else:
                job['status'] = 'pending'  # ãƒªãƒˆãƒ©ã‚¤
            
            await self.db.set_async(job_id, job)
        await self.db.flush()
    
    async def close(self):
        await self.db.flush()
        await self.db.close()

# ä½¿ç”¨ä¾‹
async def worker(queue):
    """ã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†ã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼"""
    while True:
        job_id, job = await queue.dequeue()
        
        if not job:
            await asyncio.sleep(1)
            continue
        
        try:
            print(f"Processing job {job_id}: {job['type']}")
            
            # ã‚¸ãƒ§ãƒ–å‡¦ç†ï¼ˆä¾‹ï¼‰
            if job['type'] == 'send_email':
                await send_email(job['data'])
            elif job['type'] == 'generate_report':
                await generate_report(job['data'])
            
            await queue.complete(job_id)
            print(f"Job {job_id} completed")
            
        except Exception as e:
            print(f"Job {job_id} failed: {e}")
            await queue.fail(job_id, str(e))

async def main():
    queue = AsyncJobQueue()
    
    # ã‚¸ãƒ§ãƒ–ã‚’è¿½åŠ 
    await queue.enqueue('send_email', {'to': 'user@example.com'}, priority=10)
    await queue.enqueue('generate_report', {'report_id': 123}, priority=5)
    
    # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•
    workers = [worker(queue) for _ in range(3)]  # 3ä¸¦è¡Œãƒ¯ãƒ¼ã‚«ãƒ¼
    await asyncio.gather(*workers)
    
    await queue.close()

# asyncio.run(main())
```

### ä¾‹4: é«˜é€Ÿã‚«ã‚¦ãƒ³ã‚¿ãƒ¼

```python
from dictsqlite_v4 import DictSQLiteV4
import threading

class AtomicCounter:
    def __init__(self, db_file='counters.db'):
        self.db = DictSQLiteV4(db_file, persist_mode='lazy')
        self.lock = threading.Lock()
    
    def increment(self, key, amount=1):
        """ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’å¢—åŠ """
        with self.lock:
            current = self.db.get(key, 0)
            new_value = current + amount
            self.db[key] = new_value
            return new_value
    
    def decrement(self, key, amount=1):
        """ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’æ¸›å°‘"""
        return self.increment(key, -amount)
    
    def get(self, key):
        """ç¾åœ¨ã®å€¤ã‚’å–å¾—"""
        return self.db.get(key, 0)
    
    def reset(self, key):
        """ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆ"""
        with self.lock:
            self.db[key] = 0
    
    def flush(self):
        """ãƒ‡ã‚£ã‚¹ã‚¯ã«ä¿å­˜"""
        self.db.flush()
    
    def close(self):
        self.db.flush()
        self.db.close()

# ä½¿ç”¨ä¾‹
counter = AtomicCounter()

# ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã§å®‰å…¨ã«ã‚«ã‚¦ãƒ³ãƒˆ
def worker():
    for _ in range(1000):
        counter.increment('total_requests')
        counter.increment('worker_count')

threads = [threading.Thread(target=worker) for _ in range(10)]
for t in threads:
    t.start()
for t in threads:
    t.join()

print(f"Total requests: {counter.get('total_requests')}")
print(f"Worker count: {counter.get('worker_count')}")

counter.flush()
counter.close()
```

---

## ã¾ã¨ã‚

### ã‚¯ã‚¤ãƒƒã‚¯ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**æœ€é€Ÿè¨­å®š:**
```python
db = DictSQLiteV4('data.db', persist_mode='memory', hot_capacity=1_000_000)
```

**ãƒãƒ©ãƒ³ã‚¹è¨­å®šï¼ˆæ¨å¥¨ï¼‰:**
```python
db = DictSQLiteV4('data.db', persist_mode='lazy', hot_capacity=100_000)
```

**å®‰å…¨æ€§å„ªå…ˆ:**
```python
db = DictSQLiteV4('data.db', persist_mode='writethrough', encryption_password='pass')
```

### æ€§èƒ½ç›®æ¨™

| æ“ä½œ | ç›®æ¨™é€Ÿåº¦ |
|------|----------|
| åŸºæœ¬æ“ä½œï¼ˆget/setï¼‰ | > 1M ops/sec |
| ãƒãƒ«ã‚¯æ“ä½œ | > 2M ops/sec |
| æš—å·åŒ–æ“ä½œ | > 600K ops/sec |
| LRUèª­ã¿è¾¼ã¿ | > 2M ops/sec |

### ã‚µãƒãƒ¼ãƒˆ

- GitHub Issues: [DictSQLite Issues](https://github.com/disnana/DictSQLite/issues)
- ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ: `BENCHMARK_RESULTS_JP.md`
- ãƒ†ã‚¹ãƒˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: `TESTING_DOCUMENTATION_JP.md`

---

**æœ€çµ‚æ›´æ–°**: 2024å¹´12æœˆ  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: DictSQLite v4.1  
**è‘—è€…**: DictSQLite Development Team
