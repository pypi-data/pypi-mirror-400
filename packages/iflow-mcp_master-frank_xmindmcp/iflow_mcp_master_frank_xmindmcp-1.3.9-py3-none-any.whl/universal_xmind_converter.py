#!/usr/bin/env python3
"""
Universal XMind Converter

A Python tool that converts multiple file formats (TXT, HTML, Word, Excel, Markdown) to XMind mind map format.
Supports automatic format detection and extensible parser architecture.

Version: 2.0
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
import mimetypes
from xmind_writer import create_xmind_file

# ä¾èµ–æ”¹ä¸ºæ‡’åŠ è½½ï¼Œé¿å…åœ¨æ¨¡å—å¯¼å…¥æ—¶å¼•å…¥é‡é‡åº“
def _lazy_import_docx():
    try:
        import importlib
        return importlib.import_module('docx')
    except Exception as e:
        raise ImportError("éœ€è¦å®‰è£…python-docx: pip install python-docx") from e

def _lazy_import_openpyxl():
    try:
        import importlib
        return importlib.import_module('openpyxl')
    except Exception as e:
        raise ImportError("éœ€è¦å®‰è£…openpyxl: pip install openpyxl") from e

def _lazy_import_beautifulsoup():
    try:
        from bs4 import BeautifulSoup
        return BeautifulSoup
    except Exception as e:
        raise ImportError("éœ€è¦å®‰è£…BeautifulSoup4: pip install beautifulsoup4") from e


def escape_xml_text(text):
    """Escape XML special characters"""
    if not text:
        return ""
    return (text.replace("&", "&amp;")
               .replace("<", "&lt;")
               .replace(">", "&gt;")
               .replace("\"", "&quot;")
               .replace("'", "&apos;"))


def generate_id():
    """Generate unique ID"""
    import uuid
    return str(uuid.uuid4()).replace('-', '')


def create_json_structure(title, children):
    """Create JSON structure"""
    return {
        "id": generate_id(),
        "class": "sheet",
        "rootTopic": {
            "id": generate_id(),
            "class": "topic",
            "title": title,
            "structureClass": "org.xmind.ui.logic.right",
            "children": {
                "attached": children
            }
        },
        "title": "ç”»å¸ƒ 1",
        "extensions": [{
            "provider": "org.xmind.ui.skeleton.structure.style",
            "content": {
                "centralTopic": "org.xmind.ui.logic.right"
            }
        }],
        "theme": {
            "map": {
                "id": generate_id(),
                "properties": {
                    "svg:fill": "#ffffff",
                    "multi-line-colors": "#F9423A #F6A04D #F3D321 #00BC7B #486AFF #4D49BE",
                    "color-list": "#000229 #1F2766 #52CC83 #4D86DB #99142F #245570",
                    "line-tapered": "none"
                }
            },
            "centralTopic": {
                "id": generate_id(),
                "properties": {
                    "fo:font-family": "Droid Serif",
                    "fo:font-size": "30pt",
                    "fo:font-weight": "400",
                    "fo:font-style": "normal",
                    "fo:color": "inherited",
                    "fo:text-transform": "manual",
                    "fo:text-decoration": "none",
                    "fo:text-align": "center",
                    "svg:fill": "#000229",
                    "fill-pattern": "solid",
                    "line-width": "3pt",
                    "line-color": "#000229",
                    "line-pattern": "solid",
                    "border-line-color": "inherited",
                    "border-line-width": "3pt",
                    "border-line-pattern": "inherited",
                    "shape-class": "org.xmind.topicShape.roundedRect",
                    "line-class": "org.xmind.branchConnection.roundedElbow",
                    "arrow-end-class": "org.xmind.arrowShape.none",
                    "alignment-by-level": "inactived"
                }
            },
            "mainTopic": {
                "id": generate_id(),
                "properties": {
                    "fo:font-family": "Droid Serif",
                    "fo:font-size": "18pt",
                    "fo:font-weight": "400",
                    "fo:font-style": "normal",
                    "fo:color": "inherited",
                    "fo:text-transform": "manual",
                    "fo:text-decoration": "none",
                    "fo:text-align": "left",
                    "svg:fill": "inherited",
                    "fill-pattern": "none",
                    "line-width": "inherited",
                    "line-color": "inherited",
                    "line-pattern": "inherited",
                    "border-line-color": "inherited",
                    "border-line-width": "0pt",
                    "border-line-pattern": "inherited",
                    "shape-class": "org.xmind.topicShape.roundedRect",
                    "line-class": "org.xmind.branchConnection.roundedElbow",
                    "arrow-end-class": "inherited"
                }
            },
            "subTopic": {
                "id": generate_id(),
                "properties": {
                    "fo:font-family": "Droid Serif",
                    "fo:font-size": "14pt",
                    "fo:font-weight": "400",
                    "fo:font-style": "normal",
                    "fo:color": "inherited",
                    "fo:text-transform": "manual",
                    "fo:text-decoration": "none",
                    "fo:text-align": "left",
                    "svg:fill": "inherited",
                    "fill-pattern": "none",
                    "line-width": "2pt",
                    "line-color": "inherited",
                    "line-pattern": "inherited",
                    "border-line-color": "inherited",
                    "border-line-width": "0pt",
                    "border-line-pattern": "inherited",
                    "shape-class": "org.xmind.topicShape.roundedRect",
                    "line-class": "org.xmind.branchConnection.roundedElbow",
                    "arrow-end-class": "inherited"
                }
            },
            "skeletonThemeId": "c1fbada1b45ba2e3bfc3b8b57b",
            "colorThemeId": "Rainbow-#000229-MULTI_LINE_COLORS"
        }
    }


def create_topic(title, children=None):
    """Create topic node"""
    topic = {
        "id": generate_id(),
        "title": title
    }
    
    if children:
        topic["children"] = {
            "attached": children
        }
    
    return topic


# ==============================================
# æ–‡ä»¶æ ¼å¼è§£æå™¨åŸºç±»
# ==============================================

class BaseParser:
    """åŸºç¡€è§£æå™¨ç±»"""
    
    def __init__(self, file_path):
        self.file_path = file_path
    
    def parse(self):
        """è§£ææ–‡ä»¶å¹¶è¿”å›JSONç»“æ„"""
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°parseæ–¹æ³•")
    
    def extract_title(self, content):
        """æå–æ ‡é¢˜"""
        return Path(self.file_path).stem


# ==============================================
# Markdownè§£æå™¨
# ==============================================

class MarkdownParser(BaseParser):
    """Markdownæ–‡ä»¶è§£æå™¨"""
    
    def parse(self):
        """è§£æMarkdownæ–‡ä»¶"""
        with open(self.file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        lines = content.split('\n')
        title = self.extract_title_from_content(lines)
        
        # æ„å»ºå±‚çº§ç»“æ„
        topics_by_level = {}
        root_children = []
        title_extracted = False
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # æ£€æµ‹æ ‡é¢˜çº§åˆ«
            if line.startswith('#### '):
                level = 4
                title_text = line[5:].strip()
            elif line.startswith('### '):
                level = 3
                title_text = line[4:].strip()
            elif line.startswith('## '):
                level = 2
                title_text = line[3:].strip()
            elif line.startswith('# '):
                level = 1
                title_text = line[2:].strip()
                # ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ä½œä¸ºæ–‡æ¡£æ ‡é¢˜ï¼Œä¸å¤„ç†ä¸ºèŠ‚ç‚¹
                if not title_extracted:
                    title_extracted = True
                    continue
            else:
                continue
            
            # åˆ›å»ºtopic
            topic = create_topic(title_text)
            topics_by_level[level] = topic
            
            # æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
            if level == 1:
                # ä¸€çº§æ ‡é¢˜ç›´æ¥ä½œä¸ºæ ¹èŠ‚ç‚¹çš„å­èŠ‚ç‚¹
                root_children.append(topic)
            else:
                # å…¶ä»–çº§åˆ«çš„æ ‡é¢˜ï¼Œæ‰¾åˆ°çˆ¶èŠ‚ç‚¹ï¼ˆçº§åˆ«-1ï¼‰
                parent_level = level - 1
                parent_found = False
                
                # ä»å½“å‰çº§åˆ«å¾€ä¸Šæ‰¾ï¼Œç›´åˆ°æ‰¾åˆ°åˆé€‚çš„çˆ¶èŠ‚ç‚¹
                while parent_level >= 1 and not parent_found:
                    if parent_level in topics_by_level:
                        parent_topic = topics_by_level[parent_level]
                        if "children" not in parent_topic:
                            parent_topic["children"] = {"attached": []}
                        parent_topic["children"]["attached"].append(topic)
                        parent_found = True
                    else:
                        parent_level -= 1
                
                # å¦‚æœæ²¡æ‰¾åˆ°çˆ¶èŠ‚ç‚¹ï¼Œå°±ä½œä¸ºæ ¹èŠ‚ç‚¹çš„å­èŠ‚ç‚¹
                if not parent_found:
                    root_children.append(topic)
        
        return create_json_structure(title, root_children)
    
    def extract_title_from_content(self, lines):
        """ä»å†…å®¹ä¸­æå–æ ‡é¢˜"""
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
        return Path(self.file_path).stem
    
    def parse_markdown_to_json(self, markdown_file):
        """è§£æMarkdownæ–‡ä»¶å¹¶è½¬æ¢ä¸ºJSONç»“æ„ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰"""
        return self.parse()


# ==============================================
# æ–‡æœ¬å¤§çº²è§£æå™¨
# ==============================================

class TextOutlineParser(BaseParser):
    """æ–‡æœ¬å¤§çº²è§£æå™¨ - æ”¯æŒç¼©è¿›å±‚çº§"""
    
    def parse(self):
        """è§£ææ–‡æœ¬å¤§çº²æ–‡ä»¶"""
        with open(self.file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        title = self.extract_title(lines)
        
        # æ„å»ºå±‚çº§ç»“æ„
        topics_by_level = {}
        root_children = []
        
        # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆå¦‚æœæ ‡é¢˜è¡Œå­˜åœ¨ï¼‰
        title_found = False
        for line in lines:
            line = line.rstrip('\n\r')
            if not line.strip():
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜è¡Œ
            stripped_line = line.lstrip()
            if stripped_line.strip() == title.strip() and not title_found:
                title_found = True
                continue  # è·³è¿‡æ ‡é¢˜è¡Œ
            
            # è®¡ç®—ç¼©è¿›çº§åˆ«
            indent_level = len(line) - len(stripped_line)
            level = self.indent_to_level(indent_level)
            title_text = stripped_line.strip('-*â€¢ ')
            
            if not title_text:
                continue
            
            # åˆ›å»ºtopic
            topic = create_topic(title_text)
            topics_by_level[level] = topic
            
            # æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
            if level == 0:
                root_children.append(topic)
            else:
                parent_level = level - 1
                if parent_level in topics_by_level:
                    parent_topic = topics_by_level[parent_level]
                    if "children" not in parent_topic:
                        parent_topic["children"] = {"attached": []}
                    parent_topic["children"]["attached"].append(topic)
                else:
                    # çˆ¶å±‚çº§ä¸å­˜åœ¨ï¼Œç›´æ¥æ·»åŠ åˆ°æ ¹èŠ‚ç‚¹
                    root_children.append(topic)
        
        return create_json_structure(title, root_children)
    
    def indent_to_level(self, indent):
        """å°†ç¼©è¿›è½¬æ¢ä¸ºå±‚çº§"""
        # å‡è®¾æ¯4ä¸ªç©ºæ ¼æˆ–1ä¸ªåˆ¶è¡¨ç¬¦ä¸ºä¸€çº§
        return indent // 4
    
    def extract_title(self, lines):
        """æå–æ ‡é¢˜"""
        for line in lines:
            stripped = line.strip()
            if stripped and not stripped.startswith((' ', '\t', '-', '*', 'â€¢')):
                return stripped
        return Path(self.file_path).stem


# ==============================================
# HTMLè§£æå™¨
# ==============================================

class HtmlParser(BaseParser):
    """HTMLæ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, file_path):
        super().__init__(file_path)
    
    def parse(self):
        """è§£æHTMLæ–‡ä»¶"""
        with open(self.file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        BeautifulSoup = _lazy_import_beautifulsoup()
        soup = BeautifulSoup(content, 'html.parser')
        title = self.extract_title(soup)
        
        # æŸ¥æ‰¾æ ‡é¢˜ç»“æ„ (h1-h6)
        root_children = []
        topics_by_level = {}
        
        for heading_tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            headings = soup.find_all(heading_tag)
            level = int(heading_tag[1]) - 1  # h1=0, h2=1, etc.
            
            for heading in headings:
                title_text = heading.get_text().strip()
                if not title_text:
                    continue
                
                topic = create_topic(title_text)
                topics_by_level[level] = topic
                
                if level == 0:
                    root_children.append(topic)
                else:
                    parent_level = level - 1
                    if parent_level in topics_by_level:
                        parent_topic = topics_by_level[parent_level]
                        if "children" not in parent_topic:
                            parent_topic["children"] = {"attached": []}
                        parent_topic["children"]["attached"].append(topic)
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œå°è¯•åˆ—è¡¨ç»“æ„
        if not root_children:
            root_children = self.parse_lists(soup)
        
        return create_json_structure(title, root_children)
    
    def extract_title(self, soup):
        """æå–æ ‡é¢˜"""
        title_tag = soup.find('title')
        if title_tag:
            return title_tag.get_text().strip()
        
        h1_tag = soup.find('h1')
        if h1_tag:
            return h1_tag.get_text().strip()
        
        return Path(self.file_path).stem
    
    def parse_lists(self, soup):
        """è§£æåˆ—è¡¨ç»“æ„"""
        def parse_list_items(items, level=0):
            topics = []
            for item in items:
                text = item.get_text().strip()
                if text:
                    topic = create_topic(text)
                    
                    # æŸ¥æ‰¾å­åˆ—è¡¨
                    sublist = item.find(['ul', 'ol'])
                    if sublist:
                        sub_items = sublist.find_all('li', recursive=False)
                        if sub_items:
                            sub_topics = parse_list_items(sub_items, level + 1)
                            if sub_topics:
                                topic["children"] = {"attached": sub_topics}
                    
                    topics.append(topic)
            return topics
        
        # æŸ¥æ‰¾é¡¶çº§åˆ—è¡¨
        root_topics = []
        for list_tag in soup.find_all(['ul', 'ol']):
            # åªå¤„ç†é¡¶çº§åˆ—è¡¨ï¼ˆä¸åœ¨å…¶ä»–åˆ—è¡¨å†…çš„ï¼‰
            if not list_tag.find_parent(['ul', 'ol']):
                items = list_tag.find_all('li', recursive=False)
                if items:
                    root_topics.extend(parse_list_items(items))
        
        return root_topics


# ==============================================
# Wordæ–‡æ¡£è§£æå™¨
# ==============================================

class WordParser(BaseParser):
    """Wordæ–‡æ¡£è§£æå™¨"""
    
    def __init__(self, file_path):
        super().__init__(file_path)
    
    def parse(self):
        """è§£æWordæ–‡æ¡£"""
        docx = _lazy_import_docx()
        doc = docx.Document(self.file_path)
        title = self.extract_title(doc)
        
        # æŒ‰æ®µè½è§£æ
        root_children = []
        topics_by_level = {}
        
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if not text:
                continue
            
            # æ ¹æ®æ ·å¼åˆ¤æ–­å±‚çº§
            level = self.get_heading_level(paragraph)
            if level is not None:
                topic = create_topic(text)
                topics_by_level[level] = topic
                
                if level == 0:
                    root_children.append(topic)
                else:
                    parent_level = level - 1
                    if parent_level in topics_by_level:
                        parent_topic = topics_by_level[parent_level]
                        if "children" not in parent_topic:
                            parent_topic["children"] = {"attached": []}
                        parent_topic["children"]["attached"].append(topic)
        
        return create_json_structure(title, root_children)
    
    def extract_title(self, doc):
        """æå–æ ‡é¢˜"""
        # å°è¯•ä»å±æ€§ä¸­è·å–
        if doc.core_properties.title:
            return doc.core_properties.title
        
        # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªæ ‡é¢˜
        for paragraph in doc.paragraphs:
            if paragraph.style and 'Heading' in paragraph.style.name:
                return paragraph.text.strip()
        
        # ä½¿ç”¨æ–‡ä»¶å
        return Path(self.file_path).stem
    
    def get_heading_level(self, paragraph):
        """è·å–æ®µè½æ ‡é¢˜çº§åˆ«"""
        if not paragraph.style:
            return None
        
        style_name = paragraph.style.name
        
        # Wordæ ‡å‡†æ ‡é¢˜æ ·å¼
        if style_name.startswith('Heading '):
            try:
                level = int(style_name.split()[-1]) - 1
                return min(level, 5)  # é™åˆ¶æœ€å¤§å±‚çº§
            except ValueError:
                pass
        
        # è‡ªå®šä¹‰æ ‡é¢˜æ ·å¼
        heading_patterns = ['æ ‡é¢˜', 'Heading', 'head', 'title']
        for i, pattern in enumerate(heading_patterns):
            if pattern.lower() in style_name.lower():
                return i
        
        return None


# ==============================================
# Excelè§£æå™¨
# ==============================================

class ExcelParser(BaseParser):
    """Excelæ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, file_path):
        super().__init__(file_path)
    
    def parse(self):
        """è§£æExcelæ–‡ä»¶"""
        openpyxl = _lazy_import_openpyxl()
        wb = openpyxl.load_workbook(self.file_path)
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨
        ws = wb.active
        title = self.extract_title(ws)
        
        # æŒ‰å±‚çº§ç»„ç»‡æ•°æ®
        root_children = []
        
        # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯å±‚çº§ï¼Œç¬¬äºŒåˆ—æ˜¯å†…å®¹
        # æˆ–è€…æŒ‰ç¼©è¿›å±‚çº§è§£æ
        current_topics = {}  # level -> topic
        
        for row in ws.iter_rows(min_row=1, values_only=True):
            if not row or not row[0]:
                continue
            
            # å°è¯•ä¸åŒçš„è§£æç­–ç•¥
            level, text = self.parse_row(row)
            if text:
                topic = create_topic(text)
                current_topics[level] = topic
                
                if level == 0:
                    root_children.append(topic)
                else:
                    parent_level = level - 1
                    if parent_level in current_topics:
                        parent_topic = current_topics[parent_level]
                        if "children" not in parent_topic:
                            parent_topic["children"] = {"attached": []}
                        parent_topic["children"]["attached"].append(topic)
        
        return create_json_structure(title, root_children)
    
    def extract_title(self, worksheet):
        """æå–æ ‡é¢˜"""
        # ä½¿ç”¨å·¥ä½œè¡¨åç§°
        title = worksheet.title
        
        # æˆ–è€…ä½¿ç”¨ç¬¬ä¸€ä¸ªéç©ºå•å…ƒæ ¼
        if not title or title == 'Sheet1':
            for row in worksheet.iter_rows(min_row=1, max_row=1, values_only=True):
                for cell in row:
                    if cell:
                        title = str(cell)
                        break
        
        return title or Path(self.file_path).stem
    
    def parse_row(self, row):
        """è§£æè¡Œæ•°æ®"""
        # ç­–ç•¥1: ç¬¬ä¸€åˆ—æ˜¯å±‚çº§ï¼Œç¬¬äºŒåˆ—æ˜¯å†…å®¹
        if len(row) >= 2:
            try:
                level = int(row[0]) if isinstance(row[0], (int, float)) else 0
                text = str(row[1]) if row[1] else ""
                return level, text.strip()
            except (ValueError, TypeError):
                pass
        
        # ç­–ç•¥2: æŒ‰ç¼©è¿›æˆ–ç‰¹æ®Šå­—ç¬¦åˆ¤æ–­
        text = str(row[0]) if row[0] else ""
        level = 0
        
        # è®¡ç®—å‰å¯¼ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦
        stripped = text.lstrip()
        if stripped != text:
            indent = len(text) - len(stripped)
            level = indent // 2  # æ¯2ä¸ªç©ºæ ¼ä¸€çº§
            text = stripped.strip('-*â€¢â†’')
        
        return level, text.strip()


# ==============================================
# è§£æå™¨å·¥å‚
# ==============================================

class ParserFactory:
    """è§£æå™¨å·¥å‚ç±»"""
    
    PARSERS = {
        '.md': MarkdownParser,
        '.markdown': MarkdownParser,
        '.txt': TextOutlineParser,
        '.text': TextOutlineParser,
        '.html': HtmlParser,
        '.htm': HtmlParser,
        '.docx': WordParser,
        '.xlsx': ExcelParser,
        '.xls': ExcelParser,
    }
    
    @classmethod
    def detect_file_type(cls, file_path):
        """æ£€æµ‹æ–‡ä»¶ç±»å‹ï¼ˆé€šè¿‡æ‰©å±•åå’Œå†…å®¹ï¼‰"""
        ext = Path(file_path).suffix.lower()
        
        # å¦‚æœæœ‰æ‰©å±•åï¼Œä¼˜å…ˆä½¿ç”¨æ‰©å±•å
        if ext:
            return ext
        
        # æ²¡æœ‰æ‰©å±•åæ—¶ï¼Œé€šè¿‡å†…å®¹æ£€æµ‹
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read(1000)  # è¯»å–å‰1000å­—ç¬¦
                
                # HTMLæ£€æµ‹
                if content.strip().startswith('<!DOCTYPE') or content.strip().startswith('<html'):
                    return '.html'
                
                # Markdownæ£€æµ‹
                if any(line.strip().startswith('#') for line in content.split('\n')[:10]):
                    return '.md'
                
                # OPMLæ£€æµ‹
                if '<opml' in content.lower():
                    return '.opml'
                
                # æ–‡æœ¬å¤§çº²æ£€æµ‹ï¼ˆæœ‰ç¼©è¿›ç»“æ„ï¼‰
                lines = content.split('\n')[:20]
                indent_chars = ['  ', '\t', 'Â·', 'â€¢', '-']
                if any(any(line.startswith(char) for char in indent_chars) for line in lines if line.strip()):
                    return '.txt'
                
                # é»˜è®¤æ–‡æœ¬
                return '.txt'
                
        except Exception:
            return '.txt'
    
    @classmethod
    def get_parser(cls, file_path):
        """æ ¹æ®æ–‡ä»¶è·¯å¾„è·å–ç›¸åº”çš„è§£æå™¨"""
        file_ext = cls.detect_file_type(file_path)
        
        if file_ext not in cls.PARSERS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        
        parser_class = cls.PARSERS[file_ext]
        return parser_class(file_path)
    
    @classmethod
    def get_supported_formats(cls):
        """è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼åˆ—è¡¨"""
        return list(cls.PARSERS.keys())
    
    @classmethod
    def detect_format(cls, file_path):
        """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼"""
        # åŸºäºæ–‡ä»¶æ‰©å±•å
        file_ext = Path(file_path).suffix.lower()
        if file_ext in cls.PARSERS:
            return file_ext
        
        # åŸºäºMIMEç±»å‹
        mime_type, _ = mimetypes.guess_type(file_path)
        if mime_type:
            mime_to_ext = {
                'text/markdown': '.md',
                'text/plain': '.txt',
                'text/html': '.html',
                'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
                'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx',
            }
            return mime_to_ext.get(mime_type, file_ext)
        
        return file_ext


# ==============================================
# XMindæ–‡ä»¶ç”Ÿæˆå™¨ï¼ˆå¤ç”¨åŸæœ‰ä»£ç ï¼‰
# ==============================================

# å†™å…¥å™¨åŠŸèƒ½å·²è¿ç§»è‡³ xmind_writer.pyï¼›ä¿æŒå¯¹ create_xmind_file çš„å¯¼å…¥ä½¿ç”¨


# ==============================================
# å…¼å®¹æ€§å‡½æ•°ï¼ˆä»markdown_to_xmind_converter.pyåˆå¹¶ï¼‰
# ==============================================

def parse_markdown_to_json(markdown_file):
    """å…¼å®¹æ—§ç‰ˆæœ¬çš„Markdownè§£æå‡½æ•°"""
    parser = MarkdownParser(markdown_file)
    return parser.parse()

def main():
    """ä¸»å‡½æ•° - æ”¯æŒå‘½ä»¤è¡Œå‚æ•°"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) <= 1:
        print("[ERROR] é”™è¯¯: è¯·æä¾›è¾“å…¥æ–‡ä»¶è·¯å¾„")
        print("ç”¨æ³•: python universal_xmind_converter.py <input_file>")
        print("æ”¯æŒçš„æ ¼å¼: .md, .txt, .html, .docx, .xlsx")
        return 1
    
    input_file = sys.argv[1]
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"[ERROR] é”™è¯¯: æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨")
        return 1
    
    # ä½¿ç”¨ParserFactoryè‡ªåŠ¨æ£€æµ‹æ ¼å¼å¹¶è½¬æ¢
    try:
        factory = ParserFactory()
        parser = factory.get_parser(input_file)
        
        print(f"æ­£åœ¨è§£ææ–‡ä»¶: {input_file}")
        json_structure = parser.parse()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åï¼ˆè¾“å‡ºåˆ°outputç›®å½•ï¼‰
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_dir = "output"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        output_file = os.path.join(output_dir, f"{base_name}.xmind")
        
        print(f"æ­£åœ¨åˆ›å»ºXMindæ–‡ä»¶: {output_file}")
        create_xmind_file(json_structure, output_file)
        
        print("[SUCCESS] è½¬æ¢å®Œæˆï¼")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        
    except Exception as e:
        print(f"[ERROR] è½¬æ¢å¤±è´¥: {str(e)}")
        return 1


if __name__ == '__main__':
    main()


# ==============================================
# ä¸»å‡½æ•°
# ==============================================

def main():
    """Main function"""
    import sys
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2 or sys.argv[1] in ['-h', '--help', 'help']:
        print("=" * 60)
        print("Universal XMind Converter - å¤šæ ¼å¼æ€ç»´å¯¼å›¾è½¬æ¢å™¨")
        print("=" * 60)
        print("\næ”¯æŒçš„æ–‡ä»¶æ ¼å¼:")
        print("  â€¢ Markdown     (.md)     - æ ‡é¢˜å±‚çº§è½¬æ¢")
        print("  â€¢ æ–‡æœ¬å¤§çº²     (.txt)    - ç¼©è¿›æ ¼å¼å¤§çº²")
        print("  â€¢ HTMLç½‘é¡µ     (.html)   - æ ‡é¢˜å’Œåˆ—è¡¨ç»“æ„")
        print("  â€¢ Wordæ–‡æ¡£     (.docx)   - æ ‡é¢˜æ ·å¼è½¬æ¢")
        print("  â€¢ Excelè¡¨æ ¼    (.xlsx)   - å¤šåˆ—å±‚çº§ç»“æ„")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("  python universal_xmind_converter.py <è¾“å…¥æ–‡ä»¶> [è¾“å‡ºæ–‡ä»¶]")
        print("\nç¤ºä¾‹:")
        print("  python universal_xmind_converter.py document.md")
        print("  python universal_xmind_converter.py outline.txt mymap.xmind")
        print("  python universal_xmind_converter.py data.xlsx")
        print("\nè‡ªåŠ¨è¯†åˆ«:")
        print("  æ— æ‰©å±•åæ–‡ä»¶ä¼šè‡ªåŠ¨æ£€æµ‹æ ¼å¼")
        print("\nä¾èµ–å®‰è£…:")
        print("  pip install beautifulsoup4 python-docx openpyxl")
        print("=" * 60)
        return 0
    
    if len(sys.argv) < 2:
        print("[ERROR] é”™è¯¯: è¯·æä¾›è¾“å…¥æ–‡ä»¶è·¯å¾„")
        print("ç”¨æ³•: python universal_xmind_converter.py <input_file>")
        print("\næ”¯æŒçš„æ–‡ä»¶æ ¼å¼:")
        for fmt in ParserFactory.get_supported_formats():
            print(f"  {fmt}")
        return 1
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    # éªŒè¯è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_file):
        print(f"[ERROR] é”™è¯¯: æ–‡ä»¶ '{input_file}' ä¸å­˜åœ¨")
        return 1
    
    # æ£€æµ‹æ–‡ä»¶æ ¼å¼
    file_format = ParserFactory.detect_format(input_file)
    print(f"æ£€æµ‹åˆ°æ–‡ä»¶æ ¼å¼: {file_format}")
    
    try:
        # è·å–ç›¸åº”çš„è§£æå™¨
        parser = ParserFactory.get_parser(input_file)
        print(f"ä½¿ç”¨è§£æå™¨: {parser.__class__.__name__}")
        
        # è§£ææ–‡ä»¶
        print(f"æ­£åœ¨è§£ææ–‡ä»¶: {input_file}")
        json_structure = parser.parse()
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        output_dir = "output"
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
            
        output_file = os.path.join(output_dir, f"{base_name}.xmind")
        
        # åˆ›å»ºXMindæ–‡ä»¶
        print(f"æ­£åœ¨åˆ›å»ºXMindæ–‡ä»¶: {output_file}")
        create_xmind_file(json_structure, output_file)
        
        print("[SUCCESS] è½¬æ¢å®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
        
    except ImportError as e:
        print(f"[ERROR] ç¼ºå°‘ä¾èµ–åŒ…: {e}")
        print("è¯·å®‰è£…ç›¸åº”çš„ä¾èµ–åŒ…:")
        print("  pip install beautifulsoup4  # HTMLè§£æ")
        print("  pip install python-docx   # Wordæ–‡æ¡£è§£æ")
        print("  pip install openpyxl      # Excelè§£æ")
        return 1
        
    except Exception as e:
        print(f"[ERROR] è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    main()