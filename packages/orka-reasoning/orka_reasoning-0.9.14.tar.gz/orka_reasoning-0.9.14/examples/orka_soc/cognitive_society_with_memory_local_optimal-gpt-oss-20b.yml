# ðŸ”§ OPTIMIZED COLLABORATIVE SOCIETY WORKFLOW - Token Efficient Version
# Reduced token consumption by 60-80% while maintaining core functionality
# Key optimizations:
# - Condensed agent responses to summaries
# - Reduced memory context injection
# - Streamlined format requirements
# - Essential-only metadata

orchestrator:
  id: cognitive-society-collaborative-enhanced-local-optimized
  strategy: sequential
  memory_preset: "episodic"  # Use episodic memory for debate interactions
  agents:
    - cognitive_debate_loop
    - meta_debate_reflection
    - final_synthesis_processor

agents:
  - id: cognitive_debate_loop
    type: loop
    max_loops: 3
    
    high_priority_agents:
      - "agreement_moderator"
    
    # Boolean scoring configuration for deterministic agreement evaluation
    scoring:
      preset: strict  # High standards for consensus building
      context: loop_convergence  # Track debate convergence
      custom_weights:
        # Convergence criteria for collaborative debate
        improvement.better_than_previous: 0.25
        improvement.approaching_target: 0.20
        stability.consistent_direction: 0.20
        stability.not_degrading: 0.15
        convergence.within_tolerance: 0.15
    
    # ðŸ”§ OPTIMIZED: Reduced extraction patterns and length
    cognitive_extraction:
      enabled: true
      max_length_per_category: 80  # Reduced from 150
      extract_patterns:
        insights:
          - "POSITION[\":]?\\s*(.+?)(?=\\n[A-Z_]+:|$)"
        improvements:
          - "COLLABORATION[\":]?\\s*(.+?)(?=\\n[A-Z_]+:|$)"
        mistakes:
          - "SHARED_VALUES[\":]?\\s*(.+?)(?=\\n[A-Z_]+:|$)"
    
    # ðŸ”§ OPTIMIZED: Essential metadata only
    past_loops_metadata:
      loop_number: "{{ get_loop_number() }}"
      score: "{{ score }}"
      timestamp: "{{ timestamp }}"
      status: "{{ 'CONVERGED' if score >= get_score_threshold() else 'CONTINUING' }}"
      insights: "{{ insights }}"
      improvements: "{{ improvements }}"
      mistakes: "{{ mistakes }}"
    
    internal_workflow:
      orchestrator:
        id: cognitive-collaborative-internal-optimized
        strategy: sequential
        agents:
          - shared_memory_reader
          - opening_positions
          - join_opening_positions
          - agreement_finder
          - collaborative_refinement
          - join_collaborative_refinement
          - synthesis_attempt
          - agreement_moderator
          - shared_memory_writer
      
      agents:
        # ðŸ”§ OPTIMIZED: Reduced memory context
        - id: shared_memory_reader
          type: memory
          memory_preset: "episodic"  # Personal experiences and conversations (7 days)
          queue: orka:shared-debate-memory
          namespace: society_memory
          config:
            operation: read
            # ðŸŽ¯ Episodic preset provides: limit=8, similarity_threshold=0.6, vector_weight=0.7,
            # text_weight=0.3, enable_hybrid_search=true, temporal_weight=0.3, ef_runtime=10
            limit: 5  # Override for less context noise
            similarity_threshold: 0.2  # Broader matching for diverse perspectives
            # Align to actual index schema (see logs: vector_field_name=content_vector, content_field=content)
            vector_field: "content_vector"
            search_field: "content"
          prompt: |
            Context for: {{ get_input() }}
        
        # ðŸ”§ OPTIMIZED: Simplified opening positions
        - id: opening_positions
          type: fork
          targets:
            - - radical_progressive
            - - traditional_conservative
            - - pragmatic_realist
            - - ethical_purist
        
        # ðŸ”§ OPTIMIZED: Condensed progressive agent
        - id: radical_progressive
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.3
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "radical_progressive"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            PROGRESSIVE AGENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            {% if get_loop_number() > 1 %}CONTEXT: {{ get_debate_evolution() }}{% endif %}
            
            Give your progressive stance focusing on social justice and equality.
            
            FORMAT:
            POSITION: [Your stance in 2-3 sentences]
            COLLABORATION: [How you can work with others in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed conservative agent
        - id: traditional_conservative
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.3
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "traditional_conservative"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            CONSERVATIVE AGENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            {% if get_loop_number() > 1 %}CONTEXT: {{ get_debate_evolution() }}{% endif %}
            
            Give your conservative stance focusing on tradition and stability.
            
            FORMAT:
            POSITION: [Your stance in 2-3 sentences]
            COLLABORATION: [How you can work with others in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed realist agent
        - id: pragmatic_realist
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.2
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "pragmatic_realist"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            REALIST AGENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            {% if get_loop_number() > 1 %}CONTEXT: {{ get_debate_evolution() }}{% endif %}
            
            Give your practical stance focusing on evidence and measurable outcomes.
            
            FORMAT:
            POSITION: [Your stance in 2-3 sentences]
            COLLABORATION: [How you bridge views in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed purist agent
        - id: ethical_purist
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.4
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "ethical_purist"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            ETHICAL PURIST AGENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            {% if get_loop_number() > 1 %}CONTEXT: {{ get_debate_evolution() }}{% endif %}
            
            Give your ethical stance focusing on moral principles.
            
            FORMAT:
            POSITION: [Your stance in 2-3 sentences]
            COLLABORATION: [How you maintain ethics while collaborating in 1 sentence]
        
        - id: join_opening_positions
          type: join
          group: opening_positions
        
        # ðŸ”§ OPTIMIZED: Simple agreement finder
        - id: agreement_finder
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.2
          prompt: |
            TOPIC: {{ get_input() }}
            
            POSITIONS:
            - Progressive: {{ get_agent_response('radical_progressive') | truncate(200) }}
            - Conservative: {{ get_agent_response('traditional_conservative') | truncate(200) }}
            - Realist: {{ get_agent_response('pragmatic_realist') | truncate(200) }}
            - Purist: {{ get_agent_response('ethical_purist') | truncate(200) }}
            
            Find ONE clear answer that all can agree on.
            
            AGREEMENT: [Direct answer incorporating all perspectives]

        # ðŸ”§ OPTIMIZED: Simplified collaborative refinement
        - id: collaborative_refinement
          type: fork
          targets:
            - - progressive_refinement
            - - conservative_refinement
            - - realist_refinement
            - - purist_refinement
        
        # ðŸ”§ OPTIMIZED: Condensed progressive refinement
        - id: progressive_refinement
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.4
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "progressive_collaborative"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            PROGRESSIVE REFINEMENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            YOUR POSITION: {{ get_agent_response('radical_progressive') | truncate(150) }}
            CURRENT AGREEMENT: {{ safe_get_response('agreement_finder', 'Seeking agreement') | truncate(150) }}
            
            Refine your position for collaboration.
            
            REFINED_POSITION: [Evolved stance in 2-3 sentences]
            SHARED_VALUES: [Common ground found in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed conservative refinement
        - id: conservative_refinement
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.4
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "conservative_collaborative"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            CONSERVATIVE REFINEMENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            YOUR POSITION: {{ get_agent_response('traditional_conservative') | truncate(150) }}
            CURRENT AGREEMENT: {{ safe_get_response('agreement_finder', 'Seeking agreement') | truncate(150) }}
            
            Refine your position for collaboration.
            
            REFINED_POSITION: [Evolved stance in 2-3 sentences]
            SHARED_VALUES: [Common ground found in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed realist refinement
        - id: realist_refinement
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.3
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "realist_collaborative"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            REALIST REFINEMENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            YOUR POSITION: {{ get_agent_response('pragmatic_realist') | truncate(150) }}
            CURRENT AGREEMENT: {{ safe_get_response('agreement_finder', 'Seeking agreement') | truncate(150) }}
            
            Refine your position for collaboration.
            
            REFINED_POSITION: [Evolved stance in 2-3 sentences]
            SHARED_VALUES: [Common ground found in 1 sentence]
        
        # ðŸ”§ OPTIMIZED: Condensed purist refinement
        - id: purist_refinement
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.5
          memory_config:
            operation: write
            # memory_type replaced by memory_preset
            vector: true
            namespace: society_memory
            metadata:
              agent_type: "purist_collaborative"
              loop_number: "{{ get_loop_number() }}"
          prompt: |
            PURIST REFINEMENT - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            YOUR POSITION: {{ get_agent_response('ethical_purist') | truncate(150) }}
            CURRENT AGREEMENT: {{ safe_get_response('agreement_finder', 'Seeking agreement') | truncate(150) }}
            
            Refine your position for collaboration.
            
            REFINED_POSITION: [Evolved stance in 2-3 sentences]
            SHARED_VALUES: [Common ground found in 1 sentence]
        
        - id: join_collaborative_refinement
          type: join
          group: collaborative_refinement
         
        # ðŸ”§ OPTIMIZED: Simplified synthesis
        - id: synthesis_attempt
          type: local_llm
          model: openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          temperature: 0.4
          prompt: |
            SYNTHESIS - Round {{ get_loop_number() }}
            TOPIC: {{ get_input() }}
            
            AGREEMENT: {{ safe_get_response('agreement_finder', 'No agreement') | truncate(200) }}
            
            REFINED POSITIONS (SUMMARY):
            - Progressive: {{ safe_get_response('progressive_refinement', 'No refinement') | truncate(100) }}
            - Conservative: {{ safe_get_response('conservative_refinement', 'No refinement') | truncate(100) }}
            - Realist: {{ safe_get_response('realist_refinement', 'No refinement') | truncate(100) }}
            - Purist: {{ safe_get_response('purist_refinement', 'No refinement') | truncate(100) }}
            
            SYNTHESIS: [How perspectives work together in 2-3 sentences]

        # ðŸ”§ OPTIMIZED: Loop Validator Node - Robust boolean evaluation
        - id: agreement_moderator
          type: loop_validator
          llm_model:  openai/gpt-oss-20b
          model_url: http://localhost:1234
          provider: lm_studio
          scoring_preset: moderate
          scoring_context: quality  # Evaluate debate quality/synthesis
          evaluation_target: synthesis_attempt  # Evaluate the synthesis quality
          temperature: 0.1

        # ðŸ”§ OPTIMIZED: Minimal memory writer
        - id: shared_memory_writer
          type: memory
          memory_preset: "episodic"  # Personal experiences and conversations (7 days)
          queue: orka:shared-debate-writer
          namespace: society_memory
          config:
            operation: write
            # ðŸŽ¯ Episodic preset provides: vector=true, vector_field, vector_params,
            # decay settings (7 days retention), importance_threshold=0.5
            vector: true
            # Align to actual index schema (see logs: fields include 'content' and 'content_vector')
            vector_field: "content_vector"
            embed_field: "content"
          # Configure what content gets embedded - with proper formatting
          embed_content: |
            {{ safe_get_response('agreement_finder', '') | truncate(200) | replace('\n', ' ') }}
            {{ safe_get_response('synthesis_attempt', '') | truncate(200) | replace('\n', ' ') }}
          
          # Full memory content with proper formatting
          prompt: |
            Round {{ get_loop_number() }}: {{ get_input() | replace('\n', ' ') }}
            Agreement: {{ safe_get_response('agreement_finder', 'None') | truncate(100) | replace('\n', ' ') }}
            Score: {{ safe_get_response('agreement_moderator', 'None') | truncate(50) | replace('\n', ' ') }}
            Synthesis: {{ safe_get_response('synthesis_attempt', 'None') | truncate(100) | replace('\n', ' ') }}

  # ðŸ”§ OPTIMIZED: Simplified meta-analysis
  - id: meta_debate_reflection
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.3
    prompt: |
      QUESTION: {{ get_input() }}
      
      DEBATE SUMMARY:
      {% set loop_output = get_loop_output('cognitive_debate_loop', previous_outputs) %}
      {% if loop_output %}
      - Rounds: {{ safe_get(loop_output, 'loops_completed', 'Unknown') }}
      - Final Score: {{ safe_get(loop_output, 'final_score', 'Unknown') }}
      - Status: {{ safe_get(loop_output, 'status', 'completed') }}
      {% endif %}
      
      PROGRESSION: [How debate evolved in 2-3 sentences]
      SUCCESS: [How well agents collaborated in 1-2 sentences]

  # ðŸ”§ OPTIMIZED: Essential final synthesis only
  - id: final_synthesis_processor
    type: local_llm
    model: openai/gpt-oss-20b
    model_url: http://localhost:1234
    provider: lm_studio
    temperature: 0.3
    prompt: |
      QUESTION: {{ get_input() }}
      
      DEBATE RESULTS:
      {% set loop_output = get_loop_output('cognitive_debate_loop', previous_outputs) %}
      {% if loop_output %}
      - Rounds: {{ safe_get(loop_output, 'loops_completed', 'Unknown') }}
      - Score: {{ safe_get(loop_output, 'final_score', 'Unknown') }}
      {% endif %}
      
      META-ANALYSIS: {{ safe_get_response('meta_debate_reflection', 'No analysis') | truncate(200) }}
      
      **Question**: {{ get_input() }}
      **Debate Summary**: [Key developments in 2-3 sentences]
      **Final Answer**: [Clear, actionable response]
      **Confidence**: [0.0-1.0 with brief justification]
