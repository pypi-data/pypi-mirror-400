"""
í†µí•© í…ŒìŠ¤íŠ¸

HWPXReader, HWPXWriter, ëª¨ë¸ë“¤ì˜ í†µí•©ëœ ë™ì‘ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import pytest
import tempfile
import shutil
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ íŒŒì´ì¬ ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent))

from airun_hwp.reader.hwpx_reader import HWPXReader
from airun_hwp.writer.hwpx_writer import HWPXWriter, BatchHWPXWriter
from airun_hwp.models.document import HWPXDocument
from airun_hwp.models.metadata import DocumentMetadata
from airun_hwp.models.content import Section, Paragraph, TextRun, Table, TableCell, Image, StyleInfo


@pytest.mark.integration
class TestEndToEndWorkflow:
    """ì¢…ë‹¨ ê°„(end-to-end) ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""

    def test_parse_to_markdown_workflow(self, sample_hwpx_file, temp_dir):
        """HWPX â†’ íŒŒì‹± â†’ Markdown ë³€í™˜ ì›Œí¬í”Œë¡œìš°"""
        # 1. HWPX íŒŒì‹±
        reader = HWPXReader(strict_mode=False)
        document = reader.parse(str(sample_hwpx_file))

        assert document is not None
        assert len(document.sections) > 0

        # 2. Markdown ë³€í™˜
        markdown_content = document.to_markdown(include_metadata=True)
        assert len(markdown_content) > 0

        # 3. Markdown íŒŒì¼ ì €ì¥
        md_path = temp_dir / "converted.md"
        md_path.write_text(markdown_content, encoding='utf-8')

        assert md_path.exists()
        assert md_path.stat().st_size > 0

        # 4. ë‚´ìš© í™•ì¸
        assert "title:" in markdown_content or "í…ŒìŠ¤íŠ¸" in markdown_content

    @pytest.mark.slow
    def test_complete_roundtrip(self, sample_hwpx_file, temp_dir):
        """HWPX â†’ íŒŒì‹± â†’ Markdown â†’ HWPX ì™•ë³µ ë³€í™˜"""
        pytest.skip("Requires pypandoc-hwpx installation")

        # 1. ì›ë³¸ HWPX íŒŒì‹±
        reader = HWPXReader(strict_mode=False)
        original_document = reader.parse(str(sample_hwpx_file))

        # 2. Markdownìœ¼ë¡œ ë³€í™˜
        markdown_path = temp_dir / "intermediate.md"
        markdown_content = original_document.to_markdown()
        markdown_path.write_text(markdown_content, encoding='utf-8')

        # 3. Markdownì—ì„œ ìƒˆ HWPX ìƒì„±
        writer = HWPXWriter()
        new_hwpx_path = temp_dir / "roundtrip.hwpx"
        success = writer.from_markdown(str(markdown_path), str(new_hwpx_path))

        # 4. ê²°ê³¼ í™•ì¸
        if success:
            assert new_hwpx_path.exists()
            assert new_hwpx_path.stat().st_size > 0

            # 5. ìƒˆ HWPX ë‹¤ì‹œ íŒŒì‹±
            new_reader = HWPXReader(strict_mode=False)
            new_document = new_reader.parse(str(new_hwpx_path))

            # 6. ê¸°ë³¸ ë‚´ìš© ë¹„êµ
            original_text = original_document.get_all_text()
            new_text = new_document.get_all_text()

            # ì¼ë¶€ ë‚´ìš©ì€ ì†ì‹¤ë  ìˆ˜ ìˆìœ¼ë‚˜ ê¸°ë³¸ í…ìŠ¤íŠ¸ëŠ” ìœ ì§€ë˜ì–´ì•¼ í•¨
            assert len(new_text) > 0

    def test_batch_processing_workflow(self, temp_dir):
        """ì¼ê´„ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
        # 1. ì—¬ëŸ¬ Markdown íŒŒì¼ ìƒì„±
        input_dir = temp_dir / "inputs"
        input_dir.mkdir()

        documents = []
        for i in range(3):
            # ë¬¸ì„œ ê°ì²´ ìƒì„±
            doc = HWPXDocument(
                metadata=DocumentMetadata(
                    title=f"ë¬¸ì„œ {i+1}",
                    author=f"ì‘ì„±ì {i+1}"
                )
            )

            # ì„¹ì…˜ê³¼ ë¬¸ë‹¨ ì¶”ê°€
            section = Section()
            para = Paragraph()
            para.runs.append(TextRun(text=f"ì´ê²ƒì€ ë¬¸ì„œ {i+1}ì˜ ë‚´ìš©ì…ë‹ˆë‹¤."))
            section.paragraphs.append(para)
            doc.add_section(section)

            documents.append(doc)

            # Markdownìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
            md_path = input_dir / f"doc{i+1}.md"
            md_content = doc.to_markdown()
            md_path.write_text(md_content, encoding='utf-8')

        # 2. ì¼ê´„ HWPX ë³€í™˜
        output_dir = temp_dir / "outputs"
        batch_writer = BatchHWPXWriter(str(output_dir))

        with pytest.MonkeyPatch().context() as m:
            # subprocess ëª¨í‚¹
            import subprocess
            mock_run = m.setattr(subprocess, 'run')
            mock_result = type('Mock', (), {
                'returncode': 0,
                'stdout': '',
                'stderr': ''
            })()
            mock_run.return_value = mock_result

            successful_files = batch_writer.process_directory(str(input_dir))

        # 3. ê²°ê³¼ í™•ì¸
        assert len(successful_files) == 3

    def test_complex_document_processing(self, temp_dir):
        """ë³µì¡í•œ ë¬¸ì„œ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""
        # 1. ë³µì¡í•œ ë¬¸ì„œ ìƒì„±
        document = HWPXDocument(
            metadata=DocumentMetadata(
                title="ë³µí•© ì½˜í…ì¸  ë¬¸ì„œ",
                author="í†µí•© í…ŒìŠ¤íŠ¸",
                subject="ë‹¤ì–‘í•œ ì½˜í…ì¸  íƒ€ì… í…ŒìŠ¤íŠ¸"
            )
        )

        # 2. ì—¬ëŸ¬ ì„¹ì…˜ì— ë‹¤ì–‘í•œ ì½˜í…ì¸  ì¶”ê°€
        for section_idx in range(3):
            section = Section()

            # ë¬¸ë‹¨ë“¤
            for para_idx in range(5):
                para = Paragraph()
                text = f"ì„¹ì…˜{section_idx+1} ë¬¸ë‹¨{para_idx+1}"

                # ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ ì ìš©
                if para_idx % 2 == 0:
                    style = StyleInfo(bold=True)
                elif para_idx % 3 == 0:
                    style = StyleInfo(italic=True)
                else:
                    style = StyleInfo()

                para.runs.append(TextRun(text=text, style=style))
                section.paragraphs.append(para)

            # í‘œ
            if section_idx > 0:
                table = Table(caption=f"ì„¹ì…˜{section_idx+1}ì˜ í‘œ")
                # í—¤ë”
                header_cells = [
                    TableCell(text=f"ì»¬ëŸ¼{j+1}", row=0, col=j, is_header=True)
                    for j in range(3)
                ]
                table.add_row(header_cells)

                # ë°ì´í„° í–‰
                for i in range(3):
                    data_cells = [
                        TableCell(text=f"ë°ì´í„°{i+1}-{j+1}", row=i+1, col=j)
                        for j in range(3)
                    ]
                    table.add_row(data_cells)

                section.tables.append(table)

            # ì´ë¯¸ì§€
            if section_idx == 2:
                image = Image(
                    name=f"image{section_idx}.png",
                    width=300,
                    height=200,
                    caption=f"ì„¹ì…˜{section_idx+1}ì˜ ì´ë¯¸ì§€"
                )
                section.images.append(image)

            document.add_section(section)

        # 3. ìœ íš¨ì„± ê²€ì¦
        issues = document.validate()
        assert not any(issue.startswith("Error:") for issue in issues)

        # 4. Markdown ë³€í™˜
        markdown_content = document.to_markdown()
        assert len(markdown_content) > 0

        # 5. ë‚´ìš© í™•ì¸
        assert "ë³µí•© ì½˜í…ì¸  ë¬¸ì„œ" in markdown_content
        assert "ì„¹ì…˜1 ë¬¸ë‹¨1" in markdown_content
        assert "| ì»¬ëŸ¼1 |" in markdown_content  # í‘œ ë§ˆí¬ë‹¤ìš´
        assert "ì„¹ì…˜3ì˜ ì´ë¯¸ì§€" in markdown_content

        # 6. Markdown íŒŒì¼ ì €ì¥
        md_path = temp_dir / "complex_document.md"
        md_path.write_text(markdown_content, encoding='utf-8')

        assert md_path.exists()


@pytest.mark.integration
class TestErrorRecovery:
    """ì—ëŸ¬ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""

    def test_partial_document_recovery(self, temp_dir):
        """ì†ìƒëœ ë¬¸ì„œ ë¶€ë¶„ ë³µêµ¬ í…ŒìŠ¤íŠ¸"""
        # 1. ë¶€ë¶„ì ìœ¼ë¡œ ì†ìƒëœ HWPX íŒŒì¼ ìƒì„±
        from zipfile import ZipFile
        hwpx_path = temp_dir / "corrupted.hwpx"

        with ZipFile(hwpx_path, 'w') as zf:
            # mimetype
            zf.writestr("mimetype", "application/x-hwp+xml")

            # ì •ìƒ header.xml
            header_xml = """<?xml version="1.0" encoding="UTF-8"?>
<hwpml xmlns:hh="http://www.hancom.co.kr/hwpml/2011/head">
    <hh:DocInfo>
        <hc:summary xmlns:hc="http://www.hancom.co.kr/hwpml/2011/core">
            <hc:title>ë³µêµ¬ í…ŒìŠ¤íŠ¸</hc:title>
        </hc:summary>
    </hh:DocInfo>
</hwpml>"""
            zf.writestr("Contents/header.xml", header_xml)

            # ì†ìƒëœ section.xml
            corrupted_xml = "<invalid><xml>"
            zf.writestr("Contents/section0.xml", corrupted_xml)

            # ì •ìƒ section1.xml
            section_xml = """<?xml version="1.0" encoding="UTF-8"?>
<sec xmlns:hp="http://www.hancom.co.kr/hwpml/2011/paragraph">
    <hp:p>
        <hp:run>
            <hp:t>ì •ìƒ ì„¹ì…˜ ë‚´ìš©</hp:t>
        </hp:run>
    </hp:p>
</sec>"""
            zf.writestr("Contents/section1.xml", section_xml)

            zf.writestr("Contents/content.hpf", "")

        # 2. ë¹„ì—„ê²© ëª¨ë“œë¡œ íŒŒì‹±
        reader = HWPXReader(strict_mode=False)
        document = reader.parse(str(hwpx_path))

        # 3. ë¶€ë¶„ì ìœ¼ë¡œ íŒŒì‹±ëœ ë¬¸ì„œ í™•ì¸
        assert document is not None
        assert document.metadata.title == "ë³µêµ¬ í…ŒìŠ¤íŠ¸"

        # ì •ìƒ ì„¹ì…˜ì€ íŒŒì‹±ë˜ì–´ì•¼ í•¨
        total_paragraphs = sum(len(s.paragraphs) for s in document.sections)
        assert total_paragraphs >= 0  # 0ì¼ ìˆ˜ ìˆìŒ

    def test_missing_resource_handling(self, temp_dir):
        """ëˆ„ë½ëœ ë¦¬ì†ŒìŠ¤ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # 1. ì´ë¯¸ì§€ ì°¸ì¡°ë§Œ ìˆê³  ì‹¤ì œ ì´ë¯¸ì§€ê°€ ì—†ëŠ” HWPX ìƒì„±
        from zipfile import ZipFile
        hwpx_path = temp_dir / "missing_resource.hwpx"

        with ZipFile(hwpx_path, 'w') as zf:
            zf.writestr("mimetype", "application/x-hwp+xml")

            header_xml = """<?xml version="1.0" encoding="UTF-8"?>
<hwpml xmlns:hh="http://www.hancom.co.kr/hwpml/2011/head>
</hwpml>"""
            zf.writestr("Contents/header.xml", header_xml)

            # ì´ë¯¸ì§€ ì°¸ì¡°ë§Œ ìˆê³  BinDataëŠ” ì—†ëŠ” ì„¹ì…˜
            section_xml = """<?xml version="1.0" encoding="UTF-8"?>
<sec xmlns:hp="http://www.hancom.co.kr/hwpml/2011/paragraph">
    <hp:p>
        <hp:run>
            <hp:t>ì´ë¯¸ì§€ê°€ ëˆ„ë½ëœ ë¬¸ì„œ</hp:t>
        </hp:run>
    </hp:p>
    <hp:img name="missing.png">
        <hp:rect width="100" height="100" />
    </hp:img>
</sec>"""
            zf.writestr("Contents/section0.xml", section_xml)
            zf.writestr("Contents/content.hpf", "")

        # 2. íŒŒì‹±
        reader = HWPXReader(strict_mode=False)
        document = reader.parse(str(hwpx_path))

        # 3. ë¬¸ì„œëŠ” ì •ìƒì ìœ¼ë¡œ íŒŒì‹±ë˜ì–´ì•¼ í•¨
        assert document is not None
        assert "ì´ë¯¸ì§€ê°€ ëˆ„ë½ëœ ë¬¸ì„œ" in document.get_all_text()


@pytest.mark.integration
class TestPerformance:
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""

    def test_large_text_document(self, temp_dir):
        """ëŒ€ëŸ‰ í…ìŠ¤íŠ¸ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        # 1. ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ ë¬¸ì„œ ìƒì„±
        document = HWPXDocument(
            metadata=DocumentMetadata(title="ëŒ€ìš©ëŸ‰ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸")
        )

        section = Section()

        # 1000ê°œì˜ ê¸´ ë¬¸ë‹¨
        for i in range(1000):
            para = Paragraph()
            long_text = f"ë¬¸ë‹¨ {i+1}: " + "A" * 500  # 500ì í…ìŠ¤íŠ¸
            para.runs.append(TextRun(text=long_text))
            section.paragraphs.append(para)

        document.add_section(section)

        # 2. Markdown ë³€í™˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        import time
        start_time = time.time()

        markdown_content = document.to_markdown()

        end_time = time.time()
        conversion_time = end_time - start_time

        # 3. ê²°ê³¼ í™•ì¸
        assert len(markdown_content) > 0
        assert conversion_time < 5.0  # 5ì´ˆ ì´ë‚´

        # 4. íŒŒì¼ ì €ì¥
        md_path = temp_dir / "large_text.md"
        md_path.write_text(markdown_content, encoding='utf-8')

        assert md_path.stat().st_size > 500000  # ì•½ 500KB ì´ìƒ

    def test_many_small_documents(self, temp_dir):
        """ë‹¤ìˆ˜ì˜ ì‘ì€ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        documents = []

        # 100ê°œì˜ ì‘ì€ ë¬¸ì„œ ìƒì„±
        for i in range(100):
            doc = HWPXDocument(
                metadata=DocumentMetadata(title=f"ë¬¸ì„œ {i+1}")
            )
            section = Section()
            para = Paragraph()
            para.runs.append(TextRun(text=f"ë‚´ìš© {i+1}"))
            section.paragraphs.append(para)
            doc.add_section(section)
            documents.append(doc)

        # ì¼ê´„ Markdown ë³€í™˜
        import time
        start_time = time.time()

        markdown_files = []
        for i, doc in enumerate(documents):
            md_content = doc.to_markdown()
            md_path = temp_dir / f"doc_{i+1:03d}.md"
            md_path.write_text(md_content, encoding='utf-8')
            markdown_files.append(md_path)

        end_time = time.time()
        total_time = end_time - start_time

        # ê²°ê³¼ í™•ì¸
        assert len(markdown_files) == 100
        assert total_time < 10.0  # 10ì´ˆ ì´ë‚´
        assert all(f.exists() for f in markdown_files)


@pytest.mark.integration
@pytest.mark.slow
class TestRealWorldScenarios:
    """ì‹¤ì œ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""

    def test_document_summary_workflow(self, temp_dir):
        """ë¬¸ì„œ ìš”ì•½ ì›Œí¬í”Œë¡œìš° ì‹œë®¬ë ˆì´ì…˜"""
        # 1. ë³´ê³ ì„œ ìŠ¤íƒ€ì¼ ë¬¸ì„œ ìƒì„±
        document = HWPXDocument(
            metadata=DocumentMetadata(
                title="ë¶„ê¸° ë³´ê³ ì„œ",
                author="ë‹´ë‹¹ì",
                subject="2024ë…„ 1ë¶„ê¸° ì‹¤ì "
            )
        )

        # 2. ëª©ì°¨
        section = Section()
        toc_para = Paragraph()
        toc_para.runs.append(TextRun(
            text="ëª©ì°¨\n",
            style=StyleInfo(bold=True, font_size=16)
        ))
        section.paragraphs.append(toc_para)

        toc_items = [
            "1. ê°œìš”",
            "2. ì‹¤ì  í˜„í™©",
            "3. ì£¼ìš” ì„±ê³¼",
            "4. ê°œì„  ê³¼ì œ",
            "5. í–¥í›„ ê³„íš"
        ]
        for item in toc_items:
            item_para = Paragraph()
            item_para.runs.append(TextRun(text=f"{item}\n"))
            section.paragraphs.append(item_para)

        document.add_section(section)

        # 3. ì‹¤ì  ë°ì´í„° í‘œ
        section = Section()
        title_para = Paragraph()
        title_para.runs.append(TextRun(
            text="ì‹¤ì  í˜„í™©",
            style=StyleInfo(bold=True, font_size=14)
        ))
        section.paragraphs.append(title_para)

        # ì›”ë³„ ì‹¤ì  í‘œ
        table = Table(caption="2024ë…„ 1ë¶„ê¸° ì›”ë³„ ì‹¤ì ")

        # í—¤ë”
        header_cells = [
            TableCell(text="ì›”", row=0, col=0, is_header=True),
            TableCell(text="ëª©í‘œ", row=0, col=1, is_header=True),
            TableCell(text="ì‹¤ì ", row=0, col=2, is_header=True),
            TableCell(text="ë‹¬ì„±ìœ¨", row=0, col=3, is_header=True)
        ]
        table.add_row(header_cells)

        # ë°ì´í„°
        data = [
            ["1ì›”", "100", "95", "95%"],
            ["2ì›”", "110", "115", "104.5%"],
            ["3ì›”", "120", "125", "104.2%"]
        ]
        for i, row_data in enumerate(data):
            row_cells = [
                TableCell(text=row_data[0], row=i+1, col=0),
                TableCell(text=row_data[1], row=i+1, col=1),
                TableCell(text=row_data[2], row=i+1, col=2),
                TableCell(text=row_data[3], row=i+1, col=3)
            ]
            table.add_row(row_cells)

        section.tables.append(table)
        document.add_section(section)

        # 4. ìš”ì•½ ì„¹ì…˜
        section = Section()
        summary_title = Paragraph()
        summary_title.runs.append(TextRun(
            text="ìš”ì•½",
            style=StyleInfo(bold=True, font_size=14)
        ))
        section.paragraphs.append(summary_title)

        summary_points = [
            "1ë¶„ê¸° ì´ ì‹¤ì : 335 (ëª©í‘œ 330)",
            "í‰ê·  ë‹¬ì„±ìœ¨: 101.5%",
            "2ê°œì›” ì—°ì† ëª©í‘œ ì´ˆê³¼ ë‹¬ì„±",
            "í–¥í›„ 2ë¶„ê¸° ëª©í‘œ: 10% ì„±ì¥"
        ]
        for point in summary_points:
            point_para = Paragraph()
            point_para.runs.append(TextRun(text=f"â€¢ {point}\n"))
            section.paragraphs.append(point_para)

        document.add_section(section)

        # 5. ë¬¸ì„œ ë¶„ì„
        all_text = document.get_all_text()
        total_paragraphs = sum(len(s.paragraphs) for s in document.sections)
        total_tables = sum(len(s.tables) for s in document.sections)

        # 6. ê²°ê³¼ í™•ì¸
        assert document.metadata.title == "ë¶„ê¸° ë³´ê³ ì„œ"
        assert "ëª©í‘œ" in all_text and "ì‹¤ì " in all_text
        assert total_paragraphs > 10
        assert total_tables == 1

        # 7. ìš”ì•½ ìƒì„±
        summary = {
            "title": document.metadata.title,
            "paragraph_count": total_paragraphs,
            "table_count": total_tables,
            "has_targets": "ëª©í‘œ" in all_text,
            "has_achievements": "ì‹¤ì " in all_text
        }

        assert summary["paragraph_count"] > 0
        assert summary["has_targets"] is True

    def test_multilingual_document(self, temp_dir):
        """ë‹¤êµ­ì–´ ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
        document = HWPXDocument(
            metadata=DocumentMetadata(
                title="å¤šè¨€èª ë¬¸ì„œ / Multilingual Document",
                author="í…ŒìŠ¤íŠ¸ / Test / ãƒ†ã‚¹ãƒˆ"
            )
        )

        section = Section()

        # ë‹¤ì–‘í•œ ì–¸ì–´ì˜ í…ìŠ¤íŠ¸
        multilingual_texts = [
            ("í•œê¸€ ì•ˆë…•í•˜ì„¸ìš”", "Korean"),
            ("English Hello World", "English"),
            ("æ—¥æœ¬èª ã“ã‚“ã«ã¡ã¯", "Japanese"),
            ("ä¸­æ–‡ ä½ å¥½ä¸–ç•Œ", "Chinese"),
            ("Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø±Ø­Ø¨Ø§", "Arabic"),
            ("Ğ ÑƒÑÑĞºĞ¸Ğ¹ ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€", "Russian"),
            ("Emoji Test ğŸŒğŸ“šâœ…", "Emoji")
        ]

        for text, lang in multilingual_texts:
            para = Paragraph()
            para.runs.append(TextRun(text=f"{lang}: {text}"))
            section.paragraphs.append(para)

        document.add_section(section)

        # Markdownìœ¼ë¡œ ë³€í™˜
        markdown_content = document.to_markdown()

        # ëª¨ë“  ì–¸ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        for text, _ in multilingual_texts:
            assert text in markdown_content

        # íŒŒì¼ ì €ì¥
        md_path = temp_dir / "multilingual.md"
        md_path.write_text(markdown_content, encoding='utf-8')

        # UTF-8ë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
        with open(md_path, 'r', encoding='utf-8') as f:
            saved_content = f.read()
            for text, _ in multilingual_texts:
                assert text in saved_content