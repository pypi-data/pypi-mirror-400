{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ccd6d63",
   "metadata": {},
   "source": [
    "# **Example**: Split a Document by Tokens with `TokenSplitter` (SpaCy, NLTK, tiktoken)\n",
    "\n",
    "In this example, we will use several popular NLP libraries to split a text document into token-based chunks. A **token** is the lexical unit in which a text is divided into. Tokenization can be performed in many ways: by words, by characters, by lemmas, etc. One of the most common methods is by sub-words. \n",
    "\n",
    "Observe the following example:\n",
    "\n",
    "![Tokenization illustration](https://miro.medium.com/v2/resize:fit:1400/1*8QoeQNDcgwHjrS4AcX3V8g.png)\n",
    "\n",
    "Most of Large Language Model uses tokenizers to process a large text into comprehensive lexical units . Hence, split by tokens could be a suitable option to produce chunks of a fixed length compatible with the LLM context window. So, in this tutorial we show how to split the text using three tokenizers: [**SpaCy**](https://spacy.io/api), [**NLTK**](https://www.nltk.org/), and [**tiktoken**](https://github.com/openai/tiktoken) (OpenAI tokenization). Let's see!\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Read the Text Using a Reader\n",
    "\n",
    "We will start by reading a text file using the [`MarkItDownReader`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#markitdownreader). Remember that you can use any other compatible [Reader](https://andreshere00.github.io/Splitter_MR/api_reference/reader.md). Simply, instantiate a Reader object and use the `read` method. Provide as an argument the file to be read, which can be an URL, variable or path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033384f1",
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from splitter_mr.reader import MarkItDownReader\n",
    "\n",
    "file = \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/my_wonderful_family.txt\"\n",
    "reader = MarkItDownReader()\n",
    "reader_output = reader.read(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39816cd1",
   "metadata": {},
   "source": [
    "\n",
    "The output is a `ReaderOutput` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00461f5",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"My Wonderful Family\\nI live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong. She cooks the best food!\\n\\nMy family is very important to me. We do lots of things together. My brothers and I like to go on long walks in the mountains. My sister likes to cook with my grandmother. On the weekends we all play board games together. We laugh and always have a good time. I love my family very much.\",\n",
      "    \"document_name\": \"my_wonderful_family.txt\",\n",
      "    \"document_path\": \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/my_wonderful_family.txt\",\n",
      "    \"document_id\": \"ca4c32e4-2b42-4ae3-beb1-b60fa9d44c38\",\n",
      "    \"conversion_method\": \"markdown\",\n",
      "    \"reader_method\": \"markitdown\",\n",
      "    \"ocr_method\": null,\n",
      "    \"page_placeholder\": null,\n",
      "    \"metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(reader_output.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f92e07",
   "metadata": {},
   "source": [
    "\n",
    "To see only the document text, you can access to the `text` attribute of this object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a0245a",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Wonderful Family\n",
      "I live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong. She cooks the best food!\n",
      "\n",
      "My family is very important to me. We do lots of things together. My brothers and I like to go on long walks in the mountains. My sister likes to cook with my grandmother. On the weekends we all play board games together. We laugh and always have a good time. I love my family very much.\n"
     ]
    }
   ],
   "source": [
    "print(reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5960e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Step 2: Split the Document by Tokens\n",
    "\n",
    "As we have said, the `TokenSplitter` lets you pick the tokenization backend: **SpaCy**, **NLTK**, or **tiktoken**. Use one or another depending on your needs. For every tokenizer, it should be passed:\n",
    "\n",
    "- A `chunk_size`, the maximum chunk size in characters for the tokenization process. It tries to never cut a sentence in two chunks.\n",
    "- A `model_name`, the tokenizer model to use. It should always follows this structure: `{tokenizer}/{model_name}`, e.g., `tiktoken/cl100k_base`. \n",
    "\n",
    "!!! Note\n",
    "    For **spaCy** and **tiktoken**, the corresponding models must be installed in your environment.\n",
    "\n",
    "To see a complete list of available tokenizers, refer to [Available models](#available-models).\n",
    "\n",
    "### 2.1. Split by Tokens Using **SpaCy**\n",
    "\n",
    "To split using a spaCy tokenizer model, you firstly need to instantiate the `TokenSplitter` class and select the parameters. Then, call to the `split` method with the path, URL or variable to split on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdf9fcf9",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "chunks=['My Wonderful Family\\nI live in a house near the mountains.', 'I have two brothers and one sister, and I was born last.', 'My father teaches mathematics, and my mother is a nurse at a big hospital.', 'My brothers are very smart and work hard in school.', 'My sister is a nervous girl, but she is very kind.\\n\\nMy grandmother also lives with us.', 'She came from Italy when I was two years old.\\n\\nShe has grown old, but she is still very strong.', 'She cooks the best food!\\n\\n\\n\\nMy family is very important to me.\\n\\nWe do lots of things together.', 'My brothers and I like to go on long walks in the mountains.', 'My sister likes to cook with my grandmother.\\n\\nOn the weekends we all play board games together.', 'We laugh and always have a good time.\\n\\nI love my family very much.'] chunk_id=['fb221efe-ed04-4285-b086-47bd713aa7e1', '8e477666-bc53-4a3b-a04b-2742800458be', '6e578d17-9a0b-4a9d-ac8c-89826e8439a9', 'cdd7ef5e-9174-467c-a65a-f6c76863ba06', '6bb2b2ba-e90e-4c2c-abfa-acee47f1a521', '3029b14a-7093-49f8-b40b-d3c01b66d813', '5c0fbb14-8e84-41e1-8647-36df3d1ea912', '37d818d0-ceb9-4f3f-b87d-a85bca9c56b8', 'c4c23979-fd3e-415b-a403-d3e958fbbf3e', 'c26e1d36-04f2-4bc9-9c41-9e03ce93fe7b'] document_name='my_wonderful_family.txt' document_path='https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/my_wonderful_family.txt' document_id='ca4c32e4-2b42-4ae3-beb1-b60fa9d44c38' conversion_method='markdown' reader_method='markitdown' ocr_method=None split_method='token_splitter' split_params={'chunk_size': 100, 'model_name': 'spacy/en_core_web_sm', 'language': 'english'} metadata={}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aherencia/Documents/Projects/Splitter_MR/.venv/lib/python3.13/site-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.splitter import TokenSplitter\n",
    "\n",
    "spacy_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"spacy/en_core_web_sm\",  # Use the SpaCy model with \"spacy/{model_name}\" format\n",
    ")\n",
    "spacy_output = spacy_splitter.split(reader_output)\n",
    "\n",
    "print(spacy_output)  # See the SplitterOutput object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aabcf5",
   "metadata": {},
   "source": [
    "\n",
    "To see the resulting chunks, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95de1180",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "I live in a house near the mountains.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I have two brothers and one sister, and I was born last.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My father teaches mathematics, and my mother is a nurse at a big hospital.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "My brothers are very smart and work hard in school.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "My sister is a nervous girl, but she is very kind.\n",
      "\n",
      "My grandmother also lives with us.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "She came from Italy when I was two years old.\n",
      "\n",
      "She has grown old, but she is still very strong.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "She cooks the best food!\n",
      "\n",
      "\n",
      "\n",
      "My family is very important to me.\n",
      "\n",
      "We do lots of things together.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "My brothers and I like to go on long walks in the mountains.\n",
      "\n",
      "======================================== Chunk 9 ========================================\n",
      "My sister likes to cook with my grandmother.\n",
      "\n",
      "On the weekends we all play board games together.\n",
      "\n",
      "======================================== Chunk 10 ========================================\n",
      "We laugh and always have a good time.\n",
      "\n",
      "I love my family very much.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize each chunk\n",
    "for idx, chunk in enumerate(spacy_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd89f54",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2. Split by Tokens Using **NLTK**\n",
    "\n",
    "Similarly, you can use a NLTK tokenizer. This library will always use `punkt` as the tokenizer, but you can customize the language through this parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72dd5839",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aherencia/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "I live in a house near the mountains.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I have two brothers and one sister, and I was born last.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My father teaches mathematics, and my mother is a nurse at a big hospital.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "My brothers are very smart and work hard in school.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "My sister is a nervous girl, but she is very kind.\n",
      "\n",
      "My grandmother also lives with us.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "She came from Italy when I was two years old.\n",
      "\n",
      "She has grown old, but she is still very strong.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "She cooks the best food!\n",
      "\n",
      "My family is very important to me.\n",
      "\n",
      "We do lots of things together.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "My brothers and I like to go on long walks in the mountains.\n",
      "\n",
      "======================================== Chunk 9 ========================================\n",
      "My sister likes to cook with my grandmother.\n",
      "\n",
      "On the weekends we all play board games together.\n",
      "\n",
      "======================================== Chunk 10 ========================================\n",
      "We laugh and always have a good time.\n",
      "\n",
      "I love my family very much.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"nltk/punkt\",  # Use the NLTK model as \"nltk/{model_name}\"\n",
    "    language=\"english\",  # Defaults to English\n",
    ")\n",
    "nltk_output = nltk_splitter.split(reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(nltk_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10e509",
   "metadata": {},
   "source": [
    "\n",
    "As you can see, the results are basically the same.\n",
    "\n",
    "### 2.3. Split by Tokens Using **tiktoken** (OpenAI)\n",
    "\n",
    "TikToken is one of the most extended tokenizer models. In this case, this tokenizer split by the number of tokens and chunks if `\\\\n\\\\n` is detected. Hence, the results are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab34f45b",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong. She cooks the best food!\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My family is very important to me. We do lots of things together. My brothers and I like to go on long walks in the mountains. My sister likes to cook with my grandmother. On the weekends we all play board games together. We laugh and always have a good time. I love my family very much.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tiktoken_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"tiktoken/cl100k_base\",  # Use the tiktoken model as \"tiktoken/{model_name}\"\n",
    "    language=\"english\",\n",
    ")\n",
    "tiktoken_output = tiktoken_splitter.split(reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(tiktoken_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1912f7",
   "metadata": {},
   "source": [
    "\n",
    "## **Extra:** Split by Tokens in Other Languages (e.g., Spanish)\n",
    "\n",
    "In previous examples, we show you how to split the text by tokens, but these models were adapted to English. But in case that you have texts in other languages, you can use other Tokenizers. Here, there are two examples with SpaCy and NLTK (tiktoken is multilingual by default):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea922566",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aherencia/Documents/Projects/Splitter_MR/src/splitter_mr/reader/readers/docling_reader.py:89: UserWarning: Unsupported extension 'txt'. Using VanillaReader.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra. Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles. El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar. El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas. Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión. Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import DoclingReader\n",
    "\n",
    "sp_file = \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/mi_nueva_casa.txt\"\n",
    "sp_reader = DoclingReader()\n",
    "sp_reader_output = sp_reader.read(sp_file)\n",
    "print(sp_reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756b441c",
   "metadata": {},
   "source": [
    "\n",
    "### Split Spanish by Tokens Using **SpaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f0bbd8",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting es-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: es-core-news-sm\n",
      "Successfully installed es-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('es_core_news_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 00:21:19,856 - WARNING - Created a chunk of size 107, which is longer than the specified 100\n",
      "2025-11-25 00:21:19,859 - WARNING - Created a chunk of size 142, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spacy_sp_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"spacy/es_core_news_sm\",  # Use a Spanish SpaCy model\n",
    ")\n",
    "spacy_sp_output = spacy_sp_splitter.split(sp_reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(spacy_sp_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86bcc8c",
   "metadata": {},
   "source": [
    "\n",
    "### Split Spanish by Tokens Using **NLTK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c7fd96",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aherencia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "2025-11-25 00:21:19,906 - WARNING - Created a chunk of size 107, which is longer than the specified 100\n",
      "2025-11-25 00:21:19,907 - WARNING - Created a chunk of size 142, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nltk_sp_splitter = TokenSplitter(\n",
    "    chunk_size=100, model_name=\"nltk/punkt\", language=\"spanish\"\n",
    ")\n",
    "nltk_sp_output = nltk_sp_splitter.split(sp_reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(nltk_sp_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777231fc",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**And that’s it!**\n",
    "You can now tokenize and chunk text with precision, using the NLP backend and language that best fits your project.\n",
    "\n",
    "!!! note\n",
    "    For best results, make sure to install any SpaCy/NLTK/tiktoken models needed for your language and task.\n",
    "\n",
    "## **Complete Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dfbf12f",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Wonderful Family\n",
      "I live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong. She cooks the best food!\n",
      "\n",
      "My family is very important to me. We do lots of things together. My brothers and I like to go on long walks in the mountains. My sister likes to cook with my grandmother. On the weekends we all play board games together. We laugh and always have a good time. I love my family very much.\n",
      "**************************************** spaCy ****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aherencia/Documents/Projects/Splitter_MR/.venv/lib/python3.13/site-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aherencia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"chunks\": [\n",
      "        \"My Wonderful Family\\nI live in a house near the mountains.\",\n",
      "        \"I have two brothers and one sister, and I was born last.\",\n",
      "        \"My father teaches mathematics, and my mother is a nurse at a big hospital.\",\n",
      "        \"My brothers are very smart and work hard in school.\",\n",
      "        \"My sister is a nervous girl, but she is very kind.\\n\\nMy grandmother also lives with us.\",\n",
      "        \"She came from Italy when I was two years old.\\n\\nShe has grown old, but she is still very strong.\",\n",
      "        \"She cooks the best food!\\n\\n\\n\\nMy family is very important to me.\\n\\nWe do lots of things together.\",\n",
      "        \"My brothers and I like to go on long walks in the mountains.\",\n",
      "        \"My sister likes to cook with my grandmother.\\n\\nOn the weekends we all play board games together.\",\n",
      "        \"We laugh and always have a good time.\\n\\nI love my family very much.\"\n",
      "    ],\n",
      "    \"chunk_id\": [\n",
      "        \"50353b7f-74c9-4c90-bb69-9034388501cf\",\n",
      "        \"0c72a43b-cda5-4a99-986f-724d8b6be6eb\",\n",
      "        \"f34be6df-335c-4dbc-9c60-4b9669e62189\",\n",
      "        \"1f86925d-c216-4f7b-953d-7a7b028f98e8\",\n",
      "        \"e9006699-fa48-4096-adbd-2b1a21940b48\",\n",
      "        \"111a010f-fafd-429c-9ead-e9afe634c25c\",\n",
      "        \"96f80f88-dfa1-48bd-8fd5-567dbdd3c5f1\",\n",
      "        \"2f863114-9117-414c-9a11-7f6ec410b925\",\n",
      "        \"f3ae9039-458e-41e3-b1cc-8e22337c0798\",\n",
      "        \"db35b843-c572-46c0-bba4-ccc23bd95205\"\n",
      "    ],\n",
      "    \"document_name\": \"my_wonderful_family.txt\",\n",
      "    \"document_path\": \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/my_wonderful_family.txt\",\n",
      "    \"document_id\": \"5298c61a-2aa3-408e-b0c8-63f5fc75e8f2\",\n",
      "    \"conversion_method\": \"markdown\",\n",
      "    \"reader_method\": \"markitdown\",\n",
      "    \"ocr_method\": null,\n",
      "    \"split_method\": \"token_splitter\",\n",
      "    \"split_params\": {\n",
      "        \"chunk_size\": 100,\n",
      "        \"model_name\": \"spacy/en_core_web_sm\",\n",
      "        \"language\": \"english\"\n",
      "    },\n",
      "    \"metadata\": {}\n",
      "}\n",
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "I live in a house near the mountains.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I have two brothers and one sister, and I was born last.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My father teaches mathematics, and my mother is a nurse at a big hospital.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "My brothers are very smart and work hard in school.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "My sister is a nervous girl, but she is very kind.\n",
      "\n",
      "My grandmother also lives with us.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "She came from Italy when I was two years old.\n",
      "\n",
      "She has grown old, but she is still very strong.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "She cooks the best food!\n",
      "\n",
      "\n",
      "\n",
      "My family is very important to me.\n",
      "\n",
      "We do lots of things together.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "My brothers and I like to go on long walks in the mountains.\n",
      "\n",
      "======================================== Chunk 9 ========================================\n",
      "My sister likes to cook with my grandmother.\n",
      "\n",
      "On the weekends we all play board games together.\n",
      "\n",
      "======================================== Chunk 10 ========================================\n",
      "We laugh and always have a good time.\n",
      "\n",
      "I love my family very much.\n",
      "\n",
      "**************************************** NLTK ****************************************\n",
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "I live in a house near the mountains.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I have two brothers and one sister, and I was born last.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My father teaches mathematics, and my mother is a nurse at a big hospital.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "My brothers are very smart and work hard in school.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "My sister is a nervous girl, but she is very kind.\n",
      "\n",
      "My grandmother also lives with us.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "She came from Italy when I was two years old.\n",
      "\n",
      "She has grown old, but she is still very strong.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "She cooks the best food!\n",
      "\n",
      "My family is very important to me.\n",
      "\n",
      "We do lots of things together.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "My brothers and I like to go on long walks in the mountains.\n",
      "\n",
      "======================================== Chunk 9 ========================================\n",
      "My sister likes to cook with my grandmother.\n",
      "\n",
      "On the weekends we all play board games together.\n",
      "\n",
      "======================================== Chunk 10 ========================================\n",
      "We laugh and always have a good time.\n",
      "\n",
      "I love my family very much.\n",
      "\n",
      "**************************************** Tiktoken ****************************************\n",
      "======================================== Chunk 1 ========================================\n",
      "My Wonderful Family\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "I live in a house near the mountains. I have two brothers and one sister, and I was born last. My father teaches mathematics, and my mother is a nurse at a big hospital. My brothers are very smart and work hard in school. My sister is a nervous girl, but she is very kind. My grandmother also lives with us. She came from Italy when I was two years old. She has grown old, but she is still very strong. She cooks the best food!\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "My family is very important to me. We do lots of things together. My brothers and I like to go on long walks in the mountains. My sister likes to cook with my grandmother. On the weekends we all play board games together. We laugh and always have a good time. I love my family very much.\n",
      "\n",
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra. Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles. El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar. El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas. Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión. Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n",
      "\n",
      "**************************************** Spacy in Spanish ****************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 00:21:20,780 - WARNING - Created a chunk of size 107, which is longer than the specified 100\n",
      "2025-11-25 00:21:20,780 - WARNING - Created a chunk of size 142, which is longer than the specified 100\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/aherencia/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "2025-11-25 00:21:20,782 - WARNING - Created a chunk of size 107, which is longer than the specified 100\n",
      "2025-11-25 00:21:20,782 - WARNING - Created a chunk of size 142, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================== Chunk 1 ========================================\n",
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n",
      "**************************************** NLTK in Spanish ****************************************\n",
      "======================================== Chunk 1 ========================================\n",
      "Mi nueva casa\n",
      "Yo vivo en Granada, una ciudad pequeña que tiene monumentos muy importantes como la Alhambra.\n",
      "\n",
      "======================================== Chunk 2 ========================================\n",
      "Aquí la comida es deliciosa y son famosos el gazpacho, el rebujito y el salmorejo.\n",
      "\n",
      "======================================== Chunk 3 ========================================\n",
      "Mi nueva casa está en una calle ancha que tiene muchos árboles.\n",
      "\n",
      "======================================== Chunk 4 ========================================\n",
      "El piso de arriba de mi casa tiene tres dormitorios y un despacho para trabajar.\n",
      "\n",
      "======================================== Chunk 5 ========================================\n",
      "El piso de abajo tiene una cocina muy grande, un comedor con una mesa y seis sillas, un salón con dos sofás verdes, una televisión y cortinas.\n",
      "\n",
      "======================================== Chunk 6 ========================================\n",
      "Además, tiene una pequeña terraza con piscina donde puedo tomar el sol en verano.\n",
      "\n",
      "======================================== Chunk 7 ========================================\n",
      "Me gusta mucho mi casa porque puedo invitar a mis amigos a cenar o a ver el fútbol en mi televisión.\n",
      "\n",
      "======================================== Chunk 8 ========================================\n",
      "Además, cerca de mi casa hay muchas tiendas para hacer la compra, como panadería, carnicería y pescadería.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import DoclingReader, MarkItDownReader\n",
    "from splitter_mr.splitter import TokenSplitter\n",
    "\n",
    "# 1. Read the file using any Reader (e.g., MarkItDownReader)\n",
    "\n",
    "file = \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/my_wonderful_family.txt\"\n",
    "\n",
    "reader = MarkItDownReader()\n",
    "reader_output = reader.read(file)\n",
    "print(reader_output.text)\n",
    "\n",
    "# 2. Split by Tokens\n",
    "\n",
    "## 2.1. Using SpaCy\n",
    "\n",
    "print(\"*\" * 40 + \" spaCy \" + \"*\" * 40)\n",
    "\n",
    "spacy_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"spacy/en_core_web_sm\",  # Select a valid model with nomenclature spacy/{model_name}.\n",
    ")\n",
    "# Note that it is required to have the model installed in your execution machine.\n",
    "\n",
    "spacy_output = spacy_splitter.split(reader_output)  # Split the text\n",
    "print(spacy_output.model_dump_json(indent=4))  # Print the SplitterOutput object\n",
    "\n",
    "# Visualize each chunk\n",
    "for idx, chunk in enumerate(spacy_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")\n",
    "\n",
    "## 2.2. Using NLTK\n",
    "\n",
    "print(\"*\" * 40 + \" NLTK \" + \"*\" * 40)\n",
    "\n",
    "nltk_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"nltk/punkt\",  # introduce the model as nltk/{model_name}\n",
    "    language=\"english\",  # defaults to this language\n",
    ")\n",
    "\n",
    "nltk_output = nltk_splitter.split(reader_output)\n",
    "\n",
    "# Visualize each chunk\n",
    "for idx, chunk in enumerate(nltk_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")\n",
    "\n",
    "## 2.3. Using tiktoken\n",
    "\n",
    "print(\"*\" * 40 + \" Tiktoken \" + \"*\" * 40)\n",
    "\n",
    "tiktoken_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"tiktoken/cl100k_base\",  # introduce the model as tiktoken/{model_name}\n",
    "    language=\"english\",\n",
    ")\n",
    "\n",
    "tiktoken_output = tiktoken_splitter.split(reader_output)\n",
    "\n",
    "# Visualize each chunk\n",
    "for idx, chunk in enumerate(tiktoken_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")\n",
    "\n",
    "## 2.4. Split by tokens in other languages (e.g., Spanish)\n",
    "\n",
    "sp_file = \"https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/mi_nueva_casa.txt\"\n",
    "\n",
    "sp_reader = DoclingReader()\n",
    "sp_reader_output = sp_reader.read(sp_file)\n",
    "print(sp_reader_output.text)  # Visualize the text content\n",
    "\n",
    "### 2.4.1. Using SpaCy\n",
    "\n",
    "print(\"*\" * 40 + \" Spacy in Spanish \" + \"*\" * 40)\n",
    "\n",
    "spacy_sp_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"spacy/es_core_news_sm\",  # Pick another model in Spanish\n",
    ")\n",
    "nltk_sp_output = spacy_sp_splitter.split(sp_reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(nltk_sp_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")\n",
    "\n",
    "### 2.4.2 Using NLTK\n",
    "\n",
    "print(\"*\" * 40 + \" NLTK in Spanish \" + \"*\" * 40)\n",
    "\n",
    "nltk_sp_splitter = TokenSplitter(\n",
    "    chunk_size=100,\n",
    "    model_name=\"nltk/punkt\",\n",
    "    language=\"spanish\",  # select `spanish` as language for the tokenizer\n",
    ")\n",
    "nltk_sp_output = nltk_sp_splitter.split(sp_reader_output)\n",
    "\n",
    "for idx, chunk in enumerate(nltk_sp_output.chunks):\n",
    "    print(\"=\" * 40 + f\" Chunk {idx + 1} \" + \"=\" * 40 + \"\\n\" + chunk + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c8e8c",
   "metadata": {},
   "source": [
    "\n",
    "## Available models\n",
    "\n",
    "There are several tokenizer models that you can use to split your text. In the following table is provided a summary of the models that you can currently use, among with some implementation examples:\n",
    "\n",
    "| **Library**      | **Model identifier/template**                                                                                                      | **How to implement**                      | **Reference Guide**                                            |\n",
    "| :--------------- | :--------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------- | :------------------------------------------------------------- |\n",
    "| **NLTK (Punkt)** | `<language>`                                                                                                                       | See [NLTK Example](#nltk-example)         | [NLTK Tokenizers](https://www.nltk.org/api/nltk.tokenize.html) |\n",
    "| **Tiktoken**     | `<encoder>`                                                                                                                        | See [Tiktoken Example](#tiktoken-example) | [tiktoken](https://github.com/openai/tiktoken)                 |\n",
    "| **spaCy**        | `{CC}_core_web_sm`,<br>`{CC}_core_web_md`,<br>`{CC}_core_web_lg`,<br>`{CCe}_core_web_trf`,<br>`xx_ent_wiki_sm`,<br>`xx_sent_ud_sm` | See [spaCy Example](#spacy-example)       | [spaCy Models](https://spacy.io/usage/models)                  |\n",
    "\n",
    "**spaCy Model Suffixes:**\n",
    "- `sm` (**small**): Fastest, small in size, less accurate; good for prototyping and lightweight use-cases.\n",
    "- `md` (**medium**): Medium size and accuracy; balances speed and performance.\n",
    "- `lg` (**large**): Largest and most accurate pipeline with the most vectors; slower and uses more memory.\n",
    "- `trf` (**transformer**): Uses transformer-based architectures (e.g., BERT, RoBERTa); highest accuracy, slowest, and requires more resources.\n",
    "\n",
    "### NLTK Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78050bdb",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splitter_mr.splitter.splitters.token_splitter.TokenSplitter at 0x33571c5f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = \"english\"\n",
    "TokenSplitter(model_name=\"nltk/punkt\", language=language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faf4a47",
   "metadata": {},
   "source": [
    "\n",
    "### Tiktoken Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "851034ba",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splitter_mr.splitter.splitters.token_splitter.TokenSplitter at 0x31d9d35c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = \"cl100k_base\"\n",
    "TokenSplitter(model_name=f\"tiktoken/{encoder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f3f93",
   "metadata": {},
   "source": [
    "\n",
    "### spaCy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdca2092",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<splitter_mr.splitter.splitters.token_splitter.TokenSplitter at 0x33542f150>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CC = \"en\"\n",
    "ext = \"sm\"\n",
    "encoder = f\"{CC}_core_web_{ext}\"\n",
    "TokenSplitter(model_name=f\"spacy/{encoder}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "orig_format": "markdown",
  "source_file": "docs/examples/text/token_splitter.md"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
