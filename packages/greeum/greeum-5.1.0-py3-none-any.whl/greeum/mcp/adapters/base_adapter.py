#!/usr/bin/env python3
"""
ê¸°ë³¸ MCP ì–´ëŒ‘í„° ì¸í„°í˜ì´ìŠ¤
- ëª¨ë“  í™˜ê²½ë³„ ì–´ëŒ‘í„°ì˜ ê³µí†µ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
- Greeum ì»´í¬ë„ŒíŠ¸ í†µí•© ì´ˆê¸°í™”
- ê¸°ì¡´ ë„êµ¬ API ì™„ì „ í˜¸í™˜ì„± ë³´ì¥
"""

import asyncio
import logging
import uuid
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

# Greeum í•µì‹¬ ì»´í¬ë„ŒíŠ¸
try:
    from greeum.core.block_manager import BlockManager
    from greeum.core import DatabaseManager  # Thread-safe factory pattern  
    from greeum.core.stm_manager import STMManager
    from greeum.core.duplicate_detector import DuplicateDetector
    from greeum.core.quality_validator import QualityValidator
    from greeum.core.usage_analytics import UsageAnalytics
    from greeum.core.search_engine import SearchEngine
    GREEUM_AVAILABLE = True
except ImportError:
    GREEUM_AVAILABLE = False

logger = logging.getLogger(__name__)

class BaseAdapter(ABC):
    """ëª¨ë“  MCP ì–´ëŒ‘í„°ì˜ ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.components = None
        self.initialized = False
        
    def initialize_greeum_components(self) -> Optional[Dict[str, Any]]:
        """Greeum í•µì‹¬ ì»´í¬ë„ŒíŠ¸ í†µí•© ì´ˆê¸°í™”"""
        if self.components is not None:
            return self.components
            
        if not GREEUM_AVAILABLE:
            logger.error("[ERROR] Greeum components not available")
            return None
            
        try:
            # í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”
            db_manager = DatabaseManager()
            block_manager = BlockManager(db_manager)
            stm_manager = STMManager(db_manager)
            duplicate_detector = DuplicateDetector(db_manager)
            quality_validator = QualityValidator()
            usage_analytics = UsageAnalytics(db_manager)
            search_engine = SearchEngine(block_manager)
            
            self.components = {
                'db_manager': db_manager,
                'block_manager': block_manager,
                'stm_manager': stm_manager,
                'duplicate_detector': duplicate_detector,
                'quality_validator': quality_validator,
                'usage_analytics': usage_analytics,
                'search_engine': search_engine
            }
            
            self.initialized = True
            logger.info("âœ… Greeum components initialized successfully")
            return self.components
            
        except Exception as e:
            logger.error(f"[ERROR] Failed to initialize Greeum components: {e}")
            return None
    
    # ê³µí†µ ë„êµ¬ êµ¬í˜„ (ëª¨ë“  ì–´ëŒ‘í„°ì—ì„œ ë™ì¼)
    def add_memory_tool(self, content: str, importance: float = 0.5) -> str:
        """ë©”ëª¨ë¦¬ ì¶”ê°€ ë„êµ¬ - v3 Branch/Slot ìš°ì„  ì €ì¥ ì ìš©"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"

        try:
            # ì¤‘ë³µ ê²€ì‚¬
            duplicate_check = self.components['duplicate_detector'].check_duplicate(content)
            if duplicate_check["is_duplicate"]:
                similarity = duplicate_check["similarity_score"]

                # Get block index from similar_memories (safe access)
                block_index = 'unknown'
                if duplicate_check.get('similar_memories'):
                    first_similar = duplicate_check['similar_memories'][0]
                    block_index = first_similar.get('block_index', 'unknown')

                return f"""âš ï¸  **Potential Duplicate Memory Detected**

**Similarity**: {similarity:.1%} with existing memory
**Similar Memory**: Block #{block_index}

Please search existing memories first or provide more specific content."""

            # í’ˆì§ˆ ê²€ì¦
            quality_result = self.components['quality_validator'].validate_memory_quality(content, importance)

            # v3 ë¸Œëœì¹˜/ìŠ¬ë¡¯ ìš°ì„  ì €ì¥ ì ìš©
            block_result = self._add_memory_via_core(content, importance)

            # ì‚¬ìš© í†µê³„ ë¡œê¹…
            self.components['usage_analytics'].log_quality_metrics(
                len(content), quality_result['quality_score'], quality_result['quality_level'],
                importance, importance, False, duplicate_check["similarity_score"],
                len(quality_result.get('suggestions', []))
            )

            # ì„±ê³µ ì‘ë‹µ - ë¸Œëœì¹˜/ìŠ¬ë¡¯ ì •ë³´ í¬í•¨
            quality_feedback = f"""
**Quality Score**: {quality_result['quality_score']:.1%} ({quality_result['quality_level']})
**Adjusted Importance**: {importance:.2f} (original: {importance:.2f})"""

            suggestions_text = ""
            if quality_result.get('suggestions'):
                suggestions_text = f"\n\nğŸ’¡ **Quality Suggestions**:\n" + "\n".join(f"â€¢ {s}" for s in quality_result['suggestions'][:2])

            # ë¸Œëœì¹˜/ìŠ¬ë¡¯ ë©”íƒ€ í‘œì‹œ ë° ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì •ë³´
            slot_info = ""
            routing_info = ""

            # Check if block_result is a dictionary and has the required fields
            if isinstance(block_result, dict):
                # ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ì •ë³´ ì¶”ì¶œ (metadataì—ì„œ)
                if block_result.get('metadata'):
                    metadata = block_result['metadata']
                    if isinstance(metadata, dict) and metadata.get('smart_routing'):
                        routing_info = f"\n\nğŸ¯ **Smart Routing Applied**:"
                        if metadata['smart_routing'].get('slot_updated'):
                            routing_info += f"\nâ€¢ STM Slot: {metadata['smart_routing']['slot_updated']}"
                        if metadata['smart_routing'].get('similarity_score'):
                            routing_info += f"\nâ€¢ Similarity: {metadata['smart_routing']['similarity_score']:.2%}"
                        if metadata['smart_routing'].get('placement'):
                            routing_info += f"\nâ€¢ Placement: {metadata['smart_routing']['placement']}"

            # ê¸°ë³¸ ìŠ¬ë¡¯ ì •ë³´
            if block_result.get('slot'):
                slot_info = f"\n**Slot**: {block_result['slot']}"
            if block_result.get('root'):
                slot_info += f"\n**Branch Root**: {block_result['root'][:8]}..."
            if block_result.get('before'):
                slot_info += f"\n**Connected to**: Block #{block_result['before']}"

            return f"""âœ… **Memory Successfully Added!**

**Block Index**: #{block_result.get('id', block_result.get('block_index'))}
**Storage**: Branch-based (v3 System){slot_info}
**Duplicate Check**: âœ… Passed{quality_feedback}{suggestions_text}{routing_info}"""

        except Exception as e:
            logger.error(f"add_memory failed: {e}")
            return f"[ERROR] Failed to add memory: {str(e)}"
    
    def search_memory_tool(self, query: str, limit: int = 5, depth: int = 0, tolerance: float = 0.5, entry: str = "cursor") -> str:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ - v3 ìŠ¬ë¡¯/DFS ìš°ì„  ê²€ìƒ‰ ì ìš©"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"

        try:
            # v3 ìŠ¬ë¡¯/DFS ìš°ì„  ê²€ìƒ‰ ì ìš©
            search_result = self._search_memory_via_core(query, limit, entry=entry, depth=depth)

            # ê²€ìƒ‰ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
            results = search_result.get('items', search_result.get('results', []))
            meta = search_result.get('meta', {})

            # ì—°ê´€ê´€ê³„ í™•ì¥ íƒìƒ‰ (depth > 0ì¸ ê²½ìš°) - ê¸°ì¡´ ë¡œì§ ìœ ì§€
            if depth > 0 and results and not meta.get('search_type', '').startswith('local_dfs'):
                results = self._expand_search_with_associations(results, depth, tolerance, limit)

            # ì‚¬ìš© í†µê³„ ë¡œê¹… (í™•ì¥ëœ íŒŒë¼ë¯¸í„° í¬í•¨)
            self.components['usage_analytics'].log_event(
                "tool_usage", "search_memory",
                {
                    "query_length": len(query),
                    "results_found": len(results),
                    "limit_requested": limit,
                    "depth": depth,
                    "tolerance": tolerance,
                    "search_type": meta.get('search_type', 'direct'),
                    "entry_type": meta.get('entry_type', entry)
                },
                0, True
            )

            if results:
                # ë©”íƒ€ì •ë³´ í‘œì‹œ
                search_info = f"ğŸ” Found {len(results)} memories"
                if meta.get('search_type'):
                    search_info += f" ({meta['search_type']}"
                    if meta.get('entry_type'):
                        search_info += f", entry: {meta['entry_type']}"
                    if meta.get('hops'):
                        search_info += f", hops: {meta['hops']}"
                    search_info += ")"
                elif depth > 0:
                    search_info += f" (depth {depth}, tolerance {tolerance:.1f})"
                search_info += ":\n"

                for i, memory in enumerate(results, 1):
                    timestamp = memory.get('timestamp', 'Unknown')
                    content = memory.get('context', '')[:100] + ('...' if len(memory.get('context', '')) > 100 else '')

                    # v3 ê²€ìƒ‰ íƒ€ì…ë³„ í‘œì‹œ
                    type_info = ""
                    if meta.get('search_type') == 'local_dfs_adaptive':
                        type_info = " [ğŸ¯DFS]"
                    elif meta.get('search_type') == 'jump':
                        type_info = " [âš¡JUMP]"
                    elif meta.get('search_type') == 'global':
                        type_info = " [ğŸŒGLOBAL]"
                    elif memory.get('relation_type'):
                        # ê¸°ì¡´ ì—°ê´€ê´€ê³„ í‘œì‹œ ë¡œì§ ìœ ì§€
                        if memory['relation_type'] == 'direct_match':
                            type_info = " [ğŸ¯]"
                        elif 'depth_1' in memory['relation_type']:
                            type_info = " [[LINK]]"
                        elif 'depth_2' in memory['relation_type']:
                            type_info = " [[LINK][LINK]]"
                        elif 'depth_3' in memory['relation_type']:
                            type_info = " [[LINK][LINK][LINK]]"

                    search_info += f"{i}. [{timestamp}]{type_info} {content}\n"

                # ë””ë²„ê·¸ ë©”íƒ€ ì •ë³´ ì¶”ê°€
                if meta.get('time_ms'):
                    search_info += f"\nâš¡ Search completed in {meta['time_ms']}ms"
                if meta.get('slot'):
                    search_info += f" | Slot: {meta['slot']}"

                return search_info
            else:
                return f"ğŸ” No memories found for query: '{query}' (search: {meta.get('search_type', 'direct')})"

        except Exception as e:
            logger.error(f"search_memory failed: {e}")
            return f"[ERROR] Search failed: {str(e)}"
    
    def get_memory_stats_tool(self) -> str:
        """ë©”ëª¨ë¦¬ í†µê³„ ë„êµ¬ - ë¡œì»¬ DB ê¸°ì¤€ìœ¼ë¡œ ì •í™•í•œ í†µê³„ ì œê³µ"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            db_manager = self.components['db_manager']
            stm_manager = self.components['stm_manager']
            
            # ì§ì ‘ SQLì„ ì‚¬ìš©í•œ ì •í™•í•œ í†µê³„ ê³„ì‚°
            stats = self._get_detailed_memory_stats(db_manager)
            
            # STM í†µê³„
            stm_stats = {}
            try:
                if hasattr(stm_manager, 'get_stats'):
                    stm_stats = stm_manager.get_stats()
                elif hasattr(stm_manager, 'cache'):
                    # STM ìºì‹œ ì§ì ‘ í™•ì¸
                    cache_data = stm_manager.cache
                    stm_stats = {
                        'active_count': len(cache_data) if isinstance(cache_data, dict) else 0,
                        'available_slots': max(0, 100 - len(cache_data)) if isinstance(cache_data, dict) else 100
                    }
            except:
                stm_stats = {'active_count': 0, 'available_slots': 100}
            
            return f"""ğŸ“Š **Greeum Memory Statistics**

**Long-term Memory (Local DB)**:
â€¢ Total Blocks: {stats['total_blocks']}
â€¢ This Week: {stats['week_count']}
â€¢ This Month: {stats['month_count']}
â€¢ Average Importance: {stats['avg_importance']:.2f}

**Short-term Memory**:
â€¢ Active Slots: {stm_stats.get('active_count', 0)}
â€¢ Available Slots: {stm_stats.get('available_slots', 100)}

**Database Info**:
â€¢ Database Path: {stats['db_path']}
â€¢ Last Updated: {stats['last_updated']}

**System Status**: âœ… Operational
**Version**: 2.3.0 (Local DB Optimized)"""
            
        except Exception as e:
            logger.error(f"get_memory_stats failed: {e}")
            return f"[ERROR] Stats retrieval failed: {str(e)}"
    
    def usage_analytics_tool(self, days: int = 7, report_type: str = "usage") -> str:
        """ì‚¬ìš© ë¶„ì„ ë„êµ¬ - ê¸°ì¡´ API ì™„ì „ í˜¸í™˜"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"
            
        try:
            # UsageAnalytics ì‹¤ì œ ë©”ì„œë“œ ì‚¬ìš©
            analytics_component = self.components['usage_analytics']
            if hasattr(analytics_component, 'get_usage_report'):
                analytics = analytics_component.get_usage_report(days=days, report_type=report_type)
            else:
                # fallback - ê¸°ë³¸ ë°ì´í„° ìƒì„±
                analytics = {
                    'total_operations': 'N/A',
                    'add_operations': 'N/A', 
                    'search_operations': 'N/A',
                    'avg_quality_score': 0.0,
                    'high_quality_rate': 0.0,
                    'avg_response_time': 0.0,
                    'success_rate': 1.0
                }
            
            return f"""[IMPROVE] **Usage Analytics Report** ({days} days)

**Activity Summary**:
â€¢ Total Operations: {analytics.get('total_operations', 0)}
â€¢ Memory Additions: {analytics.get('add_operations', 0)}
â€¢ Search Operations: {analytics.get('search_operations', 0)}

**Quality Metrics**:
â€¢ Average Quality Score: {analytics.get('avg_quality_score', 0):.1%}
â€¢ High Quality Rate: {analytics.get('high_quality_rate', 0):.1%}

**Performance**:
â€¢ Average Response Time: {analytics.get('avg_response_time', 0):.1f}ms
â€¢ Success Rate: {analytics.get('success_rate', 0):.1%}

**Report Type**: {report_type.title()}
**Generated**: Unified MCP v2.2.7"""
            
        except Exception as e:
            logger.error(f"usage_analytics failed: {e}")
            return f"[ERROR] Analytics failed: {str(e)}"

    def analyze_tool(self, days: int = 7) -> str:
        """ìŠ¬ë¡¯Â·ë¸Œëœì¹˜ ìš”ì•½ ë¦¬í¬íŠ¸"""
        if not self.components:
            self.initialize_greeum_components()
        if not self.components:
            return "[ERROR] Greeum components not available"

        try:
            analytics_component = self.components.get('usage_analytics')
            if analytics_component and hasattr(analytics_component, 'generate_system_report'):
                summary = analytics_component.generate_system_report(days=days)
                return summary or "No activity recorded yet."
            return "[INFO] Analytics component does not provide detailed system reports."
        except Exception as exc:
            logger.error(f"analyze failed: {exc}")
            return f"[ERROR] Analyze failed: {str(exc)}"

    def _auto_select_or_initialize_slot(self, stm_manager, content: str = None, embedding=None) -> tuple:
        """
        ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ì„ í†µí•œ ìë™ STM ìŠ¬ë¡¯ ì„ íƒ ë˜ëŠ” ì´ˆê¸°í™”

        Returns:
            (slot, smart_routing_info) íŠœí”Œ
        """
        import time

        if not stm_manager:
            return "A", None  # Fallback to A if no STM manager

        # DFS ê²€ìƒ‰ì„ í†µí•œ ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…
        try:
            from greeum.core.dfs_search import DFSSearchEngine
            dfs_search = DFSSearchEngine(self.components['block_manager'].db_manager)

            # í˜„ì¬ í™œì„± ìŠ¬ë¡¯ë“¤ì˜ í—¤ë“œ ë¸”ë¡ì—ì„œ ì‹œì‘í•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ ê²½ë¡œ íƒìƒ‰
            best_similarity = 0.0
            best_slot = None
            best_parent = None

            for slot_name, head_id in stm_manager.branch_heads.items():
                if head_id is not None:
                    # í•´ë‹¹ ë¸Œëœì¹˜ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë¸”ë¡ ì°¾ê¸°
                    # Use DFS search to find similar blocks
                    similar_blocks, _ = dfs_search.search_with_dfs(
                        query="",  # We'll use embedding directly
                        query_embedding=embedding if embedding is not None else [],
                        slot=slot_name,
                        entry="head",
                        depth=5,
                        limit=3,
                        fallback=False
                    )

                    if similar_blocks:
                        top_match = similar_blocks[0]
                        logger.debug(f"DFS result keys: {top_match.keys()}")
                        # Get similarity score (may be in different field names)
                        sim_score = top_match.get('similarity', top_match.get('score', top_match.get('similarity_score', 0)))
                        if sim_score > best_similarity:
                            best_similarity = sim_score
                            best_slot = slot_name
                            best_parent = top_match.get('hash', top_match.get('block_id'))

            # ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… ê²°ì •
            if best_similarity > 0.7:
                # ê¸°ì¡´ ë¸Œëœì¹˜ì— ì¶”ê°€
                placement_type = 'existing_branch'
                slot = best_slot
                logger.info(f"ğŸ¯ Smart Routing: Adding to existing branch {slot} (similarity: {best_similarity:.3f})")
            elif best_similarity > 0.4:
                # ìƒˆ ë¸Œëœì¹˜ë¡œ ë¶„ê¸° - LRU ìŠ¬ë¡¯ ì„ íƒ
                placement_type = 'divergence'
                # LRU ìŠ¬ë¡¯ ì°¾ê¸°
                if len([s for s, h in stm_manager.branch_heads.items() if h is not None]) >= 3:
                    # ëª¨ë“  ìŠ¬ë¡¯ì´ ì‚¬ìš© ì¤‘ì´ë©´ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ êµì²´
                    slot = min(
                        stm_manager.slot_hysteresis.keys(),
                        key=lambda k: stm_manager.slot_hysteresis[k]["last_seen_at"]
                    )
                    logger.info(f"ğŸ¯ Smart Routing: Diverging to slot {slot} (LRU replacement)")
                else:
                    # ë¹„ì–´ìˆëŠ” ìŠ¬ë¡¯ ì‚¬ìš©
                    for s in ["A", "B", "C"]:
                        if stm_manager.branch_heads.get(s) is None:
                            slot = s
                            break
                    else:
                        slot = "A"
                    logger.info(f"ğŸ¯ Smart Routing: Diverging to empty slot {slot}")
            else:
                # ì™„ì „íˆ ìƒˆë¡œìš´ ë¸Œëœì¹˜
                placement_type = 'new_branch'
                # ë¹„ì–´ìˆê±°ë‚˜ LRU ìŠ¬ë¡¯ ì„ íƒ
                empty_slots = [s for s in ["A", "B", "C"] if stm_manager.branch_heads.get(s) is None]
                if empty_slots:
                    slot = empty_slots[0]
                    logger.info(f"ğŸ¯ Smart Routing: Starting new branch in empty slot {slot}")
                else:
                    slot = min(
                        stm_manager.slot_hysteresis.keys(),
                        key=lambda k: stm_manager.slot_hysteresis[k]["last_seen_at"]
                    )
                    logger.info(f"ğŸ¯ Smart Routing: Starting new branch in slot {slot} (LRU replacement)")

            # ìŠ¬ë¡¯ íˆìŠ¤í…Œë¦¬ì‹œìŠ¤ ì—…ë°ì´íŠ¸
            stm_manager.slot_hysteresis[slot]["last_seen_at"] = time.time()
            stm_manager.slot_hysteresis[slot]["access_count"] += 1

            smart_routing_info = {
                'enabled': True,
                'slot_updated': slot,
                'similarity_score': best_similarity,
                'placement': placement_type,
                'parent': best_parent[:8] if best_parent else 'root'
            }

            return slot, smart_routing_info

        except Exception as e:
            logger.warning(f"Smart routing failed, falling back to LRU: {e}")
            # Fallback to original LRU logic

        # Fallback: ê¸°ì¡´ LRU ë¡œì§
        active_slots = [s for s, h in stm_manager.branch_heads.items() if h is not None]

        if not active_slots:
            logger.info("No active slots found, initializing slot A")
            stm_manager.slot_hysteresis["A"]["last_seen_at"] = time.time()
            stm_manager.slot_hysteresis["A"]["access_count"] = 1
            return "A", None

        # ê°€ì¥ ìµœê·¼ì— ì‚¬ìš©ëœ ìŠ¬ë¡¯ ì„ íƒ
        most_recent_slot = max(
            stm_manager.slot_hysteresis.keys(),
            key=lambda k: stm_manager.slot_hysteresis[k]["last_seen_at"]
        )

        stm_manager.slot_hysteresis[most_recent_slot]["last_seen_at"] = time.time()
        stm_manager.slot_hysteresis[most_recent_slot]["access_count"] += 1

        logger.debug(f"Selected slot {most_recent_slot} (active: {active_slots})")
        return most_recent_slot, None

    def _add_memory_via_core(self, content: str, importance: float = 0.5) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ v3 ì½”ì–´ ê²½ë¡œ ì €ì¥ - ë¸Œëœì¹˜/ìŠ¬ë¡¯ ìš°ì„  ì ìš©"""
        from greeum.text_utils import process_user_input

        if not self.components:
            raise Exception("Greeum components not available")

        block_manager = self.components['block_manager']
        stm_manager = self.components.get('stm_manager')

        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
        result = process_user_input(content)

        # ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ì„ í†µí•œ ìŠ¬ë¡¯ ì„ íƒ
        slot, smart_routing_info = self._auto_select_or_initialize_slot(
            stm_manager,
            content=content,
            embedding=result.get('embedding')
        )

        try:
            # v3 BlockManager.add_blockì„ ì‚¬ìš©í•˜ì—¬ ë¸Œëœì¹˜/ìŠ¬ë¡¯ ìš°ì„  ì €ì¥
            block_result = block_manager.add_block(
                context=content,
                keywords=result.get("keywords", []),
                tags=result.get("tags", []),
                embedding=result.get("embedding", []),
                importance=importance,
                metadata={'source': 'mcp', 'smart_routing': smart_routing_info} if smart_routing_info else {'source': 'mcp'},
                slot=slot  # Smart routing selected slot
            )

            if block_result:
                # P1: ì»¤ì„œ ìë™ ì¶”ì  - ìƒˆë¡œ ì¶”ê°€ëœ ë¸”ë¡ì„ í•´ë‹¹ ìŠ¬ë¡¯ì˜ ì»¤ì„œë¡œ ì„¤ì •
                if stm_manager and slot:
                    block_id = None
                    if isinstance(block_result, dict):
                        block_id = block_result.get('hash') or block_result.get('id')
                    elif isinstance(block_result, int):
                        # ë¸”ë¡ ì¸ë±ìŠ¤ë¡œë¶€í„° í•´ì‹œ ê°€ì ¸ì˜¤ê¸°
                        block_info = block_manager.get_block_by_index(block_result)
                        if block_info:
                            block_id = block_info.get('hash')

                    if block_id:
                        stm_manager.set_cursor(slot, block_id)
                        logger.debug(f"P1: Set cursor for slot {slot} to block {block_id}")

                # BlockManager.add_blockì´ dictë¥¼ ë°˜í™˜í•˜ë„ë¡ ë³´ì¥
                if isinstance(block_result, int):
                    # fallback: ì •ìˆ˜ ë°˜í™˜ ì‹œ dictë¡œ ë³µêµ¬
                    return {
                        'id': block_result,
                        'block_index': block_result,
                        'slot': slot,  # P1: ì‹¤ì œ ì‚¬ìš©ëœ ìŠ¬ë¡¯ ë°˜í™˜
                        'root': 'unknown',
                        'before': None
                    }
                # P1: ìŠ¬ë¡¯ ì •ë³´ ì¶”ê°€ (ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ…ì´ ì„¤ì •í•œ ìŠ¬ë¡¯ ìš°ì„ )
                if isinstance(block_result, dict):
                    # Check if smart routing already set a slot
                    if block_result.get('metadata', {}).get('smart_routing', {}).get('slot_updated'):
                        # Use the slot from smart routing
                        block_result['slot'] = block_result['metadata']['smart_routing']['slot_updated']
                    else:
                        # Fallback to the auto-selected slot
                        block_result['slot'] = slot
                return block_result
            else:
                raise Exception("BlockManager.add_block returned None")

        except Exception as e:
            logger.warning(f"Core path failed, using legacy fallback: {e}")
            # ì½”ì–´ ì‹¤íŒ¨ ì‹œ legacy ë°©ì‹ìœ¼ë¡œ fallback
            return self._add_memory_legacy_fallback(content, importance)

    def _add_memory_legacy_fallback(self, content: str, importance: float = 0.5) -> Dict[str, Any]:
        """ì½”ì–´ ì—°ë™ ì‹¤íŒ¨ ì‹œ legacy fallback"""
        from greeum.text_utils import process_user_input
        from datetime import datetime
        import json
        import hashlib

        db_manager = self.components['db_manager']

        # í…ìŠ¤íŠ¸ ì²˜ë¦¬
        result = process_user_input(content)
        result["importance"] = importance

        timestamp = datetime.now().isoformat()
        result["timestamp"] = timestamp

        # ë¸”ë¡ ì¸ë±ìŠ¤ ìƒì„±
        last_block_info = db_manager.get_last_block_info()
        if last_block_info is None:
            last_block_info = {"block_index": -1}
        block_index = last_block_info.get("block_index", -1) + 1

        # ì´ì „ í•´ì‹œ
        prev_hash = ""
        if block_index > 0:
            prev_block = db_manager.get_block(block_index - 1)
            if prev_block:
                prev_hash = prev_block.get("hash", "")

        # í•´ì‹œ ê³„ì‚°
        hash_data = {
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "prev_hash": prev_hash
        }
        hash_str = json.dumps(hash_data, sort_keys=True)
        hash_value = hashlib.sha256(hash_str.encode()).hexdigest()

        # ìµœì¢… ë¸”ë¡ ë°ì´í„°
        block_data = {
            "id": block_index,
            "block_index": block_index,
            "timestamp": timestamp,
            "context": content,
            "keywords": result.get("keywords", []),
            "tags": result.get("tags", []),
            "embedding": result.get("embedding", []),
            "importance": result.get("importance", 0.5),
            "hash": hash_value,
            "prev_hash": prev_hash,
            "slot": "legacy",
            "root": "unknown",
            "before": None
        }

        # DB ì§ì ‘ ì €ì¥
        db_manager.add_block(block_data)

        return block_data
        
    def _search_memory_via_core(self, query: str, limit: int = 5, entry: str = "cursor", depth: int = 0) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ v3 ì½”ì–´ ê²½ë¡œ ê²€ìƒ‰ - ìŠ¬ë¡¯/DFS ìš°ì„  ì ìš©"""
        if not self.components:
            raise Exception("Greeum components not available")

        block_manager = self.components['block_manager']
        stm_manager = self.components.get('stm_manager')

        # P1: ê²€ìƒ‰ í›„ ë§ˆì§€ë§‰ ê²°ê³¼ë¥¼ ì»¤ì„œë¡œ ì—…ë°ì´íŠ¸
        current_slot = None
        if stm_manager:
            # í˜„ì¬ í™œì„± ìŠ¬ë¡¯ í™•ì¸
            for slot_name, head_id in stm_manager.branch_heads.items():
                if head_id:
                    current_slot = slot_name
                    break

        try:
            # v3 BlockManager.search_with_slotsë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¡¯/DFS ìš°ì„  ê²€ìƒ‰
            search_result = block_manager.search_with_slots(
                query=query,
                limit=limit,
                use_slots=True,
                entry=entry,
                depth=depth,
                include_relationships=False
            )

            # search_with_slotsê°€ dictë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ë³´ì¥
            if isinstance(search_result, list):
                # ì˜ˆì „ í˜•ì‹: listë§Œ ë°˜í™˜
                return {
                    'items': search_result,
                    'meta': {
                        'search_type': 'local',
                        'entry_type': entry,
                        'hops': len(search_result),
                        'time_ms': 0
                    }
                }

            # P1: ê²€ìƒ‰ ê²°ê³¼ì˜ ë§ˆì§€ë§‰ í•­ëª©ì„ ì»¤ì„œë¡œ ì„¤ì •
            if stm_manager and current_slot and isinstance(search_result, dict):
                items = search_result.get('items', [])
                if items:
                    last_item = items[-1]
                    last_block_id = last_item.get('hash') or last_item.get('id')
                    if last_block_id:
                        stm_manager.set_cursor(current_slot, last_block_id)
                        logger.debug(f"P1: Updated cursor for slot {current_slot} to {last_block_id[:8]}...")

            return search_result

        except Exception as e:
            logger.warning(f"Core search failed, using legacy fallback: {e}")
            # ì½”ì–´ ì‹¤íŒ¨ ì‹œ legacy ë°©ì‹ìœ¼ë¡œ fallback
            legacy_results = self._search_memory_legacy_fallback(query, limit)
            return {
                'items': legacy_results,
                'meta': {
                    'search_type': 'legacy_fallback',
                    'entry_type': 'direct',
                    'hops': len(legacy_results),
                    'time_ms': 0
                }
            }

    def _search_memory_legacy_fallback(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """ì½”ì–´ ì—°ë™ ì‹¤íŒ¨ ì‹œ legacy fallback"""
        db_manager = self.components['db_manager']
        search_engine = self.components['search_engine']

        # SearchEngine.search ë©”ì„œë“œ ì‚¬ìš© (search_memories ì•„ë‹˜)
        search_result = search_engine.search(query, top_k=limit)
        results = search_result.get('blocks', [])

        # ê²°ê³¼ë¥¼ legacy í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        formatted_results = []
        for result in results:
            formatted_results.append({
                "block_index": result.get("block_index"),
                "context": result.get("context"),
                "timestamp": result.get("timestamp"),
                "relevance_score": result.get("relevance_score", 0.0),
                "keywords": result.get("keywords", []),
                "tags": result.get("tags", [])
            })

        return formatted_results
    
    def _expand_search_with_associations(self, base_results: List[Dict], depth: int, tolerance: float, max_results: int) -> List[Dict]:
        """
        ì—°ê´€ê´€ê³„ë¥¼ í™œìš©í•œ í™•ì¥ ê²€ìƒ‰
        
        Args:
            base_results: ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼
            depth: íƒìƒ‰ ê¹Šì´ (1-3)
            tolerance: ì—°ê´€ê´€ê³„ í—ˆìš© ì˜¤ì°¨ (0.0-1.0)
            max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            í™•ì¥ëœ ê²€ìƒ‰ ê²°ê³¼ (ì—°ê´€ê´€ê³„ ì •ë³´ í¬í•¨)
        """
        try:
            if not base_results or depth == 0:
                return base_results
            
            # AssociationSystem ì´ˆê¸°í™”
            from greeum.core.association_detector import AssociationSystem
            association_system = AssociationSystem()
            
            db_manager = self.components['db_manager']
            expanded_results = []
            processed_indices = set()
            
            # ê¸°ë³¸ ê²°ê³¼ë“¤ì„ ë¨¼ì € ì¶”ê°€ (ì›ë³¸ í‘œì‹œ)
            for memory in base_results:
                memory['relation_type'] = 'direct_match'
                expanded_results.append(memory)
                processed_indices.add(memory.get('block_index'))
            
            current_level_memories = base_results.copy()
            
            # ê° depth ë‹¨ê³„ë³„ë¡œ ì—°ê´€ ë©”ëª¨ë¦¬ íƒìƒ‰
            for current_depth in range(1, depth + 1):
                if len(expanded_results) >= max_results:
                    break
                    
                next_level_memories = []
                
                for memory in current_level_memories:
                    if len(expanded_results) >= max_results:
                        break
                    
                    # í˜„ì¬ ë©”ëª¨ë¦¬ì™€ ì—°ê´€ëœ ë©”ëª¨ë¦¬ë“¤ ì°¾ê¸°
                    associated_memories = self._find_associated_memories(
                        memory, association_system, tolerance, current_depth
                    )
                    
                    for assoc_memory in associated_memories:
                        if len(expanded_results) >= max_results:
                            break
                            
                        assoc_index = assoc_memory.get('block_index')
                        if assoc_index not in processed_indices:
                            assoc_memory['relation_type'] = f'depth_{current_depth}_association'
                            expanded_results.append(assoc_memory)
                            processed_indices.add(assoc_index)
                            next_level_memories.append(assoc_memory)
                
                current_level_memories = next_level_memories
                
                # ë” ì´ìƒ ìƒˆë¡œìš´ ì—°ê´€ ë©”ëª¨ë¦¬ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
                if not next_level_memories:
                    break
            
            return expanded_results[:max_results]
            
        except Exception as e:
            logger.error(f"Association expansion failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
            return base_results
    
    def _find_associated_memories(self, memory: Dict, association_system, tolerance: float, depth: int) -> List[Dict]:
        """
        íŠ¹ì • ë©”ëª¨ë¦¬ì™€ ì—°ê´€ëœ ë©”ëª¨ë¦¬ë“¤ ì°¾ê¸°
        
        Args:
            memory: ê¸°ì¤€ ë©”ëª¨ë¦¬
            association_system: ì—°ê´€ê´€ê³„ ì‹œìŠ¤í…œ
            tolerance: í—ˆìš© ì˜¤ì°¨
            depth: í˜„ì¬ íƒìƒ‰ ê¹Šì´
            
        Returns:
            ì—°ê´€ëœ ë©”ëª¨ë¦¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            db_manager = self.components['db_manager']
            
            # ì—°ê´€ë„ ì„ê³„ê°’ ê³„ì‚° (tolerance ê¸°ë°˜)
            base_threshold = 0.1  # ê¸°ë³¸ ì„ê³„ê°’
            adjusted_threshold = base_threshold * (1.0 - tolerance)  # tolerance ë†’ì„ìˆ˜ë¡ ë‚®ì€ ì„ê³„ê°’
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ ì—°ê´€ ë©”ëª¨ë¦¬ ê²€ìƒ‰
            if memory.get('embedding'):
                similar_memories = db_manager.search_blocks_by_embedding(
                    memory['embedding'], 
                    top_k=20,  # í›„ë³´êµ°ì„ ë„‰ë„‰íˆ
                    threshold=adjusted_threshold
                )
                
                # í˜„ì¬ ë©”ëª¨ë¦¬ ì œì™¸
                current_index = memory.get('block_index')
                filtered_memories = [m for m in similar_memories if m.get('block_index') != current_index]
                
                # tolerance ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ í•„í„°ë§
                final_memories = []
                for candidate in filtered_memories[:10]:  # ìƒìœ„ 10ê°œë§Œ ê³ ë ¤
                    # toleranceê°€ ë†’ì„ìˆ˜ë¡ ë” ë§ì€ ë©”ëª¨ë¦¬ í¬í•¨
                    similarity_score = self._calculate_similarity(memory, candidate)
                    if similarity_score >= adjusted_threshold:
                        final_memories.append(candidate)
                
                return final_memories
            
            return []
            
        except Exception as e:
            logger.error(f"Finding associated memories failed: {e}")
            return []
    
    def _calculate_similarity(self, memory1: Dict, memory2: Dict) -> float:
        """
        ë‘ ë©”ëª¨ë¦¬ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ êµ¬í˜„)
        
        ì‹¤ì œë¡œëŠ” ì„ë² ë”© ì½”ì‚¬ì¸ ìœ ì‚¬ë„, í‚¤ì›Œë“œ ê²¹ì¹¨ ë“±ì„ ì¢…í•©
        """
        try:
            import numpy as np
            
            # ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚°
            emb1 = memory1.get('embedding', [])
            emb2 = memory2.get('embedding', [])
            
            if emb1 and emb2 and len(emb1) == len(emb2):
                emb1_np = np.array(emb1)
                emb2_np = np.array(emb2)
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
                dot_product = np.dot(emb1_np, emb2_np)
                norm1 = np.linalg.norm(emb1_np)
                norm2 = np.linalg.norm(emb2_np)
                
                if norm1 > 0 and norm2 > 0:
                    return dot_product / (norm1 * norm2)
            
            # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì‚¬ë„
            keywords1 = set(memory1.get('keywords', []))
            keywords2 = set(memory2.get('keywords', []))
            
            if keywords1 and keywords2:
                intersection = keywords1.intersection(keywords2)
                union = keywords1.union(keywords2)
                return len(intersection) / len(union) if union else 0.0
            
            return 0.0
            
        except Exception as e:
            logger.error(f"Similarity calculation failed: {e}")
            return 0.0
    
    def _get_detailed_memory_stats(self, db_manager) -> Dict[str, Any]:
        """ë¡œì»¬ DBì—ì„œ ìƒì„¸í•œ ë©”ëª¨ë¦¬ í†µê³„ ì§ì ‘ ê³„ì‚°"""
        try:
            from datetime import datetime, timedelta
            import sqlite3
            
            # DB ì—°ê²° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            db_path = getattr(db_manager, 'db_path', 'Unknown')
            
            # ì§ì ‘ SQL ì¿¼ë¦¬ ì‹¤í–‰ - ë¡œì»¬ DB ìš°ì„ 
            if hasattr(db_manager, 'conn') and db_manager.conn:
                conn = db_manager.conn
            elif hasattr(db_manager, 'db_path'):
                conn = sqlite3.connect(db_manager.db_path)
            else:
                # ë¡œì»¬ ë””ë ‰í† ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ í™•ì¸
                import os
                local_db_path = './data/memory.db'
                if os.path.exists(local_db_path):
                    conn = sqlite3.connect(local_db_path)
                else:
                    # ëŒ€ì²´ ë¡œì»¬ ê²½ë¡œë“¤ ì‹œë„
                    alternative_paths = [
                        './memory.db',
                        './greeum_memory.db',
                        os.path.expanduser('~/greeum_local/memory.db')
                    ]
                    conn = None
                    for path in alternative_paths:
                        if os.path.exists(path):
                            conn = sqlite3.connect(path)
                            break
                    
                    if not conn:
                        raise FileNotFoundError("No local memory database found. Please ensure memory.db exists in current directory.")
            
            cursor = conn.cursor()
            
            # ì „ì²´ ë¸”ë¡ ìˆ˜
            cursor.execute("SELECT COUNT(*) FROM blocks")
            total_blocks = cursor.fetchone()[0]
            
            # ì´ë²ˆ ì£¼ ë¸”ë¡ ìˆ˜
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            cursor.execute("SELECT COUNT(*) FROM blocks WHERE timestamp > ?", (week_ago,))
            week_count = cursor.fetchone()[0]
            
            # ì´ë²ˆ ë‹¬ ë¸”ë¡ ìˆ˜  
            month_ago = (datetime.now() - timedelta(days=30)).isoformat()
            cursor.execute("SELECT COUNT(*) FROM blocks WHERE timestamp > ?", (month_ago,))
            month_count = cursor.fetchone()[0]
            
            # í‰ê·  ì¤‘ìš”ë„
            cursor.execute("SELECT AVG(importance) FROM blocks WHERE importance IS NOT NULL")
            avg_importance_result = cursor.fetchone()[0]
            avg_importance = avg_importance_result if avg_importance_result else 0.5
            
            # ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸
            cursor.execute("SELECT timestamp FROM blocks ORDER BY block_index DESC LIMIT 1")
            last_entry = cursor.fetchone()
            last_updated = last_entry[0] if last_entry else "Never"
            
            # ì—°ê²°ì´ ì„ì‹œë¡œ ìƒì„±ëœ ê²½ìš° ë‹«ê¸°
            if not (hasattr(db_manager, 'conn') and db_manager.conn):
                conn.close()
            
            return {
                'total_blocks': total_blocks,
                'week_count': week_count,
                'month_count': month_count,
                'avg_importance': avg_importance,
                'db_path': db_path,
                'last_updated': last_updated
            }
            
        except Exception as e:
            logger.error(f"Failed to get detailed stats: {e}")
            return {
                'total_blocks': 0,
                'week_count': 0,
                'month_count': 0,
                'avg_importance': 0.5,
                'db_path': 'Unknown',
                'last_updated': 'Error'
            }
    
    @abstractmethod
    async def run(self):
        """ì„œë²„ ì‹¤í–‰ (ê° ì–´ëŒ‘í„°ì—ì„œ êµ¬í˜„)"""
        pass
