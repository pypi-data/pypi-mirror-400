#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•ç³»ç»Ÿçš„æ€§èƒ½æŒ‡æ ‡
"""

import asyncio
import sys
import time
from concurrent.futures import ThreadPoolExecutor
from pathlib import Path
from unittest.mock import AsyncMock, Mock, patch

import psutil

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
src_path = project_root / "src"
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))


class PerformanceTimer:
    """æ€§èƒ½è®¡æ—¶å™¨"""

    def __init__(self, name="æ“ä½œ"):
        self.name = name
        self.start_time = None
        self.end_time = None

    def __enter__(self):
        self.start_time = time.perf_counter()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.end_time = time.perf_counter()

    def elapsed(self):
        """è·å–è€—æ—¶"""
        if self.end_time is None:
            return time.perf_counter() - self.start_time
        return self.end_time - self.start_time


class MemoryMonitor:
    """å†…å­˜ç›‘æ§å™¨"""

    def __init__(self):
        self.process = psutil.Process()
        self.initial_memory = None
        self.peak_memory = 0

    def start(self):
        """å¼€å§‹ç›‘æ§"""
        self.initial_memory = self.process.memory_info().rss
        self.peak_memory = self.initial_memory

    def update(self):
        """æ›´æ–°å³°å€¼å†…å­˜"""
        current_memory = self.process.memory_info().rss
        if current_memory > self.peak_memory:
            self.peak_memory = current_memory

    def get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        current = self.process.memory_info().rss
        return {
            "initial_mb": self.initial_memory / 1024 / 1024 if self.initial_memory else 0,
            "current_mb": current / 1024 / 1024,
            "peak_mb": self.peak_memory / 1024 / 1024,
            "increase_mb": (
                (current - self.initial_memory) / 1024 / 1024 if self.initial_memory else 0
            ),
        }


def test_import_performance():
    """æµ‹è¯•å¯¼å…¥æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•å¯¼å…¥æ€§èƒ½...")

    # æµ‹è¯•å¤šæ¬¡å¯¼å…¥çš„æ—¶é—´
    import_times = []
    for i in range(5):
        with PerformanceTimer(f"å¯¼å…¥ {i + 1}"):
            # åˆ·æ–°æ¨¡å—ç¼“å­˜
            if "article_mcp.cli" in sys.modules:
                del sys.modules["article_mcp.cli"]

        import_times.append(PerformanceTimer().elapsed())

    avg_time = sum(import_times) / len(import_times)
    print(f"âœ“ å¹³å‡å¯¼å…¥æ—¶é—´: {avg_time:.3f} ç§’")

    # å¯¼å…¥æ—¶é—´åº”è¯¥å°äº1ç§’
    if avg_time < 1.0:
        print("âœ“ å¯¼å…¥æ€§èƒ½è‰¯å¥½")
        return True
    else:
        print("âš ï¸ å¯¼å…¥æ€§èƒ½è¾ƒæ…¢")
        return False


def test_server_creation_performance():
    """æµ‹è¯•æœåŠ¡å™¨åˆ›å»ºæ€§èƒ½"""
    print("ğŸ” æµ‹è¯•æœåŠ¡å™¨åˆ›å»ºæ€§èƒ½...")

    creation_times = []

    for i in range(3):
        with PerformanceTimer(f"æœåŠ¡å™¨åˆ›å»º {i + 1}"):
            with patch.multiple(
                "article_mcp.cli",
                create_europe_pmc_service=Mock(),
                create_pubmed_service=Mock(),
                CrossRefService=Mock(),
                OpenAlexService=Mock(),
                create_reference_service=Mock(),
                create_literature_relation_service=Mock(),
                create_arxiv_service=Mock(),
                register_search_tools=Mock(),
                register_article_tools=Mock(),
                register_reference_tools=Mock(),
                register_relation_tools=Mock(),
                register_quality_tools=Mock(),
                register_batch_tools=Mock(),
            ):
                from article_mcp.cli import create_mcp_server

                create_mcp_server()

        creation_times.append(PerformanceTimer().elapsed())

    avg_time = sum(creation_times) / len(creation_times)
    print(f"âœ“ å¹³å‡æœåŠ¡å™¨åˆ›å»ºæ—¶é—´: {avg_time:.3f} ç§’")

    # æœåŠ¡å™¨åˆ›å»ºæ—¶é—´åº”è¯¥å°äº2ç§’
    if avg_time < 2.0:
        print("âœ“ æœåŠ¡å™¨åˆ›å»ºæ€§èƒ½è‰¯å¥½")
        return True
    else:
        print("âš ï¸ æœåŠ¡å™¨åˆ›å»ºæ€§èƒ½è¾ƒæ…¢")
        return False


def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
    print("ğŸ” æµ‹è¯•å†…å­˜ä½¿ç”¨...")

    monitor = MemoryMonitor()
    monitor.start()

    initial_memory = monitor.get_memory_usage()

    # æ‰§è¡Œå¤šä¸ªæ“ä½œ
    for _i in range(10):
        with patch.multiple(
            "article_mcp.cli",
            create_europe_pmc_service=Mock(),
            create_pubmed_service=Mock(),
            CrossRefService=Mock(),
            OpenAlexService=Mock(),
            create_reference_service=Mock(),
            create_literature_relation_service=Mock(),
            create_arxiv_service=Mock(),
            register_search_tools=Mock(),
            register_article_tools=Mock(),
            register_reference_tools=Mock(),
            register_relation_tools=Mock(),
            register_quality_tools=Mock(),
            register_batch_tools=Mock(),
        ):
            from article_mcp.cli import create_mcp_server

            create_mcp_server()

        monitor.update()

    final_memory = monitor.get_memory_usage()

    print(f"âœ“ åˆå§‹å†…å­˜: {initial_memory['initial_mb']:.2f} MB")
    print(f"âœ“ æœ€ç»ˆå†…å­˜: {final_memory['current_mb']:.2f} MB")
    print(f"âœ“ å³°å€¼å†…å­˜: {final_memory['peak_mb']:.2f} MB")
    print(f"âœ“ å†…å­˜å¢é•¿: {final_memory['increase_mb']:.2f} MB")

    # å†…å­˜å¢é•¿åº”è¯¥å°äº50MB
    if final_memory["increase_mb"] < 50:
        print("âœ“ å†…å­˜ä½¿ç”¨åˆç†")
        return True
    else:
        print("âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜")
        return False


async def test_async_performance():
    """æµ‹è¯•å¼‚æ­¥æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•å¼‚æ­¥æ€§èƒ½...")

    try:
        from article_mcp.tools.core.search_tools import _search_literature

        # åˆ›å»ºæ¨¡æ‹ŸæœåŠ¡
        Mock()
        mock_service = Mock()
        mock_service.search_articles = AsyncMock(
            return_value={
                "articles": [
                    {"title": f"Test Article {i}", "doi": f"10.1000/test{i}"} for i in range(100)
                ],
                "total_count": 100,
            }
        )

        # æµ‹è¯•å¼‚æ­¥è°ƒç”¨æ€§èƒ½
        async_times = []

        for i in range(5):
            with PerformanceTimer(f"å¼‚æ­¥è°ƒç”¨ {i + 1}"):
                with patch(
                    "article_mcp.tools.core.search_tools._search_services",
                    {"europe_pmc": mock_service},
                ):
                    await _search_literature(
                        keyword="test", sources=["europe_pmc"], max_results=100
                    )

            async_times.append(PerformanceTimer().elapsed())

        avg_time = sum(async_times) / len(async_times)
        print(f"âœ“ å¹³å‡å¼‚æ­¥è°ƒç”¨æ—¶é—´: {avg_time:.3f} ç§’")

        # å¼‚æ­¥è°ƒç”¨æ—¶é—´åº”è¯¥å°äº1ç§’
        if avg_time < 1.0:
            print("âœ“ å¼‚æ­¥æ€§èƒ½è‰¯å¥½")
            return True
        else:
            print("âš ï¸ å¼‚æ­¥æ€§èƒ½è¾ƒæ…¢")
            return False
    except Exception as e:
        print(f"âœ— å¼‚æ­¥æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_concurrent_performance():
    """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•å¹¶å‘æ€§èƒ½...")

    def create_server():
        with patch.multiple(
            "article_mcp.cli",
            create_europe_pmc_service=Mock(),
            create_pubmed_service=Mock(),
            CrossRefService=Mock(),
            OpenAlexService=Mock(),
            create_reference_service=Mock(),
            create_literature_relation_service=Mock(),
            create_arxiv_service=Mock(),
            register_search_tools=Mock(),
            register_article_tools=Mock(),
            register_reference_tools=Mock(),
            register_relation_tools=Mock(),
            register_quality_tools=Mock(),
            register_batch_tools=Mock(),
        ):
            from article_mcp.cli import create_mcp_server

            return create_mcp_server()

    # æµ‹è¯•å¹¶å‘åˆ›å»º
    thread_counts = [1, 2, 4, 8]
    results = {}

    for thread_count in thread_counts:
        with PerformanceTimer(f"{thread_count} çº¿ç¨‹å¹¶å‘"):
            with ThreadPoolExecutor(max_workers=thread_count) as executor:
                futures = [executor.submit(create_server) for _ in range(thread_count)]
                [future.result() for future in futures]

        elapsed_time = PerformanceTimer().elapsed()
        results[thread_count] = elapsed_time
        print(f"âœ“ {thread_count} çº¿ç¨‹: {elapsed_time:.3f} ç§’")

    # åˆ†æå¹¶å‘æ€§èƒ½
    single_thread_time = results[1]
    best_concurrent_time = min(results.values())

    if best_concurrent_time < single_thread_time:
        speedup = single_thread_time / best_concurrent_time
        print(f"âœ“ æœ€ä½³å¹¶å‘åŠ é€Ÿæ¯”: {speedup:.2f}x")
        return True
    else:
        print("âš ï¸ å¹¶å‘æ€§èƒ½ä¸æ˜æ˜¾")
        return False


def test_large_data_performance():
    """æµ‹è¯•å¤§æ•°æ®æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•å¤§æ•°æ®æ€§èƒ½...")

    try:
        # åˆ›å»ºå¤§é‡æ¨¡æ‹Ÿæ•°æ®
        large_dataset = [
            {"title": f"Article {i}", "doi": f"10.1000/test{i}", "authors": [f"Author {i}"]}
            for i in range(1000)
        ]

        monitor = MemoryMonitor()
        monitor.start()

        with PerformanceTimer("å¤§æ•°æ®å¤„ç†"):
            # æ¨¡æ‹Ÿå¤§æ•°æ®å¤„ç†
            result = {
                "articles": large_dataset,
                "total_count": len(large_dataset),
                "processed_at": time.time(),
            }

            # æ¨¡æ‹Ÿä¸€äº›æ•°æ®å¤„ç†æ“ä½œ
            for article in result["articles"]:
                article["processed"] = True
                article["length"] = len(article["title"])

        elapsed_time = PerformanceTimer().elapsed()
        memory_usage = monitor.get_memory_usage()

        print(f"âœ“ å¤„ç†æ—¶é—´: {elapsed_time:.3f} ç§’")
        print(f"âœ“ å†…å­˜ä½¿ç”¨: {memory_usage['increase_mb']:.2f} MB")
        print(f"âœ“ æ•°æ®é‡: {len(large_dataset)} æ¡è®°å½•")

        # å¤§æ•°æ®å¤„ç†æ—¶é—´åº”è¯¥å°äº5ç§’
        if elapsed_time < 5.0:
            print("âœ“ å¤§æ•°æ®æ€§èƒ½è‰¯å¥½")
            return True
        else:
            print("âš ï¸ å¤§æ•°æ®æ€§èƒ½è¾ƒæ…¢")
            return False
    except Exception as e:
        print(f"âœ— å¤§æ•°æ®æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("ğŸ” æµ‹è¯•ç¼“å­˜æ€§èƒ½...")

    try:
        from article_mcp.services.europe_pmc import EuropePMCService

        # åˆ›å»ºæœåŠ¡å®ä¾‹
        mock_logger = Mock()
        service = EuropePMCService(mock_logger)

        # æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡ï¼ˆæ¨¡æ‹Ÿï¼‰
        cache_stats = {"hits": 0, "misses": 0, "total_requests": 0}

        # æ¨¡æ‹Ÿç¼“å­˜æ“ä½œ
        with PerformanceTimer("ç¼“å­˜æ“ä½œ"):
            for i in range(100):
                cache_key = f"test_key_{i % 10}"  # æ¨¡æ‹Ÿé‡å¤è®¿é—®
                if cache_key in service.cache:  # æ¨¡æ‹Ÿç¼“å­˜å‘½ä¸­
                    cache_stats["hits"] += 1
                else:
                    cache_stats["misses"] += 1
                    service.cache[cache_key] = f"value_{cache_key}"
                cache_stats["total_requests"] += 1

        elapsed_time = PerformanceTimer().elapsed()
        hit_rate = cache_stats["hits"] / cache_stats["total_requests"] * 100

        print(f"âœ“ ç¼“å­˜æ“ä½œæ—¶é—´: {elapsed_time:.3f} ç§’")
        print(f"âœ“ ç¼“å­˜å‘½ä¸­ç‡: {hit_rate:.1f}%")
        print(f"âœ“ æ€»è¯·æ±‚æ•°: {cache_stats['total_requests']}")

        # ç¼“å­˜å‘½ä¸­ç‡åº”è¯¥å¤§äº50%
        if hit_rate > 50:
            print("âœ“ ç¼“å­˜æ€§èƒ½è‰¯å¥½")
            return True
        else:
            print("âš ï¸ ç¼“å­˜å‘½ä¸­ç‡è¾ƒä½")
            return False
    except Exception as e:
        print(f"âœ— ç¼“å­˜æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•"""
    print("=" * 60)
    print("âš¡ Article MCP æ€§èƒ½æµ‹è¯•")
    print("=" * 60)

    tests = [
        test_import_performance,
        test_server_creation_performance,
        test_memory_usage,
        test_concurrent_performance,
        test_large_data_performance,
        test_cache_performance,
    ]

    async_tests = [test_async_performance]

    passed = 0
    total = len(tests) + len(async_tests)

    start_time = time.time()

    # è¿è¡ŒåŒæ­¥æµ‹è¯•
    for test_func in tests:
        try:
            if test_func():
                passed += 1
            print()  # ç©ºè¡Œåˆ†éš”
        except Exception as e:
            print(f"âœ— æµ‹è¯• {test_func.__name__} å‡ºç°å¼‚å¸¸: {e}")
            print()

    # è¿è¡Œå¼‚æ­¥æµ‹è¯•
    for test_func in async_tests:
        try:
            if asyncio.run(test_func()):
                passed += 1
            print()  # ç©ºè¡Œåˆ†éš”
        except Exception as e:
            print(f"âœ— å¼‚æ­¥æµ‹è¯• {test_func.__name__} å‡ºç°å¼‚å¸¸: {e}")
            print()

    end_time = time.time()
    total_duration = end_time - start_time

    print("=" * 60)
    print(f"ğŸ“Š æ€§èƒ½æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print(f"â±ï¸  æ€»è€—æ—¶: {total_duration:.2f} ç§’")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ€§èƒ½æµ‹è¯•é€šè¿‡!")
        return 0
    else:
        print("âš ï¸ éƒ¨åˆ†æ€§èƒ½æµ‹è¯•éœ€è¦ä¼˜åŒ–")
        return 1


if __name__ == "__main__":
    sys.exit(main())
