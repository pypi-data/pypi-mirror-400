# Copyright (c) 2023-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import builtins
from typing import Literal, Optional, Union, overload
from typing import Any, List, Sequence

from nvidia.dali.types import DALIDataType, DALIImageType, DALIInterpType

from collections.abc import Iterable

from nvidia.dali._typing import TensorLike, TensorLikeArg
from nvidia.dali.experimental.dynamic._batch import Batch as Batch
from nvidia.dali.experimental.dynamic._device import Device as Device
from nvidia.dali.experimental.dynamic._eval_context import EvalContext as EvalContext
from nvidia.dali.experimental.dynamic._tensor import Tensor as Tensor
from nvidia.dali.experimental.dynamic._type import DType as DType

@overload
def max(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets maximal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def max(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets maximal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def max(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets maximal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets mean of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets mean of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets mean of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean_square(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean_square(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def mean_square(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def min(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets minimal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def min(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets minimal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def min(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets minimal input element along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def rms(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets root mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def rms(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets root mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def rms(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets root mean square of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def std_dev(
    data: Batch,
    mean: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets standard deviation of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def std_dev(
    data: Union[TensorLike, Batch],
    mean: Union[TensorLike, Batch],
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets standard deviation of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def std_dev(
    data: Union[TensorLike, Batch],
    mean: Union[TensorLike, Batch],
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets standard deviation of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def sum(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets sum of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def sum(
    input: TensorLike,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets sum of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def sum(
    input: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    dtype: Union[DALIDataType, DType, None] = None,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets sum of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    input : Tensor/Batch
        Input to the operator.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    dtype : :class:`nvidia.dali.types.DALIDataType`, optional
        Output data type. This type is used to accumulate the result.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def variance(
    data: Batch,
    mean: Batch,
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets variance of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def variance(
    data: Union[TensorLike, Batch],
    mean: Union[TensorLike, Batch],
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Union[Tensor, Batch]:
    """
    Gets variance of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """

@overload
def variance(
    data: Union[TensorLike, Batch],
    mean: Union[TensorLike, Batch],
    /,
    *,
    device: Optional[Literal["cpu", "gpu"]] = None,
    batch_size: int,
    axes: Union[Sequence[int], int, None] = None,
    axis_names: Optional[str] = None,
    ddof: Optional[int] = 0,
    keep_dims: Optional[builtins.bool] = False,
) -> Batch:
    """
    Gets variance of elements along provided axes.

    Supported backends
     * 'cpu'
     * 'gpu'


    Args
    ----
    data : Tensor/Batch
        Input to the operator.
    mean : float or Tensor/Batch of float
        Mean value to use in the calculations.


    Keyword args
    ------------
    axes : int or list of int, optional
        Axis or axes along which reduction is performed.

        Accepted range is [-ndim, ndim-1]. Negative indices are counted from the back.

        Not providing any axis results in reduction of all elements.
    axis_names : :ref:`layout str<layout_str_doc>`, optional
        Name(s) of the axis or axes along which the reduction is performed.

        The input layout is used to translate the axis names to axis indices, for example ``axis_names="HW"`` with input
        layout `"FHWC"` is equivalent to specifying ``axes=[1,2]``. This argument cannot be used together with `axes`.
    bytes_per_sample_hint : int or list of int, optional, default = `[0]`
        Output size hint, in bytes per sample.

        If specified, the operator's outputs residing in GPU or page-locked host memory will be preallocated
        to accommodate a batch of samples of this size.
    ddof : int, optional, default = `0`
        Delta Degrees of Freedom. Adjusts the divisor used in calculations, which is `N - ddof`.
    keep_dims : bool, optional, default = `False`
        If True, maintains original input dimensions.
    preserve : bool, optional, default = `False`
        Prevents the operator from being removed from the
        graph even if its outputs are not used.

    """
