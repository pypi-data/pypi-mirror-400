# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: proto/physicsaiinferenceservice/physicsaiinferenceservice.proto
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.protobuf import empty_pb2 as google_dot_protobuf_dot_empty__pb2
from luminarycloud._proto.api.v0.luminarycloud.physicsaiinference import physicsaiinference_pb2 as proto_dot_api_dot_v0_dot_luminarycloud_dot_physicsaiinference_dot_physicsaiinference__pb2
from luminarycloud._proto.ratelimit import ratelimit_pb2 as proto_dot_ratelimit_dot_ratelimit__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n?proto/physicsaiinferenceservice/physicsaiinferenceservice.proto\x12(luminary.proto.physicsaiinferenceservice\x1a\x1bgoogle/protobuf/empty.proto\x1a\x46proto/api/v0/luminarycloud/physicsaiinference/physicsaiinference.proto\x1a\x1fproto/ratelimit/ratelimit.proto2\xb1\t\n\x19PhysicsAiInferenceService\x12\xd9\x01\n\x19\x43reateInferenceServiceJob\x12X.luminary.proto.api.v0.luminarycloud.physicsaiinference.CreateInferenceServiceJobRequest\x1aV.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceServiceJobResponse\"\n\x8a\xb5\x18\x06\x08\n\x12\x02\x08\x01\x12\xde\x01\n\x1e\x43reateInferenceServiceJobAsync\x12X.luminary.proto.api.v0.luminarycloud.physicsaiinference.CreateInferenceServiceJobRequest\x1aV.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceServiceJobResponse\"\n\x8a\xb5\x18\x06\x08\n\x12\x02\x08\x01\x12\xbb\x01\n\x12GetInferenceFields\x12Q.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceFieldsRequest\x1aR.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceFieldsResponse\x12\xc7\x01\n\x16GetInferenceServiceJob\x12U.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceServiceJobRequest\x1aV.luminary.proto.api.v0.luminarycloud.physicsaiinference.GetInferenceServiceJobResponse\x12\xcd\x01\n\x18ListInferenceServiceJobs\x12W.luminary.proto.api.v0.luminarycloud.physicsaiinference.ListInferenceServiceJobsRequest\x1aX.luminary.proto.api.v0.luminarycloud.physicsaiinference.ListInferenceServiceJobsResponse\x12\x7f\n\x12\x44\x65leteInferenceJob\x12Q.luminary.proto.api.v0.luminarycloud.physicsaiinference.DeleteInferenceJobRequest\x1a\x16.google.protobuf.EmptyB8Z6luminarycloud.com/core/proto/physicsaiinferenceserviceb\x06proto3')



_PHYSICSAIINFERENCESERVICE = DESCRIPTOR.services_by_name['PhysicsAiInferenceService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'Z6luminarycloud.com/core/proto/physicsaiinferenceservice'
  _PHYSICSAIINFERENCESERVICE.methods_by_name['CreateInferenceServiceJob']._options = None
  _PHYSICSAIINFERENCESERVICE.methods_by_name['CreateInferenceServiceJob']._serialized_options = b'\212\265\030\006\010\n\022\002\010\001'
  _PHYSICSAIINFERENCESERVICE.methods_by_name['CreateInferenceServiceJobAsync']._options = None
  _PHYSICSAIINFERENCESERVICE.methods_by_name['CreateInferenceServiceJobAsync']._serialized_options = b'\212\265\030\006\010\n\022\002\010\001'
  _PHYSICSAIINFERENCESERVICE._serialized_start=244
  _PHYSICSAIINFERENCESERVICE._serialized_end=1445
# @@protoc_insertion_point(module_scope)
