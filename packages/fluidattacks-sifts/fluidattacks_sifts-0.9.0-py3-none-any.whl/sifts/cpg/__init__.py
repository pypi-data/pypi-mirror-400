import json
import logging
import re
import tempfile
from collections.abc import Iterable
from pathlib import Path
from typing import TypedDict, cast

import aiofiles
from fluidattacks_core.cpg.joern import run_joern_command
from fluidattacks_core.filesystem.defaults import Language as SystemLanguage

from common_types import Language as SiftsLanguage
from sifts_io.storage import CPGStorage, create_cpg_storage


class CPGCall(TypedDict):
    methodName: str
    callCount: str


class CPGCallSummary(TypedDict):
    orderedExternalMethods: list[CPGCall]


class CPGCalls(TypedDict):
    summary: CPGCallSummary


class FlowNode(TypedDict):
    name: str
    fullName: str
    fileName: str
    lineNumberStart: int
    lineNumberEnd: int


class PathElement(TypedDict):
    nodeType: str
    tracked: str
    lineNumberStart: int
    lineNumberEnd: int
    method: str
    fileName: str


class MethodInfo(TypedDict):
    name: str
    fullName: str
    fileName: str
    lineNumberStart: int
    lineNumberEnd: int
    isExternal: bool


class CallSite(TypedDict):
    code: str
    lineNumber: int
    columnNumber: int
    fileName: list[str]


class CalleeWithDownChain(TypedDict):
    method: MethodInfo
    callSites: list[CallSite]
    downCallChain: list["CalleeWithDownChain"]
    downCallChainCount: int


class MethodWithCallees(TypedDict):
    method: MethodInfo
    callees: list[CalleeWithDownChain]


class CallChain(TypedDict):
    pathLength: int
    callPath: list[MethodWithCallees]


class AnalysisParameters(TypedDict):
    maxUpDepth: int
    maxDownDepth: int
    downSameFileOnly: bool
    maxDownFanout: int


class Summary(TypedDict):
    totalCallChains: int
    filePath: str
    lineNumberStart: int
    lineNumberEnd: int
    parameters: AnalysisParameters


class TaintFlow(TypedDict):
    # Keep old structure for backward compatibility, but add new fields
    targetMethod: FlowNode
    entryPoint: FlowNode
    methodsInFlow: list[FlowNode]
    callChain: list[FlowNode]
    # New schema fields
    pathLength: int
    callPath: list[MethodWithCallees]


class CPGPaths(TypedDict):
    summary: Summary
    callChains: list[CallChain]


LOGGER = logging.getLogger(__name__)


def transform_method_name(method_name: str) -> tuple[str | None, str | None]:
    if method_name.startswith(("<", "__")):
        return None, None
    if ":" in method_name:
        library, method = method_name.split(":", 1)
    elif "." in method_name:
        library, method = method_name.split(".", 1)
    else:
        return None, None
    method = re.sub(r"<[^>]+>", "", method)
    method_parts = [
        part
        for part in method.split(".")
        if part and not (part.startswith("__") and part.endswith("__"))
    ]
    method = ".".join(method_parts)
    if not method:
        return None, None
    return library, method


async def load_cpg_graph_binary(  # noqa: PLR0913
    working_dir: Path,
    language: SiftsLanguage,
    exclude: Iterable[Path] | None = None,
    *,
    group: str | None = None,
    repo_nickname: str | None = None,
    storage: CPGStorage | None = None,
) -> Path | None:
    # `exclude` is reserved for future use, ignored now but kept for preserving
    # function signature.
    _ = exclude
    if not group or not repo_nickname:
        LOGGER.warning("group and repo_nickname are required to load CPG")
        return None

    if storage is None:
        storage = create_cpg_storage("s3")

    try:
        system_language = SystemLanguage(language.value)
    except ValueError:
        LOGGER.warning("Unsupported language for CPG: %s", language.value)
        return None

    return await storage.get_cpg(working_dir, system_language, group, repo_nickname)


async def extract_path_from_cpg_call(
    graph_file: Path,
    file_path: Path,
    line_start: int,
    line_end: int,
) -> CPGPaths:
    # the file path must be relative to the working dir, because joern expects it that way
    with tempfile.NamedTemporaryFile(delete=False) as f:
        output_file = Path(f.name)
        args = [
            str(graph_file),  # inputPath
            str(output_file),  # outputJsonFile
            str(line_start - 1),  # lineNumberStart
            str(line_end),  # lineNumberEnd
            str(file_path),  # filePath
            "--max-up-depth",
            "16",
            "--max-down-depth",
            "3",
            "--down-same-file-only",
            "false",
            "--max-down-fanout",
            "25",
        ]
        await run_joern_command(
            "chain-of-call",
            args,
        )
        async with aiofiles.open(output_file) as file:
            try:
                return cast("CPGPaths", json.loads(await file.read()))
            except json.JSONDecodeError:
                empty_result: CPGPaths = {
                    "summary": {
                        "totalCallChains": 0,
                        "filePath": str(file_path),
                        "lineNumberStart": line_start,
                        "lineNumberEnd": line_end,
                        "parameters": {
                            "maxUpDepth": 16,
                            "maxDownDepth": 3,
                            "downSameFileOnly": False,
                            "maxDownFanout": 25,
                        },
                    },
                    "callChains": [],
                }
                return empty_result
