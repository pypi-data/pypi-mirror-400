{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae381ce",
   "metadata": {},
   "source": [
    "# **Example**: Reading files with Visual Language Models to Provide Image Annotations\n",
    "\n",
    "!!! warning\n",
    "\n",
    "    This tutorial has been redone and it is **deprecated**. See new versions here:\n",
    "\n",
    "      1. [VanillaReader](./pdf_vanilla.md).\n",
    "      2. [DoclingReader](./pdf_docling.md).\n",
    "      3. [MarkItDownReader](./pdf_markitdown.md).\n",
    "\n",
    "When reading a PDF file or other files which contain images, it can be useful to provide descriptive text alongside those images. Since images in a Markdown file are typically rendered by encoding them in base64 format, you may alternatively want to include a description of each image instead.\n",
    "\n",
    "This is where **Visual Language Models (VLMs)** come in—to analyze and describe images automatically. In this tutorial, we'll show how to use these models with the library.\n",
    "\n",
    "## Step 1: Load a Model\n",
    "\n",
    "To extract image descriptions or perform OCR, instantiate any model that implements the [`BaseModel` interface](../../api_reference/model.md#basevisionmodel) (vision variants inherit from it).\n",
    "\n",
    "### Supported models (and when to use them)\n",
    "\n",
    "| Model (docs)                                                                    | When to use                                       | Required environment variables                                                                                        |\n",
    "| ------------------------------------------------------------------------------- | ------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |\n",
    "| [`OpenAIVisionModel`](../../api_reference/model.md#openaivisionmodel)           | You have an OpenAI API key and want OpenAI cloud. | `OPENAI_API_KEY` (optional: `OPENAI_MODEL`, defaults to `gpt-4o`)                                                     |\n",
    "| [`AzureOpenAIVisionModel`](../../api_reference/model.md#azureopenaivisionmodel) | You use Azure OpenAI Service.                     | `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT`, `AZURE_OPENAI_DEPLOYMENT`, `AZURE_OPENAI_API_VERSION`                |\n",
    "| [`GrokVisionModel`](../../api_reference/model.md#grokvisionmodel)               | You have access to xAI Grok multimodal.           | `XAI_API_KEY` (optional: `XAI_MODEL`, default `grok-4`)                                                               |\n",
    "| [`GeminiVisionModel`](../../api_reference/model.md#geminivisionmodel)           | You want Google’s Gemini vision models.           | `GEMINI_API_KEY` (also install extras: `pip install \"splitter-mr[multimodal]\"`)                                       |\n",
    "| [`AnthropicVisionModel`](../../api_reference/model.md#anthropicvisionmodel)     | You have an Anthropic key (Claude Vision).        | `ANTHROPIC_API_KEY` (optional: `ANTHROPIC_MODEL`)                                                                     |\n",
    "| [`HuggingFaceVisionModel`](../../api_reference/model.md#huggingfacevisionmodel) | You prefer local/open-source/offline inference.   | Install extras: `pip install \"splitter-mr[multimodal]\"` (optional: `HF_ACCESS_TOKEN` if the chosen model requires it) |\n",
    "\n",
    "> **Note on HuggingFace models:** Not all HF models are supported (e.g., gated or uncommon architectures). A well-tested option is **SmolDocling**.\n",
    "\n",
    "### Environment variables\n",
    "\n",
    "<details>\n",
    "  <summary><b>Show/hide environment variables needed for every provider</b></summary>\n",
    "\n",
    "  <h4>OpenAI</h4> \n",
    "\n",
    "```txt\n",
    "# OpenAI\n",
    "OPENAI_API_KEY=<your-api-key>\n",
    "# (optional) OPENAI_MODEL=gpt-4o\n",
    "```\n",
    "\n",
    "  <h4>Azure OpenAI</h4>\n",
    "\n",
    "```txt\n",
    "# Azure OpenAI\n",
    "AZURE_OPENAI_API_KEY=<your-api-key>\n",
    "AZURE_OPENAI_ENDPOINT=<your-endpoint>\n",
    "AZURE_OPENAI_API_VERSION=<your-api-version>\n",
    "AZURE_OPENAI_DEPLOYMENT=<your-model-name>\n",
    "```\n",
    "\n",
    "  <h4>xAI Grok</h4>\n",
    "\n",
    "```txt\n",
    "# xAI Grok\n",
    "XAI_API_KEY=<your-api-key>\n",
    "# (optional) XAI_MODEL=grok-4\n",
    "```\n",
    "\n",
    "  <h4>Google Gemini</h4>\n",
    "\n",
    "```txt\n",
    "# Google Gemini\n",
    "GEMINI_API_KEY=<your-api-key>\n",
    "# Also: pip install \"splitter-mr[multimodal]\"\n",
    "```\n",
    "\n",
    "  <h4>Anthropic (Claude Vision)</h4>\n",
    "\n",
    "```txt\n",
    "# Anthropic (Claude Vision)\n",
    "ANTHROPIC_API_KEY=<your-api-key>\n",
    "# (optional) ANTHROPIC_MODEL=claude-sonnet-4-20250514\n",
    "```\n",
    "\n",
    "  <h4>Hugging Face (local/open-source)</h4>\n",
    "\n",
    "```txt\n",
    "# Hugging Face (optional, only if needed by the model)\n",
    "HF_ACCESS_TOKEN=<your-hf-token>\n",
    "# Also: pip install \"splitter-mr[multimodal]\"\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "### Instantiation examples\n",
    "\n",
    "<details>\n",
    "  <summary><b>Show/hide instantiation snippets for all providers</b></summary>\n",
    "\n",
    "  <h4>OpenAI</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import OpenAIVisionModel\n",
    "\n",
    "# Reads OPENAI_API_KEY (and optional OPENAI_MODEL) from .env if present\n",
    "model = OpenAIVisionModel()\n",
    "# or pass explicitly:\n",
    "# model = OpenAIVisionModel(api_key=\"...\", model_name=\"gpt-4o\")\n",
    "```\n",
    "\n",
    "  <h4>Azure OpenAI</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import AzureOpenAIVisionModel\n",
    "\n",
    "# Reads Azure vars from .env if present\n",
    "model = AzureOpenAIVisionModel()\n",
    "# or:\n",
    "# model = AzureOpenAIVisionModel(\n",
    "#     api_key=\"...\",\n",
    "#     azure_endpoint=\"https://<resource>.openai.azure.com/\",\n",
    "#     api_version=\"2024-02-15-preview\",\n",
    "#     azure_deployment=\"<your-deployment-name>\",\n",
    "# )\n",
    "```\n",
    "\n",
    "  <h4>xAI Grok</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import GrokVisionModel\n",
    "\n",
    "# Reads XAI_API_KEY (and optional XAI_MODEL) from .env\n",
    "model = GrokVisionModel()\n",
    "```\n",
    "\n",
    "  <h4>Google Gemini</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import GeminiVisionModel\n",
    "\n",
    "# Requires GEMINI_API_KEY and the 'multimodal' extra installed\n",
    "model = GeminiVisionModel()\n",
    "```\n",
    "\n",
    "  <h4>Anthropic (Claude Vision)</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import AnthropicVisionModel\n",
    "\n",
    "# Reads ANTHROPIC_API_KEY (and optional ANTHROPIC_MODEL) from .env\n",
    "model = AnthropicVisionModel()\n",
    "```\n",
    "\n",
    "  <h4>Hugging Face (local/open-source)</h4>\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import HuggingFaceVisionModel\n",
    "\n",
    "# Token only if the model requires gating\n",
    "model = HuggingFaceVisionModel()\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "## Step 2: Read the file using a VLM\n",
    "\n",
    "All the implemented Readers support VLMs. To use these VLMs with the Readers, you only need to create the [`BaseReader`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#basereader) classes with an object from [`BaseVisionModel`](https://andreshere00.github.io/Splitter_MR/api_reference/model/#basevisionmodel) as argument.\n",
    "\n",
    "Firstly, we will use a [`VanillaReader`](https://andreshere00.github.io/Splitter_MR/api_reference/reader/#vanillareader) class:\n",
    "\n",
    "### Read a file using VanillaReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3707487",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- page -->\n",
      "\n",
      "An example of a PDF file\n",
      "This is a PDF file\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam commodo egestas suscipit.\n",
      "Morbi sodales mi et lacus laoreet, eu molestie felis sodales. Aenean mattis gravida\n",
      "congue. Suspendisse bibendum malesuada volutpat. Nunc aliquam iaculis ex, sed\n",
      "sollicitudin lorem congue et. Pellentesque imperdiet ac sem ac imperdiet. Sed vel enim\n",
      "vitae orci scelerisque convallis quis ac purus.\n",
      "Cras sed neque vel justo auctor interdum a sit amet quam. Curabitur rhoncus, ligula a\n",
      "lacinia euismod, mi nunc vestibulum erat, vitae laoreet neque lorem quis mi. Phasellus\n",
      "eu nunc in orci sagittis faucibus. Donec eget luctus sem, sit amet viverra neque.\n",
      "Curabitur pulvinar velit rhoncus mauris sodales, vitae bibendum augue vestibulum.\n",
      "Mauris porta, enim ut pellentesque bibendum, augue dui finibus nulla, et laoreet magna\n",
      "nisi eu magna. Mauris sit amet semper leo, vitae malesuada turpis. Nunc arcu felis,\n",
      "consequat in congue at, iaculis at ligula. Suspendisse potenti. Cras imperdiet enim vitae\n",
      "nunc elementum, non commodo ligula pretium. Vestibulum placerat nec tortor eu\n",
      "dapibus. Nullam et ipsum tortor. Nulla imperdiet enim velit, commodo facilisis elit\n",
      "tempus quis. Cras in interdum augue.\n",
      "\n",
      "<!-- image -->\n",
      "*Caption: A mysterious figure in a hoodie with glowing, round lenses, evoking a blend of futuristic technology and anonymity.*\n",
      "\n",
      "| It seems like | This is a table | But I am not sure |\n",
      "| --- | --- | --- |\n",
      "| About this | What do you think | ? |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import VanillaReader\n",
    "from splitter_mr.model import AzureOpenAIVisionModel\n",
    "\n",
    "FILE_PATH = \"data/pdfplumber_example.pdf\"\n",
    "\n",
    "model = AzureOpenAIVisionModel()\n",
    "reader = VanillaReader(model=model)\n",
    "reader_output = reader.read(file_path=FILE_PATH)\n",
    "\n",
    "print(reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ac137",
   "metadata": {},
   "source": [
    "!!! warning\n",
    "\n",
    "    If you dont have the file locally, it is possible that instead of loading the content of the file, it will show only the document path. In order to avoid this behavior, please, use a correct file path on the file to be read. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ea2281",
   "metadata": {},
   "source": [
    "\n",
    "In this case we have read a PDF with an image at the end of the file. When reading the file and priting the content, we can see that the image has been described by the VLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03976ed",
   "metadata": {},
   "source": [
    "\n",
    "When using a `VanillaReader` class, the image is highlighted with a `> **Caption**:` placeholder by default. But the prompt can be changed using the keyword argument `prompt`. For example, you can say that you want the Caption to be signalised as a comment `<!--- Caption: >:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113651cc",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- page -->\n",
      "\n",
      "An example of a PDF file\n",
      "This is a PDF file\n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam commodo egestas suscipit.\n",
      "Morbi sodales mi et lacus laoreet, eu molestie felis sodales. Aenean mattis gravida\n",
      "congue. Suspendisse bibendum malesuada volutpat. Nunc aliquam iaculis ex, sed\n",
      "sollicitudin lorem congue et. Pellentesque imperdiet ac sem ac imperdiet. Sed vel enim\n",
      "vitae orci scelerisque convallis quis ac purus.\n",
      "Cras sed neque vel justo auctor interdum a sit amet quam. Curabitur rhoncus, ligula a\n",
      "lacinia euismod, mi nunc vestibulum erat, vitae laoreet neque lorem quis mi. Phasellus\n",
      "eu nunc in orci sagittis faucibus. Donec eget luctus sem, sit amet viverra neque.\n",
      "Curabitur pulvinar velit rhoncus mauris sodales, vitae bibendum augue vestibulum.\n",
      "Mauris porta, enim ut pellentesque bibendum, augue dui finibus nulla, et laoreet magna\n",
      "nisi eu magna. Mauris sit amet semper leo, vitae malesuada turpis. Nunc arcu felis,\n",
      "consequat in congue at, iaculis at ligula. Suspendisse potenti. Cras imperdiet enim vitae\n",
      "nunc elementum, non commodo ligula pretium. Vestibulum placerat nec tortor eu\n",
      "dapibus. Nullam et ipsum tortor. Nulla imperdiet enim velit, commodo facilisis elit\n",
      "tempus quis. Cras in interdum augue.\n",
      "\n",
      "<!-- image -->\n",
      "<!---- Caption: Image shows a figure wearing a teal hoodie, with their hands on their head and a black face featuring glowing circular eyes, set against a dark background. The figure's expression conveys a sense of surprise or shock. ---!>\n",
      "\n",
      "| It seems like | This is a table | But I am not sure |\n",
      "| --- | --- | --- |\n",
      "| About this | What do you think | ? |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import VanillaReader\n",
    "\n",
    "PROMPT: str = \"Describe the resource in a concise way: e.g., <!---- Caption: Image shows ...!--->:\"\n",
    "\n",
    "reader = VanillaReader(model=model)\n",
    "reader_output = reader.read(file_path=FILE_PATH, prompt=PROMPT)\n",
    "\n",
    "print(reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb621ba",
   "metadata": {},
   "source": [
    "\n",
    "### Read a file using MarkItDownReader\n",
    "\n",
    "In this case, we will read an image file to provide a complete description. So, you simply instantiate the object and pass a model which inherits from a `BaseVisionModel` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4fa2a1",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- page -->\n",
      "\n",
      "# Description:\n",
      "<!---- Caption: Image shows a vibrant, colorful lizard peering out from a pink and orange floral background, showcasing its bright features and intricate details against a soft, blurred setting. ---!>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import MarkItDownReader\n",
    "\n",
    "FILE_PATH = \"data/chameleon.jpg\"\n",
    "\n",
    "md = MarkItDownReader(model=model)\n",
    "md_reader_output = md.read(file_path=FILE_PATH, prompt=PROMPT)\n",
    "\n",
    "print(md_reader_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af68805",
   "metadata": {},
   "source": [
    "\n",
    "Original image is:\n",
    "\n",
    "![Chameleon](https://raw.githubusercontent.com/andreshere00/Splitter_MR/refs/heads/main/data/chameleon.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71060e8",
   "metadata": {},
   "source": [
    "\n",
    "As we can see, `MarkItDownReader` provides a very complete but verbose description of the files that you provide. In addition, it is not capable to analyze the image contents inside a PDF. In contrast, you should provide the image separatedly. \n",
    "\n",
    "!!! warning\n",
    "    You can NOT modify the prompt of the VLM in this method.\n",
    "\n",
    "### Read the file using DoclingReader\n",
    "\n",
    "The same process can be applied to DoclingReader. This time, we will analyze an invoice. So, the code is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb173d2",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "*Caption: A decorative golden banner, ideal for adding a classic touch to titles or announcements.*\n",
      "\n",
      "<!-- image -->\n",
      "*Caption: A vibrant logo for Sunny Farm, showcasing fresh produce from Victoria, Australia, with a sun emblem symbolizing freshness and quality.*\n",
      "\n",
      "## 123 Somewhere St, Melbourne VIC 3000 (03) 1234 5678\n",
      "\n",
      "## Denny Gunawan\n",
      "\n",
      "221 Queen St Melbourne VIC 3000\n",
      "\n",
      "$39.60\n",
      "\n",
      "Invoice Number: #20130304\n",
      "\n",
      "| Organic Items   | Price/kg   |   Quantity(kg) | Subtotal   |\n",
      "|-----------------|------------|----------------|------------|\n",
      "| Apple           | $5.00      |              1 | $5.00      |\n",
      "| Orange          | $1.99      |              2 | $3.98      |\n",
      "| Watermelon      | $1.69      |              3 | $5.07      |\n",
      "| Mango           | $9.56      |              2 | $19.12     |\n",
      "| Peach           | $2.99      |              1 | $2.99      |\n",
      "\n",
      "<!-- image -->\n",
      "*Caption: A bold and expressive typography design conveying gratitude, perfect for expressing appreciation and thanks.*\n",
      "\n",
      "* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam sodales dapibus fermentum. Nunc adipiscing, magna sed scelerisque cursus, erat lectus dapibus urna, sed facilisis leo dui et ipsum.\n",
      "\n",
      "Subtotal\n",
      "\n",
      "$36.00\n",
      "\n",
      "GST (10%)\n",
      "\n",
      "$3.60\n",
      "\n",
      "Total\n",
      "\n",
      "$39.60\n",
      "\n",
      "<!-- image -->\n",
      "*Caption: A decorative brown banner, perfect for adding a rustic touch to announcements or displays.*\n"
     ]
    }
   ],
   "source": [
    "from splitter_mr.reader import DoclingReader\n",
    "\n",
    "FILE_PATH = \"data/sunny_farm.pdf\"\n",
    "\n",
    "docling = DoclingReader(model=model)\n",
    "docling_output = docling.read(file_path=FILE_PATH)\n",
    "\n",
    "print(docling_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaddb6f",
   "metadata": {},
   "source": [
    "\n",
    "The result is pretty similar to the observed PDF (https://raw.githubusercontent.com/andreshere00/Splitter_MR/blob/main/data/sunny_farm.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f157c25a",
   "metadata": {},
   "source": [
    "\n",
    "As the same way as `VanillaReader`, you can change the prompt to provide larger descriptions or whatever you want to. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87d1b3ac",
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!-- image -->\n",
      "The image presents a decorative, elongated banner that has a rustic yet elegant appearance. The banner is designed in a subtle shade of gold, reminiscent of aged parchment or well-worn fabric. Its surface features a natural texture, giving it an organic and artisanal quality. The edges of the banner are slightly frayed, suggesting it has been hand-crafted, adding a touch of vintage charm to its overall aesthetic. \n",
      "\n",
      "The banner curls gracefully at both ends, creating a sense of movement and flow that enchants the viewer's eye. This gentle curvature not only adds depth to the design but also invites the viewer to visualize the banner fluttering softly in the breeze, as if it were once proudly displayed at a grand event or a festive occasion. Its rich, warm tone exudes warmth and approachability, making it an ideal canvas for embellishments, text, or illustrations that could signify a celebration, a heartfelt message, or a call to action.  \n",
      "\n",
      "Overall, this ornate and timeless ribbon-like banner serves as an inviting feature, perfect for enhancing a range of contexts, from quaint gatherings and artisanal markets to more formal occasions, effectively drawing attention while evoking a sense of nostalgia and charm.\n",
      "\n",
      "<!-- image -->\n",
      "The Sunny Farm logo encapsulates the essence of fresh, high-quality produce cultivated in the heart of Victoria, Australia. At first glance, the design exudes a warm, inviting aura, prominently featuring a radiant sun rising or setting behind rolling hills, evoking a sense of natural beauty and vitality. The golden hues of the sunbeams symbolize the bounty of nature and the health-giving qualities of the farm’s products.\n",
      "\n",
      "At the top of the logo, the words “AUSTRALIA FRESH PRODUCE” are emblazoned in a bold and easy-to-read font, showcasing the farm’s commitment to providing only the finest, locally sourced fruits and vegetables. This tagline not only highlights the geographical origin of the produce but also underscores the farm’s dedication to freshness, quality, and sustainability. \n",
      "\n",
      "The central emblem, which displays the name “SUNNY FARM,” is designed in a distinctive, rustic font, reflecting the farm's traditional roots and authenticity. The rich brown ribbon that frames the logo carries the name of the farm, suggesting a trustworthy heritage and a connection to the land that emphasizes the back-to-basics philosophy of farming.\n",
      "\n",
      "Below the farm name, the word “VICTORIA” is elegantly inscribed, anchoring the brand identity in one of Australia’s most fertile regions known for its diverse agricultural practices. This placement serves to reassure consumers of the local origin of the produce, promoting a sense of community and environmental stewardship.\n",
      "\n",
      "The entire composition is enriched by the vibrant shades of green and yellow, representing fertile lands and abundant crops, which further reinforces the farm’s dedication to an eco-friendly and health-conscious approach to agriculture. This logo will likely appeal to customers who value not only the quality of their food but also the stories and practices behind its cultivation.\n",
      "\n",
      "In summary, the Sunny Farm logo is more than just a visual identity; it is a celebration of Australian agricultural heritage, a commitment to sustainability, and an invitation to consumers to partake in the wholesome goodness that comes straight from Victoria’s rich soil to their tables. It embodies a lifestyle of health, wellness, and respect for nature that welcomes everyone to enjoy the sun-kissed abundance of fresh produce that Sunny Farm has to offer.\n",
      "\n",
      "## 123 Somewhere St, Melbourne VIC 3000 (03) 1234 5678\n",
      "\n",
      "## Denny Gunawan\n",
      "\n",
      "221 Queen St Melbourne VIC 3000\n",
      "\n",
      "$39.60\n",
      "\n",
      "Invoice Number: #20130304\n",
      "\n",
      "| Organic Items   | Price/kg   |   Quantity(kg) | Subtotal   |\n",
      "|-----------------|------------|----------------|------------|\n",
      "| Apple           | $5.00      |              1 | $5.00      |\n",
      "| Orange          | $1.99      |              2 | $3.98      |\n",
      "| Watermelon      | $1.69      |              3 | $5.07      |\n",
      "| Mango           | $9.56      |              2 | $19.12     |\n",
      "| Peach           | $2.99      |              1 | $2.99      |\n",
      "\n",
      "<!-- image -->\n",
      "The phrase \"Thank You\" carries a weight of gratitude that is both simple and profound. It serves as an expression of appreciation, conveying recognition for kindness, assistance, or any positive action one has received from another. In our daily interactions, these two words can act as a bridge between individuals, fostering connections and reinforcing relationships. \n",
      "\n",
      "When we say \"Thank You,\" we acknowledge the efforts and intentions of others, whether they are small gestures or significant contributions. It can be uttered in countless contexts—from a polite response after receiving a cup of coffee to a heartfelt expression of gratitude in a moment of emotional support or life-changing help. The beauty of this phrase lies in its versatility; it can be formal or casual, spoken or written, but its essence remains the same—a genuine acknowledgment of someone else's impact on our lives.\n",
      "\n",
      "Moreover, expressing thanks can have a ripple effect. Research has highlighted the psychological benefits of gratitude, indicating that practicing gratitude can lead to improved mental health, enhanced well-being, and stronger interpersonal relationships. By sharing gratitude, we not only uplift others but also enrich our own lives, promoting positivity and encouraging a culture of appreciation.\n",
      "\n",
      "In essence, \"Thank You\" is much more than a polite social nicety; it is a powerful tool for building community and enhancing personal connections. Whether whispered in a moment of private reflection or shouted from the rooftops in joyous celebration, these words remind us to cherish the kindnesses we encounter and to recognize the never-ending interdependence of human experience.\n",
      "\n",
      "* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aliquam sodales dapibus fermentum. Nunc adipiscing, magna sed scelerisque cursus, erat lectus dapibus urna, sed facilisis leo dui et ipsum.\n",
      "\n",
      "Subtotal\n",
      "\n",
      "$36.00\n",
      "\n",
      "GST (10%)\n",
      "\n",
      "$3.60\n",
      "\n",
      "Total\n",
      "\n",
      "$39.60\n",
      "\n",
      "<!-- image -->\n",
      "The image you’re looking at features a beautifully crafted, flowing ribbon that evokes a sense of nostalgia and warmth. Its soft, golden hues suggest a vintage aesthetic, reminiscent of parchment or ancient scrolls, which signifies a passage through time. The ribbon undulates gracefully, as if caught in a gentle breeze, embodying motion and life. \n",
      "\n",
      "This particular ribbon is designed with a slightly worn texture, hinting at its use in various traditional settings, such as a celebratory event or as an embellishment on a gift that carries deep personal meaning. The edges of the ribbon are subtly frayed, conveying the idea that it has been cherished and appreciated over the years, adding a layer of character and history to its appearance. \n",
      "\n",
      "An ideal canvas for handwritten messages or decorative embellishments, this ribbon invites creativity and personalization. Whether it's used to adorn a wedding invitation, mark a special occasion, or simply wrap a thoughtful gift, its elegance and charm are sure to enhance any presentation. The ribbon could also serve as a visual focal point in designs, drawing the viewer’s eye and conveying messages of nostalgia, warmth, and the beauty of tradition.\n",
      "\n",
      "In summary, this exquisite ribbon captures the essence of storytelling and personal connection, making it a timeless element perfect for a myriad of creative applications. Its versatile design and beautiful color palette enable it to complement various themes and occasions, ensuring that it remains a cherished item in any decorative collection.\n"
     ]
    }
   ],
   "source": [
    "file = \"data/sunny_farm.pdf\"\n",
    "\n",
    "docling = DoclingReader(model=model)\n",
    "docling_output = docling.read(file, prompt=\"Provide a long description\")\n",
    "\n",
    "print(docling_output.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328d0643",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Although all three methods can read files from various sources, they differ significantly in how VLM analysis is implemented:\n",
    "\n",
    "* **`VanillaReader`** extracts graphical files from the input and uses a VLM to provide descriptions for these resources. Currently, it is only compatible with PDFs, and the VLM analysis and PDF reading logic are separated. It is the most scalable method for reading files, as it performs a call for every graphical resource in your PDF. However, this can become expensive for documents with a large number of images.\n",
    "\n",
    "* **`MarkItDownReader`** can only transform images into Markdown descriptions. Supported image formats include `png`, `jpg`, `jpeg`, and `svg`. It cannot provide hybrid methods for reading PDFs with image annotations. While it is fast and cost-effective, it can only process one file at a time and is limited to OpenAI models.\n",
    "\n",
    "* **`DoclingReader`** can read any file you provide using VLMs. If given a PDF, it reads the entire document with the VLM; the same applies to images and other graphical resources. However, it does not distinguish between text and image content, as the analysis is multimodal. As a result, in some cases, it cannot provide specific descriptions for images but instead analyzes the whole document.\n",
    "\n",
    "Using one or another method depends on your needs!\n",
    "\n",
    "In case that you want more information about available Models, visit [Developer guide](https://andreshere00.github.io/Splitter_MR/api_reference/model/). **Thank you for reading!**\n",
    "\n",
    "## Complete script\n",
    "\n",
    "```python\n",
    "from splitter_mr.model import AzureOpenAIVisionModel\n",
    "from splitter_mr.reader import DoclingReader, MarkItDownReader, VanillaReader\n",
    "\n",
    "# Define the model\n",
    "model = AzureOpenAIVisionModel()\n",
    "\n",
    "# Readers\n",
    "\n",
    "## Vanilla Reader\n",
    "\n",
    "FILE_PATH = \"data/pdfplumber_example.pdf\"\n",
    "\n",
    "reader = VanillaReader(model = model)\n",
    "reader_output = reader.read(file_path = FILE_PATH)\n",
    "\n",
    "print(reader_output.text)\n",
    "\n",
    "PROMPT: str = \"Describe the resource in a concise way: e.g., <!---- Caption: Image shows ...!--->:\"\n",
    "\n",
    "reader_output_with_dif_prompt = reader.read(\n",
    "    FILE_PATH, \n",
    "    prompt = PROMPT\n",
    ")\n",
    "\n",
    "print(reader_output_with_dif_prompt.text)\n",
    "\n",
    "## MarkItDown Reader\n",
    "\n",
    "FILE_PATH = \"data/chameleon.jpg\"\n",
    "\n",
    "md = MarkItDownReader(model = model)\n",
    "md_reader_output = md.read(file_path = FILE_PATH)\n",
    "\n",
    "print(md_reader_output.text)\n",
    "\n",
    "## Docling Reader\n",
    "\n",
    "FILE_PATH = \"data/sunny_farm.pdf\"\n",
    "\n",
    "docling = DoclingReader(model = model)\n",
    "docling_output = docling.read(\n",
    "    file_path = FILE_PATH, \n",
    "    prompt = \"Provide a long description\"\n",
    ")\n",
    "\n",
    "print(docling_output.text)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "orig_format": "markdown",
  "source_file": "docs/examples/pdf/pdf_with_vlm.md"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
