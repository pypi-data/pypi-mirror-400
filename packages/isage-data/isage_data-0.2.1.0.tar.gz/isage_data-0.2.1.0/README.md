# SAGE Data ğŸ“Š

**Dataset management module for SAGE benchmark suite**

Provides unified access to multiple datasets through a two-layer architecture:
- **Sources**: Physical datasets in `sage/data/sources/` (qa_base, bbh, mmlu, gpqa, locomo, orca_dpo, agent_benchmark, agent_sft, agent_tools, etc.)
- **Usages**: Logical views for experiments in `sage/data/usages/` (rag, libamm, neuromem, agent_eval)

## ğŸš€ Quick Start

### Installation

```bash
# Run the quickstart script (recommended)
./quickstart.sh

# Or install manually
pip install -e .

# Install with optional dependencies
pip install -e ".[all]"        # All datasets
pip install -e ".[datasets]"   # Hugging Face datasets
pip install -e ".[alignment]"  # DPO/alignment tools
pip install -e ".[agent]"      # Agent datasets
```

### Basic Usage

```python
from sage.data import DataManager

manager = DataManager.get_instance()

# Access datasets by logical usage profile
rag = manager.get_by_usage("rag")
qa_loader = rag.load("qa_base")  # already instantiated
queries = qa_loader.load_queries()

# Or fetch a specific data source directly
bbh_loader = manager.get_by_source("bbh")
tasks = bbh_loader.get_task_names()
```

## Available Datasets

| Dataset | Description | Download Required | Storage |
|---------|-------------|-------------------|---------|
| **qa_base** | Question-Answering with knowledge base | âŒ No (included) | Local files |
| **locomo** | Long-context memory benchmark | âœ… Yes (`python -m locomo.download`) | Local files (2.68MB) |
| **bbh** | BIG-Bench Hard reasoning tasks | âŒ No (included) | Local JSON files |
| **mmlu** | Massive Multitask Language Understanding | ğŸ“¥ Optional (`python -m mmlu.download --all-subjects`) | On-demand or Local (~160MB) |
| **gpqa** | Graduate-Level Question Answering | âœ… Auto (Hugging Face) | On-demand (~5MB cached) |
| **orca_dpo** | Preference pairs for alignment/DPO | âœ… Auto (Hugging Face) | On-demand (varies) |
| **agent_benchmark** | Agent evaluation tasks | âŒ No (included) | Local JSON files |
| **agent_sft** | Agent supervised fine-tuning conversations | âŒ No (included) | Local JSON files |
| **agent_tools** | Agent tool catalog and schemas | âŒ No (included) | Local JSON files |

See `examples/` for detailed usage examples.

## ğŸ“ Project Structure

```
sage/data/
â”œâ”€â”€ sources/              # Physical dataset loaders
â”‚   â”œâ”€â”€ qa_base/         # Q&A with knowledge base
â”‚   â”œâ”€â”€ bbh/             # BIG-Bench Hard tasks
â”‚   â”œâ”€â”€ mmlu/            # MMLU benchmark
â”‚   â”œâ”€â”€ gpqa/            # Graduate-level Q&A
â”‚   â”œâ”€â”€ locomo/          # Long-context memory
â”‚   â”œâ”€â”€ orca_dpo/        # DPO preference pairs
â”‚   â”œâ”€â”€ agent_benchmark/ # Agent evaluation tasks
â”‚   â”œâ”€â”€ agent_sft/       # Agent SFT conversations
â”‚   â””â”€â”€ agent_tools/     # Agent tool catalog
â””â”€â”€ usages/              # Logical views and profiles
    â”œâ”€â”€ rag/             # RAG experiments
    â”œâ”€â”€ libamm/          # LibAMM benchmarks
    â”œâ”€â”€ neuromem/        # Neuromem experiments
    â””â”€â”€ agent_eval/      # Agent evaluation profiles
```

See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for detailed design documentation.

## ğŸ“– Examples

```bash
python examples/qa_examples.py            # QA dataset usage
python examples/locomo_examples.py        # LoCoMo dataset usage
python examples/bbh_examples.py           # BBH dataset usage
python examples/mmlu_examples.py          # MMLU dataset usage
python examples/gpqa_examples.py          # GPQA dataset usage
python examples/orca_dpo_examples.py      # Orca DPO dataset usage
python examples/integration_example.py    # Cross-dataset integration
```

## License

MIT License - see [LICENSE](LICENSE) file.

## ğŸ”— Links

- **Repository**: https://github.com/intellistream/sageData
- **Issues**: https://github.com/intellistream/sageData/issues

## â“ Common Issues

**Q: Where's the LoCoMo data?**  
A: Run `python -m locomo.download` to download it (2.68MB from Hugging Face).

**Q: How to download MMLU for offline use?**  
A: Run `python -m mmlu.download --all-subjects` to download all subjects (~160MB).

**Q: GPQA access error?**  
A: You need to accept the dataset terms on Hugging Face: https://huggingface.co/datasets/Idavidrein/gpqa

**Q: How to use Orca DPO for alignment research?**  
A: Use `DataManager.get_by_source("orca_dpo")` to get the loader, then use `format_for_dpo()` to prepare data for training.

---

**Version**: 0.2.1.0 | **Last Updated**: January 2026
