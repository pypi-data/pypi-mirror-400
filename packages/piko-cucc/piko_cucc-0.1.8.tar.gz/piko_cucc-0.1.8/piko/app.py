import asyncio
import importlib
import pkgutil
import signal
from contextlib import asynccontextmanager
from types import ModuleType
from typing import Type, Dict, List, Set

from fastapi import FastAPI
from fastapi.responses import Response
from pydantic import BaseModel
from sqlalchemy import select

from piko.compute.manager import CpuManager
from piko.config import settings
from piko.core.cache import ConfigCache
from piko.core.registry import JobRegistry
from piko.core.resource import Resource
from piko.core.runner import JobRunner
from piko.core.scheduler import SchedulerManager
from piko.core.types import BackfillPolicy
from piko.core.watcher import ConfigWatcher
from piko.infra.db import init_db, create_all_tables, get_session, ScheduledJob
from piko.infra.leader import get_leader_mutex, get_leader_watchdog
from piko.infra.logging import get_logger, setup_logging
from piko.infra.observability import metrics_endpoint, CONTENT_TYPE_LATEST
from piko.persistence.writer import PersistenceWriter

logger = get_logger(__name__)


class PikoApp:
    """Piko åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ï¼ˆApp å®ä¾‹æ¨¡å¼ï¼‰

    è´Ÿè´£ç»„è£…æ‰€æœ‰å­ç³»ç»Ÿï¼ˆRegistry, Runner, Schedulerç­‰ï¼‰ï¼Œåè°ƒå¯åŠ¨ã€è¿è¡Œå’Œå…³é—­æµç¨‹ã€‚é‡‡ç”¨ä¾èµ–æ³¨å…¥æ¨¡å¼ç®¡ç†ç»„ä»¶

    Attributes:
        name (str): åº”ç”¨åç§°ï¼Œç”¨äºæ—¥å¿—æ ‡è¯†ã€‚
        registry (JobRegistry): ä»»åŠ¡æ³¨å†Œä¸­å¿ƒï¼Œå­˜å‚¨ä»£ç ä¸­å®šä¹‰çš„ Jobã€‚
        config_cache (ConfigCache): é…ç½®ç¼“å­˜ï¼ŒåŒæ­¥ DB ä¸­çš„ä»»åŠ¡é…ç½®ã€‚
        writer (PersistenceWriter): æŒä¹…åŒ–å†™å…¥å™¨ï¼Œè´Ÿè´£ JobRun ç­‰æ•°æ®çš„è½åº“ã€‚
        cpu_manager (CpuManager): CPU å¯†é›†å‹ä»»åŠ¡è®¡ç®—æ± ã€‚
        runner (JobRunner): ä»»åŠ¡æ‰§è¡Œå¼•æ“ã€‚
        scheduler (SchedulerManager): è°ƒåº¦ç®¡ç†å™¨ã€‚
        watcher (ConfigWatcher): é…ç½®ç›‘å¬å™¨ï¼Œè´Ÿè´£æ„ŸçŸ¥ DB å˜æ›´ã€‚
        api_app (FastAPI): å†…ç½®çš„è¿ç»´ API å®ä¾‹ã€‚
    """

    def __init__(self, name: str = "piko", modules: List[str] | None = None):
        """åˆå§‹åŒ– Piko åº”ç”¨ç¨‹åº

        Args:
            name (str): åº”ç”¨ç¨‹åºåç§°ï¼Œå°†ç”¨äº API æ–‡æ¡£æ ‡é¢˜å’Œæ—¥å¿—ã€‚
            modules (List[str] | None): éœ€è¦è‡ªåŠ¨åŠ è½½çš„æ¨¡å—è·¯å¾„åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰ã€‚å»ºè®®ä½¿ç”¨ auto_discover_jobs æ›¿ä»£æ­¤å‚æ•°
        """
        self.name = name
        self._shutdown_event = asyncio.Event()

        # ==========================================================
        # 1. å®ä¾‹åŒ–æ ¸å¿ƒç»„ä»¶
        # ==========================================================
        self.registry = JobRegistry()
        self.config_cache = ConfigCache()
        self.writer = PersistenceWriter()

        # CPU è®¡ç®—æ± ï¼ˆç”± App å®ä¾‹æŒæœ‰ï¼Œä¸å†æ˜¯å…¨å±€å•ä¾‹ï¼‰
        self.cpu_manager = CpuManager()

        # ==========================================================
        # 2. ç»„è£…ç»„ä»¶ (ä¾èµ–æ³¨å…¥)
        # ==========================================================
        self.runner = JobRunner(
            registry=self.registry,
            config_cache=self.config_cache,
            writer=self.writer
        )

        self.scheduler = SchedulerManager()

        self.watcher = ConfigWatcher(
            scheduler_manager=self.scheduler,
            config_cache=self.config_cache,
            registry=self.registry,
            runner=self.runner
        )

        # ==========================================================
        # 3. åˆå§‹åŒ–è¿ç»´ API
        # ==========================================================
        self.api_app = FastAPI(lifespan=self._lifespan_context, title=f"{name} Worker")
        self._register_api_routes()

        # ==========================================================
        # 4. åŠ è½½æ¨¡å— (å¦‚æœæœ‰)
        # ==========================================================
        if modules:
            self.load_modules(modules)

    def load_modules(self, modules: List[str]):
        """åŠ¨æ€åŠ è½½æ¨¡å—ä»¥è§¦å‘ä»»åŠ¡æ³¨å†Œ

        Args:
            modules (List[str]): æ¨¡å—è·¯å¾„åˆ—è¡¨ï¼Œä¾‹å¦‚ ["my_project.jobs.etl"]

        Raises:
            ImportError: å½“æ¨¡å—è·¯å¾„ä¸å­˜åœ¨æˆ–å¯¼å…¥å¤±è´¥æ—¶æŠ›å‡ºã€‚
        """
        for module_path in modules:
            try:
                importlib.import_module(module_path)
                logger.info("module_loaded", module=module_path)
            except ImportError as e:
                logger.error("module_load_failed", module=module_path, error=str(e))
                raise

    def auto_discover_jobs(self, base_package: str | ModuleType, pattern: str = "jobs"):
        """è‡ªåŠ¨å‘ç°å¹¶åŠ è½½ä»»åŠ¡æ¨¡å—

        é€’å½’æ‰«ææŒ‡å®šåŒ…ä¸‹çš„æ‰€æœ‰å­æ¨¡å—ï¼Œå¦‚æœæ¨¡å—ååŒ¹é… pattern (é»˜è®¤ 'jobs')ï¼Œåˆ™è‡ªåŠ¨å¯¼å…¥å®ƒï¼Œä»è€Œè§¦å‘ @app.job è£…é¥°å™¨æ³¨å†Œ

        Args:
            base_package (str | ModuleType): æ ¹åŒ…å (e.g. 'iop_session_archiver')
            pattern (str): æ¨¡å—åŒ¹é…åç¼€ (é»˜è®¤ 'jobs'ï¼Œå³åŒ¹é… xxxx.jobs.py)
        """
        if isinstance(base_package, str):
            try:
                package = importlib.import_module(base_package)
            except ImportError as e:
                logger.error("auto_discover_failed", package=base_package, error=str(e))
                raise e
        else:
            package = base_package

        if not hasattr(package, "__path__"):
            logger.warning(f"Skipping auto-discover: '{package.__name__}' is not a package.")
            return

        logger.info(f"Auto-discovering jobs in '{package.__name__}' (pattern='*{pattern}')...")

        count = 0
        prefix = package.__name__ + "."

        for _, name, is_pkg in pkgutil.walk_packages(package.__path__, prefix):
            if is_pkg:
                continue

            if name.endswith("." + pattern) or name == pattern:
                try:
                    importlib.import_module(name)
                    logger.debug(f"   -> Loaded: {name}")
                    count += 1
                except Exception as e:
                    logger.error(f"âŒ Failed to load module '{name}': {e}")

        logger.info(f"Auto-discovered {count} job modules.")

    def _register_api_routes(self):
        """æ³¨å†Œå†…ç½®çš„è¿ç»´ API è·¯ç”±"""

        @self.api_app.get("/healthz")
        async def healthz():
            """å¥åº·æ£€æŸ¥ç«¯ç‚¹ (Liveness Probe)"""
            return {"status": "ok", "shutdown": self.is_shutdown_initiated}

        @self.api_app.get("/readyz")
        async def readyz():
            """å°±ç»ªæ£€æŸ¥ç«¯ç‚¹ (Readiness Probe)

            å¦‚æœæ˜¯ Leader/Follower æ¶æ„ï¼Œé Leader èŠ‚ç‚¹å¯èƒ½è¿”å› standby çŠ¶æ€ã€‚
            """
            leader = get_leader_mutex()
            if settings.leader_enabled and not leader.is_leader:
                return {"status": "standby", "ready": False}
            return {"status": "leader", "ready": True}

        @self.api_app.get("/metrics")
        async def metrics():
            """Prometheus æŒ‡æ ‡ç«¯ç‚¹"""
            data = metrics_endpoint()
            return Response(content=data, media_type=CONTENT_TYPE_LATEST)

    @property
    def is_shutdown_initiated(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²è§¦å‘å…³é—­æµç¨‹"""
        return self._shutdown_event.is_set()

    def job(
            self,
            job_id: str,
            schema: Type[BaseModel] | None = None,
            stateful: bool = False,
            backfill_policy: BackfillPolicy = BackfillPolicy.SKIP,
            resources: Dict[str, Type[Resource]] | None = None
    ):
        """è£…é¥°å™¨ï¼šæ³¨å†Œä»»åŠ¡åˆ°å½“å‰ App å®ä¾‹

        Args:
            job_id (str): ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼Œå¿…é¡»ä¸ scheduled_job è¡¨ä¸­çš„ job_id ä¸€è‡´
            schema (Type[BaseModel] | None): ä»»åŠ¡é…ç½®çš„ Pydantic Schemaï¼Œç”¨äºéªŒè¯ config json
            stateful (bool): æ˜¯å¦ä¸ºæœ‰çŠ¶æ€ä»»åŠ¡ï¼ˆéœ€è¦ç»´æŠ¤ last_data_timeï¼‰
            backfill_policy (BackfillPolicy): è¡¥è·‘ç­–ç•¥ (SKIP æˆ– RUN)
            resources (Dict[str, Type[Resource]] | None): èµ„æºä¾èµ–æ³¨å…¥å£°æ˜

        Returns:
            Callable: è£…é¥°å™¨å‡½æ•°
        """
        return self.registry.register(
            job_id=job_id,
            schema=schema,
            stateful=stateful,
            backfill_policy=backfill_policy,
            resources=resources
        )

    async def startup(self):
        """æ‰§è¡Œåº”ç”¨å¯åŠ¨æµç¨‹ï¼ˆå…­é˜¶æ®µï¼‰

        1. åˆå§‹åŒ– DB å’Œ Table
        2. å¯åŠ¨ CPU è®¡ç®—æ± 
        3. å¯åŠ¨æŒä¹…åŒ–å†™å…¥å™¨
        4. (å¯é€‰) é€‰ä¸¾ Leader
        5. å¯åŠ¨ ConfigWatcher å’Œ Scheduler
        6. æ£€æŸ¥é…ç½®å®Œæ•´æ€§ (Integrity Check)
        """
        setup_logging()
        logger.info("piko_app_startup", app=self.name, version=settings.version)

        try:
            init_db()
            await create_all_tables()

            if settings.leader_enabled:
                await get_leader_mutex().ensure_seed()

            self.cpu_manager.startup()
            await self.writer.start()

            if settings.leader_enabled:
                is_leader = await get_leader_mutex().try_acquire()
                logger.info("leader_election", is_leader=is_leader)
                await get_leader_watchdog().start()

            await self.watcher.start()
            self.scheduler.startup()

            # å¯åŠ¨æ—¶æ£€æŸ¥ï¼šä»£ç é‡Œçš„ Job æ˜¯å¦åœ¨ DB é‡Œé…ç½®äº†
            await self._check_scheduler_integrity()

            logger.info("piko_app_started")
        except Exception as e:
            logger.critical("piko_startup_unexpected_error", error=str(e))
            raise e

    async def _check_scheduler_integrity(self):
        """æ£€æŸ¥ä»»åŠ¡é…ç½®å®Œæ•´æ€§ï¼ˆé˜²å‘†ï¼‰

        å¯¹æ¯”ä»£ç ä¸­æ³¨å†Œçš„ä»»åŠ¡ (Registry) å’Œæ•°æ®åº“ä¸­è°ƒåº¦çš„ä»»åŠ¡ (DB)ã€‚å¦‚æœå‘ç°ä»£ç é‡Œå†™äº† Job ä½†æ•°æ®åº“é‡Œæ²¡é…ï¼Œè¾“å‡ºé†’ç›®åœ°è­¦å‘Šæ—¥å¿—
        """
        # 1. è·å–ä»£ç ä¸­å®šä¹‰çš„æ‰€æœ‰ Job ID (ä½¿ç”¨ Public API)
        registered_jobs = set(self.registry.get_all_job_ids())

        if not registered_jobs:
            logger.warning("âš ï¸ No jobs registered in code. Did you forget @app.job or auto_discover_jobs?")
            return

        # 2. è·å–æ•°æ®åº“ä¸­é…ç½®çš„æ‰€æœ‰ Job ID
        db_jobs: Set[str] = set()
        try:
            async for session in get_session():
                # æŸ¥è¯¢æ‰€æœ‰å¯ç”¨çš„ä»»åŠ¡
                stmt = select(ScheduledJob.job_id).where(ScheduledJob.enabled.is_(True))
                result = await session.execute(stmt)
                db_jobs = set(result.scalars().all())
                # åªéœ€è¦è·å–ä¸€æ¬¡
                break
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to check DB integrity: {e}")
            return

        # 3. å¯¹æ¯”åˆ†æ
        # åœºæ™¯ A: ä»£ç æœ‰ä»»åŠ¡ï¼Œä½†æ•°æ®åº“å®Œå…¨æ²¡é…ç½® (æœ€å¸¸è§çš„é”™è¯¯)
        if not db_jobs:
            logger.warning(
                "\n" + "=" * 60 + "\n"
                "ğŸš¨ ä¸¥é‡è­¦å‘Šï¼šæ²¡æœ‰é…ç½®ä»»ä½•ä»»åŠ¡ï¼ ğŸš¨\n"
                f"   åœ¨ä»£ç ä¸­å‘ç°äº† {len(registered_jobs)} ä¸ªä»»åŠ¡ ({', '.join(list(registered_jobs)[:3])}...), \n"
                "   ä½†æ˜¯ 'scheduled_job' è¡¨ä¸ºç©ºæˆ–æ‰€æœ‰ä»»åŠ¡éƒ½è¢«ç¦ç”¨ã€‚\n"
                "   ğŸ‘‰ æ“ä½œï¼šæ‚¨å¿…é¡»åœ¨ 'scheduled_job' å’Œ 'job_config' è¡¨ä¸­æ’å…¥è®°å½•ã€‚\n"
                "   (æ‚¨çš„ä»£ç æ²¡æœ‰é—®é¢˜ï¼Œä½† Piko æ˜¯é…ç½®é©±åŠ¨çš„ã€‚æ²¡æœ‰æ•°æ®åº“è®°å½• = ä¸ä¼šæ‰§è¡Œ)\n"
                + "=" * 60
            )

            return

        # åœºæ™¯ B: æŸäº›ä»»åŠ¡ä»£ç é‡Œå†™äº†ï¼Œä½†æ²¡é…ç½®æ•°æ®åº“
        missing_in_db = registered_jobs - db_jobs
        if missing_in_db:
            logger.warning(
                f"âš ï¸ é…ç½®ç¼ºå¤±ï¼šä»»åŠ¡ {missing_in_db} åœ¨ä»£ç ä¸­å·²å®šä¹‰ä½†åœ¨æ•°æ®åº“ä¸­æœªé…ç½®è°ƒåº¦ã€‚\n"
                "   åœ¨æ‚¨åœ¨ 'scheduled_job' è¡¨ä¸­é…ç½®å®ƒä»¬ä¹‹å‰ï¼Œå®ƒä»¬å°†ä¸ä¼šè¿è¡Œã€‚"
            )
        # åœºæ™¯ C: æ•°æ®åº“é…äº†ä»»åŠ¡ï¼Œä½†ä»£ç é‡Œæ²¡åŠ è½½ (å¯èƒ½æ˜¯åƒµå°¸ä»»åŠ¡ï¼Œæˆ–è€…æ˜¯åˆ«çš„ Worker çš„ä»»åŠ¡)
        missing_in_code = db_jobs - registered_jobs
        if missing_in_code:
            logger.info(
                f"â„¹ï¸ å­¤å„¿é…ç½®ï¼šä»»åŠ¡ {missing_in_code} åœ¨æ•°æ®åº“ä¸­å­˜åœ¨ä½†åœ¨å½“å‰å·¥ä½œè¿›ç¨‹ä»£ç ä¸­æœªæ‰¾åˆ°ã€‚\n"
                "   å¦‚æœå®ƒä»¬å±äºå…¶ä»–å·¥ä½œè¿›ç¨‹æœåŠ¡ï¼Œåˆ™æ²¡æœ‰é—®é¢˜ã€‚"
            )

    async def shutdown(self):
        """æ‰§è¡Œåº”ç”¨å…³é—­æµç¨‹ï¼ˆé€†åºå…³é—­ï¼‰

        1. åœæ­¢è°ƒåº¦å™¨ (ä¸å†è§¦å‘æ–°ä»»åŠ¡)
        2. åœæ­¢ ConfigWatcher
        3. åœæ­¢ Leader é€‰ä¸¾
        4. åœæ­¢æŒä¹…åŒ–å†™å…¥ (ç¡®ä¿ç¼“å†²æ•°æ®è½ç›˜)
        5. åœæ­¢ CPU è®¡ç®—æ± 
        """
        logger.info("piko_app_shutdown_begin")
        self.scheduler.shutdown()
        await self.watcher.stop()

        if settings.leader_enabled:
            await get_leader_watchdog().stop()
            await get_leader_mutex().release()

        await self.writer.stop()
        self.cpu_manager.shutdown()
        logger.info("piko_app_shutdown_complete")

    @asynccontextmanager
    async def _lifespan_context(self, _app: FastAPI):
        """FastAPI Lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        await self.startup()
        try:
            yield
        finally:
            await self.shutdown()

    @property
    def lifespan(self):
        return self._lifespan_context

    async def run_forever(self):
        """CLI è¿è¡Œä¸»å…¥å£ï¼ˆé˜»å¡ç›´åˆ°æ”¶åˆ°ä¿¡å·ï¼‰"""
        await self.startup()

        loop = asyncio.get_running_loop()
        for sig in (signal.SIGINT, signal.SIGTERM):
            loop.add_signal_handler(sig, lambda: self._shutdown_event.set())

        logger.info("piko_running_wait_for_signal")
        await self._shutdown_event.wait()
        await self.shutdown()

    def run(self):
        """åŒæ­¥è¿è¡Œå…¥å£ï¼ˆå¼€å‘è°ƒè¯•ä¾¿åˆ©æ–¹æ³•ï¼‰"""
        asyncio.run(self.run_forever())
