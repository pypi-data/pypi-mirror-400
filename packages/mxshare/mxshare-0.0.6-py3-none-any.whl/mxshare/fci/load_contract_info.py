import os
import pandas as pd
import logging
import argparse 
from concurrent.futures import ThreadPoolExecutor, as_completed
import contract_info_dce as dce
# import mxshare.fci.contract_info_szse as szse
# import mxshare.fci.contract_info_czce as czce
# import mxshare.fci.contract_info_cffex as cffex
# import mxshare.fci.contract_info_gfex as gfex
# import mxshare.fci.contract_info_ine as ine
# import mxshare.fci.contract_info_shfe as shfe

# ===================== æ—¥å¿—é…ç½® =====================
def setup_logger():
    log_format = "%(asctime)s - %(levelname)s - %(message)s"
    date_format = "%Y-%m-%d %H:%M:%S"
    
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[logging.StreamHandler()]
    )
    return logging.getLogger(__name__)

logger = setup_logger()

# ===================== è§£æå‘½ä»¤è¡Œå‚æ•° =====================
def parse_args():
    parser = argparse.ArgumentParser(description='è·å–å¹¶å¯¼å‡ºäº¤æ˜“æ‰€åˆçº¦ä¿¡æ¯')
    # æ—¥æœŸå‚æ•°ï¼šå¿…ä¼ ï¼Œæ ¼å¼å¦‚20251219
    parser.add_argument('--date', default='20260107', help='æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYYMMDDï¼ˆå¦‚20251219ï¼‰')
    # è¾“å‡ºç›®å½•ï¼šå¯é€‰ï¼Œé»˜è®¤/data/airflow_exec2/commodityexch
    parser.add_argument('--output', default='/data/airflow_exec2/commodityexch', help=f'è¾“å‡ºæ ¹ç›®å½•ï¼ˆé»˜è®¤ï¼š/data/airflow_exec2/commodityexchï¼‰')
    # çº¿ç¨‹æ•°ï¼šå¯é€‰ï¼Œé»˜è®¤1ï¼Œéœ€ä¸ºæ­£æ•´æ•°
    parser.add_argument('--workers', type=int, default=1, help=f'æœ€å¤§çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š1ï¼Œéœ€ä¸ºæ­£æ•´æ•°ï¼‰')
    
    args = parser.parse_args()
    
    # éªŒè¯çº¿ç¨‹æ•°å¿…é¡»ä¸ºæ­£æ•´æ•°
    if args.workers <= 0:
        parser.error(f'--workers å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå®é™…å€¼ï¼š{args.workers}')
    
    return args

# ===================== æ ¸å¿ƒé…ç½® =====================
args = parse_args()
QUERY_DATE = args.date
OUTPUT_ROOT = args.output
MAX_WORKERS = args.workers

# ä»æ—¥æœŸè§£æå¹´å’Œå¹´æœˆ
YEAR = QUERY_DATE[:4]
YEAR_MONTH_DAY = QUERY_DATE

BASE_DATA_TYPES = ["Option", "Future"]

EXCHANGE_CONFIG = {
    "dce": {
        "module": dce,
        "func_name": "contract_info_dce",
        "data_type_mode": "original",
        "param_rules": {"need_date": False, "need_instrument": True},
        "field_mapping": {
            "Option": {
                "variety": "å“ç§",
                "contractId": "åˆçº¦ä»£ç ",
                "unit": "äº¤æ˜“å•ä½",
                "tick": "æœ€å°å˜åŠ¨ä»·ä½",
                "startTradeDate": "å¼€å§‹äº¤æ˜“æ—¥",
                "endTradeDate": "æœ€åäº¤æ˜“æ—¥",
                "endDeliveryDate": "æœ€åäº¤å‰²æ—¥",
            },
            "Future": {
                "variety": "å“ç§",
                "contractId": "åˆçº¦ä»£ç ",
                "unit": "äº¤æ˜“å•ä½",
                "tick": "æœ€å°å˜åŠ¨ä»·ä½",
                "startTradeDate": "å¼€å§‹äº¤æ˜“æ—¥",
                "endTradeDate": "æœ€åäº¤æ˜“æ—¥",
                "endDeliveryDate": "æœ€åäº¤å‰²æ—¥",
            }
        }
    },
    # "szse": {
    #     "module": szse,
    #     "func_name": "contract_info_szse",
    #     "data_type_mode": "original",
    #     "param_rules": {"need_date": False, "need_instrument": False},
    #     "field_mapping": {
    #         "all": {
    #             "hybm": "åˆçº¦ç¼–ç ",
    #             "hzjyrq": "æœ€åäº¤æ˜“æ—¥",
    #             "xqrq": "è¡Œæƒæ—¥",
    #             "dqrq": "åˆ°æœŸæ—¥",
    #             "jsrq": "äº¤æ”¶æ—¥",
    #         }
    #     }
    # },
    # "czce": {
    #     "module": czce,
    #     "func_name": "contract_info_czce",
    #     "data_type_mode": "original",
    #     "param_rules": {"need_date": True, "need_instrument": True},
    #     "field_mapping": {
    #         "Option": {
    #             "Name": "å“ç§",
    #             "CtrCd": "åˆçº¦ä»£ç ",
    #             "MsrmntUnt": "äº¤æ˜“å•ä½",
    #             "TckSz": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "FrstTrdDt": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "LstTrdDt": "æœ€åäº¤æ˜“æ—¥",
    #             "SettleDt": "ç»“ç®—æ—¥",
    #             "ExpiryDt": "åˆ°æœŸæ—¥",
    #         },
    #         "Future": {
    #             "Name": "å“ç§",
    #             "CtrCd": "åˆçº¦ä»£ç ",
    #             "MsrmntUnt": "äº¤æ˜“å•ä½",
    #             "TckSz": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "FrstTrdDt": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "LstTrdDt": "æœ€åäº¤æ˜“æ—¥",
    #             "DlvryNtcDt": "äº¤å‰²é€šçŸ¥æ—¥",
    #             "DlvrySettleDt": "äº¤å‰²ç»“ç®—æ—¥",
    #             "LstDlvryDt": "æœ€åäº¤å‰²æ—¥",
    #             "LstDlvryDtBoard": "è½¦ï¼ˆèˆ¹ï¼‰æ¿æœ€åäº¤å‰²æ—¥",
    #         }
    #     }
    # },
    # "cffex": {
    #     "module": cffex,
    #     "func_name": "contract_info_cffex",
    #     "data_type_mode": "original",
    #     "param_rules": {"need_date": True, "need_instrument": False},
    #     "field_mapping": {
    #         "all": {
    #             "INSTRUMENT_ID": "åˆçº¦ä»£ç ",
    #             "OPEN_DATE": "ä¸Šå¸‚æ—¥",
    #             "END_TRADING_DAY": "æœ€åäº¤æ˜“æ—¥",
    #         }
    #     }
    # },
    # "gfex": {
    #     "module": gfex,
    #     "func_name": "contract_info_gfex",
    #     "data_type_mode": "original",
    #     "param_rules": {"need_date": False, "need_instrument": True},
    #     "field_mapping": {
    #         "Option": {
    #             "contractId": "åˆçº¦ä»£ç ",
    #             "variety": "å“ç§",
    #             "unit": "äº¤æ˜“å•ä½",
    #             "tick": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "startTradeDate": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "endTradeDate": "æœ€åäº¤æ˜“æ—¥",
    #             "endDeliveryDate0": "æœ€åäº¤å‰²æ—¥",
    #         },
    #         "Future": {
    #             "contractId": "åˆçº¦ä»£ç ",
    #             "variety": "å“ç§",
    #             "unit": "äº¤æ˜“å•ä½",
    #             "tick": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "startTradeDate": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "endTradeDate": "æœ€åäº¤æ˜“æ—¥",
    #             "endDeliveryDate0": "æœ€åäº¤å‰²æ—¥",
    #         }
    #     }
    # },
    # "ine": {
    #     "module": ine,
    #     "func_name": "contract_info_ine",
    #     "data_type_mode": "lower",
    #     "param_rules": {"need_date": True, "need_instrument": True},
    #     "field_mapping": {
    #         "Option": {
    #             "COMMODITYNAME": "å“ç§",
    #             "INSTRUMENTID": "åˆçº¦ä»£ç ",
    #             "TRADEUNIT": "äº¤æ˜“å•ä½",
    #             "PRICETICK": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "OPENDATE": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "EXPIREDATE": "æœ€åäº¤æ˜“æ—¥",
    #         },
    #         "Future": {
    #             "INSTRUMENTID": "åˆçº¦ä»£ç ",
    #             "OPENDATE": "ä¸Šå¸‚æ—¥",
    #             "EXPIREDATE": "åˆ°æœŸæ—¥",
    #             "STARTDELIVDATE": "å¼€å§‹äº¤å‰²æ—¥",
    #             "ENDDELIVDATE": "æœ€åäº¤å‰²æ—¥",
    #         }
    #     }
    # },
    # "shfe": {
    #     "module": shfe,
    #     "func_name": "contract_info_shfe",
    #     "data_type_mode": "lower",
    #     "param_rules": {"need_date": True, "need_instrument": True},
    #     "field_mapping": {
    #         "Option": {
    #             "COMMODITYNAME": "å“ç§",
    #             "INSTRUMENTID": "åˆçº¦ä»£ç ",
    #             "TRADEUNIT": "äº¤æ˜“å•ä½",
    #             "PRICETICK": "æœ€å°å˜åŠ¨ä»·ä½",
    #             "OPENDATE": "å¼€å§‹äº¤æ˜“æ—¥",
    #             "EXPIREDATE": "æœ€åäº¤æ˜“æ—¥",
    #         },
    #         "Future": {
    #             "INSTRUMENTID": "åˆçº¦ä»£ç ",
    #             "OPENDATE": "ä¸Šå¸‚æ—¥",
    #             "EXPIREDATE": "åˆ°æœŸæ—¥",
    #             "STARTDELIVDATE": "å¼€å§‹äº¤å‰²æ—¥",
    #             "ENDDELIVDATE": "æœ€åäº¤å‰²æ—¥"
    #         }
    #     }
    # }
}

# ===================== å·¥å…·å‡½æ•° =====================
def create_output_dir(exchange):
    """åˆ›å»ºäº¤æ˜“æ‰€å¯¹åº”çš„å±‚çº§ç›®å½•"""
    dir_path = os.path.join(OUTPUT_ROOT, exchange, YEAR, YEAR_MONTH_DAY)
    if not os.path.exists(dir_path):
        os.makedirs(dir_path, exist_ok=True)
        logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•: {dir_path}")
    return dir_path

def adapt_data_type(data_type: str, mode: str) -> str:
    if mode == "lower":
        return data_type.lower()
    elif mode == "original":
        return data_type
    else:
        return data_type

def is_data_empty(data) -> bool:
    """
    é€šç”¨ç©ºå€¼åˆ¤æ–­ï¼ˆå…¼å®¹åˆ—è¡¨/å­—å…¸/DataFrameï¼‰
    :param data: å¾…åˆ¤æ–­æ•°æ®
    :return: æ˜¯å¦ä¸ºç©º
    """
    if data is None:
        return True
    # DataFrameç©ºå€¼åˆ¤æ–­
    elif isinstance(data, pd.DataFrame):
        return data.empty
    # åˆ—è¡¨/å…ƒç»„ç©ºå€¼åˆ¤æ–­
    elif isinstance(data, (list, tuple)):
        return len(data) == 0
    # å­—å…¸ç©ºå€¼åˆ¤æ–­
    elif isinstance(data, dict):
        return len(data) == 0
    # å…¶ä»–ç±»å‹é»˜è®¤éç©º
    else:
        return False

def rename_fields(data, field_mapping: dict, data_type: str) -> pd.DataFrame or list:
    """
    å…¼å®¹DataFrame/åˆ—è¡¨çš„å­—æ®µè¿‡æ»¤+é‡å‘½å
    :param data: åŸå§‹æ•°æ®ï¼ˆDataFrame/åˆ—è¡¨ï¼‰
    :param field_mapping: å­—æ®µæ˜ å°„
    :param data_type: æ•°æ®ç±»å‹ï¼ˆOption/Future/allï¼‰
    :return: å¤„ç†åçš„æ•°æ®ï¼ˆä¿æŒåŸæ•°æ®ç±»å‹ï¼‰
    """
    # ç©ºå€¼ç›´æ¥è¿”å›
    if is_data_empty(data):
        logger.warning(f"{data_type} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å­—æ®µé‡å‘½å")
        return data
    
    # è·å–å¯¹åº”ç±»å‹çš„æ˜ å°„è§„åˆ™
    type_mapping = field_mapping.get(data_type, field_mapping.get("all", {}))
    if not isinstance(type_mapping, dict) or len(type_mapping) == 0:
        logger.warning(f"{data_type} æ— æœ‰æ•ˆå­—æ®µæ˜ å°„ï¼Œè¿”å›åŸå§‹æ•°æ®")
        return data
    
    # å¤„ç†DataFrameç±»å‹ï¼ˆGFEXè¿”å›çš„ç±»å‹ï¼‰
    if isinstance(data, pd.DataFrame):
        # 1. è¿‡æ»¤åˆ—ï¼šä»…ä¿ç•™æ˜ å°„ä¸­çš„åŸå§‹å­—æ®µ
        valid_columns = [col for col in type_mapping.keys() if col in data.columns]
        filtered_df = data[valid_columns].copy()
        # 2. é‡å‘½ååˆ—
        filtered_df.rename(columns=type_mapping, inplace=True)
        return filtered_df
    
    # å¤„ç†åˆ—è¡¨ï¼ˆå­—å…¸ï¼‰ç±»å‹
    elif isinstance(data, list):
        renamed_data = []
        for row in data:
            if not isinstance(row, dict):
                renamed_data.append(row)
                continue
            new_row = {}
            # ä»…ä¿ç•™æ˜ å°„ä¸­çš„å­—æ®µ
            for old_field, new_field in type_mapping.items():
                if old_field in row:
                    new_row[new_field] = row[old_field]
            renamed_data.append(new_row)
        return renamed_data
    
    # å…¶ä»–ç±»å‹ç›´æ¥è¿”å›
    else:
        logger.warning(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(data)}ï¼Œè¿”å›åŸå§‹æ•°æ®")
        return data

# ===================== æ ¸å¿ƒé€»è¾‘ =====================
def get_contract_data(exchange: str, data_type: str) -> tuple:
    """å…¼å®¹DataFrameçš„åˆçº¦æ•°æ®è·å–é€»è¾‘"""
    try:
        config = EXCHANGE_CONFIG[exchange]
        param_rules = config["param_rules"]
        
        logger.info(f"å¤„ç† {exchange.upper()} - {data_type} | "
                    f"å‚æ•°è§„åˆ™ï¼šdate={param_rules['need_date']}, instrument={param_rules['need_instrument']}")
        
        # ç»„è£…è°ƒç”¨å‚æ•°
        call_kwargs = {}
        if param_rules["need_date"]:
            call_kwargs["date"] = QUERY_DATE
        if param_rules["need_instrument"]:
            adapted_data_type = adapt_data_type(data_type, config["data_type_mode"])
            call_kwargs["instrument"] = adapted_data_type
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query_func = getattr(config["module"], config["func_name"])
        raw_data = query_func(**call_kwargs)
        
        # å­—æ®µè¿‡æ»¤+é‡å‘½åï¼ˆå…¼å®¹DataFrame/åˆ—è¡¨ï¼‰
        processed_data = rename_fields(raw_data, config["field_mapping"], data_type)
        
        # æ—¥å¿—è¾“å‡ºæ•°æ®é‡ï¼ˆå…¼å®¹ä¸åŒç±»å‹ï¼‰
        if isinstance(processed_data, pd.DataFrame):
            data_count = len(processed_data)
        elif isinstance(processed_data, (list, tuple)):
            data_count = len(processed_data)
        else:
            data_count = "æœªçŸ¥"
        logger.info(f"{exchange.upper()} - {data_type} | å¤„ç†åæ•°æ®é‡: {data_count}")
        
        return (exchange, data_type, processed_data, None)
    except Exception as e:
        error_msg = f"{exchange.upper()} - {data_type} å¤„ç†å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return (exchange, data_type, None, error_msg)

def export_to_csv(exchange: str, data_type: str, data) -> None:
    """é€šç”¨CSVå¯¼å‡ºï¼ˆå…¼å®¹DataFrame/åˆ—è¡¨ï¼‰"""
    if is_data_empty(data):
        logger.warning(f"{exchange.upper()} - {data_type} æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡å¯¼å‡º")
        return

    # åˆ›å»ºäº¤æ˜“æ‰€å¯¹åº”çš„å±‚çº§ç›®å½•
    output_dir = create_output_dir(exchange)

    # æ„å»ºæ–‡ä»¶å
    if exchange in ("cffex", "szse"):
        filename = f"{exchange}_all_cidInfo_{QUERY_DATE}.csv"
    else:
        filename = f"{exchange}_{data_type.lower()}_cidInfo_{QUERY_DATE}.csv"
    filepath = os.path.join(output_dir, filename)

    try:
        # ç»Ÿä¸€è½¬æ¢ä¸ºDataFrameï¼ˆå…¼å®¹åˆ—è¡¨/å­—å…¸ï¼‰ 
        if isinstance(data, list) and all(isinstance(x, dict) for x in data):
            data_df = pd.DataFrame(data)
        elif isinstance(data, pd.DataFrame):
            data_df = data
        else:
            logger.warning(f"{exchange.upper()} - {data_type} æ•°æ®æ ¼å¼ä¸æ”¯æŒï¼ˆ{type(data)}ï¼‰ï¼Œè·³è¿‡å¯¼å‡º")
            return
        
        # å¯¼å‡ºCSV
        data_df.to_csv(filepath, index=False, encoding='utf_8_sig')
        logger.info(f"âœ… å¯¼å‡ºæˆåŠŸ: {filepath} | å­—æ®µåˆ—è¡¨: {list(data_df.columns)}")
    except Exception as e:
        logger.error(f"âŒ å¯¼å‡ºå¤±è´¥ {filepath}: {str(e)}")

def main():
    # æ— éœ€æå‰åˆ›å»ºæ ¹ç›®å½•ï¼Œåœ¨create_output_dirä¸­ä¼šæŒ‰äº¤æ˜“æ‰€åˆ›å»ºå®Œæ•´è·¯å¾„

    # æ„å»ºä»»åŠ¡åˆ—è¡¨
    tasks = []
    for exchange in EXCHANGE_CONFIG.keys():
        if exchange in ("cffex", "szse"):
            tasks.append((exchange, "all"))
        else:
            for data_type in BASE_DATA_TYPES:
                tasks.append((exchange, data_type))

    # å¹¶è¡Œæ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_task = {
            executor.submit(get_contract_data, exchange, data_type): (exchange, data_type)
            for exchange, data_type in tasks
        }

        # å¤„ç†ç»“æœ
        for future in as_completed(future_to_task):
            exchange, data_type = future_to_task[future]
            try:
                _, _, data, error = future.result()
                if error:
                    continue
                export_to_csv(exchange, data_type, data)
            except Exception as e:
                logger.error(f"å¤„ç† {exchange.upper()} - {data_type} ç»“æœå‡ºé”™: {str(e)}")

    logger.info("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    main()