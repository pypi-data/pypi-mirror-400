#!/usr/bin/env python3
"""
ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®çŠ¶æ…‹ã‚’è©³ç´°ã«åˆ†æã—ã€ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã«å«ã‚ã‚‹æƒ…å ±ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
"""

import logging
from datetime import datetime
from typing import Any

logger = logging.getLogger(__name__)


class CacheReporter:
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ã®ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹
    """

    def __init__(self, project_root: str | None = None):
        """
        åˆæœŸåŒ–

        Args:
            project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹
        """
        self.project_root = project_root

    def generate_cache_report(self, cache_stats: dict[str, Any]) -> dict[str, Any]:
        """
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‹ã‚‰ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

        Args:
            cache_stats: ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆæƒ…å ±

        Returns:
            ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±
        """
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": self._generate_summary(cache_stats),
            "details": self._generate_details(cache_stats),
            "recommendations": self._generate_recommendations(cache_stats),
            "cache_impact_analysis": self._analyze_cache_impact(cache_stats),
        }

        return report

    def _generate_summary(self, cache_stats: dict[str, Any]) -> dict[str, Any]:
        """ã‚µãƒãƒªãƒ¼æƒ…å ±ã‚’ç”Ÿæˆ"""
        summary = {
            "total_cache_systems": 0,
            "active_caches": 0,
            "total_cached_items": 0,
            "cache_hit_rates": {},
            "potential_issues": [],
        }

        # Analysis Engine ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        if "analysis_engine" in cache_stats and not cache_stats["analysis_engine"].get(
            "error"
        ):
            ae_stats = cache_stats["analysis_engine"]
            summary["total_cache_systems"] += 1

            if (
                ae_stats.get("l1_size", 0) > 0
                or ae_stats.get("l2_size", 0) > 0
                or ae_stats.get("l3_size", 0) > 0
            ):
                summary["active_caches"] += 1
                summary["total_cached_items"] += (
                    ae_stats.get("l1_size", 0)
                    + ae_stats.get("l2_size", 0)
                    + ae_stats.get("l3_size", 0)
                )

            if "hit_rate" in ae_stats:
                summary["cache_hit_rates"]["analysis_engine"] = ae_stats["hit_rate"]

        # Search Content ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        if "search_content" in cache_stats and not cache_stats["search_content"].get(
            "error"
        ):
            sc_stats = cache_stats["search_content"]
            summary["total_cache_systems"] += 1

            if sc_stats.get("size", 0) > 0:
                summary["active_caches"] += 1
                summary["total_cached_items"] += sc_stats.get("size", 0)

            if "hit_rate_percent" in sc_stats:
                summary["cache_hit_rates"]["search_content"] = sc_stats[
                    "hit_rate_percent"
                ]

        # æ½œåœ¨çš„ãªå•é¡Œã‚’ç‰¹å®š
        if summary["active_caches"] > 0:
            summary["potential_issues"].append(
                "ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ - ãƒ†ã‚¹ãƒˆçµæœã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            )

        for cache_name, hit_rate in summary["cache_hit_rates"].items():
            if hit_rate > 50:  # 50%ä»¥ä¸Šã®ãƒ’ãƒƒãƒˆç‡
                summary["potential_issues"].append(
                    f"{cache_name}ã®ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„ ({hit_rate}%) - ãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå…±æœ‰ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )

        return summary

    def _generate_details(self, cache_stats: dict[str, Any]) -> dict[str, Any]:
        """è©³ç´°æƒ…å ±ã‚’ç”Ÿæˆ"""
        details = {
            "analysis_engine_cache": {},
            "search_content_cache": {},
            "cache_configurations": {},
        }

        # Analysis Engine ã®è©³ç´°
        if "analysis_engine" in cache_stats:
            ae_stats = cache_stats["analysis_engine"]
            if not ae_stats.get("error"):
                details["analysis_engine_cache"] = {
                    "type": "3å±¤éšå±¤ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (L1/L2/L3)",
                    "l1_size": ae_stats.get("l1_size", 0),
                    "l2_size": ae_stats.get("l2_size", 0),
                    "l3_size": ae_stats.get("l3_size", 0),
                    "total_requests": ae_stats.get("total_requests", 0),
                    "hits": ae_stats.get("hits", 0),
                    "misses": ae_stats.get("misses", 0),
                    "hit_rate": ae_stats.get("hit_rate", 0),
                    "storage": "ãƒ¡ãƒ¢ãƒªå†… (ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†æ™‚ã«æ¶ˆå¤±)",
                }
            else:
                details["analysis_engine_cache"]["error"] = ae_stats["error"]

        # Search Content ã®è©³ç´°
        if "search_content" in cache_stats:
            sc_stats = cache_stats["search_content"]
            if not sc_stats.get("error"):
                details["search_content_cache"] = {
                    "type": "LRU + TTL ã‚­ãƒ£ãƒƒã‚·ãƒ¥",
                    "current_size": sc_stats.get("size", 0),
                    "max_size": sc_stats.get("max_size", 0),
                    "ttl_seconds": sc_stats.get("ttl_seconds", 0),
                    "hits": sc_stats.get("hits", 0),
                    "misses": sc_stats.get("misses", 0),
                    "hit_rate_percent": sc_stats.get("hit_rate_percent", 0),
                    "evictions": sc_stats.get("evictions", 0),
                    "expired_entries": sc_stats.get("expired_entries", 0),
                    "storage": "ãƒ¡ãƒ¢ãƒªå†… (ãƒ—ãƒ­ã‚»ã‚¹çµ‚äº†æ™‚ã«æ¶ˆå¤±)",
                }
            else:
                details["search_content_cache"]["error"] = sc_stats["error"]

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®šæƒ…å ±
        details["cache_configurations"] = {
            "analysis_engine": {
                "default_ttl": "3600ç§’ (1æ™‚é–“)",
                "l1_default_size": 100,
                "l2_default_size": 1000,
                "l3_default_size": 10000,
            },
            "search_content": {
                "default_ttl": "3600ç§’ (1æ™‚é–“)",
                "default_max_size": 1000,
                "eviction_policy": "LRU (Least Recently Used)",
            },
        }

        return details

    def _generate_recommendations(self, cache_stats: dict[str, Any]) -> list[str]:
        """æ¨å¥¨äº‹é …ã‚’ç”Ÿæˆ"""
        recommendations = []

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ç¢ºèª
        active_caches = 0
        if "analysis_engine" in cache_stats and not cache_stats["analysis_engine"].get(
            "error"
        ):
            ae_stats = cache_stats["analysis_engine"]
            if (
                ae_stats.get("l1_size", 0) > 0
                or ae_stats.get("l2_size", 0) > 0
                or ae_stats.get("l3_size", 0) > 0
            ):
                active_caches += 1

        if "search_content" in cache_stats and not cache_stats["search_content"].get(
            "error"
        ):
            sc_stats = cache_stats["search_content"]
            if sc_stats.get("size", 0) > 0:
                active_caches += 1

        if active_caches > 0:
            recommendations.append(
                "ğŸš¨ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ãƒ†ã‚¹ãƒˆå‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã“ã¨ã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚"
            )
            recommendations.append(
                "ğŸ’¡ --no-cache-clear ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã›ãšã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚"
            )

        # ãƒ’ãƒƒãƒˆç‡ã®ç¢ºèª
        for cache_name in ["analysis_engine", "search_content"]:
            if cache_name in cache_stats and not cache_stats[cache_name].get("error"):
                stats = cache_stats[cache_name]
                hit_rate_key = (
                    "hit_rate"
                    if cache_name == "analysis_engine"
                    else "hit_rate_percent"
                )
                hit_rate = stats.get(hit_rate_key, 0)

                if hit_rate > 30:  # 30%ä»¥ä¸Šã®ãƒ’ãƒƒãƒˆç‡
                    recommendations.append(
                        f"âš ï¸ {cache_name}ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„ ({hit_rate}%) - ãƒãƒ¼ã‚¸ãƒ§ãƒ³é–“ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒå…±æœ‰ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"
                    )

        # ä¸€èˆ¬çš„ãªæ¨å¥¨äº‹é …
        recommendations.extend(
            [
                "âœ… å„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ†ã‚¹ãƒˆå‰å¾Œã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã€ã‚¯ãƒªãƒ¼ãƒ³ãªçŠ¶æ…‹ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚",
                "ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã« 'cache_hit': true ãŒè¡¨ç¤ºã•ã‚Œã‚‹å ´åˆã¯ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å½±éŸ¿ã‚’å—ã‘ã¦ã„ã‚‹è¨¼æ‹ ã§ã™ã€‚",
                "ğŸ”„ åŒã˜ãƒ†ã‚¹ãƒˆã‚’è¤‡æ•°å›å®Ÿè¡Œã—ã¦çµæœã®ä¸€è²«æ€§ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "ğŸ“ ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ã‚’ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆã«è¨˜éŒ²ã—ã€çµæœã®è§£é‡ˆã«æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚",
            ]
        )

        return recommendations

    def _analyze_cache_impact(self, cache_stats: dict[str, Any]) -> dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãƒ†ã‚¹ãƒˆã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æ"""
        impact_analysis = {
            "risk_level": "low",  # low, medium, high
            "risk_factors": [],
            "mitigation_status": "unknown",
            "confidence_score": 0.0,  # 0.0-1.0
        }

        risk_score = 0.0
        max_risk_score = 0.0

        # Analysis Engine ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å½±éŸ¿
        if "analysis_engine" in cache_stats and not cache_stats["analysis_engine"].get(
            "error"
        ):
            ae_stats = cache_stats["analysis_engine"]
            total_items = (
                ae_stats.get("l1_size", 0)
                + ae_stats.get("l2_size", 0)
                + ae_stats.get("l3_size", 0)
            )
            hit_rate = ae_stats.get("hit_rate", 0)

            max_risk_score += 0.4
            if total_items > 0:
                risk_score += 0.2
                impact_analysis["risk_factors"].append(
                    f"Analysis Engineã«{total_items}å€‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªãŒå­˜åœ¨"
                )

            if hit_rate > 0.3:  # 30%ä»¥ä¸Š
                risk_score += 0.2
                impact_analysis["risk_factors"].append(
                    f"Analysis Engineã®ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„ ({hit_rate:.1%})"
                )

        # Search Content ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å½±éŸ¿
        if "search_content" in cache_stats and not cache_stats["search_content"].get(
            "error"
        ):
            sc_stats = cache_stats["search_content"]
            size = sc_stats.get("size", 0)
            hit_rate = sc_stats.get("hit_rate_percent", 0) / 100.0

            max_risk_score += 0.6
            if size > 0:
                risk_score += 0.3
                impact_analysis["risk_factors"].append(
                    f"Search Contentã«{size}å€‹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¨ãƒ³ãƒˆãƒªãŒå­˜åœ¨"
                )

            if hit_rate > 0.3:  # 30%ä»¥ä¸Š
                risk_score += 0.3
                impact_analysis["risk_factors"].append(
                    f"Search Contentã®ãƒ’ãƒƒãƒˆç‡ãŒé«˜ã„ ({hit_rate:.1%})"
                )

        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®æ±ºå®š
        if max_risk_score > 0:
            risk_ratio = risk_score / max_risk_score
            if risk_ratio > 0.7:
                impact_analysis["risk_level"] = "high"
            elif risk_ratio > 0.3:
                impact_analysis["risk_level"] = "medium"
            else:
                impact_analysis["risk_level"] = "low"

            impact_analysis["confidence_score"] = 1.0 - risk_ratio
        else:
            impact_analysis["confidence_score"] = 1.0

        # ç·©å’Œç­–ã®çŠ¶æ…‹
        if not impact_analysis["risk_factors"]:
            impact_analysis["mitigation_status"] = "not_needed"
        else:
            impact_analysis["mitigation_status"] = "required"

        return impact_analysis

    def format_report_for_markdown(self, report: dict[str, Any]) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        md_lines = [
            "## ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ…‹ãƒ¬ãƒãƒ¼ãƒˆ",
            "",
            f"**ç”Ÿæˆæ—¥æ™‚**: {report['timestamp']}",
            "",
            "### ğŸ“Š ã‚µãƒãƒªãƒ¼",
            "",
            f"- **ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ æ•°**: {report['summary']['total_cache_systems']}",
            f"- **ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ•°**: {report['summary']['active_caches']}",
            f"- **ç·ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¢ã‚¤ãƒ†ãƒ æ•°**: {report['summary']['total_cached_items']}",
            "",
        ]

        # ãƒ’ãƒƒãƒˆç‡
        if report["summary"]["cache_hit_rates"]:
            md_lines.append("**ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡**:")
            for cache_name, hit_rate in report["summary"]["cache_hit_rates"].items():
                md_lines.append(f"- {cache_name}: {hit_rate:.1f}%")
            md_lines.append("")

        # æ½œåœ¨çš„ãªå•é¡Œ
        if report["summary"]["potential_issues"]:
            md_lines.extend(["### âš ï¸ æ½œåœ¨çš„ãªå•é¡Œ", ""])
            for issue in report["summary"]["potential_issues"]:
                md_lines.append(f"- {issue}")
            md_lines.append("")

        # å½±éŸ¿åˆ†æ
        impact = report["cache_impact_analysis"]
        risk_emoji = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}
        md_lines.extend(
            [
                "### ğŸ¯ ã‚­ãƒ£ãƒƒã‚·ãƒ¥å½±éŸ¿åˆ†æ",
                "",
                f"- **ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«**: {risk_emoji.get(impact['risk_level'], 'â“')} {impact['risk_level'].upper()}",
                f"- **ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢**: {impact['confidence_score']:.1%}",
                f"- **ç·©å’Œç­–**: {impact['mitigation_status']}",
                "",
            ]
        )

        if impact["risk_factors"]:
            md_lines.append("**ãƒªã‚¹ã‚¯è¦å› **:")
            for factor in impact["risk_factors"]:
                md_lines.append(f"- {factor}")
            md_lines.append("")

        # æ¨å¥¨äº‹é …
        if report["recommendations"]:
            md_lines.extend(["### ğŸ’¡ æ¨å¥¨äº‹é …", ""])
            for rec in report["recommendations"]:
                md_lines.append(f"- {rec}")
            md_lines.append("")

        # è©³ç´°æƒ…å ±
        md_lines.extend(["### ğŸ” è©³ç´°æƒ…å ±", "", "#### Analysis Engine ã‚­ãƒ£ãƒƒã‚·ãƒ¥", ""])

        ae_cache = report["details"]["analysis_engine_cache"]
        if "error" not in ae_cache:
            md_lines.extend(
                [
                    f"- **ã‚¿ã‚¤ãƒ—**: {ae_cache.get('type', 'N/A')}",
                    f"- **L1ã‚µã‚¤ã‚º**: {ae_cache.get('l1_size', 0)}",
                    f"- **L2ã‚µã‚¤ã‚º**: {ae_cache.get('l2_size', 0)}",
                    f"- **L3ã‚µã‚¤ã‚º**: {ae_cache.get('l3_size', 0)}",
                    f"- **ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°**: {ae_cache.get('total_requests', 0)}",
                    f"- **ãƒ’ãƒƒãƒˆæ•°**: {ae_cache.get('hits', 0)}",
                    f"- **ãƒŸã‚¹æ•°**: {ae_cache.get('misses', 0)}",
                    "",
                ]
            )
        else:
            md_lines.append(f"- **ã‚¨ãƒ©ãƒ¼**: {ae_cache['error']}")
            md_lines.append("")

        md_lines.extend(["#### Search Content ã‚­ãƒ£ãƒƒã‚·ãƒ¥", ""])

        sc_cache = report["details"]["search_content_cache"]
        if "error" not in sc_cache:
            md_lines.extend(
                [
                    f"- **ã‚¿ã‚¤ãƒ—**: {sc_cache.get('type', 'N/A')}",
                    f"- **ç¾åœ¨ã®ã‚µã‚¤ã‚º**: {sc_cache.get('current_size', 0)}",
                    f"- **æœ€å¤§ã‚µã‚¤ã‚º**: {sc_cache.get('max_size', 0)}",
                    f"- **TTL**: {sc_cache.get('ttl_seconds', 0)}ç§’",
                    f"- **ãƒ’ãƒƒãƒˆæ•°**: {sc_cache.get('hits', 0)}",
                    f"- **ãƒŸã‚¹æ•°**: {sc_cache.get('misses', 0)}",
                    f"- **ã‚¨ãƒ“ã‚¯ã‚·ãƒ§ãƒ³æ•°**: {sc_cache.get('evictions', 0)}",
                    "",
                ]
            )
        else:
            md_lines.append(f"- **ã‚¨ãƒ©ãƒ¼**: {sc_cache['error']}")
            md_lines.append("")

        return "\n".join(md_lines)


def generate_cache_report(project_root: str | None = None) -> dict[str, Any]:
    """
    ä¾¿åˆ©é–¢æ•°ï¼šã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Args:
        project_root: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‘ã‚¹

    Returns:
        ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ãƒãƒ¼ãƒˆ
    """
    try:
        from .cache_manager import CacheManager
    except ImportError:
        # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¤±æ•—ã—ãŸå ´åˆã®ä»£æ›¿
        import sys
        from pathlib import Path

        sys.path.append(str(Path(__file__).parent))
        from cache_manager import CacheManager

    cache_manager = CacheManager(project_root)
    cache_stats = cache_manager.get_cache_stats()

    reporter = CacheReporter(project_root)
    return reporter.generate_cache_report(cache_stats)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

    logging.basicConfig(level=logging.INFO)

    print("ğŸ“Š ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    report = generate_cache_report()

    reporter = CacheReporter()
    markdown = reporter.format_report_for_markdown(report)

    print("\n" + "=" * 60)
    print(markdown)
    print("=" * 60)
