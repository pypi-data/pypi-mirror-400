"""ğŸ›ï¸ HC ç³»åˆ—æ³•å®˜ï¼ˆé…ç½®ä¼˜å…ˆ / å•ä¸€è±å… / ç²¾ç®€ç‰ˆè‰ç¨¿ï¼‰

ç›®æ ‡è®¾è®¡ï¼š
- æ‰€æœ‰å¯è°ƒå‚æ•°ï¼ˆåç§° tokenã€é˜ˆå€¼ã€å­—ç¬¦ä¸²è±å…ç‰‡æ®µç­‰ï¼‰å…¨éƒ¨ YAML åŒ–ï¼Œ
  ç”± `tools/court/yaml/config.yaml -> laws.hc001.*` æä¾›ï¼›
- Python ä»£ç åªä¿ç•™ç®—æ³•å’Œç»“æ„æ€§è§„åˆ™ï¼Œä¸å†å†™æ­»ä»»ä½•â€œä¸šåŠ¡å«ä¹‰â€çš„å¸¸é‡ï¼›
- è·¯å¾„è±å…åªæœ‰ä¸€ç§è§†è§’ï¼š`HC001` æ²»å¤–æ³•æƒæ–‡ä»¶ â†’ æ•´ä¸ª HC ç³»åˆ—(001â€“007) å…¨éƒ¨ä¸å®¡ï¼›
- åªæœ‰ä¸€ä¸ªè·¯å¾„è±å…æ–¹æ³• `_is_file_exempt`ï¼Œä¸”åªåœ¨æ€»å…¥å£ `investigate` é¡¶éƒ¨è°ƒç”¨ä¸€æ¬¡ï¼›
- å…¬å…±å·¥å…·æ–¹æ³•é›†ä¸­æ”¾åœ¨ä¸€å¤„ï¼ŒHC001/HC002/HC003/HC004/HC005 å…¨éƒ¨å¤ç”¨ã€‚

YAML æœŸæœ›ç»“æ„ï¼ˆç¤ºæ„ï¼‰ï¼š

.. code-block:: yaml

   laws:
     hc001:
       enabled: true
       exempt_files: []
       description: "HC ç³»åˆ—ï¼ˆç¡¬ç¼–ç /å¸¸é‡/æ•°å€¼é­”æ³•ï¼‰ç»Ÿä¸€é…ç½®å…¥å£"

       # constants ç›¸å…³
       module_patterns: ["constants.py", "constants/", "/constants/"]
       naked_const_exempt_patterns: ["__init__.py", "conftest.py", "test_", "_test.py"]
       system_const_prefixes: ["Final", "Literal", "TypeVar", "Generic", "Protocol", "Callable", "ClassVar", "Annotated"]
       allowed_naked_patterns: ["_LOGGER", "_LOG", "LOGGER_NAME"]
       typevar_pattern: "^[A-Z]$"

       # strings ç›¸å…³
       exclude_substrings: ["test", "example", "debug", "log"]
       report_generator_files: []
       exempt_strings: ["..."]
       logger_prefixes: ["logger.", "logging.", "log."]
       exception_call_prefixes: ["raise "]
       typealias_keywords: ["TypeAlias"]
       fstring_prefixes: ["f\"", "f'"]

       # numeric_params ç›¸å…³
       int_max: 5000
       min_control_value: 2
       strong_name_tokens: ["label_threshold_", "high_score_threshold", "score_threshold"]
       weak_name_tokens: ["threshold", "weight", "ratio", "score", "prob", "confidence"]
       control_tokens: ["retry", "retries", "attempt", "attempts", "top_", "max_", "min_", "limit", "window", "size", "timeout", "batch"]
       exempt_names: ["_NUMERIC_MIN_CONTROL_VALUE"]

å¡«æ»¡ HCConfig æ‰€éœ€å­—æ®µåï¼Œæœ¬æ–‡ä»¶ä½œä¸º HC ç³»åˆ—æ³•å®˜çš„ç»Ÿä¸€å®ç°ï¼Œ
ç”¨äºæ›¿æ¢å†å²ç‰ˆ `hc001.py`ï¼Œå®ç°æ›´ç®€æ´ä¸”é…ç½®é©±åŠ¨çš„ HC å®¡è®¡é€»è¾‘ã€‚
"""

from __future__ import annotations

import ast
import fnmatch
import re
from pathlib import Path
from typing import Final

from pycourt.config.config import (
    CourtConfig,
    HCConfig,
)
from pycourt.utils import Violation, normalize_patterns

# ============================================================================
# ä¸€ã€é…ç½®å¥‘çº¦ï¼šå¼ºç±»å‹æè¿° laws.hc001.config
# ï¼ˆå…·ä½“æ¨¡å‹å®šä¹‰é›†ä¸­åœ¨ tools.court.config ä¸­ï¼Œè¿™é‡Œåªåšå¯¼å…¥ä½¿ç”¨ï¼‰
# ============================================================================


# ============================================================================
# äºŒã€HC æ³•å®˜ï¼šå•ä¸€è·¯å¾„è±å… + å…±äº«å·¥å…· + å¤šæ¡æ³•åˆ™
# ============================================================================


class TheHardcodingLaw:
    """ğŸ›ï¸ HC ç³»åˆ—æ³•å®˜ï¼ˆ001â€“005ï¼‰ç»Ÿä¸€å®ç°ï¼ˆæ–°ç‰ˆè‰ç¨¿ï¼‰ã€‚

    - HC001: ç¡¬ç¼–ç å­—ç¬¦ä¸²æ£€æµ‹
    - HC002: è£¸å¸¸é‡å¯¼å…¥æ£€æµ‹
    - HC003: è£¸å¸¸é‡å®šä¹‰æ£€æµ‹
    - HC004: è·¨å¼•æ“å¸¸é‡å¯¼å…¥æ£€æµ‹
    - HC005: æ•°å€¼é­”æ³•ï¼ˆå¯è°ƒä¸šåŠ¡å‚æ•°ï¼‰æ£€æµ‹

    å…¼å®¹æ€§çº¦å®šï¼ˆä¸æ—§ç‰ˆ `hc001.py` è¡Œä¸ºå¯¹é½ï¼‰ï¼š
    - è·¯å¾„è±å…ä»æŒ‰æ³•æ¡ç¼–å·æ‹†åˆ†ï¼šHC001 / HC001_COMPAT_FILES /
      HC001_REPORT_GENERATOR_FILES / HC005 ç­‰ï¼›
    - æœ¬å®ç°ä»…è°ƒæ•´é…ç½®æ¥æºï¼ˆæ”¹ä¸º `config.yaml -> laws.hc001.*` + HCConfigï¼‰ï¼Œ
      ä¸æ”¹å˜è¿™äº›æ³•æ¡çº§è±å…è¯­ä¹‰ä¸å®¡è®¡ç®—æ³•çš„ 1:1 è¡Œä¸ºã€‚
    """

    CODE_HC001: Final[str] = "HC001"
    CODE_HC002: Final[str] = "HC002"
    CODE_HC003: Final[str] = "HC003"
    CODE_HC004: Final[str] = "HC004"
    CODE_HC005: Final[str] = "HC005"

    KEY_HC001_REPORT_GENERATOR_FILES: Final[str] = "HC001_REPORT_GENERATOR_FILES"
    KEY_HC001_COMPAT_FILES: Final[str] = "HC001_COMPAT_FILES"

    # éä¸šåŠ¡å«ä¹‰çš„ç®—æ³•å¸¸é‡ï¼šmapping.get(key, default) çš„å…¸å‹å‚æ•°ä¸ªæ•°ã€‚
    _MAPPING_GET_ARG_COUNT: Final[int] = 2

    def __init__(self, config: CourtConfig) -> None:
        self.config = config
        self.laws = config.laws

        # åˆ¤å†³æ¨¡æ¿ç”± CourtConfig æä¾›ï¼Œä¸èµ° HC é…ç½®ã€‚
        self._msg_hc001 = self.config.get_judge_template(self.CODE_HC001)
        self._msg_hc002 = self.config.get_judge_template(self.CODE_HC002)
        self._msg_hc003 = self.config.get_judge_template(self.CODE_HC003)
        self._msg_hc004 = self.config.get_judge_template(self.CODE_HC004)
        self._msg_hc005 = self.config.get_judge_template(self.CODE_HC005)

        # === æ ¸å¿ƒï¼šä» CourtConfig.hc è¯»å– HC ç³»åˆ—å®¶æ—é…ç½® ===
        self._payload: HCConfig = config.hc

    # ------------------------------------------------------------------
    # è·¯å¾„è±å…ï¼šHC001 é¡¶å±‚ + æ³•æ¡çº§è±å…ï¼ˆä¿æŒæ—§ç‰ˆè¡Œä¸ºï¼‰
    # ------------------------------------------------------------------

    def _match_file_patterns(self, file_path: Path, patterns: list[str]) -> bool:
        """åœ¨ç»™å®šè·¯å¾„ä¸Šåº”ç”¨ç»Ÿä¸€çš„ fnmatch/endswith æ¨¡å¼åŒ¹é…é€»è¾‘ã€‚"""

        if not patterns:
            return False

        fp_str = str(file_path)
        normalized = normalize_patterns(patterns)
        return any(
            fnmatch.fnmatch(fp_str, pattern) or fp_str.endswith(pattern)
            for pattern in normalized
        )

    def _is_file_exempt(self, file_path: Path) -> bool:
        """æ ¹æ® HC001.files è·¯å¾„è±å…ï¼Œåˆ¤æ–­æ–‡ä»¶æ˜¯å¦åœ¨æ•´ä¸ª HC ç³»åˆ—ä¸‹æ²»å¤–æ³•æƒã€‚

        ä¸æ—§ç‰ˆä¸€è‡´ï¼šè¿™é‡Œåªå¤„ç†â€œå®Œå…¨ä¸å®¡â€çš„æ–‡ä»¶é›†åˆï¼Œå…¶ä½™ HC00x çº§åˆ«çš„
        è±å…ï¼ˆä¾‹å¦‚ HC001_COMPAT_FILESã€HC001_REPORT_GENERATOR_FILESã€HC005ï¼‰
        ä»ç”±å„è‡ªè§„åˆ™å†…éƒ¨å¤„ç†ã€‚
        """

        patterns = self.config.get_exempt_files(self.CODE_HC001)
        return self._match_file_patterns(file_path, patterns)

    # ------------------------------------------------------------------
    # å¯¹å¤–æ€»å…¥å£ï¼šç»Ÿä¸€æ‰§è¡Œ HC001â€“HC007
    # ------------------------------------------------------------------

    def investigate(
        self,
        file_path: Path,
        content: str,
        lines: list[str],
        tree: ast.AST | None,
    ) -> list[Violation]:
        """å®¡æŸ¥ä»£ç ä¸­çš„ HC001â€“HC005 ç›¸å…³è¿è§„ã€‚

        - å”¯ä¸€è·¯å¾„è±å… `_is_file_exempt` åœ¨è¿™é‡Œç»Ÿä¸€å¤„ç†ï¼›
        - ä¹‹å HC001â€“HC005 éƒ½åªä¾èµ– AST ä¸ HCConfigï¼Œä¸å†ä½¿ç”¨è·¯å¾„çº§ç‰¹æ®Šé€»è¾‘ã€‚
        """

        del content  # HC ç³»åˆ—ä¸ç›´æ¥ä½¿ç”¨æ•´æ–‡ä»¶æ–‡æœ¬

        if self._is_file_exempt(file_path):
            return []

        violations: list[Violation] = []

        # HC002â€“HC007: åŸºäº AST çš„ç»“æ„æ€§æ£€æŸ¥
        if tree is not None:
            violations.extend(self._check_hc002_naked_imports(file_path, tree))
            violations.extend(self._check_hc003_naked_defs(file_path, tree))
            violations.extend(self._check_hc004_cross_engine(file_path, tree))
            violations.extend(
                self._check_hc005_numeric_magic(
                    file_path=file_path,
                    tree=tree,
                    lines=lines,
                )
            )

        # ç¡¬ç¼–ç å­—ç¬¦ä¸²é€è¡Œæ£€æŸ¥ï¼ˆHC001ï¼‰
        violations.extend(self._check_hc001_strings(file_path, lines, tree))

        return violations

    # =====================================================================
    # å…±äº«å·¥å…·ï¼šAST / æ•°å€¼ / å‘½åæ¨¡å¼
    # =====================================================================

    # ---- å¸¸é‡é…ç½®è®¿é—® ----

    # ä»¥ä¸‹ä¸‰ä¸ª property ä¿ç•™åŸæœ‰è¯­ä¹‰ï¼Œä»…ä½œä¸ºå‘½ååˆ†åŒºå¸®åŠ©é˜…è¯»ã€‚

    @property
    def _const_cfg(self) -> HCConfig:
        return self._payload

    @property
    def _str_cfg(self) -> HCConfig:
        return self._payload

    @property
    def _num_cfg(self) -> HCConfig:
        return self._payload

    # ---- å‘½åæ¨¡å¼ & è£¸å¸¸é‡ç›¸å…³ ----

    def _is_constants_module(self, file_path: Path) -> bool:
        fp_str = str(file_path)
        return any(pattern in fp_str for pattern in self._const_cfg.module_patterns)

    def _is_naked_const_exempt_file(self, file_path: Path) -> bool:
        fp_str = str(file_path)
        return any(
            pattern in fp_str for pattern in self._const_cfg.naked_const_exempt_patterns
        )

    def _is_upper_snake_case(self, name: str) -> bool:
        if not name:
            return False
        return bool(re.match(r"^[A-Z][A-Z0-9_]*$", name)) or name.isupper()

    def _is_system_typing_const(self, name: str) -> bool:
        return name in self._const_cfg.system_const_prefixes

    def _should_skip_naked_const(self, name: str) -> bool:
        cfg = self._const_cfg

        if name.startswith("__") and name.endswith("__"):
            return True
        if name.startswith("_"):
            return True
        if not self._is_upper_snake_case(name):
            return True
        if name in cfg.system_const_prefixes:
            return True
        if re.match(cfg.typevar_pattern, name):
            return True
        return any(pat in name for pat in cfg.allowed_naked_patterns)

    def _extract_naked_const_name(self, node: ast.stmt) -> str | None:
        if isinstance(node, ast.Assign):
            for target in node.targets:
                if isinstance(target, ast.Name):
                    name = target.id
                    if not self._should_skip_naked_const(name):
                        return name
        elif isinstance(node, ast.AnnAssign) and isinstance(node.target, ast.Name):
            name = node.target.id
            if self._should_skip_naked_const(name):
                return None
            if isinstance(node.annotation, ast.Subscript):
                ann_str = ast.unparse(node.annotation)
                if "Final[Literal[" in ann_str:
                    return None
            return name
        return None

    # ---- AST & æ•°å€¼å·¥å…· ----

    @staticmethod
    def _eval_numeric_literal(expr: ast.AST) -> float | int | None:
        try:
            value = ast.literal_eval(expr)
        except Exception:  # pragma: no cover - é˜²å¾¡æ€§
            return None
        return value if isinstance(value, (int, float)) else None

    @staticmethod
    def _get_assign_target_name(target: ast.expr) -> str | None:
        if isinstance(target, ast.Name):
            return target.id
        if isinstance(target, ast.Attribute):
            return target.attr
        if isinstance(target, ast.Subscript):
            base = None
            index = None

            value = target.value
            if isinstance(value, ast.Name):
                base = value.id
            elif isinstance(value, ast.Attribute):
                base = value.attr

            slc = target.slice
            if isinstance(slc, ast.Constant) and isinstance(slc.value, str):
                index = slc.value
            if base and index:
                return f"{base}.{index}"
            return base
        return None

    # ---- HC005 åç§° token & è±å…å·¥å…·ï¼ˆä¸æ—§ç‰ˆå…¼å®¹ï¼‰ ----

    def _get_numeric_param_tokens(self) -> tuple[list[str], list[str]]:
        """ä» payload.numeric_params ä¸­è¯»å–åç§° token é…ç½®ã€‚

        å®Œå…¨ YAML é©±åŠ¨ï¼š
        - strong_name_tokens: å¼ºè¯­ä¹‰ label/score åç§° tokenï¼›
        - weak_name_tokens: å…¶ä½™ç”¨äºæ•°å€¼å¯å‘å¼åˆ¤æ–­çš„é€šç”¨ tokenï¼ˆåŒæ—¶æœåŠ¡äº
          æµ®ç‚¹ä¸æ•´å‹åœºæ™¯ï¼‰ã€‚
        """

        strong_tokens = list(self._num_cfg.strong_name_tokens)
        weak_tokens = list(self._num_cfg.weak_name_tokens)
        return strong_tokens, weak_tokens

    def _get_numeric_param_exemptions(self) -> tuple[list[str], list[str]]:
        """è¯»å– HC005 æ•°å€¼è±å…é…ç½®ï¼ˆæ–‡ä»¶çº§ + åç§°çº§ï¼‰ã€‚

        ä¸æ—§ç‰ˆçº¦å®šä¿æŒä¸€è‡´ï¼š
        - æ–‡ä»¶çº§è±å…ï¼š`exempt.yaml` â†’ CourtConfig.get_exempt_files("HC005")ï¼›
        - åç§°çº§è±å…ï¼špayload.numeric_params.exempt_namesã€‚
        """

        file_patterns = self.config.get_exempt_files(self.CODE_HC005)
        exempt_names = list(self._num_cfg.exempt_names)
        return file_patterns, exempt_names

    def _is_strong_label_param(self, lowered: str, value: float | int) -> bool:
        """å¼ºè¯­ä¹‰ label/score é˜ˆå€¼ï¼Œåªçœ‹åç§°å³å¯è§†ä¸ºå¯è°ƒå‚æ•°ã€‚

        åç§° token å®Œå…¨ç”± YAML çš„ numeric_params.strong_name_tokens æä¾›ã€‚
        """

        del value  # å½“å‰ä»…ä¾èµ–åç§°è¿›è¡Œåˆ¤æ–­
        strong_tokens, _ = self._get_numeric_param_tokens()
        return any(tok.lower() in lowered for tok in strong_tokens)

    def _is_float_threshold_param(self, lowered: str, value: float | int) -> bool:
        """0~1 ä¹‹é—´çš„æµ®ç‚¹é˜ˆå€¼/æƒé‡ï¼ˆä»¥åç§° token è¾…åŠ©åˆ¤æ–­ï¼‰ã€‚"""

        if not (isinstance(value, float) and 0.0 < value < 1.0):
            return False

        _, weak_tokens = self._get_numeric_param_tokens()
        return any(tok.lower() in lowered for tok in weak_tokens)

    def _is_int_limit_param(self, lowered: str, value: float | int) -> bool:
        """æ•´å‹ä¸Šé™/çª—å£/æ‰¹å¤§å°ç­‰å¯å‘å¼å‚æ•°ï¼ˆä»¥åç§° token è¾…åŠ©åˆ¤æ–­ï¼‰ã€‚"""

        int_max = self._get_numeric_int_max()
        if not (isinstance(value, int) and 1 <= value <= int_max):
            return False

        # è¿™é‡Œæ²¿ç”¨ weak_name_tokens ä½œä¸ºæ•´å‹åœºæ™¯çš„ä¸»åç§° token é›†åˆï¼Œå…·ä½“
        # token ç”± YAML æ§åˆ¶ï¼ˆé»˜è®¤å€¼ä¸æ—§ç‰ˆ _NUMERIC_INT_KEYS å¯¹é½ï¼‰ã€‚
        _, weak_tokens = self._get_numeric_param_tokens()
        return any(tok.lower() in lowered for tok in weak_tokens)

    def _build_numeric_token_context(
        self,
    ) -> tuple[list[str], list[str], list[str], int]:
        """æ„å»ºæ•°å€¼æ£€æµ‹æ‰€éœ€çš„åç§° token é›†åˆä¸æ•´å‹ä¸Šé™ã€‚

        å®Œå…¨ YAML é©±åŠ¨ï¼š
        - strong_name_tokens/weak_name_tokens ç”± numeric_params æä¾›ï¼›
        - æ•´å‹ä¸Šé™ç”± numeric_params.int_max æä¾›ã€‚
        """

        strong_cfg, weak_cfg = self._get_numeric_param_tokens()
        strong_tokens = [t.lower() for t in strong_cfg]
        float_tokens = [t.lower() for t in weak_cfg]
        int_tokens = [t.lower() for t in weak_cfg]
        int_max = self._get_numeric_int_max()
        return strong_tokens, float_tokens, int_tokens, int_max

    def _get_numeric_int_max(self) -> int:
        """ä»é…ç½®ä¸­è¯»å– HC005 çš„æ•´å‹ä¸Šé™é˜ˆå€¼ã€‚

        çº¦æŸäº¤ç”± Pydantic æ¨¡å‹ä¿è¯ï¼ˆint_max > 0ï¼‰ï¼Œæ­¤å¤„ç›´æ¥è¿”å›ã€‚
        """

        return self._num_cfg.int_max

    def _get_min_control_value(self) -> int:
        return self._num_cfg.min_control_value

    def _get_control_tokens(self) -> list[str]:
        return [t.lower() for t in self._num_cfg.control_tokens]

    @staticmethod
    def _is_name_exempt_for_numeric(name: str, exempt_names: list[str]) -> bool:
        return any(token and token in name for token in exempt_names)

    # =====================================================================
    # è£¸å¸¸é‡å¯¼å…¥ï¼ˆHC002ï¼‰
    # =====================================================================

    def _check_hc002_naked_imports(
        self, file_path: Path, tree: ast.AST
    ) -> list[Violation]:
        violations: list[Violation] = []

        for node in ast.walk(tree):
            if not (
                isinstance(node, ast.ImportFrom)
                and node.module
                and "constants" in node.module
            ):
                continue

            for alias in node.names:
                name = alias.name
                if self._is_system_typing_const(name):
                    continue
                if name == "*":
                    continue
                if self._is_upper_snake_case(name):
                    violations.append(
                        Violation(
                            file_path=file_path,
                            line=node.lineno,
                            col=node.col_offset,
                            code=self.CODE_HC002,
                            message=self._msg_hc002.format(name=name),
                        )
                    )

        return violations

    # =====================================================================
    # è£¸å¸¸é‡å®šä¹‰ï¼ˆHC003ï¼‰
    # =====================================================================

    def _check_hc003_naked_defs(
        self, file_path: Path, tree: ast.AST
    ) -> list[Violation]:
        if self._is_constants_module(file_path):
            return []
        if self._is_naked_const_exempt_file(file_path):
            return []
        if not isinstance(tree, ast.Module):
            return []

        violations: list[Violation] = []
        for node in tree.body:
            name = self._extract_naked_const_name(node)
            if name is None:
                continue
            violations.append(
                Violation(
                    file_path=file_path,
                    line=getattr(node, "lineno", 1),
                    col=getattr(node, "col_offset", 0),
                    code=self.CODE_HC003,
                    message=self._msg_hc003.format(name=name),
                )
            )

        return violations

    # =====================================================================
    # è·¨å¼•æ“å¸¸é‡å¯¼å…¥ï¼ˆHC004ï¼‰
    # =====================================================================

    @staticmethod
    def _extract_engine_name(file_path: Path) -> str | None:
        parts = file_path.parts
        for i, part in enumerate(parts):
            if part == "engines" and i + 1 < len(parts):
                return parts[i + 1]
        return None

    def _check_hc004_cross_engine(
        self, file_path: Path, tree: ast.AST
    ) -> list[Violation]:
        current_engine = self._extract_engine_name(file_path)
        if not current_engine:
            return []

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not (isinstance(node, ast.ImportFrom) and node.module):
                continue
            module = node.module
            if "engines" not in module or "constants" not in module:
                continue

            match = re.search(r"engines\.(\w+)", module)
            if not match:
                continue
            imported_engine = match.group(1)
            if imported_engine == current_engine:
                continue

            violations.append(
                Violation(
                    file_path=file_path,
                    line=node.lineno,
                    col=node.col_offset,
                    code=self.CODE_HC004,
                    message=self._msg_hc004.format(source=module),
                )
            )

        return violations

    # =====================================================================
    # æ•°å€¼é­”æ³•ï¼ˆå¯è°ƒä¸šåŠ¡å‚æ•°ï¼‰ï¼ˆHC005ï¼‰â€”â€”ä¸æ—§ç‰ˆé€»è¾‘å¯¹é½
    # =====================================================================

    def _is_suspicious_numeric(
        self,
        *,
        name: str | None,
        value: float | int,
        context: str,
    ) -> bool:
        """å¯å‘å¼åˆ¤æ–­æ˜¯å¦ä¸ºå¯è°ƒä¸šåŠ¡å‚æ•°çš„é­”æ³•æ•°å€¼ã€‚

        é€»è¾‘ä»æ—§ç‰ˆ `hc001.py` ç›´æ¥è¿ç§»ï¼Œä»…å°†é…ç½®æ¥æºæ”¹ä¸º `_num_cfg`ã€‚
        """

        lowered = (name or "").lower()
        strong_tokens, float_tokens, int_tokens, int_max = (
            self._build_numeric_token_context()
        )

        # 1) å†å²ä¸Šçš„å¼ºè¯­ä¹‰è§„åˆ™ï¼Œä¿è¯å…¼å®¹æ€§
        if self._is_strong_label_param(lowered, value):
            return True
        if self._is_float_threshold_param(lowered, value):
            return True
        if self._is_int_limit_param(lowered, value):
            return True

        # 2) ç®€å•çš„å…¨å±€è±å…ï¼šå…¸å‹å“¨å…µå€¼ï¼ˆ0/1/-1ï¼‰ï¼Œé™¤éå‘½ä¸­å¼º token
        if self._is_globally_exempt_sentinel(lowered, value, strong_tokens):
            return False

        # 3) æŒ‰æ•°å€¼ç±»å‹åˆ†æ´¾æ›´ç»†ç²’åº¦è§„åˆ™
        if isinstance(value, float):
            return self._is_suspicious_float_value(
                lowered=lowered,
                value=value,
                context=context,
                strong_tokens=strong_tokens,
                float_tokens=float_tokens,
            )

        # _eval_numeric_literal ä»…è¿”å› int æˆ– floatï¼Œä¸”ä¸Šæ–¹å·²å¤„ç† float åˆ†æ”¯ï¼Œ
        # æ­¤å¤„å¯ä»¥å®‰å…¨åœ°å°†å‰©ä½™æƒ…å†µè§†ä¸º int å‚æ•°ã€‚
        int_ctx = (strong_tokens, int_tokens, int_max)
        return self._is_suspicious_int_value(
            lowered=lowered,
            value=value,
            context=context,
            int_ctx=int_ctx,
        )

    @staticmethod
    def _is_globally_exempt_sentinel(
        lowered: str,
        value: float | int,
        strong_tokens: list[str],
    ) -> bool:
        """æ˜¯å¦å±äºå…¨å±€è±å…çš„å…¸å‹å“¨å…µå€¼ï¼ˆ0/1/-1ï¼‰ã€‚"""

        return (
            isinstance(value, int)
            and value in (-1, 0, 1)
            and not any(tok in lowered for tok in strong_tokens)
        )

    def _is_suspicious_float_value(
        self,
        *,
        lowered: str,
        value: float,
        context: str,
        strong_tokens: list[str],
        float_tokens: list[str],
    ) -> bool:
        """0~1 åŒºé—´æµ®ç‚¹é˜ˆå€¼/æƒé‡çš„å¯ç–‘æ€§åˆ¤æ–­ã€‚"""

        if not 0.0 < value < 1.0:
            return False

        if any(tok in lowered for tok in strong_tokens + float_tokens):
            return True

        return context in ("compare", "default", "kwarg")

    def _is_suspicious_int_value(
        self,
        *,
        lowered: str,
        value: int,
        context: str,
        int_ctx: tuple[list[str], list[str], int],
    ) -> bool:
        """æ•´å‹çª—å£/ä¸Šé™å‚æ•°çš„å¯ç–‘æ€§åˆ¤æ–­ã€‚"""

        strong_tokens, int_tokens, int_max = int_ctx

        if not 1 <= value <= int_max:
            return False

        if any(tok in lowered for tok in strong_tokens + int_tokens):
            return True

        if value < self._get_min_control_value():
            return False
        if context not in ("compare", "default", "kwarg"):
            return False

        control_tokens = self._get_control_tokens()
        return any(token in lowered for token in control_tokens)

    def _is_file_exempt_for_numeric(self, file_path: Path) -> bool:
        """åˆ¤æ–­å½“å‰æ–‡ä»¶æ˜¯å¦åœ¨ HC005 é­”æ³•æ•°å€¼æ£€æŸ¥çš„è±å…åå•ä¸­ã€‚"""

        exempt_files, _ = self._get_numeric_param_exemptions()
        if not exempt_files:
            return False

        return self._match_file_patterns(file_path, exempt_files)

    def _collect_hc005_assign_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - ç®€å•èµ‹å€¼ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, ast.Assign):
                continue
            for target in node.targets:
                target_name = self._get_assign_target_name(target)
                if not target_name or self._is_name_exempt_for_numeric(
                    target_name, exempt_names
                ):
                    continue
                value = self._eval_numeric_literal(node.value)
                if value is None or not self._is_suspicious_numeric(
                    name=target_name,
                    value=value,
                    context="assign",
                ):
                    continue
                line = (
                    lines[node.lineno - 1].strip()
                    if 0 < node.lineno <= len(lines)
                    else ""
                )
                violations.append(
                    Violation(
                        file_path=file_path,
                        line=node.lineno,
                        col=getattr(node, "col_offset", 0),
                        code=self.CODE_HC005,
                        message=self._msg_hc005.format(
                            snippet=line[:60] if line else target_name
                        ),
                    )
                )
        return violations

    def _collect_hc005_annassign_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - å¸¦ç±»å‹æ³¨è§£èµ‹å€¼ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not (isinstance(node, ast.AnnAssign) and node.value is not None):
                continue
            target = node.target
            name: str | None = None
            if isinstance(target, ast.Name):
                name = target.id
            elif isinstance(target, ast.Attribute):
                name = target.attr
            if not name or self._is_name_exempt_for_numeric(name, exempt_names):
                continue
            value = self._eval_numeric_literal(node.value)
            if value is None or not self._is_suspicious_numeric(
                name=name,
                value=value,
                context="annassign",
            ):
                continue
            line = (
                lines[node.lineno - 1].strip() if 0 < node.lineno <= len(lines) else ""
            )
            violations.append(
                Violation(
                    file_path=file_path,
                    line=node.lineno,
                    col=getattr(node, "col_offset", 0),
                    code=self.CODE_HC005,
                    message=self._msg_hc005.format(snippet=line[:60] if line else name),
                )
            )
        return violations

    def _collect_hc005_call_kwarg_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - å‡½æ•°è°ƒç”¨å…³é”®å­—å‚æ•°ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, ast.Call):
                continue

            for kw in node.keywords or []:
                if kw.arg is None:
                    continue
                kw_name = kw.arg
                if self._is_name_exempt_for_numeric(kw_name, exempt_names):
                    continue
                value = self._eval_numeric_literal(kw.value)
                if value is None or not self._is_suspicious_numeric(
                    name=kw_name,
                    value=value,
                    context="kwarg",
                ):
                    continue
                line = (
                    lines[node.lineno - 1].strip()
                    if 0 < node.lineno <= len(lines)
                    else ""
                )
                violations.append(
                    Violation(
                        file_path=file_path,
                        line=node.lineno,
                        col=getattr(node, "col_offset", 0),
                        code=self.CODE_HC005,
                        message=self._msg_hc005.format(
                            snippet=line[:60] if line else kw_name
                        ),
                    )
                )
        return violations

    def _collect_hc005_call_mapping_get_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - mapping.get(key, default) å½¢å¼ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        del exempt_names  # HC005: mapping.get é»˜è®¤å€¼ä¸åŒºåˆ†åç§°è±å…ï¼Œä»…é ä¸Šä¸‹æ–‡åˆ¤æ–­

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, ast.Call):
                continue
            if not (
                isinstance(node.func, ast.Attribute)
                and node.func.attr == "get"
                and len(node.args) == self._MAPPING_GET_ARG_COUNT
            ):
                continue

            default_expr = node.args[1]
            value = self._eval_numeric_literal(default_expr)
            if value is None:
                continue
            base_name = ast.unparse(node.func.value)
            name = f"{base_name}.default"
            if not self._is_suspicious_numeric(
                name=name,
                value=value,
                context="default",
            ):
                continue
            line = (
                lines[node.lineno - 1].strip() if 0 < node.lineno <= len(lines) else ""
            )
            violations.append(
                Violation(
                    file_path=file_path,
                    line=node.lineno,
                    col=getattr(node, "col_offset", 0),
                    code=self.CODE_HC005,
                    message=self._msg_hc005.format(snippet=line[:60] if line else name),
                )
            )
        return violations

    def _collect_hc005_call_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - å‡½æ•°è°ƒç”¨ä¸­çš„æ•°å€¼é­”æ³•èšåˆæ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        violations.extend(
            self._collect_hc005_call_kwarg_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_call_mapping_get_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        return violations

    def _collect_hc005_compare_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - æ¯”è¾ƒè¡¨è¾¾å¼ä¸­çš„æ•°å€¼é­”æ³•ï¼ˆx < 10 / x >= 3 ç­‰ï¼‰ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, ast.Compare):
                continue
            if len(node.comparators) != 1 or not isinstance(
                node.ops[0], (ast.Lt, ast.LtE, ast.Gt, ast.GtE, ast.Eq)
            ):
                continue
            left_name: str | None = None
            if isinstance(node.left, ast.Name):
                left_name = node.left.id
            elif isinstance(node.left, ast.Attribute):
                left_name = node.left.attr
            if not left_name or self._is_name_exempt_for_numeric(
                left_name, exempt_names
            ):
                continue
            value = self._eval_numeric_literal(node.comparators[0])
            if value is None or not self._is_suspicious_numeric(
                name=left_name,
                value=value,
                context="compare",
            ):
                continue
            line = (
                lines[node.lineno - 1].strip() if 0 < node.lineno <= len(lines) else ""
            )
            violations.append(
                Violation(
                    file_path=file_path,
                    line=node.lineno,
                    col=getattr(node, "col_offset", 0),
                    code=self.CODE_HC005,
                    message=self._msg_hc005.format(
                        snippet=line[:60] if line else left_name
                    ),
                )
            )
        return violations

    def _collect_hc005_default_positional_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - ä½ç½®å‚æ•°é»˜è®¤å€¼ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                continue

            args = list(getattr(node.args, "args", []))
            defaults = list(getattr(node.args, "defaults", []))
            if not defaults:
                continue

            for param, default_expr in zip(
                args[-len(defaults) :], defaults, strict=True
            ):
                if not isinstance(param, ast.arg):
                    continue
                name = param.arg
                if self._is_name_exempt_for_numeric(name, exempt_names):
                    continue
                value = self._eval_numeric_literal(default_expr)
                if value is None or not self._is_suspicious_numeric(
                    name=name,
                    value=value,
                    context="default",
                ):
                    continue
                line_no = getattr(default_expr, "lineno", node.lineno)
                line = lines[line_no - 1].strip() if 0 < line_no <= len(lines) else ""
                violations.append(
                    Violation(
                        file_path=file_path,
                        line=line_no,
                        col=getattr(default_expr, "col_offset", 0),
                        code=self.CODE_HC005,
                        message=self._msg_hc005.format(
                            snippet=line[:60] if line else name
                        ),
                    )
                )
        return violations

    def _collect_hc005_default_kwonly_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - ä»…å…³é”®å­—å‚æ•°é»˜è®¤å€¼ä¸­çš„æ•°å€¼é­”æ³•æ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        for node in ast.walk(tree):
            if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                continue

            kwonlyargs = list(getattr(node.args, "kwonlyargs", []))
            kw_defaults = list(getattr(node.args, "kw_defaults", []))
            for param, default_expr in zip(kwonlyargs, kw_defaults, strict=True):
                if default_expr is None or not isinstance(param, ast.arg):
                    continue
                name = param.arg
                if self._is_name_exempt_for_numeric(name, exempt_names):
                    continue
                value = self._eval_numeric_literal(default_expr)
                if value is None or not self._is_suspicious_numeric(
                    name=name,
                    value=value,
                    context="default",
                ):
                    continue
                line_no = getattr(default_expr, "lineno", node.lineno)
                line = lines[line_no - 1].strip() if 0 < line_no <= len(lines) else ""
                violations.append(
                    Violation(
                        file_path=file_path,
                        line=line_no,
                        col=getattr(default_expr, "col_offset", 0),
                        code=self.CODE_HC005,
                        message=self._msg_hc005.format(
                            snippet=line[:60] if line else name
                        ),
                    )
                )
        return violations

    def _collect_hc005_default_violations(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
        exempt_names: list[str],
    ) -> list[Violation]:
        """HC005 - å‡½æ•°å‚æ•°é»˜è®¤å€¼ä¸­çš„æ•°å€¼é­”æ³•èšåˆæ£€æŸ¥ã€‚"""

        violations: list[Violation] = []
        violations.extend(
            self._collect_hc005_default_positional_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_default_kwonly_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        return violations

    def _check_hc005_numeric_magic(
        self,
        *,
        file_path: Path,
        tree: ast.AST,
        lines: list[str],
    ) -> list[Violation]:
        """æ£€æŸ¥å¯è°ƒä¸šåŠ¡å‚æ•°çš„é­”æ³•æ•°å€¼ç¡¬ç¼–ç ï¼ˆHC005ï¼‰ã€‚

        é€»è¾‘æ•´ä½“ä¸æ—§ç‰ˆ `_check_numeric_magic_numbers` åŠå…¶å­å‡½æ•°ä¿æŒä¸€è‡´ï¼Œ
        ä½†å†…éƒ¨æ‹†åˆ†ä¸ºå¤šä¸ªå­æ£€æŸ¥å‡½æ•°ä»¥é™ä½å•ä¸ªå‡½æ•°çš„å¤æ‚åº¦ã€‚
        """

        if self._is_file_exempt_for_numeric(file_path):
            return []

        _, exempt_names = self._get_numeric_param_exemptions()

        violations: list[Violation] = []
        violations.extend(
            self._collect_hc005_assign_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_annassign_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_call_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_compare_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )
        violations.extend(
            self._collect_hc005_default_violations(
                file_path=file_path,
                tree=tree,
                lines=lines,
                exempt_names=exempt_names,
            )
        )

        return violations

    # =====================================================================
    # HC001: ç¡¬ç¼–ç å­—ç¬¦ä¸²æ£€æµ‹ï¼ˆå®Œæ•´ç‰ˆï¼Œå°½é‡ 1:1 å¤åˆ»æ—§ hc001.py è¡Œä¸ºï¼‰
    # =====================================================================

    def _get_exclude_substrings(self) -> tuple[str, ...]:
        """è¿”å›ç”¨äºè¡Œçº§å¿«é€Ÿæ’é™¤çš„å­—ç¬¦ä¸²ç‰‡æ®µé›†åˆï¼ˆå°å†™ï¼‰ã€‚"""

        return tuple(s.lower() for s in self._str_cfg.exclude_substrings)

    def _get_exempt_strings(self) -> list[str]:
        """è¿”å› HC001 è¡Œçº§è±å…å­—ç¬¦ä¸²ç‰‡æ®µåˆ—è¡¨çš„å‰¯æœ¬ã€‚"""

        return list(self._str_cfg.exempt_strings)

    def _check_hc001_strings(
        self,
        file_path: Path,
        lines: list[str],
        tree: ast.AST | None,
    ) -> list[Violation]:
        """ç»Ÿä¸€æ‰§è¡Œ HC001 ç›¸å…³å­—ç¬¦ä¸²æ‰«æï¼ˆä¸æ—§ç‰ˆ investigate_strings_for_file ç­‰ä»·ï¼‰ã€‚"""

        exempt_strings = self._get_exempt_strings()
        gen_range = self._maybe_get_report_range(file_path, tree)
        is_compat_file = self._is_compat_file(file_path)
        docstring_ranges = self._collect_docstring_ranges(tree)

        return self._scan_lines_for_hardcoding(
            file_path=file_path,
            lines=lines,
            exempt_strings=exempt_strings,
            gen_range=gen_range,
            is_compat_file=is_compat_file,
            docstring_ranges=docstring_ranges,
        )

    def _maybe_get_report_range(
        self, file_path: Path, tree: ast.AST | None
    ) -> tuple[int, int] | None:
        """è‹¥æ–‡ä»¶å±äºæŠ¥è¡¨ç”Ÿæˆå™¨èŒƒå›´ï¼Œåˆ™è¿”å› generate_report çš„è¡Œå·åŒºé—´ã€‚"""

        patterns = self.config.get_exempt_files(self.KEY_HC001_REPORT_GENERATOR_FILES)
        if self._match_file_patterns(file_path, patterns):
            return self._generate_report_range(tree)
        return None

    def _is_compat_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­å½“å‰æ–‡ä»¶æ˜¯å¦å±äºå…¼å®¹æ€§å¸¸é‡å®¹å™¨æ–‡ä»¶é›†åˆã€‚"""

        patterns = self.config.get_exempt_files(self.KEY_HC001_COMPAT_FILES)
        return self._match_file_patterns(file_path, patterns)

    def _collect_docstring_ranges(self, tree: ast.AST | None) -> list[tuple[int, int]]:
        """æ”¶é›†æ¨¡å— / ç±» / å‡½æ•°çº§ docstring çš„è¡Œå·åŒºé—´ï¼Œç”¨äºè±å… HC001ã€‚"""

        if tree is None:
            return []

        ranges: list[tuple[int, int]] = []
        for node in ast.walk(tree):
            if (
                isinstance(
                    node,
                    ast.Module | ast.ClassDef | ast.FunctionDef | ast.AsyncFunctionDef,
                )
                and node.body
            ):
                first = node.body[0]
                if isinstance(first, ast.Expr):
                    val = getattr(first, "value", None)
                    if isinstance(val, ast.Constant) and isinstance(val.value, str):
                        start = getattr(first, "lineno", None)
                        end = getattr(first, "end_lineno", None)
                        if isinstance(start, int) and isinstance(end, int):
                            ranges.append((start, end))
        return ranges

    def _generate_report_range(self, tree: ast.AST | None) -> tuple[int, int] | None:
        """è¿”å› generate_report å‡½æ•°çš„èµ·æ­¢è¡Œå·åŒºé—´ï¼ˆè‹¥å­˜åœ¨ï¼‰ã€‚"""

        if tree is None:
            return None
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef) and node.name == "generate_report":
                end_lineno = getattr(node, "end_lineno", None)
                if isinstance(end_lineno, int):
                    return (node.lineno, end_lineno)
        return None

    def _scan_lines_for_hardcoding(  # noqa: PLR0913
        self,
        *,
        file_path: Path,
        lines: list[str],
        exempt_strings: list[str],
        gen_range: tuple[int, int] | None,
        is_compat_file: bool,
        docstring_ranges: list[tuple[int, int]],
    ) -> list[Violation]:
        """é€è¡Œæ‰«æ HC001 ç¡¬ç¼–ç è¿è§„ï¼ˆä¸å« HC002/3/4ï¼‰ã€‚"""

        in_const_block = False
        paren_depth = 0

        in_argparse_block = False
        argparse_depth = 0

        violations: list[Violation] = []

        for line_num, line in enumerate(lines, 1):
            stripped_line = line.strip()
            if not stripped_line or stripped_line.startswith("#"):
                continue
            if self._in_docstring(line_num, docstring_ranges):
                continue

            (
                in_argparse_block,
                argparse_depth,
                in_const_block,
                paren_depth,
                violation,
            ) = self._process_single_line_for_hardcoding(
                file_path=file_path,
                line=line,
                stripped_line=stripped_line,
                line_num=line_num,
                exempt_strings=exempt_strings,
                gen_range=gen_range,
                is_compat_file=is_compat_file,
                in_argparse_block=in_argparse_block,
                argparse_depth=argparse_depth,
                in_const_block=in_const_block,
                paren_depth=paren_depth,
            )

            if violation is not None:
                violations.append(violation)

        return violations

    def _process_single_line_for_hardcoding(  # noqa: PLR0913
        self,
        *,
        file_path: Path,
        line: str,
        stripped_line: str,
        line_num: int,
        exempt_strings: list[str],
        gen_range: tuple[int, int] | None,
        is_compat_file: bool,
        in_argparse_block: bool,
        argparse_depth: int,
        in_const_block: bool,
        paren_depth: int,
    ) -> tuple[bool, int, bool, int, Violation | None]:
        """å¤„ç†å•è¡Œ HC001 æ£€æŸ¥ï¼Œè¿”å›æ›´æ–°åçš„çŠ¶æ€åŠå¯èƒ½çš„è¿è§„è®°å½•ã€‚"""

        in_argparse_block, argparse_depth = self._process_argparse_for_line(
            stripped_line=stripped_line,
            line=line,
            in_argparse_block=in_argparse_block,
            argparse_depth=argparse_depth,
        )

        early_result = self._maybe_skip_after_state_updates(
            line=line,
            line_num=line_num,
            stripped_line=stripped_line,
            gen_range=gen_range,
            is_compat_file=is_compat_file,
            in_argparse_block=in_argparse_block,
            argparse_depth=argparse_depth,
            in_const_block=in_const_block,
            paren_depth=paren_depth,
        )
        if early_result is not None:
            return early_result

        return self._finalize_single_line_violation(
            file_path=file_path,
            line=line,
            stripped_line=stripped_line,
            line_num=line_num,
            exempt_strings=exempt_strings,
            in_argparse_block=in_argparse_block,
            argparse_depth=argparse_depth,
            in_const_block=in_const_block,
            paren_depth=paren_depth,
        )

    def _maybe_skip_after_state_updates(  # noqa: PLR0913
        self,
        *,
        line: str,
        line_num: int,
        stripped_line: str,
        gen_range: tuple[int, int] | None,
        is_compat_file: bool,
        in_argparse_block: bool,
        argparse_depth: int,
        in_const_block: bool,
        paren_depth: int,
    ) -> tuple[bool, int, bool, int, Violation | None] | None:
        """åœ¨å®Œæˆ argparse/å…¼å®¹æ€§çŠ¶æ€æ›´æ–°åï¼Œç»Ÿä¸€å¤„ç†æ—©é€€é€»è¾‘ã€‚"""

        if (
            in_argparse_block
            and argparse_depth > 0
            and not self._is_argparse_start(line)
        ):
            # ä»å¤„äº argparse å¤šè¡Œå—å†…éƒ¨ï¼Œä¸”æœ¬è¡Œä¸æ˜¯èµ·å§‹è¡Œ â†’ æ•´ä½“è±å…
            return in_argparse_block, argparse_depth, in_const_block, paren_depth, None

        in_const_block, paren_depth = self._process_compat_block_for_line(
            stripped_line=stripped_line,
            line=line,
            line_num=line_num,
            gen_range=gen_range,
            is_compat_file=is_compat_file,
            in_const_block=in_const_block,
            paren_depth=paren_depth,
        )
        if in_const_block:
            # ä»åœ¨å…¼å®¹æ€§å¸¸é‡å®¹å™¨å—å†… â†’ æ•´ä½“è±å…
            return in_argparse_block, argparse_depth, in_const_block, paren_depth, None

        return None

    def _process_argparse_for_line(
        self,
        *,
        stripped_line: str,
        line: str,
        in_argparse_block: bool,
        argparse_depth: int,
    ) -> tuple[bool, int]:
        """æ›´æ–° argparse å¤šè¡Œå—ç›¸å…³çŠ¶æ€ã€‚"""

        skip, new_in_block, new_depth = self._handle_argparse_multiline(
            stripped_line=stripped_line,
            line=line,
            in_argparse_block=in_argparse_block,
            argparse_depth=argparse_depth,
        )
        if skip:
            return new_in_block, new_depth
        return in_argparse_block, argparse_depth

    def _process_compat_block_for_line(  # noqa: PLR0913
        self,
        *,
        stripped_line: str,
        line: str,
        line_num: int,
        gen_range: tuple[int, int] | None,
        is_compat_file: bool,
        in_const_block: bool,
        paren_depth: int,
    ) -> tuple[bool, int]:
        """æ›´æ–°å…¼å®¹æ€§å¸¸é‡å®¹å™¨å—ç›¸å…³çŠ¶æ€ã€‚"""

        skip, new_in_block, new_depth = self._handle_compat_const_block(
            stripped_line=stripped_line,
            line=line,
            line_num=line_num,
            gen_range=gen_range,
            is_compat_file=is_compat_file,
            in_const_block=in_const_block,
            paren_depth=paren_depth,
        )
        if skip:
            return new_in_block, new_depth
        return in_const_block, paren_depth

    def _finalize_single_line_violation(  # noqa: PLR0913
        self,
        *,
        file_path: Path,
        line: str,
        stripped_line: str,
        line_num: int,
        exempt_strings: list[str],
        in_argparse_block: bool,
        argparse_depth: int,
        in_const_block: bool,
        paren_depth: int,
    ) -> tuple[bool, int, bool, int, Violation | None]:
        """åœ¨å®ŒæˆçŠ¶æ€æ›´æ–°åï¼Œæ ¹æ®ç®€å•è§„åˆ™ä¸å­—ç¬¦ä¸²å†…å®¹æ„å»ºè¿è§„è®°å½•ã€‚"""

        if self._should_skip_by_simple_line_rules(
            file_path=file_path,
            line=line,
            stripped_line=stripped_line,
            exempt_strings=exempt_strings,
        ):
            return in_argparse_block, argparse_depth, in_const_block, paren_depth, None

        violation = self._build_hardcoding_violation_if_any(
            file_path=file_path,
            line=line,
            stripped_line=stripped_line,
            line_num=line_num,
        )

        return in_argparse_block, argparse_depth, in_const_block, paren_depth, violation

    def _build_hardcoding_violation_if_any(
        self,
        *,
        file_path: Path,
        line: str,
        stripped_line: str,
        line_num: int,
    ) -> Violation | None:
        """è‹¥å½“å‰è¡Œæ„æˆ HC001 è¿è§„ï¼Œåˆ™æ„å»ºä¸€æ¡ Violationï¼›å¦åˆ™è¿”å› Noneã€‚"""

        string_match = re.search(r'["\'][^"\']{5,}["\']', line)
        if not string_match:
            return None

        line_lower = line.lower()
        exclude_tokens = self._get_exclude_substrings()
        if ("=" not in line and ":" not in line) or any(
            ex in line_lower for ex in exclude_tokens
        ):
            return None

        string_literal = string_match.group(0).strip("\"'")
        if self._should_exempt_string(line, string_literal):
            return None

        return Violation(
            file_path=file_path,
            line=line_num,
            col=0,
            code=self.CODE_HC001,
            message=self._msg_hc001.format(snippet=stripped_line[:60]),
        )

    @staticmethod
    def _is_argparse_start(line: str) -> bool:
        """æ˜¯å¦ä¸º argparse å¤šè¡Œå®šä¹‰èµ·å§‹è¡Œã€‚"""

        return (
            "parser.add_argument(" in line
            or ".add_subparsers(" in line
            or ".add_parser(" in line
        )

    @staticmethod
    def _in_docstring(line_no: int, docstring_ranges: list[tuple[int, int]]) -> bool:
        """åˆ¤æ–­å½“å‰è¡Œæ˜¯å¦å¤„äº docstring è¦†ç›–èŒƒå›´å†…ã€‚"""

        return any(s <= line_no <= e for (s, e) in docstring_ranges)

    def _handle_argparse_multiline(
        self,
        *,
        stripped_line: str,
        line: str,
        in_argparse_block: bool,
        argparse_depth: int,
    ) -> tuple[bool, bool, int]:
        """å¤„ç† argparse å¤šè¡Œå—çš„è¿›å…¥ä¸é€€å‡ºé€»è¾‘ã€‚"""

        if in_argparse_block:
            argparse_depth += stripped_line.count("(") - stripped_line.count(")")
            if argparse_depth <= 0:
                in_argparse_block = False
            return True, in_argparse_block, argparse_depth

        if self._is_argparse_start(line):
            in_argparse_block = True
            argparse_depth = stripped_line.count("(") - stripped_line.count(")")
            return True, in_argparse_block, argparse_depth

        return False, in_argparse_block, argparse_depth

    def _is_const_container_start(self, line: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå…¼å®¹æ€§å¸¸é‡å®¹å™¨èµ‹å€¼å—èµ·å§‹è¡Œï¼ˆHC001 å…¼å®¹æ–‡ä»¶ä¸“ç”¨ï¼‰ã€‚"""

        return ("self.violation_types" in line and "PromptViolationType(" in line) or (
            "self.severity_levels" in line and "PromptSeverityLevel(" in line
        )

    def _handle_compat_const_block(  # noqa: PLR0913
        self,
        *,
        stripped_line: str,
        line: str,
        line_num: int,
        gen_range: tuple[int, int] | None,
        is_compat_file: bool,
        in_const_block: bool,
        paren_depth: int,
    ) -> tuple[bool, bool, int]:
        """å¤„ç†å…¼å®¹æ€§å¸¸é‡å®¹å™¨èµ‹å€¼å—ä¸æŠ¥è¡¨é”®åè±å…é€»è¾‘ã€‚"""

        if not is_compat_file:
            return False, in_const_block, paren_depth

        if not in_const_block and self._is_const_container_start(stripped_line):
            in_const_block = True
            paren_depth = stripped_line.count("(") - stripped_line.count(")")
            return True, in_const_block, paren_depth

        if in_const_block:
            paren_depth += stripped_line.count("(") - stripped_line.count(")")
            if paren_depth <= 0:
                in_const_block = False
            return True, in_const_block, paren_depth

        if self._is_report_key_line(gen_range, line_num, line):
            return True, in_const_block, paren_depth

        return False, in_const_block, paren_depth

    def _should_skip_by_simple_line_rules(
        self,
        *,
        file_path: Path,
        line: str,
        stripped_line: str,
        exempt_strings: list[str],
    ) -> bool:
        """æ‰§è¡Œä¸€ç»„ç®€å•çš„é€è¡Œè±å…è§„åˆ™ã€‚"""

        checks = (
            self._is_line_exempt_by_strings(line, exempt_strings),
            self._is_argparse_declaration(line, stripped_line),
            self._is_typealias_forward_ref(stripped_line, line),
            self._is_prompt_report_legal_line(file_path, line),
            self._is_final_literal_token(stripped_line),
            self._is_hasattr_exempt(line),
            self._is_typevar_name_exempt(line),
            self._is_all_export_list(stripped_line),
        )
        return any(checks)

    def _is_report_key_line(
        self, gen_range: tuple[int, int] | None, line_num: int, line: str
    ) -> bool:
        """æ˜¯å¦ä¸ºæŠ¥è¡¨ç”Ÿæˆå‡½æ•°ä¸­çš„ schema keyï¼ˆHC001 è±å…ï¼‰ã€‚"""

        return bool(
            gen_range
            and gen_range[0] <= line_num <= gen_range[1]
            and re.search(r'^\s*["\']\w+["\']\s*:', line)
        )

    @staticmethod
    def _is_line_exempt_by_strings(line: str, exempt_strings: list[str]) -> bool:
        """æ˜¯å¦å‘½ä¸­ HC001.exemptions.strings ä¸­çš„ä»»æ„è±å…ç‰‡æ®µã€‚"""

        return any(exempt_str in line for exempt_str in exempt_strings)

    @staticmethod
    def _is_argparse_declaration(line: str, stripped_line: str) -> bool:
        """æ˜¯å¦ä¸º argparse ä¸€è¡Œå¼å‚æ•°/å­å‘½ä»¤å®šä¹‰ï¼ˆHC001 å…¨å±€è±å…ï¼‰ã€‚"""

        del stripped_line
        return (
            "parser.add_argument(" in line
            or ".add_subparsers(" in line
            or ".add_parser(" in line
        )

    @staticmethod
    def _is_typealias_forward_ref(stripped_line: str, line: str) -> bool:
        """æ˜¯å¦ä¸ºç±»å‹åˆ«åä¸­çš„å‰å‘å¼•ç”¨å­—ç¬¦ä¸²ï¼ˆTypeAlias / type X = list["Y"])ã€‚"""

        return (
            ("TypeAlias" in line or stripped_line.startswith("type "))
            and ("dict[" in line or "list[" in line)
            and ('"' in line or "'" in line)
        )

    def _is_prompt_report_legal_line(self, file_path: Path, line: str) -> bool:
        """check_prompt/æŠ¥å‘Šç”Ÿæˆç›¸å…³çš„åˆæ³•å­—ç¬¦ä¸²ä½¿ç”¨ã€‚

        ç›¸å…³é…ç½®æ¥è‡ª strings.report_generator_filesï¼š

        .. code-block:: yaml

           laws:
             hc001:
               payload:
                 strings:
                   report_generator_files: ["path/pattern/**", ...]
        """

        patterns = self._str_cfg.report_generator_files
        if not patterns:
            return False

        prompt_files = normalize_patterns(patterns)
        fp_str = str(file_path)
        if not any(
            fnmatch.fnmatch(fp_str, p) or fp_str.endswith(p) for p in prompt_files
        ):
            return False

        checks = (
            "violation_type=" in line,
            "legal_clause=" in line,
            "severity=" in line,
            "v.severity" in line and "==" in line,
            'rglob("*.json")' in line,
            " in line" in line,
            " in str(file_path)" in line,
            "file_path=" in line,
            "coverage_config[" in line,
            "scoring_rules[" in line,
        )
        return any(checks)

    @staticmethod
    def _is_final_literal_token(stripped_line: str) -> bool:
        """ä¸¥æ ¼ç±»å‹çš„åè®®ä»¤ç‰Œå¸¸é‡ï¼ˆFinal[Literal[...]]ï¼‰è±å…ã€‚"""

        return bool(
            re.search(
                r"^\s*\w+\s*:\s*Final\s*\[\s*Literal\[[^\]]+\]\s*\]\s*=",
                stripped_line,
            )
        )

    @staticmethod
    def _is_hasattr_exempt(line: str) -> bool:
        """hasattr(obj, "attr") çš„ç¬¬äºŒä¸ªå‚æ•°è±å…ã€‚"""

        return bool(
            "hasattr(" in line
            and re.search(r"hasattr\([^,]+,\s*['\"][^'\"]+['\"]\)", line)
        )

    @staticmethod
    def _is_typevar_name_exempt(line: str) -> bool:
        """TypeVar("Name") çš„åç§°å­—ç¬¦ä¸²è±å…ã€‚"""

        return bool(
            "TypeVar(" in line and re.search(r"TypeVar\(\s*['\"][^'\"]+['\"]", line)
        )

    @staticmethod
    def _is_all_export_list(stripped_line: str) -> bool:
        """__all__ å¯¼å‡ºåˆ—è¡¨/å…ƒç»„ä¸­çš„å­—ç¬¦ä¸²æ•´ä½“è±å…ã€‚"""

        return bool(
            re.match(
                r"^\s*__all__\s*=\s*(\[[^\]]*\]|\([^\)]*\))\s*$",
                stripped_line,
            )
        )

    # ---- å­—ç¬¦ä¸²çº§è±å…ï¼ˆä¸æ—§ç‰ˆ _should_exempt_string ç­‰ä»·ï¼‰----

    def _should_exempt_string(self, line: str, string_literal: str) -> bool:
        """åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦åº”è¯¥è±å…ç¡¬ç¼–ç æ£€æŸ¥ã€‚

        å‡å°‘è¯¯æŠ¥ï¼Œåªæ ‡è®°çœŸæ­£çš„é…ç½®å€¼ç¡¬ç¼–ç ï¼Œè€Œä¸æ˜¯åˆç†çš„å­—ç¬¦ä¸²ä½¿ç”¨ã€‚
        """

        checks = (
            self._is_attr_method_access(line),
            self._is_logger_message(line),
            self._is_exception_message(line),
            self._is_short_or_empty_literal(string_literal),
            self._is_triple_quoted(line),
            self._is_literal_annotation(line),
            self._is_fstring(line),
            self._is_decorator_param(line),
            self._is_dict_key_access(line),
            self._is_class_attr_constant(line),
        )
        return any(checks)

    @staticmethod
    def _is_attr_method_access(line: str) -> bool:
        """æ–¹æ³•å/å±æ€§åè®¿é—®ï¼ˆgetattr, hasattr, setattr, delattrï¼‰ã€‚"""

        return bool(
            re.search(r"(getattr|hasattr|setattr|delattr)\s*\([^,]+,\s*['\"]", line)
        )

    @staticmethod
    def _is_logger_message(line: str) -> bool:
        """æ—¥å¿—æ¶ˆæ¯ï¼ˆlogger.info / logger.debug / logging.*ï¼‰ã€‚"""

        return bool(re.search(r"(logger\.|log\.|logging\.)", line))

    @staticmethod
    def _is_exception_message(line: str) -> bool:
        """å¼‚å¸¸æ¶ˆæ¯ï¼ˆraise SomeError("msg")ï¼‰ã€‚"""

        return bool(re.search(r"raise\s+\w+\(", line))

    @staticmethod
    def _is_short_or_empty_literal(string_literal: str) -> bool:
        """å•å­—ç¬¦æˆ–ç©ºå­—ç¬¦ä¸²ï¼ˆé€šå¸¸æ˜¯åˆ†éš”ç¬¦ç­‰ï¼‰ã€‚"""

        return len(string_literal) <= 1

    @staticmethod
    def _is_triple_quoted(line: str) -> bool:
        """æ–‡æ¡£å­—ç¬¦ä¸²æ ‡è®°ï¼ˆä¸‰å¼•å·ï¼‰ã€‚"""

        return '"""' in line or "'''" in line

    @staticmethod
    def _is_literal_annotation(line: str) -> bool:
        """ç±»å‹æ³¨è§£ä¸­çš„ Literal å­—ç¬¦ä¸²ã€‚"""

        return "Literal[" in line

    @staticmethod
    def _is_fstring(line: str) -> bool:
        """f-string æ ¼å¼åŒ–ï¼ˆé€šå¸¸æ˜¯æ—¥å¿—æˆ–æ¶ˆæ¯ï¼‰ã€‚"""

        stripped = line.strip()
        return stripped.startswith('f"') or stripped.startswith("f'")

    @staticmethod
    def _is_decorator_param(line: str) -> bool:
        """è£…é¥°å™¨å‚æ•°ï¼ˆ@decorator(param="value")ï¼‰ã€‚"""

        stripped = line.strip()
        return stripped.startswith("@") and "=" in line

    @staticmethod
    def _is_dict_key_access(line: str) -> bool:
        """å­—å…¸é”®è®¿é—®ï¼ˆobj["key"]ï¼‰ã€‚"""

        return bool(re.search(r"\w+\[['\"]", line))

    @staticmethod
    def _is_class_attr_constant(line: str) -> bool:
        """ç±»å±æ€§å®šä¹‰ï¼ˆCLASS_ATTR: type = "value"ï¼‰- åè®®å¸¸é‡ã€‚"""

        return bool(re.match(r"^\s+[A-Z][A-Z0-9_]*\s*:\s*\w+\s*=", line))
