# RAG Memory Test Configuration
#
# Used by automated tests (pytest)
# Safe to commit - no real secrets, uses test database containers
#
# Database URLs point to test Docker Compose services
# Mounts point to test-data/ for test document ingestion

server:
  # Test database (port 54323 from docker-compose.test.yml)
  database_url: postgresql://raguser:ragpassword@localhost:54323/rag_memory_test

  # Test Neo4j (port 7689 from docker-compose.test.yml)
  neo4j_uri: bolt://localhost:7689
  neo4j_http_port: 7476
  neo4j_user: neo4j
  neo4j_password: test-password

  # OPENAI_API_KEY comes from .env (loaded by conftest.py)

  # Graphiti LLM Models (optional - uses Graphiti defaults if not specified)
  # graphiti_model: gpt-5-mini          # Main extraction model (default: gpt-5-mini)
  # graphiti_small_model: gpt-5-nano    # Small task model (default: gpt-5-nano)

  # Test with reflexion disabled for speed
  # NOTE: Only affects ingestion, not search
  max_reflexion_iterations: 0

  # Knowledge Graph search strategy (default: mmr)
  search_strategy: mmr

mounts:
  # Test documents for automated file/directory ingestion tests
  # Using relative path - will resolve relative to project root where MCP server runs
  - path: /Users/timkitchens/projects/ai-projects/rag-memory
    read_only: true
