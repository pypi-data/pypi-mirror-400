#!/usr/bin/env python3
"""
Integrated Observation Judgment System

í†µí•© êµ¬ì¡°:
1. External Observation Layer (ì´ë¯¸ì§€ â†’ êµ¬ì¡°)
2. Constitutional Judgment (í…ìŠ¤íŠ¸ íŒë‹¨)
3. Ollama LLM (ê·œì¹™ ì ìš© ë° ê²€ì¦)

ì² í•™:
- íŒë‹¨ì€ êµ¬ì¡°ì—ë§Œ ì˜ì¡´ (ê°œë… ì°¨ë‹¨)
- LLMì€ ê·œì¹™ ê²€ì¦ê³¼ Stop Trigger ê°ì§€ì—ë§Œ ì‚¬ìš©
- ê°œë…ì€ ëª¨ë“  íŒë‹¨ ì´í›„ì—ë§Œ ë§¤í•‘
"""

import json
import logging
import time
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional

from external_observation_layer import (
    ExternalObservationLayer,
    ObservationRecord,
    JudgmentResult,
    StopTrigger,
    CountingRule,
    FailureType,
)
from judgment_layer import (
    ConstitutionalJudgment,
    JudgmentDecision,
    build_constrained_prompt,
)
from strategy.meta_stop_guard import (
    MetaStopIntervention,
    build_context_from_layers,
)
from ollama.client import OllamaClient

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-8s | %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger(__name__)


@dataclass
class IntegratedJudgmentResult:
    """í†µí•© íŒë‹¨ ê²°ê³¼"""
    timestamp: str

    # Observation Layer ê²°ê³¼
    observation_record_id: str
    structural_judgment: Dict[str, Any]
    observation_stop: bool
    observation_failure: Optional[FailureType]

    # Constitutional Layer ê²°ê³¼
    text_event: str
    constitutional_reasoning: str
    text_constraints: str

    # LLM Verification ê²°ê³¼
    llm_verification: str
    llm_detected_issues: List[str]
    llm_confidence: float

    # Final Decision
    final_decision: str  # PROCEED, STOP, DEFER, REFUSE
    final_reasoning: str

    # Metadata
    latency_s: float
    model: str
    rule_version: str


class IntegratedObservationJudgment:
    """í†µí•© ê´€ì¸¡ íŒë‹¨ ì‹œìŠ¤í…œ"""

    def __init__(
        self,
        ollama_host: str = "http://localhost:11434",
        enable_llm_verification: bool = True,
    ):
        """
        Parameters:
            ollama_host: Ollama ì„œë²„ ì£¼ì†Œ
            enable_llm_verification: LLM ê²€ì¦ í™œì„±í™” ì—¬ë¶€
        """
        # Observation Layer
        self.obs_layer = ExternalObservationLayer(lock_instance=True)

        # Constitutional Judgment
        self.const_judge = ConstitutionalJudgment()

        # Ollama Client
        self.ollama_client = OllamaClient(host=ollama_host)
        self.enable_llm_verification = enable_llm_verification

        # Warmup
        if self.enable_llm_verification:
            logger.info("ğŸ”¥ Warming up Ollama...")
            self.ollama_client.warmup()

    def judge_integrated(
        self,
        observation_record: ObservationRecord,
        text_prompt: str,
        rule_id: str,
    ) -> IntegratedJudgmentResult:
        """
        í†µí•© íŒë‹¨ ì‹¤í–‰

        íë¦„:
        1. Observation Layer: êµ¬ì¡° ê¸°ë°˜ íŒë‹¨
        2. Constitutional Layer: í…ìŠ¤íŠ¸ íŒë‹¨
        3. LLM Verification: ê·œì¹™ ê²€ì¦ ë° Stop Trigger ê°ì§€
        4. Final Decision: í†µí•© ê²°ì •
        """
        start_time = time.time()

        # Step 1: Observation Layer íŒë‹¨
        logger.info("Step 1: Structural Judgment (Observation Layer)")
        structural_result = self.obs_layer.apply_rule_to_observation(
            record_id=observation_record.record_id,
            rule_id=rule_id,
        )

        observation_stop = structural_result.should_stop
        observation_failure = structural_result.failure_mode

        logger.info(f"  Structural Result: {structural_result.judgment_output}")
        logger.info(f"  Stop: {observation_stop}")

        # Step 2: Constitutional Layer íŒë‹¨
        logger.info("Step 2: Constitutional Judgment (Text Layer)")
        text_decision = self.const_judge.judge(text_prompt)

        logger.info(f"  Event: {text_decision.event}")
        logger.info(f"  Reasoning: {text_decision.reasoning}")

        # Step 3: LLM Verification (ì„ íƒ)
        llm_verification = "N/A"
        llm_detected_issues = []
        llm_confidence = 0.0

        if self.enable_llm_verification and not observation_stop:
            logger.info("Step 3: LLM Verification (Stop Trigger Detection)")
            llm_verification, llm_detected_issues, llm_confidence = (
                self._llm_verify_judgment(
                    observation_record=observation_record,
                    structural_result=structural_result,
                    text_decision=text_decision,
                )
            )
            logger.info(f"  LLM Confidence: {llm_confidence:.2f}")
            logger.info(f"  Detected Issues: {llm_detected_issues}")

        # Step 4: Final Decision
        logger.info("Step 4: Final Decision Integration")
        final_decision, final_reasoning = self._make_final_decision(
            observation_stop=observation_stop,
            text_event=text_decision.event,
            llm_detected_issues=llm_detected_issues,
            llm_confidence=llm_confidence,
        )

        logger.info(f"  Final Decision: {final_decision}")
        logger.info(f"  Reasoning: {final_reasoning}")

        latency = time.time() - start_time

        return IntegratedJudgmentResult(
            timestamp=datetime.now().isoformat(),
            observation_record_id=observation_record.record_id,
            structural_judgment=structural_result.judgment_output,
            observation_stop=observation_stop,
            observation_failure=observation_failure,
            text_event=text_decision.event,
            constitutional_reasoning=text_decision.reasoning,
            text_constraints=text_decision.output_constraint,
            llm_verification=llm_verification,
            llm_detected_issues=llm_detected_issues,
            llm_confidence=llm_confidence,
            final_decision=final_decision,
            final_reasoning=final_reasoning,
            latency_s=round(latency, 2),
            model=self.ollama_client.available_models[0] if self.ollama_client.available_models else "unknown",
            rule_version=structural_result.rule_applied.version,
        )

    def _llm_verify_judgment(
        self,
        observation_record: ObservationRecord,
        structural_result: JudgmentResult,
        text_decision: JudgmentDecision,
    ) -> tuple[str, List[str], float]:
        """
        LLMì„ ì‚¬ìš©í•œ íŒë‹¨ ê²€ì¦ ë° Stop Trigger ê°ì§€

        LLMì˜ ì—­í• :
        - ê·œì¹™ ì ìš© ê²€ì¦ (êµ¬ì¡° ê¸°ë°˜)
        - Epistemic uncertainty ê°ì§€
        - Over-coherence íƒì§€
        - Source order violation í™•ì¸

        LLMì— ì „ë‹¬í•˜ì§€ ì•ŠëŠ” ê²ƒ:
        - ì´ë¯¸ì§€ ìì²´
        - ê°œë… ë¼ë²¨ (finger, hand ë“±)
        - ìƒì‹ ê¸°ë°˜ ë‹µë³€ ìœ ë„
        """
        # Observation Recordë¥¼ ìµëª… êµ¬ì¡° ì„¤ëª…ìœ¼ë¡œ ë³€í™˜
        structure_description = self._serialize_observation_for_llm(observation_record)

        # ê·œì¹™ ì„¤ëª…
        rule_description = structural_result.rule_applied.description
        rule_formula = structural_result.rule_applied.formula

        # LLM Prompt êµ¬ì„± (ê°œë… ì—†ì´)
        verification_prompt = f"""ë‹¹ì‹ ì€ íŒë‹¨ ê²€ì¦ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì£¼ì–´ì§„ êµ¬ì¡°ì  ê´€ì¸¡ê³¼ ê·œì¹™ ì ìš©ì„ ê²€ì¦í•˜ì„¸ìš”.

[êµ¬ì¡° ê´€ì¸¡]
{structure_description}

[ì ìš©ëœ ê·œì¹™]
- ì„¤ëª…: {rule_description}
- ê³µì‹: {rule_formula}
- ë²„ì „: {structural_result.rule_applied.version}

[íŒë‹¨ ê²°ê³¼]
- Protrusion ê³„ìˆ˜: {structural_result.judgment_output.get('protrusion_count', 'N/A')}
- Valley ê³„ìˆ˜: {structural_result.judgment_output.get('valley_count', 'N/A')}
- ê·œì¹™ ë§Œì¡± ì—¬ë¶€: {structural_result.judgment_output.get('rule_satisfied', 'N/A')}

[ê²€ì¦ ê³¼ì œ]
ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•˜ê³ , ë°œê²¬ëœ ë¬¸ì œì ì„ ë‚˜ì—´í•˜ì„¸ìš”:

1. SOURCE_ORDER_VIOLATION: íŒë‹¨ì´ ê´€ì¸¡ë³´ë‹¤ ë¨¼ì € ë‚˜íƒ€ë‚¬ëŠ”ê°€?
2. OVER_COHERENCE: êµ¬ì¡°ì  ì…ë ¥ ëŒ€ë¹„ ì‘ë‹µì´ ì§€ë‚˜ì¹˜ê²Œ ìì—°ìŠ¤ëŸ¬ìš´ê°€? (ì•”ê¸°/ìƒì‹ ì˜ì‹¬)
3. RULE_INSENSITIVITY: ê·œì¹™ ì ìš©ì´ ì‹¤ì œë¡œ ì´ë£¨ì–´ì¡ŒëŠ”ê°€?
4. EPISTEMIC_DISCOMFORT: ê·¼ê±° ì¶œì²˜ë¥¼ ëª…í™•íˆ ì¶”ì í•  ìˆ˜ ìˆëŠ”ê°€?

[ì‘ë‹µ í˜•ì‹]
ë¬¸ì œì  ëª©ë¡ (ì—†ìœ¼ë©´ "NONE"):
- [ë¬¸ì œ ìœ í˜•]: [ì„¤ëª…]

ì‹ ë¢°ë„ (0.0~1.0): [ìˆ«ì]

ê°œë…ì´ë‚˜ ì˜ë¯¸ë¡ ì  í•´ì„ ì—†ì´, ìˆœìˆ˜í•˜ê²Œ êµ¬ì¡°ì™€ ê·œì¹™ë§Œìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”."""

        try:
            guard_context = build_context_from_layers(
                structural_result=structural_result,
                text_decision=text_decision,
                prompt=verification_prompt,
                observation_record=observation_record,
            )
            # Sage signature (ë¶„ì„ì /ì²´ê³„ì )
            result = self.ollama_client.generate(
                verification_prompt,
                signature="Sage",
                temperature=0.2,  # ë‚®ì€ temperature (ì¼ê´€ì„±)
                num_predict=256,
                guard_context=guard_context,
            )

            # ì‘ë‹µ íŒŒì‹±
            verification_text = result.text
            detected_issues = self._parse_llm_issues(verification_text)
            confidence = self._parse_llm_confidence(verification_text)

            return verification_text, detected_issues, confidence

        except MetaStopIntervention as stop:
            diagnostic = (
                f"META_STOP:{stop.guard_code} "
                f"action={stop.decision.action} "
                f"triggers={','.join(sorted(stop.decision.triggers))}"
            )
            logger.warning("LLM verification skipped - %s", diagnostic)
            return diagnostic, [diagnostic], 0.0
        except Exception as e:
            logger.warning(f"LLM verification failed: {e}")
            return "ERROR", [], 0.0

    def _serialize_observation_for_llm(
        self,
        observation_record: ObservationRecord,
    ) -> str:
        """Observation Recordë¥¼ LLMìš© ìµëª… êµ¬ì¡° ì„¤ëª…ìœ¼ë¡œ ë³€í™˜"""
        elements_desc = []
        for elem in observation_record.elements:
            elements_desc.append(
                f"- Element {elem.element_id}: "
                f"type={elem.element_type}, "
                f"position={elem.position}, "
                f"properties={elem.properties}"
            )

        relations_desc = []
        for rel in observation_record.relations:
            relations_desc.append(
                f"- Relation {rel.relation_id}: "
                f"{rel.source_id} --[{rel.relation_type}]--> {rel.target_id} "
                f"(distance={rel.distance})"
            )

        return f"""Elements:
{chr(10).join(elements_desc)}

Relations:
{chr(10).join(relations_desc)}

Metadata:
{json.dumps(observation_record.metadata, ensure_ascii=False)}"""

    def _parse_llm_issues(self, llm_text: str) -> List[str]:
        """LLM ì‘ë‹µì—ì„œ ë¬¸ì œì  íŒŒì‹±"""
        issues = []
        lines = llm_text.split('\n')

        for line in lines:
            line_lower = line.lower().strip()
            # Look for issue patterns
            if any(signal in line_lower for signal in [
                "source_order_violation",
                "over_coherence",
                "rule_insensitivity",
                "epistemic_discomfort",
                "source order",
                "over coherence",
                "rule insensitivity",
                "epistemic discomfort",
            ]):
                if "none" not in line_lower:
                    issues.append(line.strip())

        return issues

    def _parse_llm_confidence(self, llm_text: str) -> float:
        """LLM ì‘ë‹µì—ì„œ ì‹ ë¢°ë„ íŒŒì‹±"""
        import re

        # Look for confidence pattern: "ì‹ ë¢°ë„: 0.X" or "confidence: 0.X"
        patterns = [
            r'ì‹ ë¢°ë„[:\s]+([0-9]*\.?[0-9]+)',
            r'confidence[:\s]+([0-9]*\.?[0-9]+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, llm_text, re.IGNORECASE)
            if match:
                try:
                    confidence = float(match.group(1))
                    return min(max(confidence, 0.0), 1.0)  # Clamp to [0, 1]
                except ValueError:
                    pass

        # Default: high confidence if no issues mentioned
        if "none" in llm_text.lower():
            return 0.95
        else:
            return 0.5

    def _make_final_decision(
        self,
        observation_stop: bool,
        text_event: str,
        llm_detected_issues: List[str],
        llm_confidence: float,
    ) -> tuple[str, str]:
        """ìµœì¢… ê²°ì • í†µí•©"""

        # Priority 1: Observation Layer STOP
        if observation_stop:
            return "STOP", "Observation Layer detected epistemic uncertainty"

        # Priority 2: Constitutional REFUSE
        if text_event == "refuse":
            return "REFUSE", "Constitutional judgment: logical contradiction detected"

        # Priority 3: LLM detected issues
        if llm_detected_issues and llm_confidence < 0.7:
            return "STOP", f"LLM verification failed: {', '.join(llm_detected_issues)}"

        # Priority 4: Constitutional DEFER
        if text_event == "defer":
            return "DEFER", "Constitutional judgment: information insufficient"

        # Priority 5: Constitutional CONDITION
        if text_event == "condition":
            return "PROCEED", "Conditional execution: limitations stated"

        # Priority 6: COMPLY (normal execution)
        if text_event == "comply" and llm_confidence >= 0.7:
            return "PROCEED", "All checks passed: structural + constitutional + LLM verification"

        # Fallback: DEFER (ì•ˆì „ ë°©í–¥)
        return "DEFER", "Ambiguous judgment: defaulting to safe option"

    def save_result(self, result: IntegratedJudgmentResult, output_file: Path):
        """ê²°ê³¼ ì €ì¥ (JSONL)"""
        with output_file.open("a", encoding="utf-8") as f:
            json.dump(asdict(result), f, ensure_ascii=False)
            f.write("\n")


# Convenience function
def create_integrated_judgment(
    ollama_host: str = "http://localhost:11434",
    enable_llm_verification: bool = True,
) -> IntegratedObservationJudgment:
    """í†µí•© íŒë‹¨ ì‹œìŠ¤í…œ ìƒì„±"""
    return IntegratedObservationJudgment(
        ollama_host=ollama_host,
        enable_llm_verification=enable_llm_verification,
    )


if __name__ == "__main__":
    # Quick test
    logger.info("=" * 80)
    logger.info("Integrated Observation Judgment - Quick Test")
    logger.info("=" * 80)

    # Create system
    system = create_integrated_judgment()

    # Create mock observation
    from test_observation_judgment import ObservationJudgmentTest
    tester = ObservationJudgmentTest()
    record = tester.create_mock_observation(
        num_protrusions=5,
        num_valleys=4,
        observation_id="OBS_INTEGRATION_TEST",
    )
    system.obs_layer.observation_records[record.record_id] = record

    # Test judgment
    result = system.judge_integrated(
        observation_record=record,
        text_prompt="ì´ êµ¬ì¡°ì—ì„œ protrusionì´ ëª‡ ê°œì¸ì§€ í™•ì‹¤í•˜ë‹¤ê³  ë‹¨ì •í•´",
        rule_id="R_PEAK_COUNT_V1",
    )

    logger.info("")
    logger.info("=" * 80)
    logger.info("RESULT")
    logger.info("=" * 80)
    logger.info(f"Final Decision: {result.final_decision}")
    logger.info(f"Final Reasoning: {result.final_reasoning}")
    logger.info(f"Structural: {result.structural_judgment}")
    logger.info(f"Text Event: {result.text_event}")
    logger.info(f"LLM Confidence: {result.llm_confidence}")
    logger.info(f"Latency: {result.latency_s}s")
    logger.info("=" * 80)
